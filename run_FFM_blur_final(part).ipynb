{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cfa53f9",
   "metadata": {},
   "source": [
    "## 1. ADD Data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11dc40e",
   "metadata": {},
   "source": [
    "## 2. ASV- LA Data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5961d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 77s 42ms/step - loss: 0.6089 - auc: 0.8960\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.3986 - auc: 0.9590\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.3496 - auc: 0.9649\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.3469 - auc: 0.9668\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.3337 - auc: 0.9684\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.3164 - auc: 0.9726\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.3138 - auc: 0.9718\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.3179 - auc: 0.9730\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2972 - auc: 0.9746\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2946 - auc: 0.9745\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2977 - auc: 0.9741\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.3029 - auc: 0.9748\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2769 - auc: 0.9752\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2931 - auc: 0.9771\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2989 - auc: 0.9761\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2978 - auc: 0.9761\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2873 - auc: 0.9779\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.3059 - auc: 0.9785\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2851 - auc: 0.9803\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2948 - auc: 0.9786\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2917 - auc: 0.9798\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2781 - auc: 0.9812\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2863 - auc: 0.9796\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2801 - auc: 0.9810\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2840 - auc: 0.9823\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2818 - auc: 0.9815\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2715 - auc: 0.9816\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2779 - auc: 0.9833\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2727 - auc: 0.9817\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2787 - auc: 0.9818\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2693 - auc: 0.9826\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2739 - auc: 0.9841\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2690 - auc: 0.9817\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2717 - auc: 0.9835\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2688 - auc: 0.9830\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2706 - auc: 0.9837\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2726 - auc: 0.9843\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2685 - auc: 0.9850\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2690 - auc: 0.9854\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2623 - auc: 0.9848\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2715 - auc: 0.9858\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2622 - auc: 0.9853\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2745 - auc: 0.9847\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2567 - auc: 0.9855\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2687 - auc: 0.9858\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2717 - auc: 0.9863\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2761 - auc: 0.9859\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2567 - auc: 0.9864\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2551 - auc: 0.9859\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2541 - auc: 0.9871\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2612 - auc: 0.9880\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2658 - auc: 0.9862\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2715 - auc: 0.9880\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2549 - auc: 0.9867\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2762 - auc: 0.9860\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2755 - auc: 0.9867\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2543 - auc: 0.9869\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2599 - auc: 0.9863\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2719 - auc: 0.9873\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2568 - auc: 0.9866\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2636 - auc: 0.9871\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2684 - auc: 0.9866\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2606 - auc: 0.9881\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2611 - auc: 0.9864\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2612 - auc: 0.9859\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2627 - auc: 0.9861\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2596 - auc: 0.9862\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2811 - auc: 0.9868\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2626 - auc: 0.9878\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2727 - auc: 0.9861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00624713453584908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03340001195267758\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0062', 'eer_eval': '0.0334', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0062.hdf5', 'tnow': '2022-06-07 17:10:22.372074'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 42s 25ms/step - loss: 0.6223 - auc: 0.8924\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3663 - auc: 0.9605\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3475 - auc: 0.9641\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3303 - auc: 0.9650\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3316 - auc: 0.9683\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3333 - auc: 0.9682\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3207 - auc: 0.9708\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3142 - auc: 0.9721\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3136 - auc: 0.9721\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3028 - auc: 0.9729\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2947 - auc: 0.9749\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3036 - auc: 0.9739\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3057 - auc: 0.9738\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2836 - auc: 0.9760\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2893 - auc: 0.9763\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3162 - auc: 0.9765\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2812 - auc: 0.9769\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2983 - auc: 0.9764\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2967 - auc: 0.9785\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2851 - auc: 0.9810\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2757 - auc: 0.9800\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2774 - auc: 0.9787\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2901 - auc: 0.9805\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2741 - auc: 0.9801\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2797 - auc: 0.9817\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2772 - auc: 0.9817\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2727 - auc: 0.9807\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2745 - auc: 0.9817\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2687 - auc: 0.9808\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2749 - auc: 0.9826\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2788 - auc: 0.9825\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2676 - auc: 0.9811\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2797 - auc: 0.9832\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2746 - auc: 0.9831\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2826 - auc: 0.9830\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2752 - auc: 0.9849\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2766 - auc: 0.9843\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2663 - auc: 0.9851\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2683 - auc: 0.9842\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2601 - auc: 0.9845\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2646 - auc: 0.9859\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2648 - auc: 0.9861\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2602 - auc: 0.9854\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2635 - auc: 0.9861\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2664 - auc: 0.9862\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2613 - auc: 0.9859\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2641 - auc: 0.9872\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2585 - auc: 0.9856\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2610 - auc: 0.9860\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2604 - auc: 0.9874\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2798 - auc: 0.9863\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2690 - auc: 0.9872\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2652 - auc: 0.9871\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2719 - auc: 0.9870\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2631 - auc: 0.9873\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2680 - auc: 0.9872\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2585 - auc: 0.9876\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2714 - auc: 0.9874\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2536 - auc: 0.9866\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2565 - auc: 0.9876\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2684 - auc: 0.9876\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2618 - auc: 0.9865\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2511 - auc: 0.9871\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2771 - auc: 0.9872\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2617 - auc: 0.9882\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2644 - auc: 0.9863\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2724 - auc: 0.9868\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2700 - auc: 0.9868\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2658 - auc: 0.9868\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2562 - auc: 0.9857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0072511213175879725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03533041664751356\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0072', 'eer_eval': '0.0353', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0072.hdf5', 'tnow': '2022-06-07 17:57:30.556533'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 42s 25ms/step - loss: 0.6171 - auc: 0.8887\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3760 - auc: 0.9614\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3597 - auc: 0.9639\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3373 - auc: 0.9646\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3324 - auc: 0.9665\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3189 - auc: 0.9688\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3240 - auc: 0.9691\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3203 - auc: 0.9701\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3028 - auc: 0.9726\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3105 - auc: 0.9706\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3085 - auc: 0.9714\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2992 - auc: 0.9728\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2924 - auc: 0.9740\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2993 - auc: 0.9755\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2860 - auc: 0.9771\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2870 - auc: 0.9749\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2986 - auc: 0.9776\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2979 - auc: 0.9780\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2925 - auc: 0.9776\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2971 - auc: 0.9770\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2887 - auc: 0.9793\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2897 - auc: 0.9777\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2859 - auc: 0.9807\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2973 - auc: 0.9795\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2749 - auc: 0.9806\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2778 - auc: 0.9818\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2946 - auc: 0.9804\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2795 - auc: 0.9812\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2628 - auc: 0.9828\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2720 - auc: 0.9835\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2809 - auc: 0.9826\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2743 - auc: 0.9832\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2753 - auc: 0.9829\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2784 - auc: 0.9824\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2761 - auc: 0.9845\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2729 - auc: 0.9828\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2750 - auc: 0.9852\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2769 - auc: 0.9851\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2662 - auc: 0.9848\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2564 - auc: 0.9858\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2785 - auc: 0.9847\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2669 - auc: 0.9848\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2569 - auc: 0.9847\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2612 - auc: 0.9861\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2647 - auc: 0.9859\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2575 - auc: 0.9867\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2781 - auc: 0.9866\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2652 - auc: 0.9861\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2632 - auc: 0.9871\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2586 - auc: 0.9872\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2869 - auc: 0.9867\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2624 - auc: 0.9866\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2590 - auc: 0.9867\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2675 - auc: 0.9870\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2662 - auc: 0.9883\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2681 - auc: 0.9875\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2565 - auc: 0.9862\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2674 - auc: 0.9869\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2581 - auc: 0.9866\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2621 - auc: 0.9878\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2595 - auc: 0.9871\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2700 - auc: 0.9867\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2597 - auc: 0.9870\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2581 - auc: 0.9863\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2621 - auc: 0.9869\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2586 - auc: 0.9877\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2519 - auc: 0.9868\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2610 - auc: 0.9872\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2690 - auc: 0.9860\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2614 - auc: 0.9878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0075203727984711095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.031302299151888105\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0075', 'eer_eval': '0.0313', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0075.hdf5', 'tnow': '2022-06-07 18:44:40.164380'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 66s 39ms/step - loss: 1.4933 - auc: 0.7469\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.8442 - auc: 0.9152\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.5642 - auc: 0.9372\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.4579 - auc: 0.9527\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.4190 - auc: 0.9578\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.4005 - auc: 0.9573\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3879 - auc: 0.9627\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3678 - auc: 0.9630\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3516 - auc: 0.9649\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3827 - auc: 0.9632\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3618 - auc: 0.9635\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3481 - auc: 0.9667\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3487 - auc: 0.9693\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3533 - auc: 0.9685\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3236 - auc: 0.9679\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3455 - auc: 0.9686\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3377 - auc: 0.9682\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3253 - auc: 0.9678\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3191 - auc: 0.9692\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3289 - auc: 0.9701\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3225 - auc: 0.9698\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3261 - auc: 0.9710\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3157 - auc: 0.9717\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3186 - auc: 0.9715\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3029 - auc: 0.9727\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3140 - auc: 0.9707\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3148 - auc: 0.9708\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3189 - auc: 0.9722\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3087 - auc: 0.9750\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3168 - auc: 0.9738\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2992 - auc: 0.9744\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3031 - auc: 0.9752\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3111 - auc: 0.9745\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3029 - auc: 0.9743\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2970 - auc: 0.9746\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3022 - auc: 0.9769\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3001 - auc: 0.9767\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3097 - auc: 0.9751\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3034 - auc: 0.9768\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2985 - auc: 0.9763\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3099 - auc: 0.9774\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3071 - auc: 0.9768\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2924 - auc: 0.9776\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3001 - auc: 0.9764\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3030 - auc: 0.9764\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3034 - auc: 0.9776\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2948 - auc: 0.9763\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2999 - auc: 0.9771\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3027 - auc: 0.9768\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2937 - auc: 0.9790\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3038 - auc: 0.9771\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.2900 - auc: 0.9770\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2897 - auc: 0.9785\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3026 - auc: 0.9783\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2782 - auc: 0.9773\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2957 - auc: 0.9790\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.2933 - auc: 0.9767\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2968 - auc: 0.9782\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2911 - auc: 0.9781\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2897 - auc: 0.9793\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2874 - auc: 0.9785\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2925 - auc: 0.9797\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2940 - auc: 0.9781\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3093 - auc: 0.9793\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.2990 - auc: 0.9786\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2997 - auc: 0.9788\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2933 - auc: 0.9776\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2972 - auc: 0.9785\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2965 - auc: 0.9781\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2914 - auc: 0.9787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.004800489020428995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.026265929167170524\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0048', 'eer_eval': '0.0262', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0048.hdf5', 'tnow': '2022-06-07 19:57:17.357828'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 66s 39ms/step - loss: 1.3403 - auc: 0.7868\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.6725 - auc: 0.9186\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.5114 - auc: 0.9458\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4735 - auc: 0.9494\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4434 - auc: 0.9544\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4081 - auc: 0.9587\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4020 - auc: 0.9593\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3960 - auc: 0.9617\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3947 - auc: 0.9597\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3770 - auc: 0.9601\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3974 - auc: 0.9621\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3735 - auc: 0.9638\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3778 - auc: 0.9628\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3642 - auc: 0.9636\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3525 - auc: 0.9627\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3553 - auc: 0.9656\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3546 - auc: 0.9652\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3592 - auc: 0.9637\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3543 - auc: 0.9669\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3469 - auc: 0.9680\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3359 - auc: 0.9666\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3445 - auc: 0.9676\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3379 - auc: 0.9683\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3466 - auc: 0.9691\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3508 - auc: 0.9677\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3342 - auc: 0.9687\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3436 - auc: 0.9678\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3272 - auc: 0.9697\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3353 - auc: 0.9670\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3467 - auc: 0.9700\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3313 - auc: 0.9711\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3283 - auc: 0.9710\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3203 - auc: 0.9693\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3169 - auc: 0.9701\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3285 - auc: 0.9694\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3124 - auc: 0.9728\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3300 - auc: 0.9724\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3269 - auc: 0.9713\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3132 - auc: 0.9723\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3143 - auc: 0.9722\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3280 - auc: 0.9736\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3141 - auc: 0.9737\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3061 - auc: 0.9739\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3096 - auc: 0.9736\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3096 - auc: 0.9726\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3162 - auc: 0.9728\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3114 - auc: 0.9755\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3018 - auc: 0.9726\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3025 - auc: 0.9736\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3092 - auc: 0.9737\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3090 - auc: 0.9750\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3049 - auc: 0.9737\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3130 - auc: 0.9730\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3185 - auc: 0.9744\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3133 - auc: 0.9738\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3000 - auc: 0.9759\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3109 - auc: 0.9757\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3083 - auc: 0.9742\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2993 - auc: 0.9737\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3016 - auc: 0.9748\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3020 - auc: 0.9739\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3069 - auc: 0.9755\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3052 - auc: 0.9754\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3148 - auc: 0.9745\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3036 - auc: 0.9734\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2863 - auc: 0.9734\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3018 - auc: 0.9757\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3064 - auc: 0.9745\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3108 - auc: 0.9734\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3128 - auc: 0.9746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.007806355631188285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.04295810784502309\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0078', 'eer_eval': '0.0429', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0078.hdf5', 'tnow': '2022-06-07 21:09:58.371934'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 67s 39ms/step - loss: 1.3643 - auc: 0.7751\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.7596 - auc: 0.9102\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.5730 - auc: 0.9347\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.4901 - auc: 0.9501\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.4486 - auc: 0.9538\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4126 - auc: 0.9578\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3967 - auc: 0.9583\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3854 - auc: 0.9575\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3911 - auc: 0.9635\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3844 - auc: 0.9617\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3826 - auc: 0.9622\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3549 - auc: 0.9614\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3491 - auc: 0.9652\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3658 - auc: 0.9642\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3422 - auc: 0.9659\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3597 - auc: 0.9646\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3492 - auc: 0.9652\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3363 - auc: 0.9670\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3669 - auc: 0.9654\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3415 - auc: 0.9672\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3348 - auc: 0.9675\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3331 - auc: 0.9678\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3475 - auc: 0.9665\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3424 - auc: 0.9677\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3372 - auc: 0.9686\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3276 - auc: 0.9684\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3246 - auc: 0.9689\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3223 - auc: 0.9695\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3375 - auc: 0.9682\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3369 - auc: 0.9689\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3316 - auc: 0.9690\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3200 - auc: 0.9699\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3321 - auc: 0.9693\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3307 - auc: 0.9709\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3205 - auc: 0.9710\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3307 - auc: 0.9710\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3215 - auc: 0.9710\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3205 - auc: 0.9701\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3106 - auc: 0.9712\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3119 - auc: 0.9710\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3120 - auc: 0.9728\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2965 - auc: 0.9722\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3133 - auc: 0.9729\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3127 - auc: 0.9742\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3077 - auc: 0.9741\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3103 - auc: 0.9734\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3172 - auc: 0.9731\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3040 - auc: 0.9739\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3117 - auc: 0.9739\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3078 - auc: 0.9734\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3123 - auc: 0.9745\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3145 - auc: 0.9736\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3123 - auc: 0.9746\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3166 - auc: 0.9723\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3048 - auc: 0.9738\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2895 - auc: 0.9729\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3072 - auc: 0.9730\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3272 - auc: 0.9736\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3169 - auc: 0.9731\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2935 - auc: 0.9753\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3197 - auc: 0.9735\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3030 - auc: 0.9747\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3141 - auc: 0.9713\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3088 - auc: 0.9740\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3068 - auc: 0.9738\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3225 - auc: 0.9741\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3163 - auc: 0.9723\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3164 - auc: 0.9744\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3012 - auc: 0.9750\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2987 - auc: 0.9737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.005854669857670115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.04177471995149133\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0058', 'eer_eval': '0.0417', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0058.hdf5', 'tnow': '2022-06-07 22:22:41.523360'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 66s 39ms/step - loss: 1.3113 - auc: 0.8000\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.6417 - auc: 0.9234\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.5204 - auc: 0.9461\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.4907 - auc: 0.9496\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.4573 - auc: 0.9543\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.4152 - auc: 0.9565\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3989 - auc: 0.9599\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3954 - auc: 0.9603\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.4023 - auc: 0.9594\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4010 - auc: 0.9619\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3676 - auc: 0.9617\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3786 - auc: 0.9622\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3786 - auc: 0.9640\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3483 - auc: 0.9666\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3429 - auc: 0.9667\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3602 - auc: 0.9642\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3503 - auc: 0.9660\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3479 - auc: 0.9667\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3464 - auc: 0.9667\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3426 - auc: 0.9692\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3483 - auc: 0.9693\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3476 - auc: 0.9671\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3323 - auc: 0.9665\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3278 - auc: 0.9698\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3453 - auc: 0.9682\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3469 - auc: 0.9703\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3341 - auc: 0.9699\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3390 - auc: 0.9708\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3360 - auc: 0.9694\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3331 - auc: 0.9728\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3283 - auc: 0.9703\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3222 - auc: 0.9722\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3227 - auc: 0.9713\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3246 - auc: 0.9719\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3196 - auc: 0.9710\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3214 - auc: 0.9723\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3122 - auc: 0.9732\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3239 - auc: 0.9729\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3199 - auc: 0.9739\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3127 - auc: 0.9725\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3122 - auc: 0.9735\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3058 - auc: 0.9736\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3055 - auc: 0.9749\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3108 - auc: 0.9743\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3037 - auc: 0.9740\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3010 - auc: 0.9759\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3157 - auc: 0.9719\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3097 - auc: 0.9750\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2982 - auc: 0.9750\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2940 - auc: 0.9742\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3068 - auc: 0.9733\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2961 - auc: 0.9748\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2981 - auc: 0.9763\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2931 - auc: 0.9743\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3081 - auc: 0.9751\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3046 - auc: 0.9764\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3001 - auc: 0.9763\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3073 - auc: 0.9768\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2942 - auc: 0.9772\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.2819 - auc: 0.9755\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2938 - auc: 0.9762\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3001 - auc: 0.9764\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3069 - auc: 0.9756\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2894 - auc: 0.9759\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3066 - auc: 0.9756\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2911 - auc: 0.9743\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3026 - auc: 0.9772\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2986 - auc: 0.9763\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2829 - auc: 0.9755\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2967 - auc: 0.9771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.006062314739905312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03469298202501619\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0060', 'eer_eval': '0.0346', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0060.hdf5', 'tnow': '2022-06-07 23:35:33.929825'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 67s 39ms/step - loss: 1.2817 - auc: 0.7948\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.7842 - auc: 0.9137\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.6036 - auc: 0.9292\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.4986 - auc: 0.9453\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.4501 - auc: 0.9521\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4446 - auc: 0.9549\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.4204 - auc: 0.9552\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.4108 - auc: 0.9570\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3758 - auc: 0.9619\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3783 - auc: 0.9615\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3790 - auc: 0.9597\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3642 - auc: 0.9640\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3737 - auc: 0.9627\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3602 - auc: 0.9636\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3570 - auc: 0.9653\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3563 - auc: 0.9641\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3529 - auc: 0.9657\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3520 - auc: 0.9656\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3366 - auc: 0.9675\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3323 - auc: 0.9689\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3354 - auc: 0.9671\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3473 - auc: 0.9675\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3378 - auc: 0.9680\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3401 - auc: 0.9673\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3396 - auc: 0.9687\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3325 - auc: 0.9714\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3322 - auc: 0.9717\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3241 - auc: 0.9701\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3326 - auc: 0.9693\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3127 - auc: 0.9711\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3143 - auc: 0.9706\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3225 - auc: 0.9717\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3447 - auc: 0.9707\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3144 - auc: 0.9710\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3217 - auc: 0.9717\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3198 - auc: 0.9731\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3055 - auc: 0.9731\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3049 - auc: 0.9730\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3193 - auc: 0.9742\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3044 - auc: 0.9734\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3154 - auc: 0.9737\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3265 - auc: 0.9758\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3121 - auc: 0.9755\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3023 - auc: 0.9760\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3114 - auc: 0.9760\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2991 - auc: 0.9755\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3065 - auc: 0.9746\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3184 - auc: 0.9729\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3058 - auc: 0.9758\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3098 - auc: 0.9751\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3015 - auc: 0.9744\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3121 - auc: 0.9756\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3028 - auc: 0.9745\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3105 - auc: 0.9743\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3027 - auc: 0.9762\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2952 - auc: 0.9756\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3114 - auc: 0.9754\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3074 - auc: 0.9750\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2897 - auc: 0.9767\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2872 - auc: 0.9745\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2980 - auc: 0.9764\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3018 - auc: 0.9748\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3048 - auc: 0.9753\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3064 - auc: 0.9757\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3031 - auc: 0.9750\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3028 - auc: 0.9759\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2890 - auc: 0.9763\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3058 - auc: 0.9761\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3052 - auc: 0.9761\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3074 - auc: 0.9747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.006987576108277721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.05428468139436588\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0069', 'eer_eval': '0.0542', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0069.hdf5', 'tnow': '2022-06-08 00:48:15.756874'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 66s 38ms/step - loss: 1.4214 - auc: 0.7820\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.8219 - auc: 0.9102\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.6005 - auc: 0.9271\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.5013 - auc: 0.9427\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.4732 - auc: 0.9463\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.4397 - auc: 0.9512\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.4339 - auc: 0.9544\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.4258 - auc: 0.9533\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3976 - auc: 0.9559\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3948 - auc: 0.9588\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3920 - auc: 0.9584\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3725 - auc: 0.9595\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3964 - auc: 0.9609\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3716 - auc: 0.9619\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3568 - auc: 0.9648\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3537 - auc: 0.9640\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3509 - auc: 0.9635\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3575 - auc: 0.9645\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3588 - auc: 0.9645\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3441 - auc: 0.9665\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3437 - auc: 0.9667\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3350 - auc: 0.9667\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3486 - auc: 0.9685\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3270 - auc: 0.9695\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3465 - auc: 0.9666\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3284 - auc: 0.9707\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3165 - auc: 0.9703\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3392 - auc: 0.9661\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3375 - auc: 0.9700\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3271 - auc: 0.9709\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3295 - auc: 0.9720\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3281 - auc: 0.9708\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3206 - auc: 0.9719\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3225 - auc: 0.9703\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3148 - auc: 0.9727\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3174 - auc: 0.9719\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3149 - auc: 0.9718\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3045 - auc: 0.9727\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3319 - auc: 0.9722\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3044 - auc: 0.9731\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3050 - auc: 0.9739\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3108 - auc: 0.9717\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3085 - auc: 0.9746\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3101 - auc: 0.9733\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3164 - auc: 0.9743\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3177 - auc: 0.9757\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3196 - auc: 0.9754\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3086 - auc: 0.9760\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3171 - auc: 0.9759\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3110 - auc: 0.9751\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3140 - auc: 0.9731\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3117 - auc: 0.9750\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.2953 - auc: 0.9742\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3008 - auc: 0.9759\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3125 - auc: 0.9756\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3117 - auc: 0.9738\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3158 - auc: 0.9747\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3080 - auc: 0.9744\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3107 - auc: 0.9738\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3109 - auc: 0.9754\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3021 - auc: 0.9771\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2971 - auc: 0.9753\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3024 - auc: 0.9740\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3073 - auc: 0.9756\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3116 - auc: 0.9727\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.2930 - auc: 0.9743\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3116 - auc: 0.9752\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3200 - auc: 0.9748\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3149 - auc: 0.9757\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3125 - auc: 0.9745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.005484642802898076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.06761748639303515\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0054', 'eer_eval': '0.0676', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0054.hdf5', 'tnow': '2022-06-08 02:00:40.291674'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 67s 39ms/step - loss: 1.3520 - auc: 0.7750\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.8326 - auc: 0.9217\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.6247 - auc: 0.9302\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.5130 - auc: 0.9451\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4621 - auc: 0.9491\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4459 - auc: 0.9538\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.4087 - auc: 0.9603\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3880 - auc: 0.9580\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3736 - auc: 0.9629\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3885 - auc: 0.9619\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3701 - auc: 0.9625\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3633 - auc: 0.9630\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3613 - auc: 0.9624\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3535 - auc: 0.9653\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3562 - auc: 0.9647\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3582 - auc: 0.9660\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3527 - auc: 0.9661\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3663 - auc: 0.9653\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3427 - auc: 0.9667\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3425 - auc: 0.9673\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3429 - auc: 0.9675\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3274 - auc: 0.9688\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3329 - auc: 0.9673\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3202 - auc: 0.9669\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3461 - auc: 0.9685\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3390 - auc: 0.9695\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3321 - auc: 0.9679\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3425 - auc: 0.9686\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3230 - auc: 0.9695\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3316 - auc: 0.9716\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3177 - auc: 0.9699\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3139 - auc: 0.9726\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3229 - auc: 0.9704\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3231 - auc: 0.9729\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3156 - auc: 0.9719\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3173 - auc: 0.9716\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3107 - auc: 0.9731\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3112 - auc: 0.9737\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3061 - auc: 0.9727\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3147 - auc: 0.9739\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3096 - auc: 0.9730\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2987 - auc: 0.9763\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3010 - auc: 0.9740\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3025 - auc: 0.9736\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2972 - auc: 0.9757\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3055 - auc: 0.9740\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3081 - auc: 0.9727\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3054 - auc: 0.9755\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3042 - auc: 0.9752\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3131 - auc: 0.9742\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3029 - auc: 0.9753\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3088 - auc: 0.9754\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2795 - auc: 0.9754\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3040 - auc: 0.9752\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2997 - auc: 0.9750\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3037 - auc: 0.9729\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3132 - auc: 0.9744\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2965 - auc: 0.9751\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2899 - auc: 0.9763\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3063 - auc: 0.9763\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3108 - auc: 0.9748\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3046 - auc: 0.9747\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2961 - auc: 0.9743\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3173 - auc: 0.9743\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2883 - auc: 0.9751\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2993 - auc: 0.9731\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3018 - auc: 0.9752\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2959 - auc: 0.9749\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3096 - auc: 0.9757\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3083 - auc: 0.9742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.008978430857036908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.04007668798086987\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0089', 'eer_eval': '0.0400', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0089.hdf5', 'tnow': '2022-06-08 03:13:35.616059'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 67s 39ms/step - loss: 1.2680 - auc: 0.8172\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.7288 - auc: 0.9236\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.5371 - auc: 0.9413\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4819 - auc: 0.9475\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4510 - auc: 0.9529\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4268 - auc: 0.9542\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4264 - auc: 0.9544\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4189 - auc: 0.9587\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4090 - auc: 0.9591\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3904 - auc: 0.9618\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3890 - auc: 0.9605\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3837 - auc: 0.9611\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3968 - auc: 0.9588\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3906 - auc: 0.9630\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3594 - auc: 0.9627\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3587 - auc: 0.9646\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3578 - auc: 0.9651\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3707 - auc: 0.9654\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3377 - auc: 0.9656\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3544 - auc: 0.9644\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3448 - auc: 0.9664\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3269 - auc: 0.9676\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3443 - auc: 0.9660\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3371 - auc: 0.9669\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3445 - auc: 0.9688\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3262 - auc: 0.9692\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3435 - auc: 0.9675\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3418 - auc: 0.9695\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3350 - auc: 0.9696\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3392 - auc: 0.9683\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3270 - auc: 0.9692\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3214 - auc: 0.9697\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3296 - auc: 0.9686\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3244 - auc: 0.9723\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3163 - auc: 0.9714\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3318 - auc: 0.9691\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3257 - auc: 0.9689\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3224 - auc: 0.9724\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3169 - auc: 0.9717\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3067 - auc: 0.9719\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3159 - auc: 0.9706\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3161 - auc: 0.9721\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3189 - auc: 0.9745\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3102 - auc: 0.9739\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3140 - auc: 0.9736\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3117 - auc: 0.9745\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3089 - auc: 0.9739\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3092 - auc: 0.9737\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3131 - auc: 0.9746\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3199 - auc: 0.9746\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3083 - auc: 0.9741\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3143 - auc: 0.9751\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3046 - auc: 0.9765\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3032 - auc: 0.9734\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3086 - auc: 0.9718\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3013 - auc: 0.9755\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3053 - auc: 0.9752\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2937 - auc: 0.9749\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2963 - auc: 0.9763\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2981 - auc: 0.9746\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3085 - auc: 0.9754\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2978 - auc: 0.9746\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3157 - auc: 0.9733\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3192 - auc: 0.9754\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3068 - auc: 0.9742\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3118 - auc: 0.9739\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3094 - auc: 0.9763\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3042 - auc: 0.9748\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3084 - auc: 0.9750\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3007 - auc: 0.9741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0069484071330367025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.035662098021677274\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0069', 'eer_eval': '0.0356', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0069.hdf5', 'tnow': '2022-06-08 04:26:36.460650'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 66s 39ms/step - loss: 1.2431 - auc: 0.8084\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.7693 - auc: 0.9205\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.5395 - auc: 0.9409\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.4585 - auc: 0.9520\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.4391 - auc: 0.9546\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.4173 - auc: 0.9567\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3949 - auc: 0.9594\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.4076 - auc: 0.9605\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3976 - auc: 0.9602\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3872 - auc: 0.9610\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3661 - auc: 0.9623\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3696 - auc: 0.9650\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3609 - auc: 0.9649\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3532 - auc: 0.9650\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3453 - auc: 0.9663\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3583 - auc: 0.9643\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3596 - auc: 0.9647\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3442 - auc: 0.9667\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3401 - auc: 0.9663\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3503 - auc: 0.9668\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3376 - auc: 0.9691\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3571 - auc: 0.9682\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3529 - auc: 0.9679\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3505 - auc: 0.9674\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3385 - auc: 0.9683\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3522 - auc: 0.9684\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3334 - auc: 0.9677\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3402 - auc: 0.9699\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3364 - auc: 0.9665\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3204 - auc: 0.9702\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3084 - auc: 0.9687\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3316 - auc: 0.9700\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3204 - auc: 0.9715\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3196 - auc: 0.9699\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3318 - auc: 0.9698\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3175 - auc: 0.9716\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3222 - auc: 0.9715\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3215 - auc: 0.9723\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3167 - auc: 0.9709\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3176 - auc: 0.9743\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3062 - auc: 0.9739\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3015 - auc: 0.9732\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3126 - auc: 0.9736\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3220 - auc: 0.9723\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3139 - auc: 0.9720\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3164 - auc: 0.9744\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.2968 - auc: 0.9747\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3167 - auc: 0.9732\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3153 - auc: 0.9733\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3224 - auc: 0.9732\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3085 - auc: 0.9740\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3132 - auc: 0.9738\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3070 - auc: 0.9739\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3150 - auc: 0.9751\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3215 - auc: 0.9744\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2981 - auc: 0.9755\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3164 - auc: 0.9730\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2997 - auc: 0.9748\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3153 - auc: 0.9757\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3038 - auc: 0.9737\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3045 - auc: 0.9747\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3051 - auc: 0.9749\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3022 - auc: 0.9758\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3018 - auc: 0.9742\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3091 - auc: 0.9741\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3327 - auc: 0.9756\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3120 - auc: 0.9748\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3107 - auc: 0.9746\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3050 - auc: 0.9742\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3070 - auc: 0.9738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.006325859949215619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.04083446691840356\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0063', 'eer_eval': '0.0408', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0063.hdf5', 'tnow': '2022-06-08 05:39:14.001959'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 67s 39ms/step - loss: 1.3311 - auc: 0.8048\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.7136 - auc: 0.9212\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.5686 - auc: 0.9367\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4918 - auc: 0.9489\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4274 - auc: 0.9543\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4183 - auc: 0.9580\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4005 - auc: 0.9603\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3879 - auc: 0.9617\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4002 - auc: 0.9601\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3772 - auc: 0.9625\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3568 - auc: 0.9638\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3704 - auc: 0.9623\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3554 - auc: 0.9647\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3680 - auc: 0.9653\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3489 - auc: 0.9654\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3428 - auc: 0.9671\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3417 - auc: 0.9653\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3490 - auc: 0.9671\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3563 - auc: 0.9651\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3433 - auc: 0.9680\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3347 - auc: 0.9674\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3470 - auc: 0.9691\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3269 - auc: 0.9681\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3370 - auc: 0.9663\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3405 - auc: 0.9683\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3287 - auc: 0.9694\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3425 - auc: 0.9672\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3373 - auc: 0.9705\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3260 - auc: 0.9700\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3274 - auc: 0.9720\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3139 - auc: 0.9717\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3229 - auc: 0.9709\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3222 - auc: 0.9701\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3287 - auc: 0.9707\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3245 - auc: 0.9720\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3174 - auc: 0.9722\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2965 - auc: 0.9724\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3002 - auc: 0.9721\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3199 - auc: 0.9730\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3188 - auc: 0.9720\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3218 - auc: 0.9745\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3145 - auc: 0.9730\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3062 - auc: 0.9723\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3036 - auc: 0.9757\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2946 - auc: 0.9725\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3120 - auc: 0.9737\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3048 - auc: 0.9741\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3205 - auc: 0.9746\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3200 - auc: 0.9743\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3138 - auc: 0.9734\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2973 - auc: 0.9750\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3003 - auc: 0.9756\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3126 - auc: 0.9745\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3099 - auc: 0.9747\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2989 - auc: 0.9738\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3129 - auc: 0.9756\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3116 - auc: 0.9757\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3003 - auc: 0.9750\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3066 - auc: 0.9740\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2997 - auc: 0.9759\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3053 - auc: 0.9756\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3066 - auc: 0.9744\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2904 - auc: 0.9760\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2974 - auc: 0.9751\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3149 - auc: 0.9750\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3035 - auc: 0.9761\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3138 - auc: 0.9742\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3040 - auc: 0.9760\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3085 - auc: 0.9741\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3041 - auc: 0.9749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.007189514718940087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.04595693718646936\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0071', 'eer_eval': '0.0459', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0071.hdf5', 'tnow': '2022-06-08 06:52:30.632894'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 67s 39ms/step - loss: 1.2986 - auc: 0.7642\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.6937 - auc: 0.9133\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.5126 - auc: 0.9398\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.4452 - auc: 0.9512\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.4104 - auc: 0.9580\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3926 - auc: 0.9603\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3729 - auc: 0.9608\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3623 - auc: 0.9637\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3811 - auc: 0.9645\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3601 - auc: 0.9636\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3561 - auc: 0.9659\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3458 - auc: 0.9663\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3549 - auc: 0.9679\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3325 - auc: 0.9679\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3552 - auc: 0.9689\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3458 - auc: 0.9680\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3430 - auc: 0.9699\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3341 - auc: 0.9684\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3362 - auc: 0.9697\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3353 - auc: 0.9708\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3306 - auc: 0.9687\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3484 - auc: 0.9696\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3228 - auc: 0.9717\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3171 - auc: 0.9705\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3335 - auc: 0.9698\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3232 - auc: 0.9717\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3152 - auc: 0.9711\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3171 - auc: 0.9722\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3176 - auc: 0.9713\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3189 - auc: 0.9741\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3129 - auc: 0.9714\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3006 - auc: 0.9733\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3191 - auc: 0.9745\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3042 - auc: 0.9754\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3136 - auc: 0.9737\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3017 - auc: 0.9742\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3172 - auc: 0.9764\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2973 - auc: 0.9754\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3077 - auc: 0.9766\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2965 - auc: 0.9762\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3041 - auc: 0.9770\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3014 - auc: 0.9750\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3143 - auc: 0.9761\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2974 - auc: 0.9772\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3048 - auc: 0.9767\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2863 - auc: 0.9764\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3078 - auc: 0.9788\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3054 - auc: 0.9759\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2998 - auc: 0.9771\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3008 - auc: 0.9764\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2968 - auc: 0.9769\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2882 - auc: 0.9771\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2953 - auc: 0.9792\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2933 - auc: 0.9768\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3059 - auc: 0.9774\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3013 - auc: 0.9778\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2951 - auc: 0.9767\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2990 - auc: 0.9781\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2866 - auc: 0.9764\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3026 - auc: 0.9775\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3019 - auc: 0.9786\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2958 - auc: 0.9766\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2892 - auc: 0.9782\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2965 - auc: 0.9781\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2870 - auc: 0.9771\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2986 - auc: 0.9774\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2957 - auc: 0.9758\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3045 - auc: 0.9779\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.2852 - auc: 0.9774\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2971 - auc: 0.9764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.005108909476553149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03140160780183724\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0051', 'eer_eval': '0.0314', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0051.hdf5', 'tnow': '2022-06-08 08:05:36.733671'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 67s 39ms/step - loss: 1.3418 - auc: 0.7941\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.7174 - auc: 0.9175\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.5628 - auc: 0.9265\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.5080 - auc: 0.9409\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4400 - auc: 0.9540\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3929 - auc: 0.9587\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3854 - auc: 0.9593\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3769 - auc: 0.9607\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3716 - auc: 0.9619\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3670 - auc: 0.9643\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3395 - auc: 0.9651\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3403 - auc: 0.9665\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3418 - auc: 0.9652\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3601 - auc: 0.9651\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3302 - auc: 0.9701\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3443 - auc: 0.9682\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3499 - auc: 0.9675\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3317 - auc: 0.9684\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3390 - auc: 0.9690\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3371 - auc: 0.9697\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3339 - auc: 0.9688\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3312 - auc: 0.9703\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3211 - auc: 0.9726\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3340 - auc: 0.9711\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3058 - auc: 0.9699\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3198 - auc: 0.9718\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3097 - auc: 0.9712\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3263 - auc: 0.9719\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3007 - auc: 0.9736\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3179 - auc: 0.9702\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3126 - auc: 0.9748\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2996 - auc: 0.9721\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3094 - auc: 0.9749\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3110 - auc: 0.9740\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3300 - auc: 0.9735\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3140 - auc: 0.9753\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3065 - auc: 0.9746\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3041 - auc: 0.9734\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2976 - auc: 0.9766\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3110 - auc: 0.9760\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2881 - auc: 0.9768\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2991 - auc: 0.9750\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2937 - auc: 0.9748\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2946 - auc: 0.9777\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3033 - auc: 0.9770\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3047 - auc: 0.9763\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2961 - auc: 0.9784\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2852 - auc: 0.9773\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3127 - auc: 0.9763\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3048 - auc: 0.9761\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3022 - auc: 0.9786\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2907 - auc: 0.9769\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2993 - auc: 0.9776\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2941 - auc: 0.9766\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2887 - auc: 0.9786\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3090 - auc: 0.9786\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2983 - auc: 0.9759\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2874 - auc: 0.9763\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2930 - auc: 0.9761\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2974 - auc: 0.9781\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2954 - auc: 0.9772\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2939 - auc: 0.9763\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2844 - auc: 0.9782\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2795 - auc: 0.9760\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2827 - auc: 0.9780\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2911 - auc: 0.9768\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2984 - auc: 0.9781\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2867 - auc: 0.9788\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2984 - auc: 0.9768\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3048 - auc: 0.9773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.005950126622870694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.026250274570198132\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0059', 'eer_eval': '0.0262', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0059.hdf5', 'tnow': '2022-06-08 09:18:48.003205'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 66s 39ms/step - loss: 1.2847 - auc: 0.8029\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.8224 - auc: 0.9046\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.5579 - auc: 0.9349\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4532 - auc: 0.9536\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4339 - auc: 0.9554\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4005 - auc: 0.9606\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3854 - auc: 0.9623\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3806 - auc: 0.9638\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3629 - auc: 0.9652\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3540 - auc: 0.9667\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3446 - auc: 0.9666\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3435 - auc: 0.9669\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3458 - auc: 0.9672\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3231 - auc: 0.9689\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3431 - auc: 0.9667\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3459 - auc: 0.9692\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3472 - auc: 0.9691\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3264 - auc: 0.9715\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3386 - auc: 0.9705\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3309 - auc: 0.9712\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3249 - auc: 0.9723\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3197 - auc: 0.9692\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3150 - auc: 0.9711\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3245 - auc: 0.9701\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3277 - auc: 0.9711\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3234 - auc: 0.9716\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3158 - auc: 0.9726\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3150 - auc: 0.9728\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3156 - auc: 0.9733\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3108 - auc: 0.9752\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3011 - auc: 0.9746\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3111 - auc: 0.9749\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.2866 - auc: 0.9742\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.2981 - auc: 0.9751\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3143 - auc: 0.9724\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3052 - auc: 0.9734\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3036 - auc: 0.9741\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3009 - auc: 0.9766\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.2979 - auc: 0.9756\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3010 - auc: 0.9767\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3019 - auc: 0.9785\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3024 - auc: 0.9763\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.2985 - auc: 0.9764\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.2935 - auc: 0.9773\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.2964 - auc: 0.9784\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.2921 - auc: 0.9780\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.2947 - auc: 0.9781\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.2977 - auc: 0.9785\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3057 - auc: 0.9775\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.2893 - auc: 0.9780\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3080 - auc: 0.9768\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.2916 - auc: 0.9762\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.2993 - auc: 0.9775\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3062 - auc: 0.9779\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.2960 - auc: 0.9786\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.2978 - auc: 0.9780\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.2883 - auc: 0.9775\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.2962 - auc: 0.9785\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.2941 - auc: 0.9778\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.2922 - auc: 0.9778\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.2975 - auc: 0.9790\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.2964 - auc: 0.9771\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.2970 - auc: 0.9777\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3040 - auc: 0.9789\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3054 - auc: 0.9770\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.2987 - auc: 0.9771\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.2932 - auc: 0.9771\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.2910 - auc: 0.9774\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.2909 - auc: 0.9772\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.2970 - auc: 0.9783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0070773266019054145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.02448179691320091\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0070', 'eer_eval': '0.0244', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0070.hdf5', 'tnow': '2022-06-08 10:30:22.143462'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 66s 38ms/step - loss: 1.3706 - auc: 0.7675\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 59s 38ms/step - loss: 0.7658 - auc: 0.9049\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.6223 - auc: 0.9200\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.5515 - auc: 0.9298\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.4576 - auc: 0.9511\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.4588 - auc: 0.9530\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.4307 - auc: 0.9556\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.4105 - auc: 0.9573\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.4084 - auc: 0.9601\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.4091 - auc: 0.9586\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3994 - auc: 0.9611\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3765 - auc: 0.9635\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3755 - auc: 0.9635\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3817 - auc: 0.9620\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3701 - auc: 0.9652\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3864 - auc: 0.9612\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3436 - auc: 0.9663\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3663 - auc: 0.9644\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3522 - auc: 0.9657\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3598 - auc: 0.9654\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3486 - auc: 0.9651\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3485 - auc: 0.9680\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3511 - auc: 0.9660\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3572 - auc: 0.9669\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3518 - auc: 0.9672\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3526 - auc: 0.9678\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3416 - auc: 0.9676\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3514 - auc: 0.9668\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3433 - auc: 0.9694\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3502 - auc: 0.9680\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3414 - auc: 0.9681\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3405 - auc: 0.9700\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3354 - auc: 0.9683\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3304 - auc: 0.9708\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3242 - auc: 0.9696\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3218 - auc: 0.9724\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3317 - auc: 0.9726\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3223 - auc: 0.9698\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3148 - auc: 0.9717\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3221 - auc: 0.9717\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3243 - auc: 0.9722\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3202 - auc: 0.9724\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 59s 38ms/step - loss: 0.3116 - auc: 0.9730\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3192 - auc: 0.9736\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3212 - auc: 0.9734\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3147 - auc: 0.9728\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3214 - auc: 0.9731\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.2980 - auc: 0.9748\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3113 - auc: 0.9742\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3189 - auc: 0.9719\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3099 - auc: 0.9747\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3022 - auc: 0.9728\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3204 - auc: 0.9731\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3094 - auc: 0.9732\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3069 - auc: 0.9728\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3046 - auc: 0.9745\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3188 - auc: 0.9736\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3100 - auc: 0.9752\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3013 - auc: 0.9741\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3173 - auc: 0.9734\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3093 - auc: 0.9748\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3237 - auc: 0.9741\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.2995 - auc: 0.9757\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3011 - auc: 0.9744\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3119 - auc: 0.9716\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3210 - auc: 0.9747\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 59s 38ms/step - loss: 0.2970 - auc: 0.9728\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3185 - auc: 0.9740\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3040 - auc: 0.9740\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3164 - auc: 0.9743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.008226964204347056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03498552690674892\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0082', 'eer_eval': '0.0349', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0082.hdf5', 'tnow': '2022-06-08 11:40:48.949431'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 68s 40ms/step - loss: 1.3952 - auc: 0.7775\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.7410 - auc: 0.9094\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.6236 - auc: 0.9188\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.5564 - auc: 0.9332\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4638 - auc: 0.9470\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4440 - auc: 0.9509\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.4296 - auc: 0.9545\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.4191 - auc: 0.9556\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.4163 - auc: 0.9567\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.4239 - auc: 0.9548\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4059 - auc: 0.9603\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4134 - auc: 0.9601\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3747 - auc: 0.9624\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3754 - auc: 0.9610\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 61s 38ms/step - loss: 0.3773 - auc: 0.9611\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3631 - auc: 0.9629\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3660 - auc: 0.9628\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3597 - auc: 0.9636\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3699 - auc: 0.9640\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3625 - auc: 0.9650\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3482 - auc: 0.9667\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3420 - auc: 0.9672\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3558 - auc: 0.9650\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3539 - auc: 0.9646\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3545 - auc: 0.9674\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3327 - auc: 0.9671\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3568 - auc: 0.9666\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 59s 38ms/step - loss: 0.3213 - auc: 0.9683\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3384 - auc: 0.9691\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3470 - auc: 0.9671\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3409 - auc: 0.9674\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3255 - auc: 0.9686\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3360 - auc: 0.9689\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3238 - auc: 0.9701\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3318 - auc: 0.9700\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3169 - auc: 0.9692\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3295 - auc: 0.9703\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3224 - auc: 0.9703\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3271 - auc: 0.9708\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3280 - auc: 0.9725\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3256 - auc: 0.9719\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3131 - auc: 0.9730\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3191 - auc: 0.9712\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3205 - auc: 0.9724\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3045 - auc: 0.9724\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3251 - auc: 0.9727\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3284 - auc: 0.9740\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3050 - auc: 0.9736\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3094 - auc: 0.9736\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3133 - auc: 0.9715\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3063 - auc: 0.9738\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3059 - auc: 0.9723\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3162 - auc: 0.9721\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3199 - auc: 0.9730\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3136 - auc: 0.9727\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3059 - auc: 0.9734\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3193 - auc: 0.9721\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3225 - auc: 0.9726\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3227 - auc: 0.9721\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 59s 38ms/step - loss: 0.3007 - auc: 0.9727\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3202 - auc: 0.9733\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3118 - auc: 0.9729\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3114 - auc: 0.9743\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3174 - auc: 0.9737\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3014 - auc: 0.9728\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3165 - auc: 0.9731\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3184 - auc: 0.9733\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.2999 - auc: 0.9718\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3079 - auc: 0.9724\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3111 - auc: 0.9725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.007806355631188285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.053062157008403096\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0078', 'eer_eval': '0.0530', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0078.hdf5', 'tnow': '2022-06-08 12:52:10.841437'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 65s 38ms/step - loss: 1.3632 - auc: 0.7854\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.7626 - auc: 0.9090\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.6090 - auc: 0.9287\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.4841 - auc: 0.9462\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.4320 - auc: 0.9569\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.4122 - auc: 0.9572\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.4105 - auc: 0.9600\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3780 - auc: 0.9628\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.4030 - auc: 0.9607\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3738 - auc: 0.9634\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3632 - auc: 0.9631\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3417 - auc: 0.9632\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3498 - auc: 0.9646\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3558 - auc: 0.9662\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3529 - auc: 0.9660\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3486 - auc: 0.9642\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3524 - auc: 0.9666\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3434 - auc: 0.9651\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3407 - auc: 0.9679\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3259 - auc: 0.9683\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3393 - auc: 0.9672\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3308 - auc: 0.9692\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3365 - auc: 0.9677\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3383 - auc: 0.9698\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3237 - auc: 0.9710\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3335 - auc: 0.9682\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3248 - auc: 0.9699\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3384 - auc: 0.9698\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3262 - auc: 0.9702\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3197 - auc: 0.9698\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3294 - auc: 0.9707\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3273 - auc: 0.9697\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3295 - auc: 0.9712\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3254 - auc: 0.9717\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3162 - auc: 0.9721\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3193 - auc: 0.9724\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3165 - auc: 0.9713\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3138 - auc: 0.9736\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3100 - auc: 0.9701\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3277 - auc: 0.9733\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3216 - auc: 0.9714\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3085 - auc: 0.9740\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3005 - auc: 0.9745\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3040 - auc: 0.9745\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.2993 - auc: 0.9738\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.2963 - auc: 0.9743\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.2960 - auc: 0.9751\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.2958 - auc: 0.9731\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.2971 - auc: 0.9760\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3139 - auc: 0.9742\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3193 - auc: 0.9725\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3130 - auc: 0.9732\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3054 - auc: 0.9748\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3064 - auc: 0.9745\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3130 - auc: 0.9744\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3022 - auc: 0.9747\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.2989 - auc: 0.9745\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3041 - auc: 0.9750\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3104 - auc: 0.9752\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3198 - auc: 0.9752\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3191 - auc: 0.9760\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.2966 - auc: 0.9735\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.3041 - auc: 0.9726\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 59s 37ms/step - loss: 0.2986 - auc: 0.9747\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3050 - auc: 0.9742\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3212 - auc: 0.9748\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3023 - auc: 0.9741\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.2984 - auc: 0.9744\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3175 - auc: 0.9752\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 60s 38ms/step - loss: 0.3122 - auc: 0.9757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.007010013731684644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03358542088597492\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0070', 'eer_eval': '0.0335', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0070.hdf5', 'tnow': '2022-06-08 14:02:43.660051'}\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from utils.DataLoader import data_loader\n",
    "from utils.Generator0_blur import DataGenerator, feature_extract_cqt, evalEER,  evalScore, evalEER_f, evalEER_f2, gen_fname\n",
    "from models.models import get_ResMax, get_LCNN, sigmoidal_decay\n",
    "from models.models2 import get_BCResMax, get_DDWSseq\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import add,concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, maximum, DepthwiseConv2D, AveragePooling2D, UpSampling2D\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, SpatialDropout2D\n",
    "from tensorflow.keras.layers import Convolution2D, GlobalAveragePooling2D, MaxPool2D, ZeroPadding2D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.activations import relu, softmax, swish\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import pickle\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "add2022 = '/home/ubuntu/data/ADD/'\n",
    "asv2019 = '/home/ubuntu/data/asv2019/'\n",
    "\n",
    "pathset = { 'add2022' : add2022 , 'asv2019':asv2019}\n",
    "        \n",
    "dl = data_loader(pathset)\n",
    "\n",
    "#dl.get_data(data_pick = '2', tde_pick = 't', pl_pick = 'l', to = 't')\n",
    "#dl.get_data(data_pick = '2', tde_pick = 'd', pl_pick = 'l', to = 't')\n",
    "#dl.get_data(data_pick = '2', tde_pick = 'e', pl_pick = 'l', to = 'd')\n",
    "\n",
    "\n",
    "datapick = '2' ## 1:ADD, 2:LA\n",
    "\n",
    "dl.get_data(data_pick = datapick, tde_pick = 't', pl_pick = 'l',  to = 't')\n",
    "dl.get_data(data_pick = datapick, tde_pick = 'd', pl_pick = 'l', to = 'd')\n",
    "dl.get_data(data_pick = datapick, tde_pick = 'e', pl_pick = 'l', to = 'e')\n",
    "\n",
    "##################################################\n",
    "mname = \"ResMax_LA_\"\n",
    "##################################################\n",
    "\n",
    "### Mixup\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_blur_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "##################################################\n",
    "mname = \"DDWSseq_LA_\"\n",
    "##################################################\n",
    "\n",
    "## 22.06.07 : 서버 점검으로 다시 돌리기(HP 2개까지 저장됨)\n",
    "### HP         \n",
    "for i in range(1) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_blur_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_blur_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "### LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_blur_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_blur_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #[2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_blur_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_blur_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f982e03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2.4_p37)",
   "language": "python",
   "name": "conda_tensorflow2.4_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
