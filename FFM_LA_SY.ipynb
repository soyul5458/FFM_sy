{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35df4441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 27 10:29:24 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:05.0 Off |                  Off |\r\n",
      "| N/A   40C    P0    40W / 300W |      0MiB / 32510MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:00:06.0 Off |                  Off |\r\n",
      "| N/A   35C    P0    37W / 300W |      0MiB / 32510MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ce51044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from utils.DataLoader import data_loader\n",
    "from utils.Generator0 import DataGenerator, feature_extract_cqt, evalEER,  evalScore, evalEER_f, evalEER_f2, gen_fname\n",
    "from models.models import get_ResMax, get_LCNN, sigmoidal_decay\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import add,concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, maximum, DepthwiseConv2D, AveragePooling2D, UpSampling2D\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, SpatialDropout2D\n",
    "from tensorflow.keras.layers import Convolution2D, GlobalAveragePooling2D, MaxPool2D, ZeroPadding2D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.activations import relu, softmax, swish\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import pickle\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "add2022 = '/home/ubuntu/data/ADD/'\n",
    "asv2019 = '/home/ubuntu/data/asv2019/'\n",
    "\n",
    "pathset = { 'add2022' : add2022 , 'asv2019':asv2019}\n",
    "        \n",
    "dl = data_loader(pathset)\n",
    "\n",
    "#dl.get_data(data_pick = '2', tde_pick = 't', pl_pick = 'l', to = 't')\n",
    "#dl.get_data(data_pick = '2', tde_pick = 'd', pl_pick = 'l', to = 't')\n",
    "#dl.get_data(data_pick = '2', tde_pick = 'e', pl_pick = 'l', to = 'd')\n",
    "\n",
    "\n",
    "datapick = '' ## 1:ADD, 2:LA\n",
    "\n",
    "dl.get_data(data_pick = datapick, tde_pick = 't', pl_pick = 'l',  to = 't')\n",
    "dl.get_data(data_pick = datapick, tde_pick = 'd', pl_pick = 'l', to = 'd')\n",
    "dl.get_data(data_pick = datapick, tde_pick = 'e', pl_pick = 'l', to = 'e')\n",
    "\n",
    "#track1 = data_loader(pathset)\n",
    "#track1_generator = DataGenerator(track1.eval, track1.labels, **params_no_shuffle)\n",
    "\n",
    "#################################################\n",
    "### get_ResMax\n",
    "mname = 'ResMax_LA_'\n",
    "#################################################\n",
    "\n",
    "### Mixup\n",
    "\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False # np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': False, # beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e97b7feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False # np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': False, # beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5392f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = os.listdir(params['data_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9374d275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asvspoof2019_evaluation_plan.pdf',\n",
       " 'asvspoof2019_Interspeech2019_submission.pdf',\n",
       " 'README.txt',\n",
       " 'LICENSE_text.txt',\n",
       " 'LA',\n",
       " 'PA',\n",
       " 'tmp']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82a6f32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_train_ids = []\n",
    "PA_train_ids = []\n",
    "LA_dev_ids = []\n",
    "PA_dev_ids = []\n",
    "    #LA_TnD_ids = []\n",
    "#PA_TnD_ids = []\n",
    "LA_eval_ids = []\n",
    "PA_eval_ids = []\n",
    "labels_tmp = {}\n",
    "eval_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faa7394b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-16-caf15d9e33b0>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-caf15d9e33b0>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    LA_train_ids = []\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "## Train set start with T, Dev set start with D and Eval set start with E\n",
    "    LA_train_ids = []\n",
    "    PA_train_ids = []\n",
    "    LA_dev_ids = []\n",
    "    PA_dev_ids = []\n",
    "    #LA_TnD_ids = []\n",
    "    #PA_TnD_ids = []\n",
    "    LA_eval_ids = []\n",
    "    PA_eval_ids = []\n",
    "    labels_tmp = {}\n",
    "    eval_ids = []\n",
    "\n",
    "    for (path, dir, files) in os.walk(asv2019) :\n",
    "        for filename in files:\n",
    "            ext = os.path.splitext(filename)[-1]\n",
    "            if ext == '.flac':\n",
    "                fnm = path + '/' + filename\n",
    "                labels_tmp[filename] = fnm\n",
    "                if filename[:2] == 'LA' :\n",
    "                    if filename[3] == 'T' :\n",
    "                        LA_train_ids.append(fnm)\n",
    "    #                    LA_TnD_ids.append(fnm)\n",
    "                    elif filename[3] == 'D' :\n",
    "                        LA_dev_ids.append(fnm)\n",
    "    #                    LA_TnD_ids.append(fnm)\n",
    "                    else :\n",
    "                        LA_eval_ids.append(fnm)\n",
    "                elif filename[:2] == 'PA' :\n",
    "                    if filename[3] == 'T' :\n",
    "                        PA_train_ids.append(fnm)\n",
    "    #                    PA_TnD_ids.append(fnm)\n",
    "                    elif filename[3] == 'D' :\n",
    "                        PA_dev_ids.append(fnm)\n",
    "    #                    PA_TnD_ids.append(fnm)\n",
    "                    else :\n",
    "                        PA_eval_ids.append(fnm)\n",
    "\n",
    "    labels = {}\n",
    "    PA_train_ids2 = []\n",
    "    fname = path2019+'PA/ASVspoof2019_PA_cm_protocols/ASVspoof2019.PA.cm.train.trn.txt'\n",
    "    with open(fname, encoding='utf-8') as f:\n",
    "        wav_fnm = []\n",
    "        label = []\n",
    "        for i, doc in enumerate(f):                \n",
    "            _, wav, _, _, lb = doc.strip().split(' ')\n",
    "            if(lb == 'bonafide'):\n",
    "                labels[labels_tmp[wav+'.flac']] = 0\n",
    "            else: \n",
    "                labels[labels_tmp[wav+'.flac']] = 1\n",
    "            PA_train_ids2.append(labels_tmp[wav+'.flac'])\n",
    "            \n",
    "    LA_train_ids2 = []\n",
    "    fname = path2019+'LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt'\n",
    "    with open(fname, encoding='utf-8') as f:\n",
    "        wav_fnm = []\n",
    "        label = []\n",
    "        for i, doc in enumerate(f):                \n",
    "            _, wav, _, _, lb = doc.strip().split(' ')\n",
    "            if(lb == 'bonafide'):\n",
    "                labels[labels_tmp[wav+'.flac']] = 0\n",
    "            else: \n",
    "                labels[labels_tmp[wav+'.flac']] = 1\n",
    "            LA_train_ids2.append(labels_tmp[wav+'.flac'])\n",
    "            \n",
    "    ## label for dev set\n",
    "    PA_dev_ids2 = []\n",
    "    fname = path2019+'PA/ASVspoof2019_PA_cm_protocols/ASVspoof2019.PA.cm.dev.trl.txt'\n",
    "    with open(fname, encoding='utf-8') as f:\n",
    "        wav_fnm = []\n",
    "        label = []\n",
    "        for i, doc in enumerate(f):                \n",
    "            _, wav, _, _, lb = doc.strip().split(' ')\n",
    "            if(lb == 'bonafide'):\n",
    "                labels[labels_tmp[wav+'.flac']] = 0\n",
    "            else: \n",
    "                labels[labels_tmp[wav+'.flac']] = 1\n",
    "            PA_dev_ids2.append(labels_tmp[wav+'.flac'])\n",
    "\n",
    "    LA_dev_ids2 = []\n",
    "    fname = path2019+'LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt'\n",
    "    with open(fname, encoding='utf-8') as f:\n",
    "        wav_fnm = []\n",
    "        label = []\n",
    "        for i, doc in enumerate(f):                \n",
    "            _, wav, _, _, lb = doc.strip().split(' ')\n",
    "            if(lb == 'bonafide'):\n",
    "                labels[labels_tmp[wav+'.flac']] = 0\n",
    "            else: \n",
    "                labels[labels_tmp[wav+'.flac']] = 1\n",
    "            LA_dev_ids2.append(labels_tmp[wav+'.flac'])\n",
    "\n",
    "\n",
    "    ## label for eval set\n",
    "    PA_eval_ids2 = []\n",
    "    fname = path2019+'PA/ASVspoof2019_PA_cm_protocols/ASVspoof2019.PA.cm.eval.trl.txt'\n",
    "    with open(fname, encoding='utf-8') as f:\n",
    "        wav_fnm = []\n",
    "        label = []\n",
    "        for i, doc in enumerate(f):                \n",
    "            _, wav, _, _, lb = doc.strip().split(' ')\n",
    "            if(lb == 'bonafide'):\n",
    "                labels[labels_tmp[wav+'.flac']] = 0\n",
    "            else: \n",
    "                labels[labels_tmp[wav+'.flac']] = 1\n",
    "            PA_eval_ids2.append(labels_tmp[wav+'.flac'])\n",
    "\n",
    "    LA_eval_ids2 = []\n",
    "    fname = path2019+'LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt'\n",
    "    with open(fname, encoding='utf-8') as f:\n",
    "        wav_fnm = []\n",
    "        label = []\n",
    "        for i, doc in enumerate(f):                \n",
    "            _, wav, _, _, lb = doc.strip().split(' ')\n",
    "            if(lb == 'bonafide'):\n",
    "                labels[labels_tmp[wav+'.flac']] = 0\n",
    "            else: \n",
    "                labels[labels_tmp[wav+'.flac']] = 1\n",
    "            LA_eval_ids2.append(labels_tmp[wav+'.flac'])\n",
    "\n",
    "    IDs_set = []\n",
    "    \n",
    "    if tde_loader['t'] and pl_loader['p'] :\n",
    "        IDs_set += PA_train_ids2\n",
    "    if tde_loader['t'] and pl_loader['l'] :\n",
    "        IDs_set += LA_train_ids2\n",
    "    if tde_loader['d'] and pl_loader['p'] :\n",
    "        IDs_set += PA_dev_ids2\n",
    "    if tde_loader['d'] and pl_loader['l'] :\n",
    "        IDs_set += LA_dev_ids2\n",
    "    if tde_loader['e'] and pl_loader['p'] :\n",
    "        IDs_set += PA_eval_ids2\n",
    "    if tde_loader['e'] and pl_loader['l'] :\n",
    "        IDs_set += LA_eval_ids2\n",
    "    \n",
    "    partition = {'IDs' : IDs_set, 'labels' : labels }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7484453b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-8-dfe16e48979f>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-dfe16e48979f>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    for c in tde :\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "tde_loader = {'t':False, 'd': False, 'e':False}\n",
    "pl_loader = {'p':False, 'l': False}\n",
    "    for c in tde :\n",
    "        tde_loader[c] = True\n",
    "    for c in pl :\n",
    "        pl_loader[c] = True\n",
    "\n",
    "        \n",
    "    fs = os.listdir(asv2019)\n",
    "\n",
    "    ## Train set start with T, Dev set start with D and Eval set start with E\n",
    "    LA_train_ids = []\n",
    "    PA_train_ids = []\n",
    "    LA_dev_ids = []\n",
    "    PA_dev_ids = []\n",
    "    #LA_TnD_ids = []\n",
    "    #PA_TnD_ids = []\n",
    "    LA_eval_ids = []\n",
    "    PA_eval_ids = []\n",
    "    labels_tmp = {}\n",
    "    eval_ids = []\n",
    "\n",
    "    for (path, dir, files) in os.walk(path2019) :\n",
    "        for filename in files:\n",
    "            ext = os.path.splitext(filename)[-1]\n",
    "            if ext == '.flac':\n",
    "                fnm = path + '/' + filename\n",
    "                labels_tmp[filename] = fnm\n",
    "                if filename[:2] == 'LA' :\n",
    "                    if filename[3] == 'T' :\n",
    "                        LA_train_ids.append(fnm)\n",
    "    #                    LA_TnD_ids.append(fnm)\n",
    "                    elif filename[3] == 'D' :\n",
    "                        LA_dev_ids.append(fnm)\n",
    "    #                    LA_TnD_ids.append(fnm)\n",
    "                    else :\n",
    "                        LA_eval_ids.append(fnm)\n",
    "                elif filename[:2] == 'PA' :\n",
    "                    if filename[3] == 'T' :\n",
    "                        PA_train_ids.append(fnm)\n",
    "    #                    PA_TnD_ids.append(fnm)\n",
    "                    elif filename[3] == 'D' :\n",
    "                        PA_dev_ids.append(fnm)\n",
    "    #                    PA_TnD_ids.append(fnm)\n",
    "                    else :\n",
    "                        PA_eval_ids.append(fnm)\n",
    "\n",
    "    labels = {}\n",
    "    PA_train_ids2 = []\n",
    "    fname = path2019+'PA/ASVspoof2019_PA_cm_protocols/ASVspoof2019.PA.cm.train.trn.txt'\n",
    "    with open(fname, encoding='utf-8') as f:\n",
    "        wav_fnm = []\n",
    "        label = []\n",
    "        for i, doc in enumerate(f):                \n",
    "            _, wav, _, _, lb = doc.strip().split(' ')\n",
    "            if(lb == 'bonafide'):\n",
    "                labels[labels_tmp[wav+'.flac']] = 0\n",
    "            else: \n",
    "                labels[labels_tmp[wav+'.flac']] = 1\n",
    "            PA_train_ids2.append(labels_tmp[wav+'.flac'])\n",
    "            \n",
    "    LA_train_ids2 = []\n",
    "    fname = path2019+'LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt'\n",
    "    with open(fname, encoding='utf-8') as f:\n",
    "        wav_fnm = []\n",
    "        label = []\n",
    "        for i, doc in enumerate(f):                \n",
    "            _, wav, _, _, lb = doc.strip().split(' ')\n",
    "            if(lb == 'bonafide'):\n",
    "                labels[labels_tmp[wav+'.flac']] = 0\n",
    "            else: \n",
    "                labels[labels_tmp[wav+'.flac']] = 1\n",
    "            LA_train_ids2.append(labels_tmp[wav+'.flac'])\n",
    "            \n",
    "    ## label for dev set\n",
    "    PA_dev_ids2 = []\n",
    "    fname = path2019+'PA/ASVspoof2019_PA_cm_protocols/ASVspoof2019.PA.cm.dev.trl.txt'\n",
    "    with open(fname, encoding='utf-8') as f:\n",
    "        wav_fnm = []\n",
    "        label = []\n",
    "        for i, doc in enumerate(f):                \n",
    "            _, wav, _, _, lb = doc.strip().split(' ')\n",
    "            if(lb == 'bonafide'):\n",
    "                labels[labels_tmp[wav+'.flac']] = 0\n",
    "            else: \n",
    "                labels[labels_tmp[wav+'.flac']] = 1\n",
    "            PA_dev_ids2.append(labels_tmp[wav+'.flac'])\n",
    "\n",
    "    LA_dev_ids2 = []\n",
    "    fname = path2019+'LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt'\n",
    "    with open(fname, encoding='utf-8') as f:\n",
    "        wav_fnm = []\n",
    "        label = []\n",
    "        for i, doc in enumerate(f):                \n",
    "            _, wav, _, _, lb = doc.strip().split(' ')\n",
    "            if(lb == 'bonafide'):\n",
    "                labels[labels_tmp[wav+'.flac']] = 0\n",
    "            else: \n",
    "                labels[labels_tmp[wav+'.flac']] = 1\n",
    "            LA_dev_ids2.append(labels_tmp[wav+'.flac'])\n",
    "\n",
    "\n",
    "    ## label for eval set\n",
    "    PA_eval_ids2 = []\n",
    "    fname = path2019+'PA/ASVspoof2019_PA_cm_protocols/ASVspoof2019.PA.cm.eval.trl.txt'\n",
    "    with open(fname, encoding='utf-8') as f:\n",
    "        wav_fnm = []\n",
    "        label = []\n",
    "        for i, doc in enumerate(f):                \n",
    "            _, wav, _, _, lb = doc.strip().split(' ')\n",
    "            if(lb == 'bonafide'):\n",
    "                labels[labels_tmp[wav+'.flac']] = 0\n",
    "            else: \n",
    "                labels[labels_tmp[wav+'.flac']] = 1\n",
    "            PA_eval_ids2.append(labels_tmp[wav+'.flac'])\n",
    "\n",
    "    LA_eval_ids2 = []\n",
    "    fname = path2019+'LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt'\n",
    "    with open(fname, encoding='utf-8') as f:\n",
    "        wav_fnm = []\n",
    "        label = []\n",
    "        for i, doc in enumerate(f):                \n",
    "            _, wav, _, _, lb = doc.strip().split(' ')\n",
    "            if(lb == 'bonafide'):\n",
    "                labels[labels_tmp[wav+'.flac']] = 0\n",
    "            else: \n",
    "                labels[labels_tmp[wav+'.flac']] = 1\n",
    "            LA_eval_ids2.append(labels_tmp[wav+'.flac'])\n",
    "\n",
    "    IDs_set = []\n",
    "    \n",
    "    if tde_loader['t'] and pl_loader['p'] :\n",
    "        IDs_set += PA_train_ids2\n",
    "    if tde_loader['t'] and pl_loader['l'] :\n",
    "        IDs_set += LA_train_ids2\n",
    "    if tde_loader['d'] and pl_loader['p'] :\n",
    "        IDs_set += PA_dev_ids2\n",
    "    if tde_loader['d'] and pl_loader['l'] :\n",
    "        IDs_set += LA_dev_ids2\n",
    "    if tde_loader['e'] and pl_loader['p'] :\n",
    "        IDs_set += PA_eval_ids2\n",
    "    if tde_loader['e'] and pl_loader['l'] :\n",
    "        IDs_set += LA_eval_ids2\n",
    "    \n",
    "    partition = {'IDs' : IDs_set, 'labels' : labels }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e7d8623",
   "metadata": {},
   "outputs": [],
   "source": [
    "asv2019 = '/home/ubuntu/data/asv2019/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6ab15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 70s 41ms/step - loss: 0.3845 - auc: 0.9323\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 0.0936 - auc: 0.9975\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0553 - auc: 0.9989\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0550 - auc: 0.9987\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0470 - auc: 0.9991\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0250 - auc: 0.9997\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0216 - auc: 0.9998\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0150 - auc: 0.9998\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0226 - auc: 0.9997\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 0.0168 - auc: 0.9997\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 0.0222 - auc: 0.9994\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0118 - auc: 0.9998\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0064 - auc: 0.9999\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0184 - auc: 0.9993\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0087 - auc: 0.9999\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0050 - auc: 1.0000\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0162 - auc: 0.9997\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0072 - auc: 0.9998\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0079 - auc: 0.9999\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0072 - auc: 0.9999\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0041 - auc: 0.9999\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0036 - auc: 1.0000\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0030 - auc: 1.0000\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0039 - auc: 0.9999\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0027 - auc: 1.0000\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0058 - auc: 0.9999\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0012 - auc: 1.0000\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0070 - auc: 0.9999\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0024 - auc: 0.9999\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0014 - auc: 0.9999\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 8.4555e-04 - auc: 1.0000\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0029 - auc: 1.0000\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 7.8157e-04 - auc: 1.0000\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 6.3323e-04 - auc: 1.0000\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0010 - auc: 1.0000\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 8.8411e-04 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.4615e-04 - auc: 1.0000\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.8441e-04 - auc: 1.0000\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 4.5268e-05 - auc: 1.0000\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.6050e-04 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.2772e-05 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 6.1235e-05 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 4.3615e-06 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.6110e-06 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 4.1998e-06 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 3.1621e-06 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 2.3597e-06 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.9025e-06 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 5.7049e-06 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.2470e-06 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 4.7768e-06 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 7.3465e-07 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 8.9953e-07 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.2847e-06 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 9.8868e-07 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 4.4475e-06 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 7.4103e-07 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.9646e-07 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.1683e-07 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.8499e-07 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 6.8052e-07 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 4.2847e-07 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 4.6907e-07 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.8438e-07 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.8551e-07 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 4.1847e-07 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.5720e-07 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 8.2524e-07 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 8.3560e-07 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.8638e-07 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.009622640738495794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.040275305280768205\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0096', 'eer_eval': '0.0402', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0096.hdf5', 'tnow': '2022-05-25 21:55:20.816208'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 43s 26ms/step - loss: 0.3685 - auc: 0.9376\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0790 - auc: 0.9975\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0582 - auc: 0.9985\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0444 - auc: 0.9992\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0284 - auc: 0.9994\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0348 - auc: 0.9995\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0303 - auc: 0.9994\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0150 - auc: 0.9997\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0311 - auc: 0.9993\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0150 - auc: 0.9997\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0097 - auc: 0.9997\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0120 - auc: 0.9998\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0070 - auc: 0.9999\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0120 - auc: 0.9997\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0171 - auc: 0.9997\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0031 - auc: 0.9999\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0109 - auc: 0.9998\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0080 - auc: 0.9998\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0050 - auc: 0.9998\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 9.8491e-04 - auc: 1.0000 0s - loss: 9.8772e\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0120 - auc: 0.9998\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0079 - auc: 0.9999\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0063 - auc: 0.9999\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0014 - auc: 1.0000\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 9.4087e-04 - auc: 1.0000\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0033 - auc: 0.9999\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0050 - auc: 0.9999\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0029 - auc: 0.9999\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0046 - auc: 0.9999\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.1519e-04 - auc: 1.0000\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0029 - auc: 1.0000\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0021 - auc: 0.9999\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 6.9901e-04 - auc: 1.0000\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0062 - auc: 0.9998\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.0989e-04 - auc: 1.0000\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 6.5902e-05 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.9316e-05 - auc: 1.0000\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0019 - auc: 1.0000\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 4.7867e-04 - auc: 1.0000\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 1.4864e-04 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 3.0935e-04 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 9.0112e-05 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.3136e-05 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.6082e-05 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 9.1309e-05 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 6.5175e-06 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 2.5853e-06 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 3.6067e-06 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.9005e-06 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 2.0014e-04 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.5041e-06 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 9.9126e-06 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 9.0138e-07 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 6.1214e-06 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 1.9163e-06 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.0965e-06 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.5583e-06 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.8993e-07 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 1.3142e-06 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 8.1422e-07 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 8.7330e-07 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 4.1563e-07 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 7.0191e-07 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.8494e-07 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.5971e-06 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.6837e-07 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 1.1821e-06 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 6.1101e-07 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 2.0336e-06 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 4.5073e-07 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.006230403184014985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.04092056720175177\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0062', 'eer_eval': '0.0409', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0062.hdf5', 'tnow': '2022-05-25 22:43:52.612214'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 42s 25ms/step - loss: 0.4247 - auc: 0.9223\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0754 - auc: 0.9980\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0603 - auc: 0.9984\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0489 - auc: 0.9990\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0367 - auc: 0.9992\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0198 - auc: 0.9997\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0182 - auc: 0.9996\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0238 - auc: 0.9994\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0155 - auc: 0.9998\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0116 - auc: 1.0000\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0212 - auc: 0.9997\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0083 - auc: 0.9999\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0125 - auc: 0.9997\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0167 - auc: 0.9996\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0044 - auc: 0.9999\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0089 - auc: 0.9997\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0080 - auc: 0.9999\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0082 - auc: 1.0000\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0089 - auc: 0.9998\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0037 - auc: 0.9999\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 0.0067 - auc: 0.9999\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0032 - auc: 0.9999\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0030 - auc: 1.0000\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0041 - auc: 1.0000\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0033 - auc: 0.9999\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0037 - auc: 1.0000\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0018 - auc: 1.0000\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0040 - auc: 0.9999\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0040 - auc: 0.9999\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 3.1525e-04 - auc: 1.0000\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 7.6882e-05 - auc: 1.0000\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.5977e-05 - auc: 1.0000\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 4.1996e-04 - auc: 1.0000\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0014 - auc: 1.0000\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0021 - auc: 1.0000\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 9.0946e-04 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 8.4367e-04 - auc: 1.0000\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.5619e-04 - auc: 1.0000\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.2148e-04 - auc: 1.0000\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.3742e-04 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 4.7907e-05 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.3399e-04 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0012 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 3.4749e-05 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.7124e-05 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 9.4477e-06 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 7.0394e-06 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 9.7549e-06 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 8.9768e-06 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 4.0407e-05 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 3.4347e-06 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.8373e-06 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.3048e-06 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 1.5220e-05 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.3716e-06 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.6897e-05 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.2746e-06 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 1.1348e-06 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 1.7168e-06 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 1.2626e-06 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.2212e-06 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.2441e-06 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 1.8197e-06 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 1.0334e-06 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.1397e-07 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 5.3661e-07 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 1.2520e-06 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 1.1004e-06 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 9.9876e-07 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 7.0102e-07 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00855211601230525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.05100896176815933\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0085', 'eer_eval': '0.0510', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0085.hdf5', 'tnow': '2022-05-25 23:32:11.874216'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 43s 26ms/step - loss: 0.6746 - auc: 0.8741\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3819 - auc: 0.9587\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3563 - auc: 0.9633\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3357 - auc: 0.9667\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3332 - auc: 0.9653\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3136 - auc: 0.9690\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3168 - auc: 0.9691\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3148 - auc: 0.9715\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2989 - auc: 0.9726\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3152 - auc: 0.9723\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3031 - auc: 0.9728\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3124 - auc: 0.9737\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2890 - auc: 0.9750\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3014 - auc: 0.9758\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2951 - auc: 0.9779\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2928 - auc: 0.9767\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2867 - auc: 0.9759\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2979 - auc: 0.9780\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2858 - auc: 0.9788\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2854 - auc: 0.9782\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2893 - auc: 0.9807\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2905 - auc: 0.9774\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2722 - auc: 0.9802\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2803 - auc: 0.9794\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2794 - auc: 0.9799\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2797 - auc: 0.9808\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2836 - auc: 0.9810\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2744 - auc: 0.9813\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2733 - auc: 0.9813\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2835 - auc: 0.9830\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2808 - auc: 0.9810\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2759 - auc: 0.9833\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2827 - auc: 0.9817\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2600 - auc: 0.9823\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2845 - auc: 0.9830\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2748 - auc: 0.9837\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2881 - auc: 0.9836\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2669 - auc: 0.9848\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2873 - auc: 0.9848\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2739 - auc: 0.9846\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2627 - auc: 0.9845\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2721 - auc: 0.9846\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2653 - auc: 0.9846\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2575 - auc: 0.9846\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2673 - auc: 0.9860\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2601 - auc: 0.9863\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2699 - auc: 0.9858\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2617 - auc: 0.9866\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2606 - auc: 0.9853\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2694 - auc: 0.9856\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2615 - auc: 0.9872\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2648 - auc: 0.9867\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2587 - auc: 0.9859\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2611 - auc: 0.9870\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2666 - auc: 0.9862\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2713 - auc: 0.9860\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2507 - auc: 0.9859\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2584 - auc: 0.9868\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2586 - auc: 0.9864\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2663 - auc: 0.9872\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2667 - auc: 0.9865\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2615 - auc: 0.9865\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2659 - auc: 0.9864\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2669 - auc: 0.9875\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2625 - auc: 0.9870\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2701 - auc: 0.9867\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2651 - auc: 0.9876\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2696 - auc: 0.9866\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2574 - auc: 0.9866\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2618 - auc: 0.9872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.007610123292098803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.038906508453939045\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0076', 'eer_eval': '0.0389', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0076.hdf5', 'tnow': '2022-05-26 00:20:57.145604'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 43s 26ms/step - loss: 0.6232 - auc: 0.8868\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3806 - auc: 0.9626\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3569 - auc: 0.9644\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3306 - auc: 0.9659\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3357 - auc: 0.9688\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3087 - auc: 0.9676\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3005 - auc: 0.9700\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3310 - auc: 0.9689\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3191 - auc: 0.9715\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2990 - auc: 0.9739\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3015 - auc: 0.9730\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3069 - auc: 0.9758\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3012 - auc: 0.9769\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3067 - auc: 0.9758\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2959 - auc: 0.9752\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2965 - auc: 0.9777\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2858 - auc: 0.9769\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2811 - auc: 0.9812\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2863 - auc: 0.9802\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2793 - auc: 0.9798\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2914 - auc: 0.9793 0s - loss: 0.2\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2802 - auc: 0.9794\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2861 - auc: 0.9795\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2798 - auc: 0.9814\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2855 - auc: 0.9811\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2707 - auc: 0.9811\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2822 - auc: 0.9819\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2668 - auc: 0.9824\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2846 - auc: 0.9806\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2723 - auc: 0.9825\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2724 - auc: 0.9837\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2742 - auc: 0.9835\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2602 - auc: 0.9835\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2650 - auc: 0.9853\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2606 - auc: 0.9834\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2710 - auc: 0.9842\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2709 - auc: 0.9845\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2730 - auc: 0.9851\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2632 - auc: 0.9853\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2720 - auc: 0.9847\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2596 - auc: 0.9855\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2695 - auc: 0.9857\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2645 - auc: 0.9850\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2600 - auc: 0.9845\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2627 - auc: 0.9875\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2536 - auc: 0.9863\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2679 - auc: 0.9863\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2606 - auc: 0.9871\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2732 - auc: 0.9859\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2639 - auc: 0.9864\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2750 - auc: 0.9860\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2680 - auc: 0.9868\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2732 - auc: 0.9867\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2569 - auc: 0.9867\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2674 - auc: 0.9866\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2851 - auc: 0.9872\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2656 - auc: 0.9865\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2593 - auc: 0.9866\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2543 - auc: 0.9872\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2583 - auc: 0.9866\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2673 - auc: 0.9872\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2638 - auc: 0.9879\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2580 - auc: 0.9868\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2689 - auc: 0.9873\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2637 - auc: 0.9866\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2607 - auc: 0.9871\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2629 - auc: 0.9869\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2589 - auc: 0.9875\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2733 - auc: 0.9872\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2734 - auc: 0.9873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0060566084683324264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03171763457902857\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0060', 'eer_eval': '0.0317', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0060.hdf5', 'tnow': '2022-05-26 01:09:43.813707'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 44s 26ms/step - loss: 0.6086 - auc: 0.8936\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.4171 - auc: 0.9569\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3613 - auc: 0.9651\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3301 - auc: 0.9686\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3314 - auc: 0.9684\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3389 - auc: 0.9694\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3265 - auc: 0.9682\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3148 - auc: 0.9709\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3099 - auc: 0.9732\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2947 - auc: 0.9743\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3083 - auc: 0.9757\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2951 - auc: 0.9732\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2947 - auc: 0.9761\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2775 - auc: 0.9775\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2838 - auc: 0.9770\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2933 - auc: 0.9765\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2811 - auc: 0.9774\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2865 - auc: 0.9778\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2916 - auc: 0.9767\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2869 - auc: 0.9775\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2862 - auc: 0.9783\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2942 - auc: 0.9779\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2871 - auc: 0.9799\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2891 - auc: 0.9799\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2834 - auc: 0.9805\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2726 - auc: 0.9812\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2727 - auc: 0.9810\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2748 - auc: 0.9825\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2863 - auc: 0.9816\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2768 - auc: 0.9818\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2740 - auc: 0.9820\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2681 - auc: 0.9826\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2691 - auc: 0.9833\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2722 - auc: 0.9799\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2749 - auc: 0.9844\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2839 - auc: 0.9845\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2734 - auc: 0.9842\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2641 - auc: 0.9843\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2645 - auc: 0.9845\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2754 - auc: 0.9863\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2678 - auc: 0.9846\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2732 - auc: 0.9842\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2604 - auc: 0.9848\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2591 - auc: 0.9865\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2646 - auc: 0.9861\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2748 - auc: 0.9863\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2598 - auc: 0.9861\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2580 - auc: 0.9869\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2625 - auc: 0.9863\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2654 - auc: 0.9868\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2645 - auc: 0.9856\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2525 - auc: 0.9859\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2610 - auc: 0.9861\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2775 - auc: 0.9859\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2651 - auc: 0.9860\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2673 - auc: 0.9867\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2704 - auc: 0.9879\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2549 - auc: 0.9871\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2628 - auc: 0.9868\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2673 - auc: 0.9863\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2603 - auc: 0.9859\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2669 - auc: 0.9866\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2623 - auc: 0.9870\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2705 - auc: 0.9868\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2632 - auc: 0.9853\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2575 - auc: 0.9851\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2613 - auc: 0.9876\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2578 - auc: 0.9871\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2535 - auc: 0.9874\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2702 - auc: 0.9883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.006438048066250236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.037953047054250344\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0064', 'eer_eval': '0.0379', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0064.hdf5', 'tnow': '2022-05-26 01:56:37.064998'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 41s 25ms/step - loss: 0.6472 - auc: 0.8856\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3927 - auc: 0.9592\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3623 - auc: 0.9635\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3586 - auc: 0.9661\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3208 - auc: 0.9673\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3273 - auc: 0.9693\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3156 - auc: 0.9709\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3062 - auc: 0.9713\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3131 - auc: 0.9695\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3111 - auc: 0.9729\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2985 - auc: 0.9756\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2967 - auc: 0.9738\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2981 - auc: 0.9770\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3004 - auc: 0.9736\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2946 - auc: 0.9772\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2983 - auc: 0.9762\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2914 - auc: 0.9764\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2808 - auc: 0.9786\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2845 - auc: 0.9774\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2914 - auc: 0.9780\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2880 - auc: 0.9786\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3086 - auc: 0.9768\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2797 - auc: 0.9814\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2803 - auc: 0.9810\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2720 - auc: 0.9808\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2880 - auc: 0.9816\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2853 - auc: 0.9822\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2806 - auc: 0.9814\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2721 - auc: 0.9843\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2797 - auc: 0.9824\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2873 - auc: 0.9828\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2699 - auc: 0.9822\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2791 - auc: 0.9840\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2824 - auc: 0.9837\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2723 - auc: 0.9839\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2789 - auc: 0.9839\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2752 - auc: 0.9840\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2671 - auc: 0.9846\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2753 - auc: 0.9854\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2656 - auc: 0.9851\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2733 - auc: 0.9860\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2686 - auc: 0.9854\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2675 - auc: 0.9854\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2753 - auc: 0.9859\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2670 - auc: 0.9868\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2640 - auc: 0.9863\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2594 - auc: 0.9875\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2625 - auc: 0.9874\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2629 - auc: 0.9866\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2666 - auc: 0.9875\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2687 - auc: 0.9867\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2588 - auc: 0.9870\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2680 - auc: 0.9863\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2647 - auc: 0.9873\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2716 - auc: 0.9869\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2615 - auc: 0.9859\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2570 - auc: 0.9873\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2556 - auc: 0.9868\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2681 - auc: 0.9870\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2546 - auc: 0.9878\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2685 - auc: 0.9878\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2602 - auc: 0.9872\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2696 - auc: 0.9858\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2628 - auc: 0.9871\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2607 - auc: 0.9878\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2609 - auc: 0.9868\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2577 - auc: 0.9870\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2559 - auc: 0.9866\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2673 - auc: 0.9879\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2700 - auc: 0.9873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.007761480384374438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03542972529746276\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0077', 'eer_eval': '0.0354', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0077.hdf5', 'tnow': '2022-05-26 02:43:20.740384'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 41s 25ms/step - loss: 0.6256 - auc: 0.8873\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3837 - auc: 0.9590\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3663 - auc: 0.9654\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3294 - auc: 0.9643\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3314 - auc: 0.9658\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3204 - auc: 0.9700\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3297 - auc: 0.9690\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3242 - auc: 0.9697\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3137 - auc: 0.9713\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2996 - auc: 0.9730\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2965 - auc: 0.9733\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3056 - auc: 0.9753 1s - loss:\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2984 - auc: 0.9751\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3022 - auc: 0.9758\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2972 - auc: 0.9760\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2941 - auc: 0.9763\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2813 - auc: 0.9764\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2896 - auc: 0.9790\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2927 - auc: 0.9786\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2871 - auc: 0.9790\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2788 - auc: 0.9793\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2889 - auc: 0.9783\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2816 - auc: 0.9793\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2782 - auc: 0.9801\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2878 - auc: 0.9802\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2781 - auc: 0.9802\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2825 - auc: 0.9824\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2833 - auc: 0.9817\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2730 - auc: 0.9819\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2707 - auc: 0.9829\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2769 - auc: 0.9828\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2847 - auc: 0.9827\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2727 - auc: 0.9824\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2671 - auc: 0.9840\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2737 - auc: 0.9831\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2634 - auc: 0.9829\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2727 - auc: 0.9819\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2721 - auc: 0.9843\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2687 - auc: 0.9844\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2677 - auc: 0.9855\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2638 - auc: 0.9848\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2679 - auc: 0.9857\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2613 - auc: 0.9849\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2721 - auc: 0.9858\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2776 - auc: 0.9861\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2584 - auc: 0.9873\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2605 - auc: 0.9865\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2635 - auc: 0.9870\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2559 - auc: 0.9866\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2613 - auc: 0.9868\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2669 - auc: 0.9877\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2693 - auc: 0.9865\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2649 - auc: 0.9873\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2698 - auc: 0.9869\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2846 - auc: 0.9866\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2576 - auc: 0.9869\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2581 - auc: 0.9864\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2759 - auc: 0.9876\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2699 - auc: 0.9860\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2726 - auc: 0.9867\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2697 - auc: 0.9873\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2669 - auc: 0.9872\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2595 - auc: 0.9866\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2582 - auc: 0.9876\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2508 - auc: 0.9876\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2572 - auc: 0.9865\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2592 - auc: 0.9867\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2622 - auc: 0.9867\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2689 - auc: 0.9860\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2524 - auc: 0.9867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00623610945558787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03849117302679859\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0062', 'eer_eval': '0.0384', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0062.hdf5', 'tnow': '2022-05-26 03:29:54.443649'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 41s 25ms/step - loss: 0.6229 - auc: 0.8930\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.4020 - auc: 0.9579\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3612 - auc: 0.9612\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3335 - auc: 0.9658\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3326 - auc: 0.9670\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3218 - auc: 0.9698\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3337 - auc: 0.9696\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3240 - auc: 0.9701\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3153 - auc: 0.9716\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3018 - auc: 0.9734\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2918 - auc: 0.9757\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3016 - auc: 0.9741\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2969 - auc: 0.9736\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2994 - auc: 0.9762\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2963 - auc: 0.9761\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2944 - auc: 0.9775\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3016 - auc: 0.9773\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3005 - auc: 0.9775\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2904 - auc: 0.9790\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2773 - auc: 0.9786\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2925 - auc: 0.9781\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2859 - auc: 0.9790\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2887 - auc: 0.9794\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2781 - auc: 0.9798\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2929 - auc: 0.9805\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2838 - auc: 0.9805\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2857 - auc: 0.9807\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2772 - auc: 0.9813\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2752 - auc: 0.9813\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2753 - auc: 0.9832\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2764 - auc: 0.9829\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2648 - auc: 0.9825\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2704 - auc: 0.9837\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2849 - auc: 0.9838\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2722 - auc: 0.9829\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2671 - auc: 0.9852\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2683 - auc: 0.9859\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2746 - auc: 0.9857\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2689 - auc: 0.9851\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2717 - auc: 0.9840\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2706 - auc: 0.9846\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2675 - auc: 0.9868\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2668 - auc: 0.9861\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2664 - auc: 0.9857\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2679 - auc: 0.9869\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2669 - auc: 0.9848\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2750 - auc: 0.9853\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2572 - auc: 0.9857\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2571 - auc: 0.9861\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2711 - auc: 0.9874\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2743 - auc: 0.9861\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2718 - auc: 0.9879\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2628 - auc: 0.9871\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2741 - auc: 0.9876\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2538 - auc: 0.9867\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2673 - auc: 0.9868\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2578 - auc: 0.9862\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2656 - auc: 0.9871\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2711 - auc: 0.9866\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2703 - auc: 0.9872\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2715 - auc: 0.9853\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2631 - auc: 0.9867\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2599 - auc: 0.9870\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2733 - auc: 0.9869\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2678 - auc: 0.9859\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2611 - auc: 0.9877\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2698 - auc: 0.9868\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2675 - auc: 0.9864\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2586 - auc: 0.9862\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2689 - auc: 0.9878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00557439329652577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03792173786030556\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0055', 'eer_eval': '0.0379', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0055.hdf5', 'tnow': '2022-05-26 04:16:34.701070'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 41s 24ms/step - loss: 0.6567 - auc: 0.8768\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.3889 - auc: 0.9605\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3778 - auc: 0.9643\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3517 - auc: 0.9633\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3397 - auc: 0.9658\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3228 - auc: 0.9685\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3326 - auc: 0.9677\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3287 - auc: 0.9694\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3223 - auc: 0.9713\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3047 - auc: 0.9707\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3085 - auc: 0.9708\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3142 - auc: 0.9726\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3149 - auc: 0.9737\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2973 - auc: 0.9741\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3036 - auc: 0.9733\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2865 - auc: 0.9757\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2962 - auc: 0.9772\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2918 - auc: 0.9759\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2984 - auc: 0.9751\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2929 - auc: 0.9782\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2913 - auc: 0.9785\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2920 - auc: 0.9785\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2970 - auc: 0.9796\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2789 - auc: 0.9783\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2832 - auc: 0.9792\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2793 - auc: 0.9807\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2850 - auc: 0.9809\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2752 - auc: 0.9792\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2918 - auc: 0.9812\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2772 - auc: 0.9825\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2790 - auc: 0.9821\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2773 - auc: 0.9819\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2788 - auc: 0.9826\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2755 - auc: 0.9821\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2634 - auc: 0.9836\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2837 - auc: 0.9837\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2707 - auc: 0.9838\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2722 - auc: 0.9825\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2688 - auc: 0.9843\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2754 - auc: 0.9833\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2787 - auc: 0.9850\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2739 - auc: 0.9837\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2589 - auc: 0.9842\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2726 - auc: 0.9856\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2672 - auc: 0.9855\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2646 - auc: 0.9855\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2525 - auc: 0.9868\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2610 - auc: 0.9858\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2641 - auc: 0.9861\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2640 - auc: 0.9850\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2594 - auc: 0.9846\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2786 - auc: 0.9854\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2877 - auc: 0.9860\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2586 - auc: 0.9866\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2679 - auc: 0.9860\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2670 - auc: 0.9847\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2666 - auc: 0.9867\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2595 - auc: 0.9860\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2648 - auc: 0.9853\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2690 - auc: 0.9860\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2595 - auc: 0.9862\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2659 - auc: 0.9861\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2685 - auc: 0.9865\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2664 - auc: 0.9859\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2690 - auc: 0.9869\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2674 - auc: 0.9863\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2696 - auc: 0.9857\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2695 - auc: 0.9873\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2723 - auc: 0.9869\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2677 - auc: 0.9863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.004800489020428995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.020529506172065944\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [78, 79, 80, 81, 82]], 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0048', 'eer_eval': '0.0205', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0048.hdf5', 'tnow': '2022-05-26 05:02:55.033066'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 41s 24ms/step - loss: 0.6408 - auc: 0.8847\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3897 - auc: 0.9618\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3585 - auc: 0.9638\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3566 - auc: 0.9664\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.3422 - auc: 0.9655\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3358 - auc: 0.9652\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3199 - auc: 0.9691\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3127 - auc: 0.9699\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3327 - auc: 0.9707\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3110 - auc: 0.9708\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3007 - auc: 0.9744\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2881 - auc: 0.9735\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3072 - auc: 0.9746\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3073 - auc: 0.9731\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2952 - auc: 0.9767\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2808 - auc: 0.9756\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2978 - auc: 0.9759\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2914 - auc: 0.9775\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2998 - auc: 0.9787\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2820 - auc: 0.9793\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2873 - auc: 0.9782\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2890 - auc: 0.9787\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2859 - auc: 0.9790\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2896 - auc: 0.9793\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2875 - auc: 0.9791\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2926 - auc: 0.9797\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2816 - auc: 0.9816\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2798 - auc: 0.9810\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2850 - auc: 0.9801\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2729 - auc: 0.9821\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2710 - auc: 0.9817\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2822 - auc: 0.9825\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2696 - auc: 0.9804\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2700 - auc: 0.9848\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2654 - auc: 0.9841\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2813 - auc: 0.9834\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2689 - auc: 0.9844\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2693 - auc: 0.9831\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2672 - auc: 0.9838\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2659 - auc: 0.9841\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2731 - auc: 0.9839\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2667 - auc: 0.9847\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2727 - auc: 0.9861\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2678 - auc: 0.9846\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2629 - auc: 0.9854\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2510 - auc: 0.9849\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2526 - auc: 0.9858\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2730 - auc: 0.9854\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2726 - auc: 0.9866\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2717 - auc: 0.9832\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2662 - auc: 0.9856\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2647 - auc: 0.9858\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2615 - auc: 0.9860\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2564 - auc: 0.9869\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2680 - auc: 0.9861\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2730 - auc: 0.9862\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2668 - auc: 0.9851\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2606 - auc: 0.9875\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2573 - auc: 0.9866\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2569 - auc: 0.9853\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2826 - auc: 0.9849\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2706 - auc: 0.9861\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2693 - auc: 0.9866\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 38s 24ms/step - loss: 0.2772 - auc: 0.9858\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2715 - auc: 0.9859\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2483 - auc: 0.9859\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2716 - auc: 0.9866\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2590 - auc: 0.9871\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2531 - auc: 0.9867\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2792 - auc: 0.9869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0045536751629527816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.021866993804950316\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [78, 79, 80, 81, 82]], 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0045', 'eer_eval': '0.0218', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0045.hdf5', 'tnow': '2022-05-26 05:49:16.343058'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 41s 24ms/step - loss: 0.6687 - auc: 0.8759\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3968 - auc: 0.9585\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3627 - auc: 0.9617\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3550 - auc: 0.9659\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3449 - auc: 0.9661\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3403 - auc: 0.9679\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3355 - auc: 0.9661\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3336 - auc: 0.9679\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3213 - auc: 0.9694\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3092 - auc: 0.9711\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3165 - auc: 0.9705\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3007 - auc: 0.9727\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3144 - auc: 0.9740\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2959 - auc: 0.9740\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3086 - auc: 0.9758\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2997 - auc: 0.9760\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2926 - auc: 0.9761\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2981 - auc: 0.9762\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2941 - auc: 0.9774\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2997 - auc: 0.9772\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2877 - auc: 0.9782\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3005 - auc: 0.9783\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2968 - auc: 0.9766\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2830 - auc: 0.9799\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2792 - auc: 0.9800\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2878 - auc: 0.9802\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2851 - auc: 0.9816\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2843 - auc: 0.9784\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2784 - auc: 0.9802\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2899 - auc: 0.9806\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2776 - auc: 0.9798\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2954 - auc: 0.9817\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2761 - auc: 0.9830\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2826 - auc: 0.9819\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2676 - auc: 0.9826\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2820 - auc: 0.9828\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2824 - auc: 0.9825\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2650 - auc: 0.9830\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2748 - auc: 0.9826\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2762 - auc: 0.9832\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2745 - auc: 0.9846\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2722 - auc: 0.9853\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2617 - auc: 0.9864\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2726 - auc: 0.9856\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2743 - auc: 0.9849\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2611 - auc: 0.9841\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2636 - auc: 0.9858\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2646 - auc: 0.9856\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2672 - auc: 0.9846\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2615 - auc: 0.9859\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2642 - auc: 0.9856\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2590 - auc: 0.9856\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2708 - auc: 0.9868\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2617 - auc: 0.9862\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2632 - auc: 0.9864\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2650 - auc: 0.9859\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2691 - auc: 0.9871\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2646 - auc: 0.9859\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2576 - auc: 0.9847\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2659 - auc: 0.9862\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2558 - auc: 0.9859\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2617 - auc: 0.9861\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2692 - auc: 0.9850\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2677 - auc: 0.9856\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2610 - auc: 0.9856\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2642 - auc: 0.9865\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2665 - auc: 0.9861\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2677 - auc: 0.9866\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2732 - auc: 0.9860\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2638 - auc: 0.9864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.005815500882429098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.019753626407188453\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [78, 79, 80, 81, 82]], 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0058', 'eer_eval': '0.0197', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0058.hdf5', 'tnow': '2022-05-26 06:35:46.831770'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 42s 25ms/step - loss: 0.6644 - auc: 0.8781\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.4234 - auc: 0.9569\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3803 - auc: 0.9625\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3549 - auc: 0.9649\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3520 - auc: 0.9652\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3654 - auc: 0.9663\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3361 - auc: 0.9656\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3331 - auc: 0.9675\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3253 - auc: 0.9685\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3115 - auc: 0.9711\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3018 - auc: 0.9702\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3041 - auc: 0.9721\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3106 - auc: 0.9711\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2991 - auc: 0.9748\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3015 - auc: 0.9727\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2980 - auc: 0.9765\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3005 - auc: 0.9740\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2878 - auc: 0.9770\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2813 - auc: 0.9776\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2975 - auc: 0.9779\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2921 - auc: 0.9765\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2847 - auc: 0.9777\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2931 - auc: 0.9762\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2846 - auc: 0.9772\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2955 - auc: 0.9787\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2756 - auc: 0.9786\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2879 - auc: 0.9804\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2854 - auc: 0.9794\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2709 - auc: 0.9803\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2912 - auc: 0.9810\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2791 - auc: 0.9821\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2690 - auc: 0.9804\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2837 - auc: 0.9805\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2802 - auc: 0.9797\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2751 - auc: 0.9815\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2735 - auc: 0.9813\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2717 - auc: 0.9827\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2791 - auc: 0.9834\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2834 - auc: 0.9827\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2672 - auc: 0.9844\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2655 - auc: 0.9828\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2862 - auc: 0.9836\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2659 - auc: 0.9843\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2696 - auc: 0.9830\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2661 - auc: 0.9841\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2615 - auc: 0.9840\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2710 - auc: 0.9850\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2714 - auc: 0.9851\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2687 - auc: 0.9843\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2902 - auc: 0.9858\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2820 - auc: 0.9842\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2621 - auc: 0.9841\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2662 - auc: 0.9856\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2624 - auc: 0.9838\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2597 - auc: 0.9851\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2644 - auc: 0.9851\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2577 - auc: 0.9836\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2535 - auc: 0.9857\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2663 - auc: 0.9841\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2613 - auc: 0.9856\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2725 - auc: 0.9860\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2604 - auc: 0.9855\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2700 - auc: 0.9867\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2828 - auc: 0.9863\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2718 - auc: 0.9858\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2682 - auc: 0.9842\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2719 - auc: 0.9855\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2626 - auc: 0.9869\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2650 - auc: 0.9844\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2703 - auc: 0.9857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0067126183558216986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.048749321929531096\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [10, 11, 12, 13, 14]], 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0067', 'eer_eval': '0.0487', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0067.hdf5', 'tnow': '2022-05-26 07:22:20.941783'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 41s 25ms/step - loss: 0.6773 - auc: 0.8751\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.4194 - auc: 0.9576\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3719 - auc: 0.9606\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3741 - auc: 0.9602\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3445 - auc: 0.9645\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3473 - auc: 0.9649\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3378 - auc: 0.9682\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3182 - auc: 0.9681\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3173 - auc: 0.9694\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3193 - auc: 0.9702\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3148 - auc: 0.9701 0s - loss: 0.3148 \n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3297 - auc: 0.9699\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3132 - auc: 0.9703\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3069 - auc: 0.9729\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2882 - auc: 0.9713\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3057 - auc: 0.9733\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3022 - auc: 0.9726\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2925 - auc: 0.9761\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2943 - auc: 0.9739\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2898 - auc: 0.9764\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2955 - auc: 0.9767\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3099 - auc: 0.9770\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3011 - auc: 0.9761\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2832 - auc: 0.9778\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3006 - auc: 0.9780\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2854 - auc: 0.9782\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2843 - auc: 0.9777\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2899 - auc: 0.9790\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2820 - auc: 0.9815\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2888 - auc: 0.9807\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2856 - auc: 0.9785\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2844 - auc: 0.9807\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2869 - auc: 0.9813\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2923 - auc: 0.9822\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2796 - auc: 0.9818\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2716 - auc: 0.9811\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2730 - auc: 0.9806\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2804 - auc: 0.9816\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2921 - auc: 0.9809\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2758 - auc: 0.9841\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2733 - auc: 0.9828\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2789 - auc: 0.9834\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2743 - auc: 0.9828\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2781 - auc: 0.9824\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2683 - auc: 0.9839\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2678 - auc: 0.9838\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2687 - auc: 0.9845\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2736 - auc: 0.9839\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2631 - auc: 0.9833\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2674 - auc: 0.9835\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2701 - auc: 0.9837\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2637 - auc: 0.9836\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2605 - auc: 0.9854\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2780 - auc: 0.9840\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2812 - auc: 0.9843\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2567 - auc: 0.9849\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2622 - auc: 0.9856\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2807 - auc: 0.9856\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2611 - auc: 0.9850\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2701 - auc: 0.9850\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2578 - auc: 0.9847\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2760 - auc: 0.9850\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2842 - auc: 0.9842\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2735 - auc: 0.9836\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2615 - auc: 0.9852\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2576 - auc: 0.9855\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2798 - auc: 0.9852\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2722 - auc: 0.9845\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2747 - auc: 0.9849\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2630 - auc: 0.9836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.009309288936567985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0393374984780519\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [10, 11, 12, 13, 14]], 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0093', 'eer_eval': '0.0393', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0093.hdf5', 'tnow': '2022-05-26 08:09:02.000006'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 42s 25ms/step - loss: 0.6742 - auc: 0.8747\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.4212 - auc: 0.9539\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3864 - auc: 0.9603\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3490 - auc: 0.9645\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3418 - auc: 0.9665\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3450 - auc: 0.9659\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3238 - auc: 0.9670\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3406 - auc: 0.9674\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3323 - auc: 0.9673\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3220 - auc: 0.9694\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3102 - auc: 0.9724\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3078 - auc: 0.9726\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3081 - auc: 0.9732\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3052 - auc: 0.9727\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3017 - auc: 0.9741\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3112 - auc: 0.9739\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3038 - auc: 0.9742\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2853 - auc: 0.9766\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2935 - auc: 0.9754\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2999 - auc: 0.9771\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2960 - auc: 0.9759\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2950 - auc: 0.9778\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2932 - auc: 0.9767\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2947 - auc: 0.9774\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2829 - auc: 0.9793\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2852 - auc: 0.9782\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2859 - auc: 0.9795\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2992 - auc: 0.9795\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2805 - auc: 0.9799\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2829 - auc: 0.9806\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2777 - auc: 0.9810\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2889 - auc: 0.9809\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2955 - auc: 0.9815\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2723 - auc: 0.9813\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2732 - auc: 0.9828\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2642 - auc: 0.9816\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2753 - auc: 0.9817\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2692 - auc: 0.9826\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2812 - auc: 0.9824\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2709 - auc: 0.9839\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2709 - auc: 0.9846\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2609 - auc: 0.9839\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2612 - auc: 0.9845\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2734 - auc: 0.9832\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2648 - auc: 0.9850\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2643 - auc: 0.9832\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2726 - auc: 0.9837\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2742 - auc: 0.9848\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2707 - auc: 0.9847\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2770 - auc: 0.9838\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2552 - auc: 0.9855\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2740 - auc: 0.9851\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2691 - auc: 0.9864\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2607 - auc: 0.9860\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2660 - auc: 0.9849\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2842 - auc: 0.9857\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2717 - auc: 0.9853\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2726 - auc: 0.9851\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2596 - auc: 0.9861\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2771 - auc: 0.9849\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2612 - auc: 0.9854\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2560 - auc: 0.9846\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2604 - auc: 0.9854\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2680 - auc: 0.9858\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2682 - auc: 0.9854\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2688 - auc: 0.9848\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2662 - auc: 0.9842\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2626 - auc: 0.9857\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2702 - auc: 0.9854\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2719 - auc: 0.9843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.005607856000193846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.050071154965443024\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [10, 11, 12, 13, 14]], 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0056', 'eer_eval': '0.0500', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0056.hdf5', 'tnow': '2022-05-26 08:55:43.133140'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 41s 25ms/step - loss: 0.6813 - auc: 0.8750\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3961 - auc: 0.9566\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3588 - auc: 0.9613\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3518 - auc: 0.9641\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3513 - auc: 0.9636\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3376 - auc: 0.9666\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3420 - auc: 0.9678\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3240 - auc: 0.9695\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3198 - auc: 0.9699\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3216 - auc: 0.9717\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3099 - auc: 0.9712\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3202 - auc: 0.9720\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3095 - auc: 0.9733\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2988 - auc: 0.9745\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3094 - auc: 0.9743\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2960 - auc: 0.9750\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2888 - auc: 0.9752\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2940 - auc: 0.9750\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3089 - auc: 0.9756\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3013 - auc: 0.9774\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2911 - auc: 0.9762\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2894 - auc: 0.9764\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2928 - auc: 0.9776\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2822 - auc: 0.9777\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2886 - auc: 0.9785\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2789 - auc: 0.9792\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2806 - auc: 0.9790\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2788 - auc: 0.9789\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2810 - auc: 0.9815\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2831 - auc: 0.9797\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2903 - auc: 0.9795\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2678 - auc: 0.9811\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2885 - auc: 0.9809\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2852 - auc: 0.9805\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2869 - auc: 0.9808\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2867 - auc: 0.9820\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2735 - auc: 0.9817\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2721 - auc: 0.9825\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2919 - auc: 0.9822\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2700 - auc: 0.9838\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2773 - auc: 0.9820\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2810 - auc: 0.9824\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2754 - auc: 0.9832\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2780 - auc: 0.9835\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2744 - auc: 0.9841\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2734 - auc: 0.9842\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2712 - auc: 0.9848\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2595 - auc: 0.9839\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2768 - auc: 0.9841\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2709 - auc: 0.9854\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2806 - auc: 0.9847\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2677 - auc: 0.9839\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2648 - auc: 0.9854\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2698 - auc: 0.9842\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2600 - auc: 0.9841\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2610 - auc: 0.9850\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2654 - auc: 0.9865\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2768 - auc: 0.9856\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2626 - auc: 0.9854\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2757 - auc: 0.9844\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2637 - auc: 0.9851\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2661 - auc: 0.9859\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2693 - auc: 0.9851\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2745 - auc: 0.9854\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2659 - auc: 0.9842\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2729 - auc: 0.9860\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2617 - auc: 0.9842\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2740 - auc: 0.9853\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2612 - auc: 0.9850\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2686 - auc: 0.9853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00541732993267725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.05360028298095128\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0054', 'eer_eval': '0.0536', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0054.hdf5', 'tnow': '2022-05-26 09:42:19.521600'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 41s 25ms/step - loss: 0.6572 - auc: 0.8826\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.4095 - auc: 0.9570 1s - l\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3928 - auc: 0.9612\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3645 - auc: 0.9632\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3457 - auc: 0.9642\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3224 - auc: 0.9675\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3328 - auc: 0.9672\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3111 - auc: 0.9692\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3131 - auc: 0.9716\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3089 - auc: 0.9713\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3096 - auc: 0.9716\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3154 - auc: 0.9732\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2934 - auc: 0.9742\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2949 - auc: 0.9725\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2976 - auc: 0.9725\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3008 - auc: 0.9743\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3084 - auc: 0.9732\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2909 - auc: 0.9747\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2889 - auc: 0.9774\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2815 - auc: 0.9766\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3064 - auc: 0.9779\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2828 - auc: 0.9775\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2890 - auc: 0.9772\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2829 - auc: 0.9798\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2918 - auc: 0.9786\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2857 - auc: 0.9792\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2857 - auc: 0.9789\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2839 - auc: 0.9798\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2859 - auc: 0.9807\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2805 - auc: 0.9809\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2849 - auc: 0.9801\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2738 - auc: 0.9804\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2907 - auc: 0.9822\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2728 - auc: 0.9821\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2746 - auc: 0.9817\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2751 - auc: 0.9812\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2756 - auc: 0.9832\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2705 - auc: 0.9832\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2855 - auc: 0.9826\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2745 - auc: 0.9841\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2691 - auc: 0.9845\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2671 - auc: 0.9838\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2700 - auc: 0.9845\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2656 - auc: 0.9836\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2634 - auc: 0.9844\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2674 - auc: 0.9849\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2697 - auc: 0.9862\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2707 - auc: 0.9852\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2718 - auc: 0.9842\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2609 - auc: 0.9846\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2728 - auc: 0.9854\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2696 - auc: 0.9843\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2616 - auc: 0.9841\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2732 - auc: 0.9846\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2762 - auc: 0.9850 0s - loss: 0.2762 -\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2636 - auc: 0.9862\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2835 - auc: 0.9854\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2689 - auc: 0.9843\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2613 - auc: 0.9854\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2617 - auc: 0.9848\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2661 - auc: 0.9837\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2786 - auc: 0.9854\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2676 - auc: 0.9848\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2626 - auc: 0.9860\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2655 - auc: 0.9847\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2684 - auc: 0.9857\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2733 - auc: 0.9853\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2707 - auc: 0.9856\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2682 - auc: 0.9849\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2702 - auc: 0.9848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00623610945558787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.04222136457257658\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0062', 'eer_eval': '0.0422', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0062.hdf5', 'tnow': '2022-05-26 10:28:56.337282'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 42s 25ms/step - loss: 0.6551 - auc: 0.8769\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.4105 - auc: 0.9553\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3801 - auc: 0.9592\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3535 - auc: 0.9633\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3642 - auc: 0.9656\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3408 - auc: 0.9654\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3411 - auc: 0.9687\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3379 - auc: 0.9691\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3167 - auc: 0.9687\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3104 - auc: 0.9707\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2999 - auc: 0.9719\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3131 - auc: 0.9714\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3005 - auc: 0.9741\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3139 - auc: 0.9739\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3093 - auc: 0.9729\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2850 - auc: 0.9758\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2986 - auc: 0.9744\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2967 - auc: 0.9739\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2973 - auc: 0.9765\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2953 - auc: 0.9759\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3051 - auc: 0.9756\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2904 - auc: 0.9761\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2853 - auc: 0.9791\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3081 - auc: 0.9783\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2917 - auc: 0.9778\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2852 - auc: 0.9785\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2882 - auc: 0.9810\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2966 - auc: 0.9787\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2984 - auc: 0.9795\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2785 - auc: 0.9800\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2753 - auc: 0.9821\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2725 - auc: 0.9808\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2812 - auc: 0.9819\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2877 - auc: 0.9804\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2797 - auc: 0.9818\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2622 - auc: 0.9814\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2749 - auc: 0.9827\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2825 - auc: 0.9829\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2712 - auc: 0.9828\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2703 - auc: 0.9824\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2718 - auc: 0.9841\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2714 - auc: 0.9844\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2734 - auc: 0.9838\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2778 - auc: 0.9842\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2619 - auc: 0.9833\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2647 - auc: 0.9848\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2633 - auc: 0.9847\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2735 - auc: 0.9845\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2678 - auc: 0.9841\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2726 - auc: 0.9855\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2662 - auc: 0.9849\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2701 - auc: 0.9841\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2616 - auc: 0.9852\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2705 - auc: 0.9848\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2623 - auc: 0.9857\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2618 - auc: 0.9850\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2703 - auc: 0.9866\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2726 - auc: 0.9856\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2644 - auc: 0.9854\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2801 - auc: 0.9844\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2668 - auc: 0.9843\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2672 - auc: 0.9854\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2703 - auc: 0.9847\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2661 - auc: 0.9841\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2707 - auc: 0.9855\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2605 - auc: 0.9865\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2747 - auc: 0.9846\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2598 - auc: 0.9858\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2667 - auc: 0.9860\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2592 - auc: 0.9859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00962341566426497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.049209174917217324\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0096', 'eer_eval': '0.0492', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0096.hdf5', 'tnow': '2022-05-26 11:17:42.201263'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 43s 26ms/step - loss: 0.6971 - auc: 0.8696\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.4253 - auc: 0.9549\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.4051 - auc: 0.9570\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3660 - auc: 0.9628\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3609 - auc: 0.9633\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3554 - auc: 0.9645\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3617 - auc: 0.9662\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3385 - auc: 0.9673\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3369 - auc: 0.9664\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3152 - auc: 0.9681\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3370 - auc: 0.9709\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3183 - auc: 0.9690\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3290 - auc: 0.9702\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3081 - auc: 0.9721\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3224 - auc: 0.9717\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3135 - auc: 0.9734\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2983 - auc: 0.9736\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3079 - auc: 0.9743\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3142 - auc: 0.9740\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2936 - auc: 0.9757\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3002 - auc: 0.9750\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2991 - auc: 0.9743\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2886 - auc: 0.9760\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2946 - auc: 0.9773\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2844 - auc: 0.9760\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2870 - auc: 0.9787\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2889 - auc: 0.9782\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2867 - auc: 0.9794\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2810 - auc: 0.9781\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2849 - auc: 0.9786\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2801 - auc: 0.9795\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2791 - auc: 0.9807\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2997 - auc: 0.9781\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2883 - auc: 0.9800\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2858 - auc: 0.9794\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2881 - auc: 0.9807\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2862 - auc: 0.9813\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2810 - auc: 0.9804\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2982 - auc: 0.9818\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2702 - auc: 0.9805\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2789 - auc: 0.9824\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2801 - auc: 0.9831\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2802 - auc: 0.9824\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2791 - auc: 0.9818\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2763 - auc: 0.9829\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2744 - auc: 0.9834\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2743 - auc: 0.9824\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2704 - auc: 0.9823\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2677 - auc: 0.9825\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2674 - auc: 0.9846\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2742 - auc: 0.9838\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2621 - auc: 0.9847\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2784 - auc: 0.9821\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2649 - auc: 0.9833\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2700 - auc: 0.9829\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2687 - auc: 0.9848\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2706 - auc: 0.9845\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2653 - auc: 0.9838\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2817 - auc: 0.9829\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2842 - auc: 0.9829\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2678 - auc: 0.9831\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2790 - auc: 0.9835\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2783 - auc: 0.9841\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2808 - auc: 0.9835\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2612 - auc: 0.9839\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2583 - auc: 0.9842\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2732 - auc: 0.9852\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2700 - auc: 0.9841\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2641 - auc: 0.9842\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2801 - auc: 0.9839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0058379385058360215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.035622961529246294\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [78, 79, 80, 81, 82]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0058', 'eer_eval': '0.0356', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0058.hdf5', 'tnow': '2022-05-26 12:06:42.443863'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 43s 26ms/step - loss: 0.7011 - auc: 0.8722\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.4345 - auc: 0.9527\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3911 - auc: 0.9621\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3670 - auc: 0.9624\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3761 - auc: 0.9607\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 0.3519 - auc: 0.9647\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3391 - auc: 0.9673\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3298 - auc: 0.9693 0s - loss: 0.3298\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3291 - auc: 0.9682\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3146 - auc: 0.9705\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3321 - auc: 0.9696\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3216 - auc: 0.9683\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3021 - auc: 0.9736\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3012 - auc: 0.9727\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3044 - auc: 0.9752\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3082 - auc: 0.9718\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3016 - auc: 0.9751\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3003 - auc: 0.9745\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3002 - auc: 0.9755\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3024 - auc: 0.9755\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2901 - auc: 0.9773\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2895 - auc: 0.9774\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2834 - auc: 0.9779\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2883 - auc: 0.9762\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3039 - auc: 0.9768\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2879 - auc: 0.9793\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2829 - auc: 0.9776\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2823 - auc: 0.9797\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2744 - auc: 0.9802\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2880 - auc: 0.9782\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2885 - auc: 0.9779\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2848 - auc: 0.9801\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2861 - auc: 0.9815\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3012 - auc: 0.9817\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2713 - auc: 0.9818\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2714 - auc: 0.9820\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2581 - auc: 0.9824\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2829 - auc: 0.9819\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2811 - auc: 0.9816\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2675 - auc: 0.9834\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2753 - auc: 0.9840\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2831 - auc: 0.9821\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2724 - auc: 0.9831\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2879 - auc: 0.9833\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2816 - auc: 0.9836\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2610 - auc: 0.9831\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2675 - auc: 0.9842\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2647 - auc: 0.9844\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2818 - auc: 0.9828\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2704 - auc: 0.9837\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2749 - auc: 0.9847\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2598 - auc: 0.9852\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2640 - auc: 0.9847\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2691 - auc: 0.9848\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2576 - auc: 0.9832\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2592 - auc: 0.9833\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2683 - auc: 0.9865\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2654 - auc: 0.9859\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2600 - auc: 0.9858\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2711 - auc: 0.9855\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2670 - auc: 0.9856\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2813 - auc: 0.9850\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2540 - auc: 0.9838\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2878 - auc: 0.9838\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2770 - auc: 0.9841\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2771 - auc: 0.9846\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2732 - auc: 0.9864\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2622 - auc: 0.9859\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2603 - auc: 0.9857\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2719 - auc: 0.9846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.006656718028746642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.02909500417229178\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [78, 79, 80, 81, 82]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0066', 'eer_eval': '0.0290', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0066.hdf5', 'tnow': '2022-05-26 12:54:25.023353'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 42s 25ms/step - loss: 0.6899 - auc: 0.8690\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.4428 - auc: 0.9538\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3987 - auc: 0.9595\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3694 - auc: 0.9623\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3455 - auc: 0.9654\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3521 - auc: 0.9653\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3270 - auc: 0.9666\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3363 - auc: 0.9663\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3231 - auc: 0.9695\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3266 - auc: 0.9680\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3150 - auc: 0.9693\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3052 - auc: 0.9717\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3056 - auc: 0.9720\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3038 - auc: 0.9735\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3101 - auc: 0.9721\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3214 - auc: 0.9726\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2982 - auc: 0.9744\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3183 - auc: 0.9733\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3053 - auc: 0.9745\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2955 - auc: 0.9747\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3033 - auc: 0.9744\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2968 - auc: 0.9758\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3045 - auc: 0.9753\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2922 - auc: 0.9757\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2976 - auc: 0.9758\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2983 - auc: 0.9777\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2930 - auc: 0.9777\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2826 - auc: 0.9794\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2824 - auc: 0.9788\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2793 - auc: 0.9799\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3027 - auc: 0.9791\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2695 - auc: 0.9807\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2868 - auc: 0.9800\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2871 - auc: 0.9810\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2851 - auc: 0.9796\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2738 - auc: 0.9816\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2690 - auc: 0.9813\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2748 - auc: 0.9811\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2808 - auc: 0.9820\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2619 - auc: 0.9830\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2840 - auc: 0.9831\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2766 - auc: 0.9830\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2662 - auc: 0.9834\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2776 - auc: 0.9850\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2675 - auc: 0.9808\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2676 - auc: 0.9833\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2725 - auc: 0.9844\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2737 - auc: 0.9844\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2625 - auc: 0.9832\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2790 - auc: 0.9845\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2686 - auc: 0.9844\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2832 - auc: 0.9841\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2751 - auc: 0.9846\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2686 - auc: 0.9851\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2715 - auc: 0.9848\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2710 - auc: 0.9829\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2751 - auc: 0.9846\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2674 - auc: 0.9846\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2790 - auc: 0.9837\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2762 - auc: 0.9841\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2668 - auc: 0.9846\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2659 - auc: 0.9836\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2804 - auc: 0.9844\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2665 - auc: 0.9852\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2768 - auc: 0.9845\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2710 - auc: 0.9845\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2725 - auc: 0.9851\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2648 - auc: 0.9847\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2770 - auc: 0.9857\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2786 - auc: 0.9832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.006068021011478197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.029348412561593533\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [78, 79, 80, 81, 82]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0060', 'eer_eval': '0.0293', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0060.hdf5', 'tnow': '2022-05-26 13:41:13.250297'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 41s 25ms/step - loss: 0.6474 - auc: 0.8809\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.4035 - auc: 0.9615\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3767 - auc: 0.9612\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3396 - auc: 0.9646\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3323 - auc: 0.9663\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3372 - auc: 0.9680\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3550 - auc: 0.9670\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3159 - auc: 0.9682\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3203 - auc: 0.9699\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3261 - auc: 0.9712\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3119 - auc: 0.9723\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3098 - auc: 0.9715\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3022 - auc: 0.9746\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3134 - auc: 0.9736\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2999 - auc: 0.9733\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2933 - auc: 0.9735\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3037 - auc: 0.9761\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3021 - auc: 0.9742\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2918 - auc: 0.9762\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3016 - auc: 0.9778\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2879 - auc: 0.9775\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2842 - auc: 0.9783\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2901 - auc: 0.9769\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2955 - auc: 0.9802\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2922 - auc: 0.9786\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2784 - auc: 0.9794\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2878 - auc: 0.9793\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2897 - auc: 0.9788\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2786 - auc: 0.9801\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2875 - auc: 0.9809\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2867 - auc: 0.9816\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2776 - auc: 0.9817\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2840 - auc: 0.9810\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2802 - auc: 0.9818\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2821 - auc: 0.9813\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2782 - auc: 0.9827\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2799 - auc: 0.9831\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2887 - auc: 0.9833\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2590 - auc: 0.9844\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2650 - auc: 0.9838\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2658 - auc: 0.9830\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2676 - auc: 0.9833\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2750 - auc: 0.9828\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2682 - auc: 0.9843\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2522 - auc: 0.9826\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2638 - auc: 0.9852\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2696 - auc: 0.9849\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2740 - auc: 0.9844\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2755 - auc: 0.9851\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2612 - auc: 0.9845\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2638 - auc: 0.9844\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2746 - auc: 0.9849\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2616 - auc: 0.9839\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2693 - auc: 0.9855\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2670 - auc: 0.9841\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2736 - auc: 0.9855\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2698 - auc: 0.9863\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2660 - auc: 0.9859\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2717 - auc: 0.9851\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2775 - auc: 0.9852\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2746 - auc: 0.9858\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2676 - auc: 0.9855\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2753 - auc: 0.9852\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2658 - auc: 0.9856\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2696 - auc: 0.9854\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2624 - auc: 0.9861\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2706 - auc: 0.9863\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2691 - auc: 0.9861\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2610 - auc: 0.9861\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2722 - auc: 0.9860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.004839657995670012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.01874537391809633\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0048', 'eer_eval': '0.0187', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0048.hdf5', 'tnow': '2022-05-26 14:27:53.720605'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 42s 25ms/step - loss: 0.6448 - auc: 0.8870\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3959 - auc: 0.9593\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3684 - auc: 0.9640\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3653 - auc: 0.9646\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3514 - auc: 0.9649\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3426 - auc: 0.9673\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3205 - auc: 0.9681\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3196 - auc: 0.9703\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3243 - auc: 0.9703\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3260 - auc: 0.9698\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3161 - auc: 0.9717\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2953 - auc: 0.9736\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3118 - auc: 0.9753\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2911 - auc: 0.9748\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3086 - auc: 0.9741\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3038 - auc: 0.9762\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2969 - auc: 0.9773\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2979 - auc: 0.9755\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3020 - auc: 0.9771\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2836 - auc: 0.9789\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2983 - auc: 0.9768\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2970 - auc: 0.9773\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2898 - auc: 0.9788\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2907 - auc: 0.9775\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2752 - auc: 0.9801\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2880 - auc: 0.9805\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2836 - auc: 0.9791\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2827 - auc: 0.9798\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2839 - auc: 0.9820\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2829 - auc: 0.9809\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2814 - auc: 0.9818\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2646 - auc: 0.9820\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2690 - auc: 0.9828\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2709 - auc: 0.9835\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2800 - auc: 0.9826\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2736 - auc: 0.9838\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2707 - auc: 0.9837\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2770 - auc: 0.9839\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2763 - auc: 0.9846\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2727 - auc: 0.9840\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2728 - auc: 0.9846\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2605 - auc: 0.9848\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2699 - auc: 0.9844\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2601 - auc: 0.9852\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2713 - auc: 0.9861\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2666 - auc: 0.9863\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2677 - auc: 0.9861\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2730 - auc: 0.9844\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2655 - auc: 0.9865\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2640 - auc: 0.9851\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2653 - auc: 0.9865\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2609 - auc: 0.9862\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2672 - auc: 0.9849\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2638 - auc: 0.9851\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2762 - auc: 0.9858\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2712 - auc: 0.9859\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2633 - auc: 0.9857\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2472 - auc: 0.9859\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2756 - auc: 0.9846\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2644 - auc: 0.9856\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2745 - auc: 0.9863\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2604 - auc: 0.9870\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2516 - auc: 0.9863\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2723 - auc: 0.9861\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2684 - auc: 0.9859\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2610 - auc: 0.9857\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2678 - auc: 0.9872\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2588 - auc: 0.9864\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2689 - auc: 0.9860\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2627 - auc: 0.9862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.005927688999463771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.02094484159920646\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0059', 'eer_eval': '0.0209', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0059.hdf5', 'tnow': '2022-05-26 15:14:36.827834'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 41s 25ms/step - loss: 0.6646 - auc: 0.8722\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3994 - auc: 0.9588\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3721 - auc: 0.9633\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3620 - auc: 0.9650\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3599 - auc: 0.9654\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3440 - auc: 0.9680\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3221 - auc: 0.9682\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3180 - auc: 0.9722\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.3110 - auc: 0.9714\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3267 - auc: 0.9731\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3031 - auc: 0.9718\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3051 - auc: 0.9729\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3173 - auc: 0.9718\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2969 - auc: 0.9744\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3063 - auc: 0.9766\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2929 - auc: 0.9774\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3179 - auc: 0.9726\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2970 - auc: 0.9761\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2945 - auc: 0.9745\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2834 - auc: 0.9783\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2817 - auc: 0.9788\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2867 - auc: 0.9796\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2940 - auc: 0.9786\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2952 - auc: 0.9781\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2947 - auc: 0.9801\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2771 - auc: 0.9800\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2831 - auc: 0.9800\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2845 - auc: 0.9804\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2832 - auc: 0.9810\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2796 - auc: 0.9806\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2748 - auc: 0.9811\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2850 - auc: 0.9827\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2811 - auc: 0.9830\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2834 - auc: 0.9830\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2820 - auc: 0.9823\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2639 - auc: 0.9850\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2820 - auc: 0.9839\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2623 - auc: 0.9833\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2745 - auc: 0.9824\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2692 - auc: 0.9839\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2654 - auc: 0.9845\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2704 - auc: 0.9855\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2774 - auc: 0.9856\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2635 - auc: 0.9863\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2734 - auc: 0.9847\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2781 - auc: 0.9849\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2604 - auc: 0.9844\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2750 - auc: 0.9854\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2603 - auc: 0.9850\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2663 - auc: 0.9856\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2697 - auc: 0.9861\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2802 - auc: 0.9861\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2596 - auc: 0.9857\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2762 - auc: 0.9865\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2697 - auc: 0.9854\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2737 - auc: 0.9852\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2679 - auc: 0.9874\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2621 - auc: 0.9858\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2686 - auc: 0.9860\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2661 - auc: 0.9864\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2694 - auc: 0.9848\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2747 - auc: 0.9854\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2639 - auc: 0.9858\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2673 - auc: 0.9864\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2563 - auc: 0.9861\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2643 - auc: 0.9872\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2648 - auc: 0.9864\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2660 - auc: 0.9865\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2627 - auc: 0.9861\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 39s 24ms/step - loss: 0.2726 - auc: 0.9858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.005305141815642633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.02175203055802879\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0053', 'eer_eval': '0.0217', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0053.hdf5', 'tnow': '2022-05-26 16:01:14.112448'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 42s 25ms/step - loss: 0.7260 - auc: 0.8549\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.4248 - auc: 0.9550\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.4044 - auc: 0.9613\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3930 - auc: 0.9593\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3593 - auc: 0.9634\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3445 - auc: 0.9644\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3495 - auc: 0.9671\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3363 - auc: 0.9677\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3191 - auc: 0.9694\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3127 - auc: 0.9691\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3233 - auc: 0.9686\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3013 - auc: 0.9712\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.3280 - auc: 0.9686\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3162 - auc: 0.9724\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3196 - auc: 0.9716\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2937 - auc: 0.9711\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3042 - auc: 0.9720\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2862 - auc: 0.9741\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3012 - auc: 0.9742\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3034 - auc: 0.9728\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3150 - auc: 0.9739\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2923 - auc: 0.9755\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2926 - auc: 0.9742\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.3081 - auc: 0.9769\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2973 - auc: 0.9762\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2853 - auc: 0.9756\n",
      "Epoch 27/70\n",
      " 851/1586 [===============>..............] - ETA: 18s - loss: 0.2963 - auc: 0.9765"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from utils.DataLoader import data_loader\n",
    "from utils.Generator0 import DataGenerator, feature_extract_cqt, evalEER,  evalScore, evalEER_f, evalEER_f2, gen_fname\n",
    "from models.models import get_ResMax, get_LCNN, sigmoidal_decay\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import add,concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, maximum, DepthwiseConv2D, AveragePooling2D, UpSampling2D\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, SpatialDropout2D\n",
    "from tensorflow.keras.layers import Convolution2D, GlobalAveragePooling2D, MaxPool2D, ZeroPadding2D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.activations import relu, softmax, swish\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import pickle\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "add2022 = '/home/ubuntu/data/ADD/'\n",
    "asv2019 = '/home/ubuntu/data/asv2019/'\n",
    "\n",
    "pathset = { 'add2022' : add2022 , 'asv2019':asv2019}\n",
    "        \n",
    "dl = data_loader(pathset)\n",
    "\n",
    "#dl.get_data(data_pick = '2', tde_pick = 't', pl_pick = 'l', to = 't')\n",
    "#dl.get_data(data_pick = '2', tde_pick = 'd', pl_pick = 'lload_asv2019', to = 't')\n",
    "#dl.get_data(data_pick = '2', tde_pick = 'e', pl_pick = 'l', to = 'd')\n",
    "\n",
    "\n",
    "datapick = '2' ## 1:ADD, 2:LA\n",
    "\n",
    "dl.get_data(data_pick = datapick, tde_pick = 't', pl_pick = 'l',  to = 't')\n",
    "dl.get_data(data_pick = datapick, tde_pick = 'd', pl_pick = 'l', to = 'd')\n",
    "dl.get_data(data_pick = datapick, tde_pick = 'e', pl_pick = 'l', to = 'e')\n",
    "\n",
    "#track1 = data_loader(pathset)\n",
    "#track1_generator = DataGenerator(track1.eval, track1.labels, **params_no_shuffle)\n",
    "\n",
    "#################################################\n",
    "### get_ResMax\n",
    "mname = 'ResMax_LA_'\n",
    "#################################################\n",
    "\n",
    "### Mixup\n",
    "\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False # np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': False, # beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False # np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### LP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "#    ru = np.random.uniform(.1, .9)\n",
    "    ru = 0.5\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "### HP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "#    ru = np.random.uniform(.1, .9)\n",
    "    ru = 0.5\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [78, 79, 80, 81, 82] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [10,11,12,13,14]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "### LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 # np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [78, 79, 80, 81, 82] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #[2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [78, 79, 80, 81, 82] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mname = \"LCNN_LA_\"\n",
    "\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = False\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "\n",
    "### LP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [78, 79, 80, 81, 82] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "### LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [78, 79, 80, 81, 82] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #[2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [78, 79, 80, 81, 82] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "##################################################\n",
    "from models.models2 import get_BCResMax, get_DDWSseq\n",
    "\n",
    "mname = \"BCResMax_LA_\"\n",
    "\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = False\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### LP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [78, 79, 80, 81, 82] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "### LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [78, 79, 80, 81, 82] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #[2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [78, 79, 80, 81, 82] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "##################################################\n",
    "from models.models2 import get_BCResMax, get_DDWSseq\n",
    "\n",
    "mname = \"DDWSseq_LA_\"\n",
    "\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = False\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### LP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [78, 79, 80, 81, 82] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "### LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [78, 79, 80, 81, 82] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #[2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [78, 79, 80, 81, 82] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_pp2/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51da362f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2.4_p37)",
   "language": "python",
   "name": "conda_tensorflow2.4_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
