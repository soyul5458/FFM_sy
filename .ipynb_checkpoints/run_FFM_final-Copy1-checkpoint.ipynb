{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cfa53f9",
   "metadata": {},
   "source": [
    "## 1. ADD Data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5759fe9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 47s 25ms/step - loss: 0.1961 - auc: 0.9764\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 0.0241 - auc: 0.9993\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 0.0133 - auc: 0.9999\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 0.0206 - auc: 0.9997\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 0.0034 - auc: 0.9999\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 0.0081 - auc: 0.9998\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 0.0264 - auc: 0.9994\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 0.0106 - auc: 0.9998\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 0.0121 - auc: 0.9998\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 2.9108e-04 - auc: 1.0000\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0075 - auc: 0.9999\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 2.0486e-04 - auc: 1.0000\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 0.0072 - auc: 0.9998\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0071 - auc: 0.9999\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 0.0017 - auc: 1.0000\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 5.6887e-05 - auc: 1.0000\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 2.4015e-05 - auc: 1.0000\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 4.0653e-04 - auc: 1.0000\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 0.0049 - auc: 0.9998\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0034 - auc: 0.9999\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 0.0138 - auc: 0.9995\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 0.0012 - auc: 0.9999\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 0.0024 - auc: 0.9999\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 9.9318e-05 - auc: 1.0000\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 3.7345e-05 - auc: 1.0000\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 1.4215e-05 - auc: 1.0000\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 0.0073 - auc: 0.9997\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 3.3188e-04 - auc: 1.0000\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 2.1265e-04 - auc: 1.0000\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 7.9118e-05 - auc: 1.0000\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 1.3528e-05 - auc: 1.0000\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 7.2473e-06 - auc: 1.0000\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 0.0089 - auc: 0.9998\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 4.5803e-05 - auc: 1.0000\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 1.5991e-05 - auc: 1.0000\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 7.8345e-04 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 9.8253e-06 - auc: 1.0000\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 3.4005e-05 - auc: 1.0000\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 1.9388e-05 - auc: 1.0000\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 7.2866e-06 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 4.7708e-06 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 2.1233e-05 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 2.2220e-06 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 2.7844e-06 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 1.2527e-06 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 1.2489e-06 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 1.0969e-06 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 1.0918e-06 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 7.3061e-07 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 4.6559e-07 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 3.8358e-07 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 2.0638e-07 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 6.7497e-07 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 2.8222e-07 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 4.7467e-07 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 2.8552e-07 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 1.9667e-07 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 8.3438e-08 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 1.0353e-07 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 8.3674e-08 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 9.4019e-08 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 7.1173e-08 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 9.4104e-08 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 1.8982e-07 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 1.7591e-07 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 9.0769e-08 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 6.4710e-08 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 1.5012e-06 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 1.8732e-07 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 9.5362e-08 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.000548790324253671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.1968884540117417\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0005', 'eer_eval': '0.1968', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0005.hdf5', 'tnow': '2022-05-27 12:33:41.354185'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 45s 25ms/step - loss: 0.2002 - auc: 0.9728\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0209 - auc: 0.9995\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0118 - auc: 1.0000\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0178 - auc: 0.9997\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0120 - auc: 0.9996\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0022 - auc: 0.9999\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0194 - auc: 0.9994\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0042 - auc: 0.9999\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 6.1440e-04 - auc: 1.0000\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0151 - auc: 0.9996\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0075 - auc: 0.9997\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0024 - auc: 1.0000\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 4.1702e-04 - auc: 1.0000\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0018 - auc: 1.0000\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0028 - auc: 1.0000\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 6.7772e-04 - auc: 1.0000\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 4.9522e-05 - auc: 1.0000\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 5.4280e-05 - auc: 1.0000\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0021 - auc: 0.9999\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 4.2577e-04 - auc: 1.0000\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 6.0503e-04 - auc: 1.0000\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 7.9487e-04 - auc: 0.9999\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 2.4228e-05 - auc: 1.0000\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0044 - auc: 0.9998\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 1.1912e-04 - auc: 1.0000\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 1.4536e-05 - auc: 1.0000\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 1.5878e-05 - auc: 1.0000\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0030 - auc: 0.9999\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 6.4229e-04 - auc: 1.0000\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 7.0230e-05 - auc: 1.0000\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 1.3178e-05 - auc: 1.0000\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 1.6863e-05 - auc: 1.0000\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 8.0496e-06 - auc: 1.0000\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 8.7337e-04 - auc: 1.0000\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 5.8303e-04 - auc: 1.0000\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 3.1594e-05 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 7.3089e-06 - auc: 1.0000\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 8.4781e-06 - auc: 1.0000\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 2.5765e-04 - auc: 1.0000\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 1.2613e-04 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 2.7553e-06 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 2.5945e-06 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 1.7049e-06 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 1.0427e-06 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 1.2373e-06 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 5.9186e-07 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 7.9209e-07 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 4.1969e-07 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 5.8324e-06 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 1.7261e-07 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 1.4905e-07 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 8.8549e-08 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 9.4237e-08 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 7.4511e-08 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 7.0302e-08 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 9.8246e-08 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 1.9443e-07 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 6.6611e-08 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 1.2688e-07 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 1.3082e-07 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 1.7529e-07 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 9.1605e-08 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 5.1010e-08 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 4.7108e-08 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 5.0561e-08 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 2.2512e-08 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 2.4247e-08 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 4.0024e-08 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 1.6769e-07 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 2.3049e-08 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00042816443133840323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.2017416829745597\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0004', 'eer_eval': '0.2017', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0004.hdf5', 'tnow': '2022-05-27 13:23:45.546761'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 45s 25ms/step - loss: 0.2005 - auc: 0.9751\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0134 - auc: 0.9997\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 0.0185 - auc: 0.9997\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0121 - auc: 0.9999\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0027 - auc: 0.9999\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 0.0158 - auc: 0.9995\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0115 - auc: 0.9998\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 2.8578e-04 - auc: 1.0000\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0057 - auc: 0.9999\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0020 - auc: 1.0000\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0059 - auc: 0.9999\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0019 - auc: 0.9999\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0066 - auc: 0.9998\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0054 - auc: 0.9998\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0105 - auc: 0.9997\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 8.4014e-04 - auc: 1.0000\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0039 - auc: 0.9999\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 5.5094e-04 - auc: 1.0000\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0043 - auc: 0.9999\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 8.7103e-04 - auc: 1.0000\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 5.0541e-04 - auc: 1.0000\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 2.8324e-05 - auc: 1.0000\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0047 - auc: 0.9999\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 6.1435e-04 - auc: 1.0000\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 4.9575e-05 - auc: 1.0000\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 3.3454e-05 - auc: 1.0000\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 4.9879e-04 - auc: 1.0000\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 7.5249e-04 - auc: 1.0000\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 2.6677e-04 - auc: 1.0000\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 2.0613e-05 - auc: 1.0000\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 3.5251e-05 - auc: 1.0000\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0063 - auc: 0.9997\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 3.0007e-05 - auc: 1.0000\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 1.3460e-05 - auc: 1.0000\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 8.1078e-04 - auc: 1.0000\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 3.1993e-05 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 9.2758e-06 - auc: 1.0000\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 7.0369e-04 - auc: 1.0000\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0037 - auc: 0.9999\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 1.4581e-05 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 7.8576e-06 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 2.2103e-06 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 1.6940e-06 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 2.4857e-06 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 1.0836e-06 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 9.8515e-07 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 2.8094e-07 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 2.9043e-07 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 3.2464e-07 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 2.5995e-07 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 1.1530e-07 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 1.0635e-06 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 7.4729e-08 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 1.2300e-07 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 5.3255e-08 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 6.6301e-08 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 8.1902e-08 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 1.0160e-07 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 5.1897e-08 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 4.2360e-08 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 1.0431e-07 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 2.8364e-08 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 2.7716e-08 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 2.1994e-07 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 5.8042e-08 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 2.7361e-08 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 4.1753e-08 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 6.5036e-08 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 1.5926e-07 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 2.1305e-08 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00031283747942971354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.20074363992172212\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0003', 'eer_eval': '0.2007', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0003.hdf5', 'tnow': '2022-05-27 14:13:47.752259'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 46s 25ms/step - loss: 0.5630 - auc: 0.9031\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3287 - auc: 0.9709\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3342 - auc: 0.9754\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3287 - auc: 0.9761\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2949 - auc: 0.9785\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3140 - auc: 0.9796\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3043 - auc: 0.9815\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3176 - auc: 0.9814\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3075 - auc: 0.9824\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2851 - auc: 0.9833 0s - loss: 0.284\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2970 - auc: 0.9836\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2959 - auc: 0.9845\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2812 - auc: 0.9849\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2958 - auc: 0.9849\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2809 - auc: 0.9839\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2988 - auc: 0.9851\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2860 - auc: 0.9840\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2919 - auc: 0.9862\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2806 - auc: 0.9848\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2864 - auc: 0.9869\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2874 - auc: 0.9843\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2963 - auc: 0.9861\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2884 - auc: 0.9870\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2935 - auc: 0.9877\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2891 - auc: 0.9861\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2876 - auc: 0.9870\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2865 - auc: 0.9879\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2778 - auc: 0.9867\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2860 - auc: 0.9875\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2710 - auc: 0.9862\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2804 - auc: 0.9874\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2811 - auc: 0.9879\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2685 - auc: 0.9880\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2754 - auc: 0.9890\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2680 - auc: 0.9893\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2803 - auc: 0.9890\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2766 - auc: 0.9892\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2699 - auc: 0.9889\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2767 - auc: 0.9895\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2763 - auc: 0.9895\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2740 - auc: 0.9893\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2802 - auc: 0.9893\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2692 - auc: 0.9895\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2793 - auc: 0.9896\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2686 - auc: 0.9898\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2731 - auc: 0.9901\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2847 - auc: 0.9903\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2866 - auc: 0.9898\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2777 - auc: 0.9903\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2745 - auc: 0.9895\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2851 - auc: 0.9909\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2739 - auc: 0.9903\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2770 - auc: 0.9900\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2690 - auc: 0.9895\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2670 - auc: 0.9913\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2712 - auc: 0.9906\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2785 - auc: 0.9905\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2790 - auc: 0.9901\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2649 - auc: 0.9906 1s - loss: 0.\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2715 - auc: 0.9908\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2698 - auc: 0.9896\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2733 - auc: 0.9906\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2918 - auc: 0.9902\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2707 - auc: 0.9907\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2762 - auc: 0.9909\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2794 - auc: 0.9891\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2822 - auc: 0.9905\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2695 - auc: 0.9909\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2811 - auc: 0.9908\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2797 - auc: 0.9902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 7.688463460575612e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.14163405088062625\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '7.6884', 'eer_eval': '0.1416', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!7.6884.hdf5', 'tnow': '2022-05-27 15:04:20.989363'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.5388 - auc: 0.9066\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3454 - auc: 0.9723\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3277 - auc: 0.9753\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3105 - auc: 0.9766\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3152 - auc: 0.9781\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3067 - auc: 0.9804\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2936 - auc: 0.9810\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2956 - auc: 0.9802\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3075 - auc: 0.9819\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2954 - auc: 0.9824\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2992 - auc: 0.9834\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3098 - auc: 0.9825\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2893 - auc: 0.9833\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2939 - auc: 0.9838\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2939 - auc: 0.9853\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2962 - auc: 0.9847\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2870 - auc: 0.9853\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2799 - auc: 0.9860\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2840 - auc: 0.9864\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2898 - auc: 0.9859\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2912 - auc: 0.9847\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2881 - auc: 0.9864\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2791 - auc: 0.9866\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2715 - auc: 0.9879\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2852 - auc: 0.9867\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2729 - auc: 0.9872\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2771 - auc: 0.9868\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2875 - auc: 0.9877\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2785 - auc: 0.9878\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2680 - auc: 0.9876\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2838 - auc: 0.9877\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2893 - auc: 0.9878\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2825 - auc: 0.9888\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2796 - auc: 0.9885\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2939 - auc: 0.9888\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2852 - auc: 0.9884\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2783 - auc: 0.9891\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2731 - auc: 0.9893\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2826 - auc: 0.9897\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2690 - auc: 0.9897\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2811 - auc: 0.9905\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2827 - auc: 0.9892\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2817 - auc: 0.9896\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2693 - auc: 0.9901\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2829 - auc: 0.9896\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2786 - auc: 0.9904\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2833 - auc: 0.9891\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2669 - auc: 0.9897\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2881 - auc: 0.9902\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2698 - auc: 0.9896\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2699 - auc: 0.9898\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2653 - auc: 0.9901\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2671 - auc: 0.9897\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2630 - auc: 0.9895\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2768 - auc: 0.9898\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2666 - auc: 0.9907\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2720 - auc: 0.9899\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2760 - auc: 0.9902\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2697 - auc: 0.9910\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2866 - auc: 0.9911\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2782 - auc: 0.9910\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2735 - auc: 0.9904\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2836 - auc: 0.9903\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2683 - auc: 0.9911\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2712 - auc: 0.9903\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2727 - auc: 0.9895\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2816 - auc: 0.9897\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2691 - auc: 0.9906\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2776 - auc: 0.9905\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2764 - auc: 0.9909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 3.844231730287806e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.16047945205479452\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '3.8442', 'eer_eval': '0.1604', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!3.8442.hdf5', 'tnow': '2022-05-27 15:55:01.020697'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 45s 25ms/step - loss: 0.5248 - auc: 0.9154\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3269 - auc: 0.9723\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3065 - auc: 0.9760\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3060 - auc: 0.9768\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3065 - auc: 0.9773\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3174 - auc: 0.9788\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3147 - auc: 0.9799\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2970 - auc: 0.9809\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3106 - auc: 0.9834\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3063 - auc: 0.9824\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2992 - auc: 0.9833\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2860 - auc: 0.9826\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2972 - auc: 0.9837\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 0.2924 - auc: 0.9837\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2955 - auc: 0.9840\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2898 - auc: 0.9851\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3045 - auc: 0.9851\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2874 - auc: 0.9848\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 0.2877 - auc: 0.9849\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2962 - auc: 0.9844\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2918 - auc: 0.9850\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2951 - auc: 0.9849\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2964 - auc: 0.9859\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2913 - auc: 0.9864\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2937 - auc: 0.9854\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 0.2849 - auc: 0.9854\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 0.2869 - auc: 0.9867\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 0.2844 - auc: 0.9866\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2861 - auc: 0.9855\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2738 - auc: 0.9870\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2831 - auc: 0.9873\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2908 - auc: 0.9862\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2876 - auc: 0.9867\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2738 - auc: 0.9873\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2760 - auc: 0.9876\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2812 - auc: 0.9876\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2820 - auc: 0.9873\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2920 - auc: 0.9871\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2814 - auc: 0.9873\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2756 - auc: 0.9868\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2766 - auc: 0.9890\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2849 - auc: 0.9882\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2803 - auc: 0.9886\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2808 - auc: 0.9888\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2835 - auc: 0.9884\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2811 - auc: 0.9889\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2687 - auc: 0.9890\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2783 - auc: 0.9866\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2741 - auc: 0.9882\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2746 - auc: 0.9886\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2846 - auc: 0.9886\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2727 - auc: 0.9898\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2678 - auc: 0.9890\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2733 - auc: 0.9886\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2734 - auc: 0.9874\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2817 - auc: 0.9890\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2701 - auc: 0.9892\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2778 - auc: 0.9887\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2792 - auc: 0.9870\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2762 - auc: 0.9893\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2610 - auc: 0.9893\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2773 - auc: 0.9887\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2779 - auc: 0.9892\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2709 - auc: 0.9899\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2762 - auc: 0.9885\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2733 - auc: 0.9900\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2767 - auc: 0.9881\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2702 - auc: 0.9890\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2755 - auc: 0.9892\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2752 - auc: 0.9884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0008178865453739284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.16604696673189823\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0008', 'eer_eval': '0.1660', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0008.hdf5', 'tnow': '2022-05-27 16:45:26.735095'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 46s 26ms/step - loss: 0.5471 - auc: 0.9032\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3358 - auc: 0.9714\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3302 - auc: 0.9758\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3077 - auc: 0.9767\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3081 - auc: 0.9783\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3107 - auc: 0.9785\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3106 - auc: 0.9799\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3109 - auc: 0.9806\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3023 - auc: 0.9824\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3015 - auc: 0.9818\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2821 - auc: 0.9826 0s - loss: 0.2821 - auc: 0.98\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3010 - auc: 0.9820\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2854 - auc: 0.9835\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3052 - auc: 0.9828\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3023 - auc: 0.9839\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2922 - auc: 0.9840\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2874 - auc: 0.9844\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2898 - auc: 0.9843\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2871 - auc: 0.9851\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2893 - auc: 0.9849\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2924 - auc: 0.9848\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2866 - auc: 0.9859\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2892 - auc: 0.9851\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2880 - auc: 0.9862\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2828 - auc: 0.9856\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2804 - auc: 0.9860\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2956 - auc: 0.9851\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2722 - auc: 0.9859\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2816 - auc: 0.9858\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2898 - auc: 0.9857\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2783 - auc: 0.9863\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2890 - auc: 0.9874\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2779 - auc: 0.9859\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2819 - auc: 0.9859\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2740 - auc: 0.9862\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2772 - auc: 0.9884\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2819 - auc: 0.9881\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2796 - auc: 0.9863\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2935 - auc: 0.9880\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2746 - auc: 0.9878\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2684 - auc: 0.9876\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2840 - auc: 0.9888\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2826 - auc: 0.9875\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2765 - auc: 0.9883\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2760 - auc: 0.9881\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2749 - auc: 0.9880\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2923 - auc: 0.9879\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2838 - auc: 0.9882\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2775 - auc: 0.9884\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2871 - auc: 0.9890\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2685 - auc: 0.9892\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2752 - auc: 0.9884\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2835 - auc: 0.9888 1s - lo\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2792 - auc: 0.9891\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2807 - auc: 0.9876\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2805 - auc: 0.9885\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2721 - auc: 0.9874\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2775 - auc: 0.9888\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2800 - auc: 0.9884\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2803 - auc: 0.9898\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2804 - auc: 0.9895\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2661 - auc: 0.9887\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2743 - auc: 0.9898\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2796 - auc: 0.9881\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2664 - auc: 0.9887\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2638 - auc: 0.9885\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2711 - auc: 0.9883\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2822 - auc: 0.9886\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2834 - auc: 0.9894\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2751 - auc: 0.9897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 9.610579325719515e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.19545988258317026\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '9.6105', 'eer_eval': '0.1954', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!9.6105.hdf5', 'tnow': '2022-05-27 17:35:54.241445'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.5645 - auc: 0.9033\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3471 - auc: 0.9726\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3067 - auc: 0.9747\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3263 - auc: 0.9776\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3057 - auc: 0.9786\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3237 - auc: 0.9772\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3039 - auc: 0.9797\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2998 - auc: 0.9802\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3129 - auc: 0.9795\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3008 - auc: 0.9809\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2903 - auc: 0.9839\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2915 - auc: 0.9832\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2976 - auc: 0.9835\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2950 - auc: 0.9858\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2960 - auc: 0.9842\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2922 - auc: 0.9837\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2879 - auc: 0.9848\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2928 - auc: 0.9847\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2909 - auc: 0.9852\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2791 - auc: 0.9865\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2946 - auc: 0.9867\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2856 - auc: 0.9870\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2850 - auc: 0.9863\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2817 - auc: 0.9866\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2739 - auc: 0.9864\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2881 - auc: 0.9863\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3111 - auc: 0.9858\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2787 - auc: 0.9881\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2930 - auc: 0.9870\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2848 - auc: 0.9879\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2832 - auc: 0.9883\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2886 - auc: 0.9885\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2864 - auc: 0.9880\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2923 - auc: 0.9889\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2894 - auc: 0.9880\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3000 - auc: 0.9882\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2805 - auc: 0.9888\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2784 - auc: 0.9891\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2680 - auc: 0.9896\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2842 - auc: 0.9898\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2808 - auc: 0.9888\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2723 - auc: 0.9880\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2909 - auc: 0.9902\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2859 - auc: 0.9888\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2867 - auc: 0.9899\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2682 - auc: 0.9893\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2751 - auc: 0.9890\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2633 - auc: 0.9895\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2796 - auc: 0.9899\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2681 - auc: 0.9897\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2828 - auc: 0.9903\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2894 - auc: 0.9902\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2898 - auc: 0.9900\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2764 - auc: 0.9893\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2707 - auc: 0.9910\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2757 - auc: 0.9904\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2825 - auc: 0.9904\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2720 - auc: 0.9900\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2769 - auc: 0.9902\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2861 - auc: 0.9907\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2660 - auc: 0.9898\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2740 - auc: 0.9907\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2729 - auc: 0.9908\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2737 - auc: 0.9905\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2717 - auc: 0.9910\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2660 - auc: 0.9909\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2777 - auc: 0.9909\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2798 - auc: 0.9903\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2794 - auc: 0.9901\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2711 - auc: 0.9906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 3.844231730287806e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.14962818003913894\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '3.8442', 'eer_eval': '0.1496', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!3.8442.hdf5', 'tnow': '2022-05-27 18:26:41.571455'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.5351 - auc: 0.9100\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3366 - auc: 0.9722\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3310 - auc: 0.9734\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3187 - auc: 0.9771\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3068 - auc: 0.9775\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3001 - auc: 0.9798\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3029 - auc: 0.9811\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3103 - auc: 0.9822\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3018 - auc: 0.9820\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2999 - auc: 0.9826\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2992 - auc: 0.9827\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2983 - auc: 0.9845\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3047 - auc: 0.9869\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2992 - auc: 0.9845\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2897 - auc: 0.9841\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2929 - auc: 0.9849\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2792 - auc: 0.9850\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2719 - auc: 0.9854\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2798 - auc: 0.9858\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2869 - auc: 0.9854\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2877 - auc: 0.9857\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2914 - auc: 0.9864\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2835 - auc: 0.9856\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2813 - auc: 0.9870\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2787 - auc: 0.9879\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2768 - auc: 0.9875\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2710 - auc: 0.9874\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2846 - auc: 0.9874\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2899 - auc: 0.9874\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2743 - auc: 0.9882\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2833 - auc: 0.9880\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2813 - auc: 0.9893\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2632 - auc: 0.9885\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2765 - auc: 0.9886\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2815 - auc: 0.9890\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2862 - auc: 0.9888\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2801 - auc: 0.9890\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2750 - auc: 0.9899\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2757 - auc: 0.9892\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2688 - auc: 0.9895\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2735 - auc: 0.9896\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2670 - auc: 0.9903\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2695 - auc: 0.9900\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2708 - auc: 0.9907\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2788 - auc: 0.9901\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2723 - auc: 0.9904\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2613 - auc: 0.9913\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2810 - auc: 0.9896\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2839 - auc: 0.9898\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2710 - auc: 0.9901\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2684 - auc: 0.9898\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2669 - auc: 0.9905\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2803 - auc: 0.9904\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2802 - auc: 0.9906\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2648 - auc: 0.9902\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2794 - auc: 0.9914\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2705 - auc: 0.9903\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2848 - auc: 0.9910\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2696 - auc: 0.9906\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2767 - auc: 0.9909\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2892 - auc: 0.9907\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2777 - auc: 0.9910\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2686 - auc: 0.9914\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2716 - auc: 0.9902\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2741 - auc: 0.9915\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2899 - auc: 0.9906\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2739 - auc: 0.9910\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2887 - auc: 0.9905\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2666 - auc: 0.9909\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2647 - auc: 0.9902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00021673168617251842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.14962818003913894\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0002', 'eer_eval': '0.1496', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0002.hdf5', 'tnow': '2022-05-27 19:17:11.383447'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 45s 25ms/step - loss: 0.5780 - auc: 0.8992\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3400 - auc: 0.9703\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3394 - auc: 0.9738\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3196 - auc: 0.9767\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3136 - auc: 0.9772\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3039 - auc: 0.9786\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3080 - auc: 0.9800\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3020 - auc: 0.9817\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3066 - auc: 0.9807\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2916 - auc: 0.9823\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3075 - auc: 0.9827\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2826 - auc: 0.9843\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2907 - auc: 0.9840\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3030 - auc: 0.9847\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2858 - auc: 0.9848\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2838 - auc: 0.9843\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2959 - auc: 0.9852\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2781 - auc: 0.9856\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2831 - auc: 0.9847\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2829 - auc: 0.9859\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2848 - auc: 0.9865\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2799 - auc: 0.9856\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2861 - auc: 0.9862\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2892 - auc: 0.9874\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2818 - auc: 0.9867\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2861 - auc: 0.9860\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2819 - auc: 0.9865\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2879 - auc: 0.9876\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2910 - auc: 0.9869\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2818 - auc: 0.9879\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2873 - auc: 0.9876\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2865 - auc: 0.9881\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2947 - auc: 0.9880\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2753 - auc: 0.9879\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2720 - auc: 0.9886\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2787 - auc: 0.9873\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2792 - auc: 0.9889\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2807 - auc: 0.9887\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2796 - auc: 0.9902\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2581 - auc: 0.9885\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2735 - auc: 0.9889\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2693 - auc: 0.9884\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2681 - auc: 0.9892\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2852 - auc: 0.9908\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2748 - auc: 0.9897\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2874 - auc: 0.9896\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2682 - auc: 0.9890\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2722 - auc: 0.9910\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2733 - auc: 0.9894\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2834 - auc: 0.9892\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2866 - auc: 0.9890\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2774 - auc: 0.9897\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2713 - auc: 0.9890\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2854 - auc: 0.9904\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2850 - auc: 0.9901\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2790 - auc: 0.9906\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2655 - auc: 0.9904\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2650 - auc: 0.9905\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2797 - auc: 0.9897\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2684 - auc: 0.9907\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2666 - auc: 0.9907\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2635 - auc: 0.9912\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2698 - auc: 0.9903\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2796 - auc: 0.9903\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2691 - auc: 0.9910\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2716 - auc: 0.9901\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2749 - auc: 0.9915\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2712 - auc: 0.9902\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2785 - auc: 0.9902\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2873 - auc: 0.9917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 3.844231730287806e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.1831800391389432\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '3.8442', 'eer_eval': '0.1831', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!3.8442.hdf5', 'tnow': '2022-05-27 20:08:04.648693'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 46s 26ms/step - loss: 0.5866 - auc: 0.8997\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3393 - auc: 0.9719\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3234 - auc: 0.9758\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3105 - auc: 0.9753\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3197 - auc: 0.9772\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3122 - auc: 0.9798\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3034 - auc: 0.9793\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3064 - auc: 0.9804\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3077 - auc: 0.9801\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2974 - auc: 0.9802\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3022 - auc: 0.9820\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2901 - auc: 0.9838\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3031 - auc: 0.9828\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2961 - auc: 0.9847 0s - loss: 0.2960 - auc:\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2920 - auc: 0.9825\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2981 - auc: 0.9838\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2865 - auc: 0.9840\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2870 - auc: 0.9851\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3029 - auc: 0.9847\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2791 - auc: 0.9847\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2868 - auc: 0.9855\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2905 - auc: 0.9869\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2796 - auc: 0.9864\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2916 - auc: 0.9852\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2811 - auc: 0.9866\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2818 - auc: 0.9868\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2892 - auc: 0.9876\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2820 - auc: 0.9872\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2814 - auc: 0.9860\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2771 - auc: 0.9875\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2883 - auc: 0.9869\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2810 - auc: 0.9867\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2829 - auc: 0.9874\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2770 - auc: 0.9883\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2883 - auc: 0.9881\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2799 - auc: 0.9870\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2833 - auc: 0.9879\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2927 - auc: 0.9888\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2738 - auc: 0.9891\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2728 - auc: 0.9887\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2848 - auc: 0.9890\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2784 - auc: 0.9882\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2852 - auc: 0.9892\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2716 - auc: 0.9891\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2774 - auc: 0.9884\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2760 - auc: 0.9877\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2872 - auc: 0.9903\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2706 - auc: 0.9887\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2642 - auc: 0.9888\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2839 - auc: 0.9888\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2796 - auc: 0.9895\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2747 - auc: 0.9893\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2806 - auc: 0.9885\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2753 - auc: 0.9895\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2740 - auc: 0.9895\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2713 - auc: 0.9886\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2817 - auc: 0.9888\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2799 - auc: 0.9887\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2728 - auc: 0.9896\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2744 - auc: 0.9895\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2871 - auc: 0.9898\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2812 - auc: 0.9887\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2775 - auc: 0.9889\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2858 - auc: 0.9894\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2647 - auc: 0.9887\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2830 - auc: 0.9898\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2793 - auc: 0.9890\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2774 - auc: 0.9892\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2700 - auc: 0.9888\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2643 - auc: 0.9893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00023595284482395745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.1597651663405088\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0002', 'eer_eval': '0.1597', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0002.hdf5', 'tnow': '2022-05-27 20:58:44.787740'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 46s 26ms/step - loss: 0.5484 - auc: 0.9080\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3403 - auc: 0.9736\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3226 - auc: 0.9754\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3162 - auc: 0.9760\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3146 - auc: 0.9786\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3123 - auc: 0.9791\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3141 - auc: 0.9785\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3024 - auc: 0.9820\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3168 - auc: 0.9816\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2940 - auc: 0.9810\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3015 - auc: 0.9839\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2959 - auc: 0.9842\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2940 - auc: 0.9847\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2879 - auc: 0.9857\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2941 - auc: 0.9840\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2823 - auc: 0.9851\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3030 - auc: 0.9848\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3077 - auc: 0.9853\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2903 - auc: 0.9849\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3003 - auc: 0.9849\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2923 - auc: 0.9865\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2958 - auc: 0.9856\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2914 - auc: 0.9844\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2797 - auc: 0.9858\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2937 - auc: 0.9867\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2877 - auc: 0.9868\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2860 - auc: 0.9876\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2766 - auc: 0.9885\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2748 - auc: 0.9880\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2852 - auc: 0.9880\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2745 - auc: 0.9872\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2811 - auc: 0.9891\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2760 - auc: 0.9885\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2834 - auc: 0.9875\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2800 - auc: 0.9881\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2796 - auc: 0.9896\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2880 - auc: 0.9882\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2889 - auc: 0.9889\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2911 - auc: 0.9893\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2782 - auc: 0.9902\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2692 - auc: 0.9895\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2767 - auc: 0.9898\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2729 - auc: 0.9888\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2768 - auc: 0.9894\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2976 - auc: 0.9897\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2717 - auc: 0.9901\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2757 - auc: 0.9901\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2774 - auc: 0.9901\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2863 - auc: 0.9902\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2841 - auc: 0.9896\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2797 - auc: 0.9903\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2747 - auc: 0.9913\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2728 - auc: 0.9904\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2733 - auc: 0.9891\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2744 - auc: 0.9895\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2812 - auc: 0.9909\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2812 - auc: 0.9895\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2706 - auc: 0.9898\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2794 - auc: 0.9903\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2809 - auc: 0.9901\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2684 - auc: 0.9905\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2799 - auc: 0.9903\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2750 - auc: 0.9907\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2722 - auc: 0.9901\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2837 - auc: 0.9909\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2725 - auc: 0.9899\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2778 - auc: 0.9901\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2665 - auc: 0.9906\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2790 - auc: 0.9892\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2695 - auc: 0.9908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00044738558998984226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.17832681017612526\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0004', 'eer_eval': '0.1783', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0004.hdf5', 'tnow': '2022-05-27 21:49:33.041974'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 45s 25ms/step - loss: 0.5813 - auc: 0.9002\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3684 - auc: 0.9684\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3370 - auc: 0.9722\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3296 - auc: 0.9748\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3156 - auc: 0.9772\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3111 - auc: 0.9789\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3103 - auc: 0.9781\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2974 - auc: 0.9799\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3099 - auc: 0.9806\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2885 - auc: 0.9818\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2900 - auc: 0.9826\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2833 - auc: 0.9828\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2976 - auc: 0.9824\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2908 - auc: 0.9843\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2955 - auc: 0.9840\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2903 - auc: 0.9842\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2876 - auc: 0.9840\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2843 - auc: 0.9843\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2977 - auc: 0.9847\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2849 - auc: 0.9842\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2906 - auc: 0.9856\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2885 - auc: 0.9855\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2912 - auc: 0.9844\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2756 - auc: 0.9864\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2776 - auc: 0.9859\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2815 - auc: 0.9861\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2847 - auc: 0.9869\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2840 - auc: 0.9867\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2888 - auc: 0.9867\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2784 - auc: 0.9867\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2858 - auc: 0.9869\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2791 - auc: 0.9866\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2873 - auc: 0.9875\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2813 - auc: 0.9873\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2866 - auc: 0.9875\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2825 - auc: 0.9881\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2863 - auc: 0.9878\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2935 - auc: 0.9881\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2732 - auc: 0.9886\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2881 - auc: 0.9886\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2861 - auc: 0.9888\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2932 - auc: 0.9889\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2819 - auc: 0.9893\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2777 - auc: 0.9888\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2860 - auc: 0.9889\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2791 - auc: 0.9887\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2701 - auc: 0.9872\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2846 - auc: 0.9898\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2746 - auc: 0.9884\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2784 - auc: 0.9893\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2846 - auc: 0.9894\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2755 - auc: 0.9892\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2742 - auc: 0.9889\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2795 - auc: 0.9904\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2741 - auc: 0.9892\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2736 - auc: 0.9896\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2758 - auc: 0.9894\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2832 - auc: 0.9896\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2734 - auc: 0.9894\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2776 - auc: 0.9895\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2738 - auc: 0.9909\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2709 - auc: 0.9898\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2667 - auc: 0.9897\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2721 - auc: 0.9898\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2644 - auc: 0.9903\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2816 - auc: 0.9895\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2797 - auc: 0.9889\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2739 - auc: 0.9907\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2801 - auc: 0.9895\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2667 - auc: 0.9890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 3.844231730287806e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.14091976516634053\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '3.8442', 'eer_eval': '0.1409', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!3.8442.hdf5', 'tnow': '2022-05-27 22:40:13.896765'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 45s 25ms/step - loss: 0.5755 - auc: 0.8986\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3474 - auc: 0.9701\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3289 - auc: 0.9732\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3210 - auc: 0.9753\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3220 - auc: 0.9766\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2895 - auc: 0.9789 0s - loss: 0.2892 -\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3061 - auc: 0.9772\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3016 - auc: 0.9818\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2979 - auc: 0.9800\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3040 - auc: 0.9831\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3098 - auc: 0.9808\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2881 - auc: 0.9828\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2946 - auc: 0.9842\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2909 - auc: 0.9846\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2996 - auc: 0.9831\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2922 - auc: 0.9848\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3051 - auc: 0.9840\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2938 - auc: 0.9854\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2994 - auc: 0.9842\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2832 - auc: 0.9852\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2935 - auc: 0.9849\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2923 - auc: 0.9859\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2971 - auc: 0.9873\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2821 - auc: 0.9870\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2924 - auc: 0.9866\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3048 - auc: 0.9878\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2977 - auc: 0.9866\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2792 - auc: 0.9864\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2828 - auc: 0.9885\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2762 - auc: 0.9874\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2931 - auc: 0.9878\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2879 - auc: 0.9878\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2760 - auc: 0.9890\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2851 - auc: 0.9878\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2735 - auc: 0.9885\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2889 - auc: 0.9891\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2678 - auc: 0.9875\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2822 - auc: 0.9895\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2785 - auc: 0.9896\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2780 - auc: 0.9892\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2864 - auc: 0.9897\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2813 - auc: 0.9893\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2768 - auc: 0.9896\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2705 - auc: 0.9891\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2729 - auc: 0.9900\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2692 - auc: 0.9902\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2814 - auc: 0.9900\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2728 - auc: 0.9905\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2802 - auc: 0.9901\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2730 - auc: 0.9893\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2744 - auc: 0.9899\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2791 - auc: 0.9910\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2678 - auc: 0.9893\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2859 - auc: 0.9903\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2689 - auc: 0.9896\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2679 - auc: 0.9893\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2656 - auc: 0.9905\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2737 - auc: 0.9907\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2846 - auc: 0.9900\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2692 - auc: 0.9902\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2728 - auc: 0.9899\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2724 - auc: 0.9905\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2804 - auc: 0.9916\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2753 - auc: 0.9902\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2692 - auc: 0.9899\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2711 - auc: 0.9906\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2653 - auc: 0.9898\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2795 - auc: 0.9906\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2723 - auc: 0.9899\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2683 - auc: 0.9896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 3.844231730287806e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.12792563600782775\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '3.8442', 'eer_eval': '0.1279', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!3.8442.hdf5', 'tnow': '2022-05-27 23:30:43.073022'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.5917 - auc: 0.8900\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3674 - auc: 0.9682\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3274 - auc: 0.9723\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3324 - auc: 0.9748\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3187 - auc: 0.9747\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3146 - auc: 0.9772\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3032 - auc: 0.9759\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3072 - auc: 0.9782\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3012 - auc: 0.9782\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3029 - auc: 0.9779\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3055 - auc: 0.9803\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2937 - auc: 0.9805\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2974 - auc: 0.9818\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2903 - auc: 0.9805\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3029 - auc: 0.9818\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3044 - auc: 0.9819\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2884 - auc: 0.9843\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2903 - auc: 0.9830\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2837 - auc: 0.9810\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2911 - auc: 0.9832\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2926 - auc: 0.9833\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2978 - auc: 0.9832\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2833 - auc: 0.9843\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2862 - auc: 0.9855\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2779 - auc: 0.9848\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2845 - auc: 0.9844\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2801 - auc: 0.9850\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2860 - auc: 0.9847\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2991 - auc: 0.9840\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2849 - auc: 0.9848\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2975 - auc: 0.9847\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2864 - auc: 0.9858\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2909 - auc: 0.9851\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2863 - auc: 0.9853\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2762 - auc: 0.9858\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2827 - auc: 0.9856\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2871 - auc: 0.9868\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2844 - auc: 0.9858\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2875 - auc: 0.9852\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2905 - auc: 0.9875\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2792 - auc: 0.9872\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2825 - auc: 0.9861\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2673 - auc: 0.9879\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2833 - auc: 0.9876\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2729 - auc: 0.9867\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2865 - auc: 0.9868\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2793 - auc: 0.9875\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2900 - auc: 0.9871\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2815 - auc: 0.9884\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2870 - auc: 0.9889\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2795 - auc: 0.9882\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2799 - auc: 0.9879\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2900 - auc: 0.9880\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2794 - auc: 0.9877\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2703 - auc: 0.9875\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2775 - auc: 0.9868\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2789 - auc: 0.9863\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2804 - auc: 0.9876\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2788 - auc: 0.9879\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2818 - auc: 0.9887\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2808 - auc: 0.9877\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2831 - auc: 0.9876\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2797 - auc: 0.9872\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2838 - auc: 0.9870\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2680 - auc: 0.9884\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2718 - auc: 0.9880\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2816 - auc: 0.9865\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2795 - auc: 0.9875\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2818 - auc: 0.9882\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2697 - auc: 0.9881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0006064538002080436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.1877495107632094\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0006', 'eer_eval': '0.1877', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0006.hdf5', 'tnow': '2022-05-28 00:21:57.197436'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 45s 25ms/step - loss: 0.5898 - auc: 0.8926\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3702 - auc: 0.9679\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3337 - auc: 0.9716\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3239 - auc: 0.9738\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3083 - auc: 0.9763\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3103 - auc: 0.9773\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3213 - auc: 0.9793\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3161 - auc: 0.9784 0s - loss: 0.3162 - auc: 0.97\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3045 - auc: 0.9819\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3125 - auc: 0.9816\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3093 - auc: 0.9807\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3025 - auc: 0.9825\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2974 - auc: 0.9811\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 0.2809 - auc: 0.9817\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3137 - auc: 0.9836\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2991 - auc: 0.9837\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2887 - auc: 0.9834\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2864 - auc: 0.9859\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2965 - auc: 0.9849\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2909 - auc: 0.9848\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2910 - auc: 0.9850\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2938 - auc: 0.9847\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2781 - auc: 0.9868\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2895 - auc: 0.9858\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2875 - auc: 0.9859\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2746 - auc: 0.9858\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2885 - auc: 0.9865\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2940 - auc: 0.9857\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2850 - auc: 0.9876\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2915 - auc: 0.9869\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2845 - auc: 0.9865\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2799 - auc: 0.9878\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2905 - auc: 0.9873\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2850 - auc: 0.9877\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2676 - auc: 0.9885\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2872 - auc: 0.9863\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2838 - auc: 0.9874\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2861 - auc: 0.9884\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2776 - auc: 0.9888\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2656 - auc: 0.9883\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2885 - auc: 0.9889\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2795 - auc: 0.9887\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2777 - auc: 0.9895\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2691 - auc: 0.9883\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2741 - auc: 0.9892\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2707 - auc: 0.9898\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2719 - auc: 0.9897\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2844 - auc: 0.9894\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2799 - auc: 0.9885\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2790 - auc: 0.9893\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2673 - auc: 0.9903\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2764 - auc: 0.9902\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2853 - auc: 0.9892\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2819 - auc: 0.9899\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2745 - auc: 0.9900\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2789 - auc: 0.9889\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2750 - auc: 0.9895\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2684 - auc: 0.9903\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2848 - auc: 0.9888\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2815 - auc: 0.9898\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2871 - auc: 0.9894\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2682 - auc: 0.9898\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2724 - auc: 0.9905\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2788 - auc: 0.9899\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2685 - auc: 0.9899\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2752 - auc: 0.9900\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2675 - auc: 0.9905\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2835 - auc: 0.9910\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2718 - auc: 0.9902\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2693 - auc: 0.9897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.14648727984344423\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0', 'eer_eval': '0.1464', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0.hdf5', 'tnow': '2022-05-28 01:12:36.422722'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 46s 26ms/step - loss: 0.5723 - auc: 0.9009\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3379 - auc: 0.9685\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3282 - auc: 0.9714\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3287 - auc: 0.9745\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3182 - auc: 0.9764\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3247 - auc: 0.9758\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3030 - auc: 0.9789\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3116 - auc: 0.9785\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3058 - auc: 0.9811\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3221 - auc: 0.9802\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3026 - auc: 0.9800\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2960 - auc: 0.9802\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2971 - auc: 0.9796\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2957 - auc: 0.9801\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2926 - auc: 0.9811\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3084 - auc: 0.9814\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3068 - auc: 0.9820\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2937 - auc: 0.9817\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2934 - auc: 0.9811\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3075 - auc: 0.9834\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2944 - auc: 0.9833\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2856 - auc: 0.9833\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2950 - auc: 0.9845\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2850 - auc: 0.9837\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2871 - auc: 0.9837\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2873 - auc: 0.9842\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2966 - auc: 0.9841\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2961 - auc: 0.9844\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2805 - auc: 0.9849\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2967 - auc: 0.9842\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2927 - auc: 0.9858\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2926 - auc: 0.9842\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2935 - auc: 0.9861\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2934 - auc: 0.9866\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2984 - auc: 0.9859\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2801 - auc: 0.9862\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2721 - auc: 0.9870\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3021 - auc: 0.9868\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2836 - auc: 0.9861\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2772 - auc: 0.9859\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2830 - auc: 0.9858\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2868 - auc: 0.9868\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2833 - auc: 0.9870\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2949 - auc: 0.9880\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2926 - auc: 0.9872\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2769 - auc: 0.9878\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2821 - auc: 0.9871\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2896 - auc: 0.9871\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2732 - auc: 0.9879\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2819 - auc: 0.9873\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2893 - auc: 0.9878\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2917 - auc: 0.9880\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2808 - auc: 0.9874\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2834 - auc: 0.9876\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2823 - auc: 0.9871\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2802 - auc: 0.9881\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2804 - auc: 0.9889\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2847 - auc: 0.9884\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2788 - auc: 0.9883\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2765 - auc: 0.9889\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2813 - auc: 0.9889\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2765 - auc: 0.9876\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2875 - auc: 0.9887\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2757 - auc: 0.9877\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2760 - auc: 0.9882\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2828 - auc: 0.9884\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2777 - auc: 0.9879\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2652 - auc: 0.9881\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2742 - auc: 0.9890\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2729 - auc: 0.9875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 9.610579325719515e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.17832681017612526\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '9.6105', 'eer_eval': '0.1783', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!9.6105.hdf5', 'tnow': '2022-05-28 02:03:30.555200'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.5989 - auc: 0.8940\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3519 - auc: 0.9687\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3384 - auc: 0.9719\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3278 - auc: 0.9724\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3308 - auc: 0.9740\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3196 - auc: 0.9773\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3254 - auc: 0.9750\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3106 - auc: 0.9791\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3070 - auc: 0.9801\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3014 - auc: 0.9792\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3057 - auc: 0.9803\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3068 - auc: 0.9785\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3033 - auc: 0.9821\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2992 - auc: 0.9813\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2969 - auc: 0.9812\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3038 - auc: 0.9817\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2848 - auc: 0.9821\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2883 - auc: 0.9825\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2884 - auc: 0.9821\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2854 - auc: 0.9820\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2946 - auc: 0.9849\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3010 - auc: 0.9824\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2927 - auc: 0.9836\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3034 - auc: 0.9840\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2829 - auc: 0.9847\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2884 - auc: 0.9840\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2967 - auc: 0.9837\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2916 - auc: 0.9852\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2866 - auc: 0.9852\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2888 - auc: 0.9849\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2934 - auc: 0.9854\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2977 - auc: 0.9853\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2862 - auc: 0.9858\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2808 - auc: 0.9864\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2801 - auc: 0.9864\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2804 - auc: 0.9862\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2934 - auc: 0.9861\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2822 - auc: 0.9858\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2897 - auc: 0.9858\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2806 - auc: 0.9869\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2803 - auc: 0.9861\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2815 - auc: 0.9876\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2738 - auc: 0.9881\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2836 - auc: 0.9874\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2806 - auc: 0.9873\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2785 - auc: 0.9873\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2801 - auc: 0.9878\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2831 - auc: 0.9882\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2809 - auc: 0.9874\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2725 - auc: 0.9879\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2667 - auc: 0.9869\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2766 - auc: 0.9880\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2811 - auc: 0.9881\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2706 - auc: 0.9884\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2798 - auc: 0.9888\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2842 - auc: 0.9870\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2846 - auc: 0.9870\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2742 - auc: 0.9865\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2839 - auc: 0.9880\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2854 - auc: 0.9869\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2834 - auc: 0.9867\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2765 - auc: 0.9880\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2922 - auc: 0.9872\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2941 - auc: 0.9873\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2718 - auc: 0.9869\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2653 - auc: 0.9875\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2815 - auc: 0.9882\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2773 - auc: 0.9870\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2851 - auc: 0.9885\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2766 - auc: 0.9870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 1.922115865143903e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.18218199608610566\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '1.9221', 'eer_eval': '0.1821', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!1.9221.hdf5', 'tnow': '2022-05-28 02:54:06.997904'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 46s 26ms/step - loss: 0.5911 - auc: 0.8943\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3722 - auc: 0.9702\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3410 - auc: 0.9723\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3265 - auc: 0.9743\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3212 - auc: 0.9762\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3099 - auc: 0.9764 1s - loss: \n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3181 - auc: 0.9771\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3139 - auc: 0.9779\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2935 - auc: 0.9803\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3055 - auc: 0.9802\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3021 - auc: 0.9784\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2991 - auc: 0.9799\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3038 - auc: 0.9800\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3055 - auc: 0.9829\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3081 - auc: 0.9820\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2933 - auc: 0.9831\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2876 - auc: 0.9834\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3030 - auc: 0.9839\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2913 - auc: 0.9849\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2954 - auc: 0.9841\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2945 - auc: 0.9857\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2929 - auc: 0.9834\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2864 - auc: 0.9855\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2906 - auc: 0.9842\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2922 - auc: 0.9860\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2782 - auc: 0.9848\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2877 - auc: 0.9854\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2945 - auc: 0.9858\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2884 - auc: 0.9859\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2817 - auc: 0.9862\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2889 - auc: 0.9860\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2832 - auc: 0.9864\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2693 - auc: 0.9877\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2891 - auc: 0.9869\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2862 - auc: 0.9865\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2763 - auc: 0.9864\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2917 - auc: 0.9871\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2913 - auc: 0.9870\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2824 - auc: 0.9876\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2770 - auc: 0.9876\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2761 - auc: 0.9883\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2752 - auc: 0.9885\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2818 - auc: 0.9889\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2831 - auc: 0.9889\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2879 - auc: 0.9897\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2803 - auc: 0.9883\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2709 - auc: 0.9884\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2716 - auc: 0.9887\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2863 - auc: 0.9889\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2704 - auc: 0.9890\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2682 - auc: 0.9892\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2713 - auc: 0.9890\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2824 - auc: 0.9889\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2609 - auc: 0.9896\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2867 - auc: 0.9890\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2687 - auc: 0.9895\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2754 - auc: 0.9887\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2651 - auc: 0.9889\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2799 - auc: 0.9898\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2768 - auc: 0.9892\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2783 - auc: 0.9894\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2814 - auc: 0.9889\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2696 - auc: 0.9887\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2765 - auc: 0.9887\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2763 - auc: 0.9889\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2676 - auc: 0.9885\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2736 - auc: 0.9896\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2715 - auc: 0.9901\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2835 - auc: 0.9900\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2710 - auc: 0.9891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.1720450097847358\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0', 'eer_eval': '0.1720', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0.hdf5', 'tnow': '2022-05-28 03:44:41.192833'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 46s 26ms/step - loss: 0.6174 - auc: 0.8861\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3602 - auc: 0.9691\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3330 - auc: 0.9727\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3319 - auc: 0.9745\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3489 - auc: 0.9733\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3065 - auc: 0.9771\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3174 - auc: 0.9762\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3128 - auc: 0.9782\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3120 - auc: 0.9788\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2959 - auc: 0.9798\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3113 - auc: 0.9796\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3001 - auc: 0.9812\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2947 - auc: 0.9813\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3046 - auc: 0.9818\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2866 - auc: 0.9826\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2903 - auc: 0.9830\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2870 - auc: 0.9816\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3038 - auc: 0.9830\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2918 - auc: 0.9836\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2919 - auc: 0.9847\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2764 - auc: 0.9859\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2890 - auc: 0.9839\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2898 - auc: 0.9854\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3063 - auc: 0.9850\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2980 - auc: 0.9840\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2882 - auc: 0.9851\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2892 - auc: 0.9857\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2888 - auc: 0.9855\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2820 - auc: 0.9866\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2866 - auc: 0.9852\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2828 - auc: 0.9868\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2810 - auc: 0.9871\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2897 - auc: 0.9870\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2965 - auc: 0.9857\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2785 - auc: 0.9874\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2885 - auc: 0.9875\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2804 - auc: 0.9870\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2956 - auc: 0.9877\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2791 - auc: 0.9875\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2809 - auc: 0.9873\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2705 - auc: 0.9883\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2741 - auc: 0.9886\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2835 - auc: 0.9876\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2864 - auc: 0.9882\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2880 - auc: 0.9881\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2697 - auc: 0.9885\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2854 - auc: 0.9884\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2731 - auc: 0.9890\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2841 - auc: 0.9882\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2733 - auc: 0.9879\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2721 - auc: 0.9882\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2770 - auc: 0.9883\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2790 - auc: 0.9890\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2757 - auc: 0.9888\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2732 - auc: 0.9888\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2850 - auc: 0.9878\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2758 - auc: 0.9873\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2726 - auc: 0.9887\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2822 - auc: 0.9885\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2714 - auc: 0.9891\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2801 - auc: 0.9884\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2718 - auc: 0.9896\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2716 - auc: 0.9901\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2799 - auc: 0.9887\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2853 - auc: 0.9901\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2771 - auc: 0.9892\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2808 - auc: 0.9893\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2760 - auc: 0.9885\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2709 - auc: 0.9883\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2748 - auc: 0.9885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 1.922115865143903e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.17975538160469665\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '1.9221', 'eer_eval': '0.1797', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!1.9221.hdf5', 'tnow': '2022-05-28 04:35:47.370569'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 46s 26ms/step - loss: 0.5939 - auc: 0.8937\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3627 - auc: 0.9681\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3413 - auc: 0.9718\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3248 - auc: 0.9741\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3230 - auc: 0.9757\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3201 - auc: 0.9780\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3134 - auc: 0.9786\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3039 - auc: 0.9788\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3158 - auc: 0.9796\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3011 - auc: 0.9820\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3059 - auc: 0.9795\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3071 - auc: 0.9817\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2905 - auc: 0.9834\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3119 - auc: 0.9802\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3003 - auc: 0.9816\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2894 - auc: 0.9844\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3019 - auc: 0.9821\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2909 - auc: 0.9833\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2945 - auc: 0.9838\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3014 - auc: 0.9838\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2967 - auc: 0.9831\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2882 - auc: 0.9841\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2814 - auc: 0.9851\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2764 - auc: 0.9849\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2906 - auc: 0.9857\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3034 - auc: 0.9854\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2921 - auc: 0.9854\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2782 - auc: 0.9856\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2766 - auc: 0.9856\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2837 - auc: 0.9847\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2901 - auc: 0.9860\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2857 - auc: 0.9863\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2920 - auc: 0.9859\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2723 - auc: 0.9854\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2809 - auc: 0.9864\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2838 - auc: 0.9868\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2958 - auc: 0.9871\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2868 - auc: 0.9868\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2848 - auc: 0.9876\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2704 - auc: 0.9873\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2935 - auc: 0.9868\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2848 - auc: 0.9880\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2927 - auc: 0.9879\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2837 - auc: 0.9887\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2850 - auc: 0.9875\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2754 - auc: 0.9882\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2842 - auc: 0.9878\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2992 - auc: 0.9874\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2770 - auc: 0.9879\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2856 - auc: 0.9884\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2764 - auc: 0.9875\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2881 - auc: 0.9883\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2911 - auc: 0.9889\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2817 - auc: 0.9872\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2752 - auc: 0.9892\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2704 - auc: 0.9876\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2915 - auc: 0.9879\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2684 - auc: 0.9871\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2690 - auc: 0.9888\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2827 - auc: 0.9886\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2890 - auc: 0.9889\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2763 - auc: 0.9886\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2798 - auc: 0.9875\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2852 - auc: 0.9878\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2803 - auc: 0.9877\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2742 - auc: 0.9886\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2835 - auc: 0.9886\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2804 - auc: 0.9890\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2728 - auc: 0.9890\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2876 - auc: 0.9880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0004089432726869642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.1681898238747554\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0004', 'eer_eval': '0.1681', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0004.hdf5', 'tnow': '2022-05-28 05:26:36.495087'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 46s 26ms/step - loss: 0.5527 - auc: 0.9006\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3490 - auc: 0.9695\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3532 - auc: 0.9735\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3271 - auc: 0.9768\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3172 - auc: 0.9761\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3071 - auc: 0.9788\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3161 - auc: 0.9802\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3081 - auc: 0.9790\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3175 - auc: 0.9804\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2986 - auc: 0.9813\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3016 - auc: 0.9830\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3104 - auc: 0.9810\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3039 - auc: 0.9824\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2935 - auc: 0.9828\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2999 - auc: 0.9838\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3057 - auc: 0.9825\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2972 - auc: 0.9829\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2909 - auc: 0.9843\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2896 - auc: 0.9841\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2928 - auc: 0.9849\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2881 - auc: 0.9845\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2949 - auc: 0.9843\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2881 - auc: 0.9854\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2887 - auc: 0.9859\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2881 - auc: 0.9849\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2767 - auc: 0.9859\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2886 - auc: 0.9852\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2929 - auc: 0.9844\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2837 - auc: 0.9856\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2899 - auc: 0.9850\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2870 - auc: 0.9870\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2800 - auc: 0.9844\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2863 - auc: 0.9866\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2904 - auc: 0.9868\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2757 - auc: 0.9871\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2811 - auc: 0.9861\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2714 - auc: 0.9863\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2849 - auc: 0.9867\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2693 - auc: 0.9869\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2674 - auc: 0.9870\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2806 - auc: 0.9873 1s - l\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2770 - auc: 0.9879\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2925 - auc: 0.9879\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2781 - auc: 0.9875\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2750 - auc: 0.9876\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2815 - auc: 0.9883\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2926 - auc: 0.9872\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2800 - auc: 0.9874\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2839 - auc: 0.9874\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2649 - auc: 0.9871\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2711 - auc: 0.9872\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2751 - auc: 0.9869\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2827 - auc: 0.9880\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2727 - auc: 0.9883\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2829 - auc: 0.9881\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2820 - auc: 0.9883\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2812 - auc: 0.9873\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2674 - auc: 0.9875 1s - loss:\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2827 - auc: 0.9891\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2729 - auc: 0.9881\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2672 - auc: 0.9886\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2829 - auc: 0.9882\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2672 - auc: 0.9866\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2790 - auc: 0.9886\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2927 - auc: 0.9895\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2694 - auc: 0.9875\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2772 - auc: 0.9887\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2838 - auc: 0.9894\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2717 - auc: 0.9875\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2906 - auc: 0.9883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0008371077040253674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.21187866927592952\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0008', 'eer_eval': '0.2118', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0008.hdf5', 'tnow': '2022-05-28 06:17:19.102955'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 46s 26ms/step - loss: 0.5866 - auc: 0.8971\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3626 - auc: 0.9707\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3310 - auc: 0.9736\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3225 - auc: 0.9779\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3159 - auc: 0.9776\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3184 - auc: 0.9767\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3072 - auc: 0.9811\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3003 - auc: 0.9788\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3049 - auc: 0.9812\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2982 - auc: 0.9809\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3000 - auc: 0.9816\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2975 - auc: 0.9821\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2895 - auc: 0.9821\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2911 - auc: 0.9824\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2875 - auc: 0.9831\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2854 - auc: 0.9838\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2876 - auc: 0.9826\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3057 - auc: 0.9833\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2962 - auc: 0.9829\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2906 - auc: 0.9847\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2809 - auc: 0.9838\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2891 - auc: 0.9847\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2863 - auc: 0.9857\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2983 - auc: 0.9843\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2830 - auc: 0.9847\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2996 - auc: 0.9850\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2825 - auc: 0.9863\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2763 - auc: 0.9871\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2753 - auc: 0.9861\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2832 - auc: 0.9846\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2755 - auc: 0.9869\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2993 - auc: 0.9868\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2825 - auc: 0.9874\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2867 - auc: 0.9861\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2802 - auc: 0.9860\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2933 - auc: 0.9884\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2817 - auc: 0.9863\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2846 - auc: 0.9875\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2803 - auc: 0.9871\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2786 - auc: 0.9887\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2743 - auc: 0.9883\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2727 - auc: 0.9877\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2879 - auc: 0.9889\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2789 - auc: 0.9884\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2800 - auc: 0.9886\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2808 - auc: 0.9890\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2869 - auc: 0.9881\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2841 - auc: 0.9893\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2770 - auc: 0.9887\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2754 - auc: 0.9884\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2651 - auc: 0.9886\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2781 - auc: 0.9899\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2834 - auc: 0.9886\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2862 - auc: 0.9883\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2760 - auc: 0.9885\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2851 - auc: 0.9891\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2666 - auc: 0.9890\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2753 - auc: 0.9904\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2789 - auc: 0.9899\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2790 - auc: 0.9894\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2670 - auc: 0.9889\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2788 - auc: 0.9900\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2783 - auc: 0.9893\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2873 - auc: 0.9893\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2763 - auc: 0.9894\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2701 - auc: 0.9891\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2776 - auc: 0.9886\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2747 - auc: 0.9893\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2689 - auc: 0.9896\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2802 - auc: 0.9886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.17133072407045008\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0', 'eer_eval': '0.1713', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0.hdf5', 'tnow': '2022-05-28 07:08:17.778780'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 45s 25ms/step - loss: 0.5999 - auc: 0.8897\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3574 - auc: 0.9694\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3337 - auc: 0.9730\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3087 - auc: 0.9746\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3115 - auc: 0.9798\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3042 - auc: 0.9800\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3081 - auc: 0.9795\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3040 - auc: 0.9799\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3000 - auc: 0.9816\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3058 - auc: 0.9826\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2982 - auc: 0.9807\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2969 - auc: 0.9816\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2974 - auc: 0.9832\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2919 - auc: 0.9820\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2819 - auc: 0.9834\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3061 - auc: 0.9840\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3005 - auc: 0.9832\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2985 - auc: 0.9836\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2896 - auc: 0.9836\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2909 - auc: 0.9850\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2894 - auc: 0.9848\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2896 - auc: 0.9847\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2956 - auc: 0.9838\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2995 - auc: 0.9851\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 42s 25ms/step - loss: 0.2838 - auc: 0.9848\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2913 - auc: 0.9846\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2864 - auc: 0.9853\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2778 - auc: 0.9870\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2895 - auc: 0.9863\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2825 - auc: 0.9850\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2744 - auc: 0.9859\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2870 - auc: 0.9863\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2974 - auc: 0.9866\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2808 - auc: 0.9879\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2826 - auc: 0.9868\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2811 - auc: 0.9872\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2852 - auc: 0.9866\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2872 - auc: 0.9860\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2850 - auc: 0.9874\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2714 - auc: 0.9860\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2782 - auc: 0.9874\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2915 - auc: 0.9881\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2734 - auc: 0.9875\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2882 - auc: 0.9876\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2862 - auc: 0.9879\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2899 - auc: 0.9878\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2782 - auc: 0.9884\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2812 - auc: 0.9880\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2663 - auc: 0.9876\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2872 - auc: 0.9877\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2672 - auc: 0.9872\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2757 - auc: 0.9882\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2806 - auc: 0.9872\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2769 - auc: 0.9878\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2738 - auc: 0.9887\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2869 - auc: 0.9883\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2757 - auc: 0.9879\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2748 - auc: 0.9885\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2716 - auc: 0.9890\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2797 - auc: 0.9885\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2653 - auc: 0.9882\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2784 - auc: 0.9888\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2771 - auc: 0.9877\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2768 - auc: 0.9881\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2771 - auc: 0.9882\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2695 - auc: 0.9874\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2776 - auc: 0.9894\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2764 - auc: 0.9886\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2760 - auc: 0.9888\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2803 - auc: 0.9873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0004911268482993539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.20559686888454012\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0004', 'eer_eval': '0.2055', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0004.hdf5', 'tnow': '2022-05-28 07:58:45.834243'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 45s 25ms/step - loss: 0.6173 - auc: 0.8912\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3750 - auc: 0.9673\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3294 - auc: 0.9728 1s - lo\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3375 - auc: 0.9725\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3240 - auc: 0.9739\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3181 - auc: 0.9742\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3109 - auc: 0.9759\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3083 - auc: 0.9780\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3180 - auc: 0.9778\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2928 - auc: 0.9797\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3008 - auc: 0.9811\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3063 - auc: 0.9810\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3014 - auc: 0.9805\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2991 - auc: 0.9819\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3003 - auc: 0.9818\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3003 - auc: 0.9834\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3045 - auc: 0.9833\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2925 - auc: 0.9835\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2944 - auc: 0.9821\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2860 - auc: 0.9846\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2881 - auc: 0.9820\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2852 - auc: 0.9838\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2965 - auc: 0.9846\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2877 - auc: 0.9838\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2933 - auc: 0.9844\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2906 - auc: 0.9845\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2847 - auc: 0.9844\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2852 - auc: 0.9834\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2962 - auc: 0.9843\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2942 - auc: 0.9850\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2934 - auc: 0.9853\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2888 - auc: 0.9865\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2838 - auc: 0.9863\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2874 - auc: 0.9870\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2817 - auc: 0.9860\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3012 - auc: 0.9865\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2850 - auc: 0.9859\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2870 - auc: 0.9866\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2835 - auc: 0.9865\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2882 - auc: 0.9869\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2881 - auc: 0.9874\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2810 - auc: 0.9879\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2807 - auc: 0.9868\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2821 - auc: 0.9874\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2827 - auc: 0.9877\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2899 - auc: 0.9872\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2912 - auc: 0.9873\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2710 - auc: 0.9873\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2776 - auc: 0.9868\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2807 - auc: 0.9865\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2799 - auc: 0.9885\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2788 - auc: 0.9872\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2878 - auc: 0.9875\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2792 - auc: 0.9875\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2860 - auc: 0.9881\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2888 - auc: 0.9880\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2882 - auc: 0.9872\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2879 - auc: 0.9895\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2811 - auc: 0.9875\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2799 - auc: 0.9883\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2826 - auc: 0.9880\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2818 - auc: 0.9877\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2833 - auc: 0.9860\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2858 - auc: 0.9872\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2826 - auc: 0.9887 1\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2835 - auc: 0.9873\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2806 - auc: 0.9872\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2863 - auc: 0.9890\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2844 - auc: 0.9874\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2795 - auc: 0.9873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0008563288626768065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.18389432485322893\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0008', 'eer_eval': '0.1838', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0008.hdf5', 'tnow': '2022-05-28 08:49:47.358243'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 45s 25ms/step - loss: 0.6013 - auc: 0.8931\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3509 - auc: 0.9690\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3479 - auc: 0.9715\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3332 - auc: 0.9752\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3169 - auc: 0.9747\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3211 - auc: 0.9766\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3036 - auc: 0.9777\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2991 - auc: 0.9785\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2988 - auc: 0.9797\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3105 - auc: 0.9795\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3140 - auc: 0.9818\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3065 - auc: 0.9811\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2939 - auc: 0.9827\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2960 - auc: 0.9814\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2858 - auc: 0.9817\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2977 - auc: 0.9827\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2902 - auc: 0.9840\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2904 - auc: 0.9836\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2892 - auc: 0.9847\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2814 - auc: 0.9834\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2946 - auc: 0.9851\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2796 - auc: 0.9850\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2833 - auc: 0.9852\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2924 - auc: 0.9848\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2834 - auc: 0.9862\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2909 - auc: 0.9862\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2951 - auc: 0.9855\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2760 - auc: 0.9852\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2862 - auc: 0.9862\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2859 - auc: 0.9863\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2873 - auc: 0.9852\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2924 - auc: 0.9867\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2807 - auc: 0.9863\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2719 - auc: 0.9869\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2936 - auc: 0.9882\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2758 - auc: 0.9881\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2886 - auc: 0.9877\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2847 - auc: 0.9878\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2883 - auc: 0.9882\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2772 - auc: 0.9889\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2758 - auc: 0.9877\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2873 - auc: 0.9899\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2709 - auc: 0.9886\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2755 - auc: 0.9888\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2924 - auc: 0.9881 0s - loss: 0.2926 \n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2737 - auc: 0.9891\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2786 - auc: 0.9892\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2891 - auc: 0.9886\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2787 - auc: 0.9904\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2740 - auc: 0.9896\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2806 - auc: 0.9897\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2665 - auc: 0.9894\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2779 - auc: 0.9889\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2860 - auc: 0.9893\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2725 - auc: 0.9896\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2697 - auc: 0.9901\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2732 - auc: 0.9896\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2781 - auc: 0.9893\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2687 - auc: 0.9889\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2795 - auc: 0.9895\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2756 - auc: 0.9894\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2879 - auc: 0.9894\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2818 - auc: 0.9886\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2800 - auc: 0.9900\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2825 - auc: 0.9900\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2791 - auc: 0.9894\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2778 - auc: 0.9890 1s - \n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2685 - auc: 0.9887\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2724 - auc: 0.9890\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2696 - auc: 0.9886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.15590998043052834\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0', 'eer_eval': '0.1559', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0.hdf5', 'tnow': '2022-05-28 09:40:28.866887'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 45s 25ms/step - loss: 0.6124 - auc: 0.8899\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3761 - auc: 0.9661\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3437 - auc: 0.9709\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3295 - auc: 0.9738\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3189 - auc: 0.9753\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3224 - auc: 0.9754\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3153 - auc: 0.9762\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3037 - auc: 0.9794\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3198 - auc: 0.9788\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3113 - auc: 0.9799\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3091 - auc: 0.9798\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3139 - auc: 0.9792\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3081 - auc: 0.9811\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3101 - auc: 0.9814\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3069 - auc: 0.9812\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.3031 - auc: 0.9839\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3008 - auc: 0.9818\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3028 - auc: 0.9837\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2991 - auc: 0.9811\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2912 - auc: 0.9837\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2860 - auc: 0.9815\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.3011 - auc: 0.9840\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2849 - auc: 0.9838\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2945 - auc: 0.9845\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2722 - auc: 0.9843\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2823 - auc: 0.9844\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2945 - auc: 0.9827\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2765 - auc: 0.9839\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2835 - auc: 0.9845\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2990 - auc: 0.9850\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2798 - auc: 0.9846\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2944 - auc: 0.9844\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2852 - auc: 0.9872\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2952 - auc: 0.9861\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2876 - auc: 0.9865\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2884 - auc: 0.9854\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2782 - auc: 0.9862\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2815 - auc: 0.9864\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2888 - auc: 0.9857\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2841 - auc: 0.9859\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2891 - auc: 0.9867\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2883 - auc: 0.9869\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2722 - auc: 0.9876\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2834 - auc: 0.9875\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2805 - auc: 0.9865\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2836 - auc: 0.9872\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2853 - auc: 0.9876\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2885 - auc: 0.9874\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2845 - auc: 0.9877\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2853 - auc: 0.9866\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2688 - auc: 0.9875\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2861 - auc: 0.9869\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2886 - auc: 0.9876\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2855 - auc: 0.9867\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2898 - auc: 0.9869\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2816 - auc: 0.9871\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2864 - auc: 0.9862\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2849 - auc: 0.9881\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2848 - auc: 0.9881\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2841 - auc: 0.9868\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2888 - auc: 0.9877\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.2757 - auc: 0.9887\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2866 - auc: 0.9875\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2815 - auc: 0.9879\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2873 - auc: 0.9879\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2728 - auc: 0.9877\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2706 - auc: 0.9867\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2814 - auc: 0.9870\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2657 - auc: 0.9873\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.2886 - auc: 0.9869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0005050490659441593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.18460861056751465\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0005', 'eer_eval': '0.1846', 'saved_model': 'saved_models/model_name!ResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0005.hdf5', 'tnow': '2022-05-28 10:31:01.100309'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 35s 19ms/step - loss: 0.3530 - auc: 0.9413\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.0361 - auc: 0.9994\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0217 - auc: 0.9996\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.0192 - auc: 0.9998\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.0615 - auc: 0.9973\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.0086 - auc: 0.9998\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0154 - auc: 0.9996\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0047 - auc: 1.0000\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0074 - auc: 1.0000\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0013 - auc: 1.0000\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.0116 - auc: 0.9996\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0033 - auc: 0.9999\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0096 - auc: 0.9998\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0026 - auc: 1.0000\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0098 - auc: 0.9997\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.0034 - auc: 0.9999\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 9.4960e-04 - auc: 1.0000\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 3.7398e-04 - auc: 1.0000\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0183 - auc: 0.9996\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0012 - auc: 1.0000\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0032 - auc: 0.9999\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.0024 - auc: 1.0000\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0096 - auc: 0.9999\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0064 - auc: 0.9999\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0012 - auc: 1.0000\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0086 - auc: 0.9999\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 7.4986e-04 - auc: 1.0000\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.0015 - auc: 1.0000\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0013 - auc: 1.0000\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 6.4035e-04 - auc: 1.0000\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0028 - auc: 0.9999\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 2.9340e-04 - auc: 1.0000\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 1.5328e-04 - auc: 1.0000\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 4.8168e-04 - auc: 1.0000\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 5.6967e-04 - auc: 1.0000\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 1.4690e-04 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 1.5972e-04 - auc: 1.0000\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 3.3393e-04 - auc: 1.0000\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 2.5560e-04 - auc: 1.0000\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 1.5246e-04 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0013 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 5.4903e-04 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 6.6310e-04 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 2.1990e-04 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 1.6859e-04 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 3.7200e-04 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 7.5470e-05 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 5.4698e-04 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 7.1958e-05 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 5.8197e-05 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 9.8925e-05 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 6.0790e-05 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 2.3799e-05 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 5.6454e-05 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 2.1434e-05 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 8.6448e-05 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 4.1213e-05 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 3.7689e-05 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 4.9705e-05 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 7.7623e-05 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 6.3174e-05 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 2.0115e-05 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 1.3720e-04 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 3.9514e-05 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 7.1066e-05 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 1.4154e-04 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 2.1355e-05 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 2.6285e-04 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 3.1115e-05 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 2.1359e-04 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0009139923386311235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.2048825831702544\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0009', 'eer_eval': '0.2048', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0009.hdf5', 'tnow': '2022-05-28 11:09:10.880728'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 35s 19ms/step - loss: 0.3339 - auc: 0.9472\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.0381 - auc: 0.9993\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.0216 - auc: 0.9997\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.0199 - auc: 0.9997\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0257 - auc: 0.9996\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0081 - auc: 0.9998\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0099 - auc: 0.9998\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0073 - auc: 1.0000\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0074 - auc: 0.9999\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0043 - auc: 1.0000\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0020 - auc: 1.0000\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.0025 - auc: 1.0000\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0063 - auc: 0.9999\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0050 - auc: 0.9999\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0051 - auc: 0.9999\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0019 - auc: 1.0000\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0021 - auc: 1.0000\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.0069 - auc: 0.9999\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.0046 - auc: 0.9999\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0013 - auc: 1.0000\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 6.7543e-04 - auc: 1.0000\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 3.8351e-04 - auc: 1.0000\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0117 - auc: 0.9997\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 2.2397e-04 - auc: 1.0000\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 2.2779e-04 - auc: 1.0000\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0043 - auc: 0.9998\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0072 - auc: 0.9998\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0012 - auc: 1.0000\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.0024 - auc: 1.0000\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 5.0041e-04 - auc: 1.0000\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 1.6880e-04 - auc: 1.0000\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 9.3258e-04 - auc: 1.0000\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 9.8859e-04 - auc: 1.0000\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 2.6697e-04 - auc: 1.0000\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 9.2754e-04 - auc: 1.0000\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 4.0085e-04 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 6.2963e-04 - auc: 1.0000\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 2.7647e-04 - auc: 1.0000\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 6.1164e-05 - auc: 1.0000\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 7.7104e-05 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 1.1214e-04 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 5.8022e-05 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 1.4370e-04 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 4.6630e-05 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 4.1932e-05 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 2.9732e-05 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 2.9670e-04 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 1.2717e-04 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 5.5101e-04 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 1.1105e-04 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 4.0101e-05 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 1.9911e-05 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 1.8802e-04 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 5.0180e-05 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 1.8397e-04 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 2.0859e-05 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 4.6379e-05 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 2.9900e-05 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 9.0679e-05 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 6.8376e-05 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 1.7005e-05 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 1.6573e-05 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 1.7341e-04 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 2.3732e-04 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 8.3869e-05 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 2.2030e-05 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 7.2449e-06 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 5.2320e-05 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 9.1590e-06 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 6.3567e-04 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0004666067486412813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.20416829745596868\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0004', 'eer_eval': '0.2041', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0004.hdf5', 'tnow': '2022-05-28 11:47:18.580614'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 34s 19ms/step - loss: 0.3241 - auc: 0.9473\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0402 - auc: 0.9993\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.0412 - auc: 0.9987\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0128 - auc: 0.9999\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0556 - auc: 0.9988\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0083 - auc: 0.9999\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0076 - auc: 0.9999\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.0080 - auc: 0.9999\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.0047 - auc: 1.0000\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0040 - auc: 0.9999\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0164 - auc: 0.9997\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0032 - auc: 1.0000\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0038 - auc: 1.0000\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0072 - auc: 0.9999\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0053 - auc: 0.9998\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.0050 - auc: 0.9999\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 5.5410e-04 - auc: 1.0000\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0092 - auc: 0.9997\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0021 - auc: 1.0000\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0024 - auc: 0.9999\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0075 - auc: 0.9998\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0010 - auc: 1.0000\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.0041 - auc: 1.0000\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 8.2628e-04 - auc: 1.0000\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.0063 - auc: 0.9999\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 2.9140e-04 - auc: 1.0000\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0017 - auc: 1.0000\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 7.3944e-04 - auc: 1.0000\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0014 - auc: 0.9999\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 9.1270e-04 - auc: 1.0000\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 7.6059e-04 - auc: 1.0000\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0020 - auc: 0.9999\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0020 - auc: 0.9999\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 5.3715e-04 - auc: 1.0000\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0056 - auc: 0.9999\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 6.1101e-04 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 1.2647e-04 - auc: 1.0000\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 1.1118e-04 - auc: 1.0000\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 2.2615e-04 - auc: 1.0000\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 1.5089e-04 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.0011 - auc: 0.9999\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 5.2539e-04 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 9.3062e-04 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 4.0115e-04 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 5.1409e-04 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 5.3221e-05 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 1.7289e-04 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 1.1217e-04 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 4.1593e-05 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 2.3344e-05 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 2.2302e-04 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 1.9525e-05 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 5.3166e-04 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 5.3737e-05 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 6.9263e-05 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 1.2624e-04 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 1.6713e-04 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 9.5930e-05 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 5.0486e-05 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 4.2309e-04 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 2.1260e-04 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 2.6374e-04 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 2.1136e-04 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 8.1106e-05 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 1.7218e-04 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 2.5818e-05 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 3.1864e-05 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 4.3743e-04 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 8.0909e-05 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 2.6195e-05 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0009332134972825626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.19545988258317026\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0009', 'eer_eval': '0.1954', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0009.hdf5', 'tnow': '2022-05-28 12:25:17.424972'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 35s 19ms/step - loss: 0.7445 - auc: 0.8427\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3726 - auc: 0.9621\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3733 - auc: 0.9664\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3468 - auc: 0.9712\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3456 - auc: 0.9708\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3336 - auc: 0.9729\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3268 - auc: 0.9717\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3205 - auc: 0.9739\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3262 - auc: 0.9763\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3185 - auc: 0.9758\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3231 - auc: 0.9774\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3165 - auc: 0.9752\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3133 - auc: 0.9797\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3102 - auc: 0.9777\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3022 - auc: 0.9785\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3103 - auc: 0.9781\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3059 - auc: 0.9790\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3092 - auc: 0.9793\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2917 - auc: 0.9805\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3093 - auc: 0.9816\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3049 - auc: 0.9812\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3134 - auc: 0.9810\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2944 - auc: 0.9805\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3143 - auc: 0.9797\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3097 - auc: 0.9805\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3013 - auc: 0.9807\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2894 - auc: 0.9802\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3041 - auc: 0.9807\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2870 - auc: 0.9821\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3025 - auc: 0.9819\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2960 - auc: 0.9829\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3030 - auc: 0.9804\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3090 - auc: 0.9829\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3075 - auc: 0.9824\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2981 - auc: 0.9829\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2940 - auc: 0.9834\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3093 - auc: 0.9817\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3031 - auc: 0.9842\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2930 - auc: 0.9842\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2901 - auc: 0.9841\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2821 - auc: 0.9847\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2841 - auc: 0.9843\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2909 - auc: 0.9831\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2838 - auc: 0.9845\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2902 - auc: 0.9850\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2941 - auc: 0.9852\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2781 - auc: 0.9838\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2848 - auc: 0.9846\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2902 - auc: 0.9844\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2928 - auc: 0.9843\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2967 - auc: 0.9852\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2933 - auc: 0.9860\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2874 - auc: 0.9845\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2916 - auc: 0.9847\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2990 - auc: 0.9849\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2862 - auc: 0.9859\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2822 - auc: 0.9850\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2827 - auc: 0.9857\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2818 - auc: 0.9860\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2779 - auc: 0.9847\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2843 - auc: 0.9866\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2855 - auc: 0.9859\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2795 - auc: 0.9853\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3004 - auc: 0.9849\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2887 - auc: 0.9854\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2853 - auc: 0.9853\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2911 - auc: 0.9854\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2956 - auc: 0.9861\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2804 - auc: 0.9850\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2826 - auc: 0.9854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.20702544031311151\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0', 'eer_eval': '0.2070', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0.hdf5', 'tnow': '2022-05-28 13:03:42.279915'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 35s 19ms/step - loss: 0.6707 - auc: 0.8617\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3912 - auc: 0.9620\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3487 - auc: 0.9683\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3407 - auc: 0.9709\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3355 - auc: 0.9726\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3229 - auc: 0.9713\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3210 - auc: 0.9745\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3228 - auc: 0.9739\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3150 - auc: 0.9760\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3154 - auc: 0.9775\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3149 - auc: 0.9782\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3157 - auc: 0.9779\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3118 - auc: 0.9777\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3201 - auc: 0.9769\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3055 - auc: 0.9775\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3019 - auc: 0.9789\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3126 - auc: 0.9791\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3045 - auc: 0.9786\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3071 - auc: 0.9797\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3099 - auc: 0.9808\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3057 - auc: 0.9799\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2990 - auc: 0.9814\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2933 - auc: 0.9794\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3109 - auc: 0.9805\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2984 - auc: 0.9803\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3109 - auc: 0.9805\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2905 - auc: 0.9823\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2944 - auc: 0.9813\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2903 - auc: 0.9818\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2924 - auc: 0.9819\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3004 - auc: 0.9825\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2992 - auc: 0.9827\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2864 - auc: 0.9824\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2936 - auc: 0.9824\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2986 - auc: 0.9834\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2842 - auc: 0.9828\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3010 - auc: 0.9829\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3003 - auc: 0.9830\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2838 - auc: 0.9838\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2853 - auc: 0.9830\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2883 - auc: 0.9839\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2891 - auc: 0.9864\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2846 - auc: 0.9843\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2882 - auc: 0.9840\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3024 - auc: 0.9839\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2948 - auc: 0.9855\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2862 - auc: 0.9844\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2802 - auc: 0.9857\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2810 - auc: 0.9862\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2966 - auc: 0.9857\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2788 - auc: 0.9845\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2865 - auc: 0.9850\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2884 - auc: 0.9848\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2904 - auc: 0.9860\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2942 - auc: 0.9843\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2771 - auc: 0.9843\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2935 - auc: 0.9857\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2894 - auc: 0.9860\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2789 - auc: 0.9852\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2915 - auc: 0.9850\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3011 - auc: 0.9850\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2704 - auc: 0.9858\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2826 - auc: 0.9852\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2784 - auc: 0.9856\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2868 - auc: 0.9854\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2896 - auc: 0.9854\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2894 - auc: 0.9854\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2828 - auc: 0.9863\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2918 - auc: 0.9862\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2864 - auc: 0.9857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00031283747942971354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.18646771037181994\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0003', 'eer_eval': '0.1864', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0003.hdf5', 'tnow': '2022-05-28 13:42:23.451500'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 35s 19ms/step - loss: 0.7416 - auc: 0.8465\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3678 - auc: 0.9640\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3526 - auc: 0.9697\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3428 - auc: 0.9703\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3302 - auc: 0.9723\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3239 - auc: 0.9744\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3364 - auc: 0.9748\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3199 - auc: 0.9747\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3260 - auc: 0.9766\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3119 - auc: 0.9754\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3168 - auc: 0.9776\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3177 - auc: 0.9778\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3026 - auc: 0.9789\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3041 - auc: 0.9781\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3030 - auc: 0.9787\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3030 - auc: 0.9802\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3061 - auc: 0.9777\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3169 - auc: 0.9799\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3082 - auc: 0.9797\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3015 - auc: 0.9806\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2952 - auc: 0.9796\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2958 - auc: 0.9809\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3049 - auc: 0.9811\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2862 - auc: 0.9810\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2928 - auc: 0.9819\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2979 - auc: 0.9823\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2961 - auc: 0.9816\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3025 - auc: 0.9827\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2920 - auc: 0.9819\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2897 - auc: 0.9815\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2977 - auc: 0.9813\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2985 - auc: 0.9818\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2857 - auc: 0.9828\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2942 - auc: 0.9828\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2940 - auc: 0.9834\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2809 - auc: 0.9829\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2802 - auc: 0.9836\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3012 - auc: 0.9839\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2890 - auc: 0.9843\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2888 - auc: 0.9834\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2965 - auc: 0.9844\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2910 - auc: 0.9850\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2787 - auc: 0.9846\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2856 - auc: 0.9849\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2929 - auc: 0.9852\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2910 - auc: 0.9860\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2920 - auc: 0.9842\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2715 - auc: 0.9847\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2818 - auc: 0.9846\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2907 - auc: 0.9856\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2831 - auc: 0.9857\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2824 - auc: 0.9847\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2854 - auc: 0.9852\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2913 - auc: 0.9849\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2845 - auc: 0.9862\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2869 - auc: 0.9855\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2811 - auc: 0.9851\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2788 - auc: 0.9867\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2825 - auc: 0.9868\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2977 - auc: 0.9840\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2855 - auc: 0.9862\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2843 - auc: 0.9854\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2862 - auc: 0.9853\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2822 - auc: 0.9856\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2913 - auc: 0.9848\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2812 - auc: 0.9869\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2808 - auc: 0.9851\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2805 - auc: 0.9855\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2905 - auc: 0.9854\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3065 - auc: 0.9855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 3.844231730287806e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.21088062622309198\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '3.8442', 'eer_eval': '0.2108', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!3.8442.hdf5', 'tnow': '2022-05-28 14:20:39.446124'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 34s 19ms/step - loss: 0.7630 - auc: 0.8420\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3953 - auc: 0.9617\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3651 - auc: 0.9679\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3332 - auc: 0.9719\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3440 - auc: 0.9722\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3379 - auc: 0.9742\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3270 - auc: 0.9734\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3314 - auc: 0.9740\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3202 - auc: 0.9756\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3145 - auc: 0.9772\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3222 - auc: 0.9759\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3095 - auc: 0.9759\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2999 - auc: 0.9770\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3122 - auc: 0.9783\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3108 - auc: 0.9772\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3106 - auc: 0.9780\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3089 - auc: 0.9796\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3088 - auc: 0.9781\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3004 - auc: 0.9787\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3062 - auc: 0.9782\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2951 - auc: 0.9795\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3072 - auc: 0.9772\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3132 - auc: 0.9810\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3050 - auc: 0.9814\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3015 - auc: 0.9814\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2908 - auc: 0.9818\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2877 - auc: 0.9819\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3029 - auc: 0.9819\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3001 - auc: 0.9819\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2986 - auc: 0.9818\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2998 - auc: 0.9821\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2931 - auc: 0.9820\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3035 - auc: 0.9822\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2917 - auc: 0.9824\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2972 - auc: 0.9826\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3004 - auc: 0.9821\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2883 - auc: 0.9819\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2866 - auc: 0.9828\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2926 - auc: 0.9829\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2855 - auc: 0.9840\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2902 - auc: 0.9853\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2845 - auc: 0.9836\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2871 - auc: 0.9839\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2782 - auc: 0.9845\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2990 - auc: 0.9857\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2860 - auc: 0.9843\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2894 - auc: 0.9851\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2956 - auc: 0.9857\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2872 - auc: 0.9838\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2909 - auc: 0.9845\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2854 - auc: 0.9857\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2908 - auc: 0.9849\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2861 - auc: 0.9854\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2869 - auc: 0.9839\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3032 - auc: 0.9846\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2812 - auc: 0.9840\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2849 - auc: 0.9856\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2910 - auc: 0.9857\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2827 - auc: 0.9853\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2858 - auc: 0.9847\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2770 - auc: 0.9858\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2940 - auc: 0.9857\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2875 - auc: 0.9840\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2863 - auc: 0.9850\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2886 - auc: 0.9844\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2875 - auc: 0.9855\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2891 - auc: 0.9859\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2785 - auc: 0.9869\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2787 - auc: 0.9853\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2900 - auc: 0.9846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.21330724070450097\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0', 'eer_eval': '0.2133', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0.hdf5', 'tnow': '2022-05-28 14:58:56.917920'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 35s 19ms/step - loss: 0.7609 - auc: 0.8507\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3738 - auc: 0.9617\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3525 - auc: 0.9686\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3345 - auc: 0.9720\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3815 - auc: 0.9652\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3445 - auc: 0.9724\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3171 - auc: 0.9713\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3246 - auc: 0.9749\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3232 - auc: 0.9756\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3118 - auc: 0.9766\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3226 - auc: 0.9768\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3285 - auc: 0.9768\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3158 - auc: 0.9774\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3047 - auc: 0.9777\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3170 - auc: 0.9779\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3066 - auc: 0.9781\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3033 - auc: 0.9797\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3128 - auc: 0.9783\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2951 - auc: 0.9802\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3029 - auc: 0.9791\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3042 - auc: 0.9797\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3079 - auc: 0.9798\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3026 - auc: 0.9809\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2943 - auc: 0.9824\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3059 - auc: 0.9793\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3065 - auc: 0.9817\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2971 - auc: 0.9804\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2908 - auc: 0.9810\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2968 - auc: 0.9819\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2928 - auc: 0.9832\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2872 - auc: 0.9839\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2946 - auc: 0.9824\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2995 - auc: 0.9819\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2957 - auc: 0.9825\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2941 - auc: 0.9842\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2812 - auc: 0.9836\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2771 - auc: 0.9841\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2869 - auc: 0.9839\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2819 - auc: 0.9843\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3023 - auc: 0.9845\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2982 - auc: 0.9839\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2963 - auc: 0.9851\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2840 - auc: 0.9854\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2878 - auc: 0.9858\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2800 - auc: 0.9844\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2992 - auc: 0.9847\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2870 - auc: 0.9850\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2933 - auc: 0.9861\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2774 - auc: 0.9857\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2758 - auc: 0.9862\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2863 - auc: 0.9849\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2838 - auc: 0.9856\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2754 - auc: 0.9853\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2796 - auc: 0.9844\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2891 - auc: 0.9852\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2784 - auc: 0.9859\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3006 - auc: 0.9862\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2731 - auc: 0.9869\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2788 - auc: 0.9856\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2948 - auc: 0.9858\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2883 - auc: 0.9862\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2728 - auc: 0.9848\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2734 - auc: 0.9858\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2862 - auc: 0.9866\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2780 - auc: 0.9863\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2846 - auc: 0.9868\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2839 - auc: 0.9852\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2876 - auc: 0.9859\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2998 - auc: 0.9853\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2901 - auc: 0.9854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.19474559686888454\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0', 'eer_eval': '0.1947', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0.hdf5', 'tnow': '2022-05-28 15:37:40.816383'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 35s 19ms/step - loss: 0.6750 - auc: 0.8490\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.4115 - auc: 0.9614\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3692 - auc: 0.9694\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3428 - auc: 0.9690\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3284 - auc: 0.9732\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3213 - auc: 0.9716\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3228 - auc: 0.9737\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3287 - auc: 0.9729\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3195 - auc: 0.9758\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3134 - auc: 0.9761\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3102 - auc: 0.9759\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3291 - auc: 0.9773\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3054 - auc: 0.9790\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3094 - auc: 0.9789\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3153 - auc: 0.9795\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3135 - auc: 0.9782\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3108 - auc: 0.9801\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3076 - auc: 0.9791\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2986 - auc: 0.9794\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3003 - auc: 0.9801\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3022 - auc: 0.9796\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3082 - auc: 0.9782\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3041 - auc: 0.9797\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3036 - auc: 0.9789\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3067 - auc: 0.9787\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2965 - auc: 0.9815\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2980 - auc: 0.9816\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2965 - auc: 0.9803\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3001 - auc: 0.9810\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3027 - auc: 0.9819\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2879 - auc: 0.9811\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2940 - auc: 0.9816\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2966 - auc: 0.9808\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2971 - auc: 0.9814\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3013 - auc: 0.9837\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2888 - auc: 0.9840\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3047 - auc: 0.9824\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2871 - auc: 0.9832\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2948 - auc: 0.9842\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2896 - auc: 0.9842\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2947 - auc: 0.9843\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2958 - auc: 0.9842\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2871 - auc: 0.9835\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2823 - auc: 0.9842\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2953 - auc: 0.9851\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2830 - auc: 0.9841\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2935 - auc: 0.9858\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2914 - auc: 0.9843\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2818 - auc: 0.9849\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2844 - auc: 0.9848\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2929 - auc: 0.9852\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2754 - auc: 0.9851\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2852 - auc: 0.9849\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2965 - auc: 0.9859\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2880 - auc: 0.9860\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2893 - auc: 0.9844\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2806 - auc: 0.9849\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2820 - auc: 0.9842\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2845 - auc: 0.9852\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2775 - auc: 0.9862\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2887 - auc: 0.9841\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2879 - auc: 0.9838\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2864 - auc: 0.9853\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2851 - auc: 0.9853\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2790 - auc: 0.9848\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2882 - auc: 0.9857\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2790 - auc: 0.9869\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2786 - auc: 0.9852\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2807 - auc: 0.9855\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2925 - auc: 0.9850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 7.688463460575612e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.18846379647749512\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '7.6884', 'eer_eval': '0.1884', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!7.6884.hdf5', 'tnow': '2022-05-28 16:16:06.728067'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 34s 19ms/step - loss: 0.7975 - auc: 0.8361\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3810 - auc: 0.9625\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3676 - auc: 0.9669\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3369 - auc: 0.9712\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3527 - auc: 0.9719\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3458 - auc: 0.9724\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3319 - auc: 0.9745\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3236 - auc: 0.9746\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3268 - auc: 0.9760\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3131 - auc: 0.9749\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3156 - auc: 0.9772\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3172 - auc: 0.9772\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3175 - auc: 0.9784\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3154 - auc: 0.9778\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2975 - auc: 0.9796\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3142 - auc: 0.9801\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3037 - auc: 0.9796\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2974 - auc: 0.9785\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3013 - auc: 0.9785\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3113 - auc: 0.9818\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3029 - auc: 0.9800\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2999 - auc: 0.9812\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3011 - auc: 0.9811\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3084 - auc: 0.9793\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2978 - auc: 0.9804\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2935 - auc: 0.9814\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3035 - auc: 0.9809\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3070 - auc: 0.9809\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2897 - auc: 0.9818\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2971 - auc: 0.9812\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3012 - auc: 0.9830\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2897 - auc: 0.9823\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2930 - auc: 0.9814\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2951 - auc: 0.9824\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2904 - auc: 0.9833\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2915 - auc: 0.9829\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2992 - auc: 0.9829\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3040 - auc: 0.9838\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3118 - auc: 0.9817\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2704 - auc: 0.9844\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2789 - auc: 0.9836\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2893 - auc: 0.9851\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3024 - auc: 0.9849\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2944 - auc: 0.9847\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2888 - auc: 0.9839\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2833 - auc: 0.9857\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2836 - auc: 0.9834\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2923 - auc: 0.9849\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2809 - auc: 0.9851\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2757 - auc: 0.9843\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2869 - auc: 0.9855\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2835 - auc: 0.9845\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2862 - auc: 0.9855\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2665 - auc: 0.9849\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3052 - auc: 0.9856\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2781 - auc: 0.9846\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2810 - auc: 0.9855\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2936 - auc: 0.9850\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2903 - auc: 0.9844\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2832 - auc: 0.9841\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2830 - auc: 0.9848\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2822 - auc: 0.9843\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2787 - auc: 0.9844\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2905 - auc: 0.9850\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2854 - auc: 0.9851\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2860 - auc: 0.9851\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2799 - auc: 0.9851\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2844 - auc: 0.9851\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2897 - auc: 0.9851\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2856 - auc: 0.9848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 9.610579325719515e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.17832681017612526\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '9.6105', 'eer_eval': '0.1783', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!9.6105.hdf5', 'tnow': '2022-05-28 16:54:11.349920'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 35s 19ms/step - loss: 0.7724 - auc: 0.8461\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3807 - auc: 0.9632\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3576 - auc: 0.9681\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3484 - auc: 0.9704\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3512 - auc: 0.9713\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3363 - auc: 0.9725\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3216 - auc: 0.9733\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3290 - auc: 0.9761\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3147 - auc: 0.9765\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3225 - auc: 0.9762\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3127 - auc: 0.9759\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3084 - auc: 0.9755\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3190 - auc: 0.9773\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3020 - auc: 0.9782\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3194 - auc: 0.9774\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3069 - auc: 0.9794\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3079 - auc: 0.9779\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3125 - auc: 0.9788\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2967 - auc: 0.9780\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3039 - auc: 0.9795\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3059 - auc: 0.9788\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3095 - auc: 0.9787\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2980 - auc: 0.9803\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3112 - auc: 0.9797\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3026 - auc: 0.9797\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2978 - auc: 0.9804\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3110 - auc: 0.9801\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3016 - auc: 0.9804\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3109 - auc: 0.9821\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3004 - auc: 0.9822\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2998 - auc: 0.9827\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3017 - auc: 0.9815\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2898 - auc: 0.9812\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2884 - auc: 0.9824\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3004 - auc: 0.9824\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3019 - auc: 0.9821\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3005 - auc: 0.9818\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2914 - auc: 0.9823\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2844 - auc: 0.9841\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2920 - auc: 0.9826\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2846 - auc: 0.9836\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3011 - auc: 0.9827\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2943 - auc: 0.9828\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2896 - auc: 0.9831\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2976 - auc: 0.9826\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2993 - auc: 0.9841\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2802 - auc: 0.9832\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2975 - auc: 0.9835\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2898 - auc: 0.9837\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2810 - auc: 0.9844\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3027 - auc: 0.9843\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2875 - auc: 0.9843\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3069 - auc: 0.9845\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2904 - auc: 0.9837\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2929 - auc: 0.9854\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2865 - auc: 0.9844\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2839 - auc: 0.9840\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2811 - auc: 0.9854\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2924 - auc: 0.9856\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2877 - auc: 0.9837\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2910 - auc: 0.9845\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2927 - auc: 0.9843\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2883 - auc: 0.9847\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2856 - auc: 0.9848\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2922 - auc: 0.9840\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2877 - auc: 0.9854\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2976 - auc: 0.9851\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2820 - auc: 0.9852\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2867 - auc: 0.9847\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2873 - auc: 0.9852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00042816443133840323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.20416829745596868\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0004', 'eer_eval': '0.2041', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0004.hdf5', 'tnow': '2022-05-28 17:32:33.967323'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 35s 19ms/step - loss: 0.7831 - auc: 0.8342\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3872 - auc: 0.9622\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3563 - auc: 0.9692\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3360 - auc: 0.9699\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3411 - auc: 0.9720\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3272 - auc: 0.9731\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3282 - auc: 0.9738\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3183 - auc: 0.9740\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3290 - auc: 0.9756\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3236 - auc: 0.9743\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3069 - auc: 0.9753\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3144 - auc: 0.9772\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3159 - auc: 0.9766\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3199 - auc: 0.9771\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3075 - auc: 0.9787\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3139 - auc: 0.9772\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3164 - auc: 0.9773\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3058 - auc: 0.9775\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3115 - auc: 0.9790\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2957 - auc: 0.9795\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3081 - auc: 0.9801\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2939 - auc: 0.9792\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2957 - auc: 0.9797\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3060 - auc: 0.9791\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2993 - auc: 0.9799\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3099 - auc: 0.9815\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2966 - auc: 0.9794\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2884 - auc: 0.9817\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2923 - auc: 0.9828\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3083 - auc: 0.9819\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2872 - auc: 0.9818\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2891 - auc: 0.9822\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3028 - auc: 0.9823\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2918 - auc: 0.9822\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2876 - auc: 0.9814\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3042 - auc: 0.9815\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2993 - auc: 0.9823\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2888 - auc: 0.9811\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2895 - auc: 0.9829\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2829 - auc: 0.9839\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2833 - auc: 0.9844\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2864 - auc: 0.9840\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2879 - auc: 0.9838\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2946 - auc: 0.9847\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2787 - auc: 0.9840\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2901 - auc: 0.9831\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2899 - auc: 0.9838\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2965 - auc: 0.9843\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2921 - auc: 0.9844\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2860 - auc: 0.9834\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2867 - auc: 0.9837\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2857 - auc: 0.9830\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2827 - auc: 0.9838\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2842 - auc: 0.9846\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2897 - auc: 0.9847\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2947 - auc: 0.9843\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2791 - auc: 0.9849\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2956 - auc: 0.9847\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2788 - auc: 0.9855\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2845 - auc: 0.9838\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2868 - auc: 0.9846\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2738 - auc: 0.9845\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2912 - auc: 0.9860\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2942 - auc: 0.9845\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2827 - auc: 0.9855\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2712 - auc: 0.9838\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2830 - auc: 0.9848\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2987 - auc: 0.9840\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2935 - auc: 0.9860\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2840 - auc: 0.9849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0008755500213282455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.2087377690802348\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0008', 'eer_eval': '0.2087', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0008.hdf5', 'tnow': '2022-05-28 18:10:58.925506'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 35s 19ms/step - loss: 0.7935 - auc: 0.8359\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.4125 - auc: 0.9579\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3889 - auc: 0.9634\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3532 - auc: 0.9686\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3388 - auc: 0.9692\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3414 - auc: 0.9709\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3364 - auc: 0.9710\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3295 - auc: 0.9719\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3237 - auc: 0.9747\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3264 - auc: 0.9728\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3173 - auc: 0.9738\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3267 - auc: 0.9750\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3212 - auc: 0.9753\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3139 - auc: 0.9736\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3136 - auc: 0.9750\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3077 - auc: 0.9773\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3171 - auc: 0.9766\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3096 - auc: 0.9768\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3205 - auc: 0.9774\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3132 - auc: 0.9786\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2950 - auc: 0.9775\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2985 - auc: 0.9784\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3005 - auc: 0.9785\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3086 - auc: 0.9780\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3183 - auc: 0.9788\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3036 - auc: 0.9796\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3039 - auc: 0.9809\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3023 - auc: 0.9797\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3026 - auc: 0.9799\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3043 - auc: 0.9810\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2961 - auc: 0.9800\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2985 - auc: 0.9790\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3058 - auc: 0.9816\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3062 - auc: 0.9817\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2998 - auc: 0.9824\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3069 - auc: 0.9812\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2941 - auc: 0.9819\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3027 - auc: 0.9818\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2953 - auc: 0.9819\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3058 - auc: 0.9814\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2837 - auc: 0.9827\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3104 - auc: 0.9829\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2846 - auc: 0.9841\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3058 - auc: 0.9835\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2915 - auc: 0.9838\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2868 - auc: 0.9841\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2841 - auc: 0.9833\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2966 - auc: 0.9827\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3020 - auc: 0.9829\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2942 - auc: 0.9833\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2909 - auc: 0.9826\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2948 - auc: 0.9832\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3066 - auc: 0.9829\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2890 - auc: 0.9816\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2925 - auc: 0.9845\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2831 - auc: 0.9835\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2937 - auc: 0.9828\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2925 - auc: 0.9832\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2954 - auc: 0.9829\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2929 - auc: 0.9843\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3104 - auc: 0.9846\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2753 - auc: 0.9842\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2900 - auc: 0.9825\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2957 - auc: 0.9838\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2853 - auc: 0.9843\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2961 - auc: 0.9838\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2964 - auc: 0.9842\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2863 - auc: 0.9850\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2914 - auc: 0.9840\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3062 - auc: 0.9833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.20145792563600784\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0', 'eer_eval': '0.2014', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0.hdf5', 'tnow': '2022-05-28 18:49:19.776327'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 35s 19ms/step - loss: 0.8019 - auc: 0.8300\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3926 - auc: 0.9599\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3516 - auc: 0.9669\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3597 - auc: 0.9681\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3567 - auc: 0.9691\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3367 - auc: 0.9720\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3380 - auc: 0.9728\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3232 - auc: 0.9741\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3161 - auc: 0.9732\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3184 - auc: 0.9753\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3216 - auc: 0.9742\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3188 - auc: 0.9744\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3138 - auc: 0.9771\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3179 - auc: 0.9776\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3229 - auc: 0.9771\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3183 - auc: 0.9772\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2952 - auc: 0.9778\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3036 - auc: 0.9784\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3134 - auc: 0.9794\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3161 - auc: 0.9800\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3054 - auc: 0.9788\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3212 - auc: 0.9783\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3157 - auc: 0.9797\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3112 - auc: 0.9791\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3029 - auc: 0.9791\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3016 - auc: 0.9784\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3069 - auc: 0.9813\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3042 - auc: 0.9792\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3093 - auc: 0.9817\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2996 - auc: 0.9809\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2964 - auc: 0.9826\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3084 - auc: 0.9815\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2999 - auc: 0.9798\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3025 - auc: 0.9815\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2835 - auc: 0.9815\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3047 - auc: 0.9816\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3064 - auc: 0.9823\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2889 - auc: 0.9830\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2834 - auc: 0.9819\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2992 - auc: 0.9830\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2804 - auc: 0.9821\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2816 - auc: 0.9840\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3001 - auc: 0.9830\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3084 - auc: 0.9831\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3019 - auc: 0.9829\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2851 - auc: 0.9839\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2807 - auc: 0.9836\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2925 - auc: 0.9848\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2870 - auc: 0.9841\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2896 - auc: 0.9840\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3064 - auc: 0.9844\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2842 - auc: 0.9849\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2798 - auc: 0.9844\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2839 - auc: 0.9840\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2991 - auc: 0.9851\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2886 - auc: 0.9847\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2895 - auc: 0.9839\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2910 - auc: 0.9852\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2911 - auc: 0.9847\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2909 - auc: 0.9846\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2976 - auc: 0.9860\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2931 - auc: 0.9851\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2907 - auc: 0.9844\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2940 - auc: 0.9850\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2775 - auc: 0.9835\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2793 - auc: 0.9845\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2866 - auc: 0.9853\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2968 - auc: 0.9831\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2860 - auc: 0.9850\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2865 - auc: 0.9837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.1706164383561644\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0', 'eer_eval': '0.1706', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0.hdf5', 'tnow': '2022-05-28 19:27:46.472380'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 35s 19ms/step - loss: 0.8070 - auc: 0.8276\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3864 - auc: 0.9619\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3779 - auc: 0.9649\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3536 - auc: 0.9673\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3421 - auc: 0.9683\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3431 - auc: 0.9697\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3430 - auc: 0.9702\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3304 - auc: 0.9718\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3372 - auc: 0.9718\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3305 - auc: 0.9721\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3312 - auc: 0.9736\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3202 - auc: 0.9760\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3267 - auc: 0.9758\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3106 - auc: 0.9749\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3178 - auc: 0.9766\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3060 - auc: 0.9751\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3125 - auc: 0.9773\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3095 - auc: 0.9785\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3144 - auc: 0.9778\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3072 - auc: 0.9779\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3093 - auc: 0.9774\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3027 - auc: 0.9784\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2943 - auc: 0.9789\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3169 - auc: 0.9799\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3079 - auc: 0.9796\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3006 - auc: 0.9791\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3126 - auc: 0.9803\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2976 - auc: 0.9804\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2955 - auc: 0.9802\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3000 - auc: 0.9797\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3057 - auc: 0.9787\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3045 - auc: 0.9806\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3001 - auc: 0.9810\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2982 - auc: 0.9805\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2905 - auc: 0.9813\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2945 - auc: 0.9807\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2937 - auc: 0.9814\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2988 - auc: 0.9808\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2925 - auc: 0.9826\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2926 - auc: 0.9814\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2803 - auc: 0.9823\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2905 - auc: 0.9815\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2949 - auc: 0.9839\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3042 - auc: 0.9832\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3003 - auc: 0.9824\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3036 - auc: 0.9830\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2927 - auc: 0.9838\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2828 - auc: 0.9830\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2862 - auc: 0.9821\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2920 - auc: 0.9835\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3009 - auc: 0.9836\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2990 - auc: 0.9829\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2943 - auc: 0.9836\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2917 - auc: 0.9839\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2790 - auc: 0.9849\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2922 - auc: 0.9852\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2931 - auc: 0.9838\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3033 - auc: 0.9831\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2931 - auc: 0.9836\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2937 - auc: 0.9827\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2780 - auc: 0.9837\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2868 - auc: 0.9840\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2978 - auc: 0.9836\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3020 - auc: 0.9835\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2842 - auc: 0.9849\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2873 - auc: 0.9836\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2887 - auc: 0.9851\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2776 - auc: 0.9829\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2790 - auc: 0.9849\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2935 - auc: 0.9847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0004858279072927203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.18146771037181994\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0004', 'eer_eval': '0.1814', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0004.hdf5', 'tnow': '2022-05-28 20:06:02.885359'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 35s 19ms/step - loss: 0.7278 - auc: 0.8405\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3975 - auc: 0.9566\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3511 - auc: 0.9643\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3614 - auc: 0.9655\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3311 - auc: 0.9695\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3397 - auc: 0.9722\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3495 - auc: 0.9728\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3349 - auc: 0.9731\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3222 - auc: 0.9733\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3240 - auc: 0.9736\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3313 - auc: 0.9748\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3202 - auc: 0.9761\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3138 - auc: 0.9762\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3241 - auc: 0.9747\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3140 - auc: 0.9767\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3230 - auc: 0.9758\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3193 - auc: 0.9753\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3179 - auc: 0.9761\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3131 - auc: 0.9758\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3155 - auc: 0.9789\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3170 - auc: 0.9776\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2997 - auc: 0.9786\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3130 - auc: 0.9785\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3022 - auc: 0.9785\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3023 - auc: 0.9797\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3101 - auc: 0.9783\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3071 - auc: 0.9797\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3057 - auc: 0.9790\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3026 - auc: 0.9797\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3075 - auc: 0.9802\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3098 - auc: 0.9808\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3154 - auc: 0.9803\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3057 - auc: 0.9794\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2956 - auc: 0.9808\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2905 - auc: 0.9835\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3141 - auc: 0.9812\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2810 - auc: 0.9815\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3121 - auc: 0.9806\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3034 - auc: 0.9825\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2939 - auc: 0.9832\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3019 - auc: 0.9823\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2932 - auc: 0.9828\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3001 - auc: 0.9836\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2872 - auc: 0.9823\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3009 - auc: 0.9830\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2905 - auc: 0.9846\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2783 - auc: 0.9831\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2982 - auc: 0.9841\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2824 - auc: 0.9832\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3005 - auc: 0.9836\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2958 - auc: 0.9844\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3008 - auc: 0.9846\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2895 - auc: 0.9833\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2875 - auc: 0.9828\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2959 - auc: 0.9833\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2843 - auc: 0.9835\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3042 - auc: 0.9825\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2917 - auc: 0.9834\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2834 - auc: 0.9833\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2946 - auc: 0.9838\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2879 - auc: 0.9839\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2873 - auc: 0.9836\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2839 - auc: 0.9844\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2938 - auc: 0.9846\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2882 - auc: 0.9835\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2895 - auc: 0.9840\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2804 - auc: 0.9857\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2893 - auc: 0.9843\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2914 - auc: 0.9826\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2926 - auc: 0.9842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00021673168617251842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.15034246575342466\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0002', 'eer_eval': '0.1503', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0002.hdf5', 'tnow': '2022-05-28 20:44:23.762749'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 35s 19ms/step - loss: 0.8289 - auc: 0.8239\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.4005 - auc: 0.9586\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3710 - auc: 0.9647\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3602 - auc: 0.9682\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3424 - auc: 0.9699\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3558 - auc: 0.9708\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3360 - auc: 0.9714\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3287 - auc: 0.9713\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3376 - auc: 0.9713\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3371 - auc: 0.9735\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3221 - auc: 0.9748\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3217 - auc: 0.9745\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3312 - auc: 0.9751\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3266 - auc: 0.9768\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3075 - auc: 0.9766\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3172 - auc: 0.9756\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3213 - auc: 0.9782\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3213 - auc: 0.9768\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3090 - auc: 0.9780\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3077 - auc: 0.9776\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2961 - auc: 0.9779\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3065 - auc: 0.9780\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3151 - auc: 0.9779\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2984 - auc: 0.9782\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3122 - auc: 0.9782\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3003 - auc: 0.9788\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3158 - auc: 0.9788\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2905 - auc: 0.9800\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3037 - auc: 0.9813\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3088 - auc: 0.9796\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3019 - auc: 0.9809\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3107 - auc: 0.9812\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3014 - auc: 0.9803\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3103 - auc: 0.9812\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2965 - auc: 0.9817\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2985 - auc: 0.9822\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3084 - auc: 0.9818\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3046 - auc: 0.9820\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2884 - auc: 0.9817\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2958 - auc: 0.9820\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2978 - auc: 0.9823\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2975 - auc: 0.9839\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2793 - auc: 0.9822\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2998 - auc: 0.9831\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3027 - auc: 0.9821\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2948 - auc: 0.9828\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2965 - auc: 0.9822\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2837 - auc: 0.9835\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2956 - auc: 0.9826\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2866 - auc: 0.9838\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2863 - auc: 0.9833\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2899 - auc: 0.9833\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2806 - auc: 0.9831\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2984 - auc: 0.9853\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3005 - auc: 0.9848\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3002 - auc: 0.9837\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2906 - auc: 0.9842\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2865 - auc: 0.9829\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2953 - auc: 0.9840\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2865 - auc: 0.9835\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2923 - auc: 0.9844\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2905 - auc: 0.9827\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2862 - auc: 0.9851\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2980 - auc: 0.9849\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2957 - auc: 0.9838\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2839 - auc: 0.9835\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2898 - auc: 0.9841\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2894 - auc: 0.9824\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2870 - auc: 0.9832\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2942 - auc: 0.9834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 3.844231730287806e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.17133072407045008\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '3.8442', 'eer_eval': '0.1713', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!3.8442.hdf5', 'tnow': '2022-05-28 21:22:49.598063'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 35s 19ms/step - loss: 0.8855 - auc: 0.8230\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.4191 - auc: 0.9567\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3894 - auc: 0.9633\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3712 - auc: 0.9671\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3450 - auc: 0.9679\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3434 - auc: 0.9675\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3370 - auc: 0.9723\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3322 - auc: 0.9714\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3279 - auc: 0.9725\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3282 - auc: 0.9731\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3251 - auc: 0.9740\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3297 - auc: 0.9746\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3144 - auc: 0.9740\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3198 - auc: 0.9745\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3365 - auc: 0.9757\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3124 - auc: 0.9766\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3147 - auc: 0.9782\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3095 - auc: 0.9755\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3052 - auc: 0.9779\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2986 - auc: 0.9779\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3087 - auc: 0.9785\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3124 - auc: 0.9765\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3169 - auc: 0.9780\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3153 - auc: 0.9792\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3000 - auc: 0.9797\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2983 - auc: 0.9790\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3076 - auc: 0.9799\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2950 - auc: 0.9799\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3001 - auc: 0.9801\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3025 - auc: 0.9797\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3134 - auc: 0.9797\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3093 - auc: 0.9816\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3070 - auc: 0.9804\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2932 - auc: 0.9812\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2945 - auc: 0.9829\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3024 - auc: 0.9812\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2906 - auc: 0.9824\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2909 - auc: 0.9827\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3018 - auc: 0.9821\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2863 - auc: 0.9822\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2943 - auc: 0.9832\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3049 - auc: 0.9834\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3012 - auc: 0.9837\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3005 - auc: 0.9835\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2990 - auc: 0.9827\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2952 - auc: 0.9833\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2935 - auc: 0.9836\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2911 - auc: 0.9836\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2926 - auc: 0.9835\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3033 - auc: 0.9836\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2878 - auc: 0.9829\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2890 - auc: 0.9835\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2920 - auc: 0.9834\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2871 - auc: 0.9840\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3070 - auc: 0.9835\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2866 - auc: 0.9847\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2869 - auc: 0.9840\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2887 - auc: 0.9857\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2975 - auc: 0.9845\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2812 - auc: 0.9847\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2967 - auc: 0.9837\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2988 - auc: 0.9858\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2877 - auc: 0.9841\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2969 - auc: 0.9842\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2950 - auc: 0.9838\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2846 - auc: 0.9837\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2916 - auc: 0.9840\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2882 - auc: 0.9839\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2858 - auc: 0.9842\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2925 - auc: 0.9845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.18289628180039139\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0', 'eer_eval': '0.1828', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0.hdf5', 'tnow': '2022-05-28 22:01:24.736832'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 34s 19ms/step - loss: 0.7411 - auc: 0.8379\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.4094 - auc: 0.9578\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3658 - auc: 0.9668\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3563 - auc: 0.9683\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3674 - auc: 0.9677\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3330 - auc: 0.9710\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3384 - auc: 0.9721\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3324 - auc: 0.9719\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3193 - auc: 0.9728\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3271 - auc: 0.9733\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3150 - auc: 0.9752\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3299 - auc: 0.9762\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3336 - auc: 0.9762\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3279 - auc: 0.9754\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3266 - auc: 0.9761\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3155 - auc: 0.9770\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2994 - auc: 0.9772\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3096 - auc: 0.9792\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3102 - auc: 0.9762\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3204 - auc: 0.9786\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2978 - auc: 0.9787\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2960 - auc: 0.9796\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3157 - auc: 0.9791\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3153 - auc: 0.9781\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3017 - auc: 0.9799\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3106 - auc: 0.9798\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3016 - auc: 0.9806\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3012 - auc: 0.9774\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2990 - auc: 0.9792\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2934 - auc: 0.9813\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2941 - auc: 0.9822\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2974 - auc: 0.9805\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2992 - auc: 0.9801\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2915 - auc: 0.9814\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2958 - auc: 0.9812\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2933 - auc: 0.9815\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2900 - auc: 0.9823\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2936 - auc: 0.9832\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2985 - auc: 0.9828\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2922 - auc: 0.9826\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2963 - auc: 0.9829\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2937 - auc: 0.9824\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2874 - auc: 0.9838\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2915 - auc: 0.9832\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3006 - auc: 0.9839\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2919 - auc: 0.9828\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2847 - auc: 0.9834\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2943 - auc: 0.9835\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2918 - auc: 0.9833\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2955 - auc: 0.9844\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2826 - auc: 0.9836\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2906 - auc: 0.9845\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2894 - auc: 0.9836\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2818 - auc: 0.9840\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2933 - auc: 0.9837\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2957 - auc: 0.9834\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2953 - auc: 0.9829\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2853 - auc: 0.9833\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3063 - auc: 0.9832\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2801 - auc: 0.9841\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2847 - auc: 0.9839\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2874 - auc: 0.9838\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2872 - auc: 0.9834\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2806 - auc: 0.9842\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2899 - auc: 0.9834\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2881 - auc: 0.9843\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2887 - auc: 0.9834\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2975 - auc: 0.9844\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2796 - auc: 0.9849\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2854 - auc: 0.9833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.198600782778865\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0', 'eer_eval': '0.1986', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0.hdf5', 'tnow': '2022-05-28 22:39:38.601554'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 35s 19ms/step - loss: 0.7463 - auc: 0.8294\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.4162 - auc: 0.9587\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3831 - auc: 0.9645\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3559 - auc: 0.9673\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3538 - auc: 0.9678\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3333 - auc: 0.9701\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3357 - auc: 0.9739\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3407 - auc: 0.9711\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3421 - auc: 0.9716\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3283 - auc: 0.9746\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3277 - auc: 0.9729\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3156 - auc: 0.9751\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3176 - auc: 0.9753\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3236 - auc: 0.9757\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3260 - auc: 0.9747\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3080 - auc: 0.9758\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3164 - auc: 0.9771\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3081 - auc: 0.9775\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3080 - auc: 0.9779\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3136 - auc: 0.9764\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3064 - auc: 0.9772\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3078 - auc: 0.9757\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3054 - auc: 0.9779\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2994 - auc: 0.9783\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3196 - auc: 0.9779\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3109 - auc: 0.9801\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3149 - auc: 0.9785\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3090 - auc: 0.9799\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3123 - auc: 0.9809\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3086 - auc: 0.9796\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3031 - auc: 0.9807\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2968 - auc: 0.9795\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3075 - auc: 0.9796\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3004 - auc: 0.9807\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3025 - auc: 0.9814\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2926 - auc: 0.9822\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3064 - auc: 0.9810\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3112 - auc: 0.9816\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2915 - auc: 0.9821\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3050 - auc: 0.9818\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3001 - auc: 0.9819\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2874 - auc: 0.9835\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3073 - auc: 0.9819\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2981 - auc: 0.9826\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2898 - auc: 0.9838\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2968 - auc: 0.9842\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2988 - auc: 0.9824\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2955 - auc: 0.9828\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2886 - auc: 0.9826\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2944 - auc: 0.9823\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3078 - auc: 0.9830\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2946 - auc: 0.9832\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2937 - auc: 0.9837\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2910 - auc: 0.9824\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2856 - auc: 0.9835\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2948 - auc: 0.9831\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2973 - auc: 0.9841\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2957 - auc: 0.9826\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2888 - auc: 0.9851\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2968 - auc: 0.9836\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2789 - auc: 0.9826\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3184 - auc: 0.9831\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2861 - auc: 0.9834\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2897 - auc: 0.9835\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2942 - auc: 0.9831\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3078 - auc: 0.9846\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2877 - auc: 0.9852\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2857 - auc: 0.9828\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3029 - auc: 0.9828\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2951 - auc: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0007410019107681168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.20945205479452053\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0007', 'eer_eval': '0.2094', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0007.hdf5', 'tnow': '2022-05-28 23:17:59.619621'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 35s 19ms/step - loss: 0.7943 - auc: 0.8300\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.4161 - auc: 0.9583\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3722 - auc: 0.9640\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3487 - auc: 0.9664\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3647 - auc: 0.9688\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3468 - auc: 0.9694\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3592 - auc: 0.9710\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3377 - auc: 0.9707\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3251 - auc: 0.9733\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3274 - auc: 0.9737\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3147 - auc: 0.9760\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3259 - auc: 0.9744\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3294 - auc: 0.9757\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3193 - auc: 0.9762\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3161 - auc: 0.9739\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3160 - auc: 0.9774\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3192 - auc: 0.9763\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3090 - auc: 0.9760\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3100 - auc: 0.9776\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3205 - auc: 0.9779\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3171 - auc: 0.9777\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3067 - auc: 0.9772\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3081 - auc: 0.9771\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3066 - auc: 0.9787\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3235 - auc: 0.9787\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3115 - auc: 0.9792\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3185 - auc: 0.9773\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3115 - auc: 0.9786\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3024 - auc: 0.9800\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3056 - auc: 0.9817\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3013 - auc: 0.9790\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2947 - auc: 0.9787\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2988 - auc: 0.9808\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2947 - auc: 0.9806\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3031 - auc: 0.9811\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2984 - auc: 0.9796\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2857 - auc: 0.9819\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2849 - auc: 0.9823\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2975 - auc: 0.9809\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2959 - auc: 0.9816\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2952 - auc: 0.9829\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3056 - auc: 0.9833\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2946 - auc: 0.9808\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2962 - auc: 0.9819\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2983 - auc: 0.9824\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2842 - auc: 0.9826\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2972 - auc: 0.9830\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2921 - auc: 0.9821\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2856 - auc: 0.9825\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2998 - auc: 0.9830\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2866 - auc: 0.9823\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2892 - auc: 0.9837\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2925 - auc: 0.9828\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2779 - auc: 0.9825\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2904 - auc: 0.9821\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2807 - auc: 0.9829\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2883 - auc: 0.9844\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2818 - auc: 0.9829\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2974 - auc: 0.9819\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2872 - auc: 0.9832\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2817 - auc: 0.9822\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2965 - auc: 0.9838\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3081 - auc: 0.9820\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2976 - auc: 0.9841\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2970 - auc: 0.9840\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2984 - auc: 0.9829\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2890 - auc: 0.9833\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2978 - auc: 0.9847\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2995 - auc: 0.9839\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2904 - auc: 0.9840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0010100981318883187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.19931506849315067\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0010', 'eer_eval': '0.1993', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0010.hdf5', 'tnow': '2022-05-28 23:56:33.785151'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 34s 19ms/step - loss: 0.7897 - auc: 0.8354\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3892 - auc: 0.9621\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3505 - auc: 0.9672\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3512 - auc: 0.9688\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3360 - auc: 0.9710\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3447 - auc: 0.9706\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3284 - auc: 0.9737\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3400 - auc: 0.9745\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3269 - auc: 0.9746\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3174 - auc: 0.9760\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3189 - auc: 0.9755\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3059 - auc: 0.9755\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3232 - auc: 0.9783\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3164 - auc: 0.9759\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2989 - auc: 0.9785\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3177 - auc: 0.9792\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3122 - auc: 0.9791\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3163 - auc: 0.9784\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2946 - auc: 0.9781\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3084 - auc: 0.9795\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2982 - auc: 0.9794\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3114 - auc: 0.9785\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3041 - auc: 0.9807\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2992 - auc: 0.9802\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2992 - auc: 0.9805\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3029 - auc: 0.9802\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3049 - auc: 0.9806\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3071 - auc: 0.9821\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3126 - auc: 0.9833\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3000 - auc: 0.9813\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2928 - auc: 0.9826\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2998 - auc: 0.9826\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3099 - auc: 0.9824\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2943 - auc: 0.9818\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2874 - auc: 0.9823\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2983 - auc: 0.9838\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2987 - auc: 0.9831\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2822 - auc: 0.9836\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2961 - auc: 0.9831\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2965 - auc: 0.9835\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2961 - auc: 0.9837\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2903 - auc: 0.9835\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2822 - auc: 0.9847\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2961 - auc: 0.9847\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2766 - auc: 0.9850\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2881 - auc: 0.9838\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2857 - auc: 0.9850\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2868 - auc: 0.9849\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2876 - auc: 0.9847\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2822 - auc: 0.9837\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2797 - auc: 0.9835\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3018 - auc: 0.9835\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2858 - auc: 0.9856\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2771 - auc: 0.9857\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2943 - auc: 0.9851\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2774 - auc: 0.9846\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2808 - auc: 0.9844\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2831 - auc: 0.9847\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2872 - auc: 0.9859\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2834 - auc: 0.9850\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2844 - auc: 0.9856\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2798 - auc: 0.9859\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2833 - auc: 0.9857\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2891 - auc: 0.9851\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2908 - auc: 0.9854\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2903 - auc: 0.9848\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2916 - auc: 0.9846\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2931 - auc: 0.9856\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2848 - auc: 0.9847\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2816 - auc: 0.9854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.000581933700549971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.2017416829745597\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0005', 'eer_eval': '0.2017', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0005.hdf5', 'tnow': '2022-05-29 00:34:52.013689'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 35s 19ms/step - loss: 0.7682 - auc: 0.8325\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3822 - auc: 0.9647\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3708 - auc: 0.9657\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3503 - auc: 0.9699\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3333 - auc: 0.9714\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3465 - auc: 0.9715\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3432 - auc: 0.9738\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3157 - auc: 0.9727\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3213 - auc: 0.9750\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3235 - auc: 0.9764\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3231 - auc: 0.9750\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3076 - auc: 0.9775\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3067 - auc: 0.9761\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3219 - auc: 0.9764\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3171 - auc: 0.9779\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3174 - auc: 0.9770\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3146 - auc: 0.9788\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3211 - auc: 0.9781\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2938 - auc: 0.9785\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3156 - auc: 0.9797\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3042 - auc: 0.9804\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3044 - auc: 0.9795\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3048 - auc: 0.9801\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2990 - auc: 0.9797\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2855 - auc: 0.9792\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3193 - auc: 0.9806\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2956 - auc: 0.9812\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3211 - auc: 0.9815\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3011 - auc: 0.9803\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3094 - auc: 0.9812\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3107 - auc: 0.9802\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3028 - auc: 0.9816\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3035 - auc: 0.9823\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3087 - auc: 0.9816\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2951 - auc: 0.9829\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2923 - auc: 0.9814\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3036 - auc: 0.9828\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2878 - auc: 0.9821\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2947 - auc: 0.9844\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2891 - auc: 0.9828\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2863 - auc: 0.9834\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2976 - auc: 0.9838\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3017 - auc: 0.9831\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2876 - auc: 0.9849\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3065 - auc: 0.9835\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2914 - auc: 0.9844\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2793 - auc: 0.9825\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2930 - auc: 0.9848\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2941 - auc: 0.9839\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2846 - auc: 0.9826\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2820 - auc: 0.9825\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2874 - auc: 0.9844\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2981 - auc: 0.9842\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2928 - auc: 0.9848\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2898 - auc: 0.9837\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2883 - auc: 0.9853\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2853 - auc: 0.9833\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2905 - auc: 0.9857\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2863 - auc: 0.9841\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2768 - auc: 0.9842\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2867 - auc: 0.9846\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2954 - auc: 0.9850\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2857 - auc: 0.9841\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2865 - auc: 0.9836\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2885 - auc: 0.9843\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2893 - auc: 0.9846\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2736 - auc: 0.9852\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2907 - auc: 0.9853\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2903 - auc: 0.9849\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2854 - auc: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.18289628180039139\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0', 'eer_eval': '0.1828', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0.hdf5', 'tnow': '2022-05-29 01:13:05.793174'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 36s 20ms/step - loss: 0.7567 - auc: 0.8372\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3856 - auc: 0.9622\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3640 - auc: 0.9678\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3608 - auc: 0.9688\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3671 - auc: 0.9692\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3530 - auc: 0.9709\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3406 - auc: 0.9740\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3455 - auc: 0.9744\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3223 - auc: 0.9743\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3207 - auc: 0.9730\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3245 - auc: 0.9750\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3219 - auc: 0.9752\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3106 - auc: 0.9769\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3057 - auc: 0.9754\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3105 - auc: 0.9783\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3133 - auc: 0.9766\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3083 - auc: 0.9785\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3043 - auc: 0.9782\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3123 - auc: 0.9795\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3064 - auc: 0.9791\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3105 - auc: 0.9789\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2946 - auc: 0.9803\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3093 - auc: 0.9794\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2950 - auc: 0.9798\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3033 - auc: 0.9788\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3017 - auc: 0.9794\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2975 - auc: 0.9801\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3068 - auc: 0.9822\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3026 - auc: 0.9820\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2989 - auc: 0.9802\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3044 - auc: 0.9807\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2947 - auc: 0.9820\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2924 - auc: 0.9811\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2888 - auc: 0.9811\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2899 - auc: 0.9827\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2970 - auc: 0.9831\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2928 - auc: 0.9833\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2988 - auc: 0.9833\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2796 - auc: 0.9822\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2845 - auc: 0.9821\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2875 - auc: 0.9831\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2846 - auc: 0.9836\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2903 - auc: 0.9825\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2916 - auc: 0.9832\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2739 - auc: 0.9836\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2919 - auc: 0.9846\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2917 - auc: 0.9843\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2900 - auc: 0.9844\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2922 - auc: 0.9842\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2927 - auc: 0.9844\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2838 - auc: 0.9849\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2907 - auc: 0.9837\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2871 - auc: 0.9839\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2883 - auc: 0.9839\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2940 - auc: 0.9855\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2788 - auc: 0.9851\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2966 - auc: 0.9844\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2798 - auc: 0.9849\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2953 - auc: 0.9846\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2912 - auc: 0.9842\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2872 - auc: 0.9853\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3015 - auc: 0.9851\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2890 - auc: 0.9851\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2970 - auc: 0.9851\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2775 - auc: 0.9845\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2828 - auc: 0.9849\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2823 - auc: 0.9852\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2765 - auc: 0.9839\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2839 - auc: 0.9847\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2920 - auc: 0.9840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.2024559686888454\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0', 'eer_eval': '0.2024', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0.hdf5', 'tnow': '2022-05-29 01:51:45.728786'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 35s 19ms/step - loss: 0.7998 - auc: 0.8287\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.4147 - auc: 0.9568\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3960 - auc: 0.9617\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3657 - auc: 0.9676\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3563 - auc: 0.9704\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3439 - auc: 0.9688\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3414 - auc: 0.9700\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3277 - auc: 0.9709\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3286 - auc: 0.9713\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3268 - auc: 0.9727\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3184 - auc: 0.9731\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3221 - auc: 0.9722\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3224 - auc: 0.9738\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3085 - auc: 0.9747\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3228 - auc: 0.9753\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3266 - auc: 0.9746\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3064 - auc: 0.9762\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3055 - auc: 0.9768\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3147 - auc: 0.9771\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3137 - auc: 0.9760\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3153 - auc: 0.9786\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3114 - auc: 0.9772\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3328 - auc: 0.9775\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3020 - auc: 0.9774\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3053 - auc: 0.9784\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3109 - auc: 0.9768\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3288 - auc: 0.9784\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3040 - auc: 0.9790\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2936 - auc: 0.9781\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3074 - auc: 0.9811\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3011 - auc: 0.9797\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2996 - auc: 0.9807\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2912 - auc: 0.9808\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2961 - auc: 0.9804\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2955 - auc: 0.9797\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2902 - auc: 0.9817\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3119 - auc: 0.9805\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2935 - auc: 0.9811\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2976 - auc: 0.9798\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2955 - auc: 0.9812\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2939 - auc: 0.9815\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3041 - auc: 0.9843\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2924 - auc: 0.9820\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3022 - auc: 0.9809\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3008 - auc: 0.9825\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2915 - auc: 0.9837\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3003 - auc: 0.9819\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3032 - auc: 0.9824\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2882 - auc: 0.9834\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2949 - auc: 0.9809\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2870 - auc: 0.9831\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3041 - auc: 0.9832\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3011 - auc: 0.9837\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2945 - auc: 0.9835\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2919 - auc: 0.9839\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2905 - auc: 0.9829\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2918 - auc: 0.9837\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2837 - auc: 0.9831\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2993 - auc: 0.9837\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3045 - auc: 0.9841\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2867 - auc: 0.9842\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2866 - auc: 0.9834\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2996 - auc: 0.9845\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2934 - auc: 0.9830\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2939 - auc: 0.9839\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2921 - auc: 0.9841\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3061 - auc: 0.9833\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2859 - auc: 0.9835\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2888 - auc: 0.9840\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3010 - auc: 0.9846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0007217807521166777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.18917808219178078\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0007', 'eer_eval': '0.1891', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0007.hdf5', 'tnow': '2022-05-29 02:30:10.289905'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 34s 19ms/step - loss: 0.7509 - auc: 0.8336\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.4072 - auc: 0.9584\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3827 - auc: 0.9641\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3835 - auc: 0.9652\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3493 - auc: 0.9683\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3453 - auc: 0.9716\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3487 - auc: 0.9729\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3265 - auc: 0.9724\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3199 - auc: 0.9726\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3292 - auc: 0.9722\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3166 - auc: 0.9731\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3361 - auc: 0.9724\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3405 - auc: 0.9733\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3253 - auc: 0.9755\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3244 - auc: 0.9749\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3167 - auc: 0.9758\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3206 - auc: 0.9743\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3139 - auc: 0.9766\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3085 - auc: 0.9778\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3130 - auc: 0.9776\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2996 - auc: 0.9776\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3141 - auc: 0.9765\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3236 - auc: 0.9778\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3054 - auc: 0.9779\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3020 - auc: 0.9792\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3118 - auc: 0.9774\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3111 - auc: 0.9789\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2970 - auc: 0.9780\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3009 - auc: 0.9803\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2980 - auc: 0.9794\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3031 - auc: 0.9788\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.3100 - auc: 0.9801\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2961 - auc: 0.9797\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2931 - auc: 0.9798\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2899 - auc: 0.9807\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3046 - auc: 0.9819\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2990 - auc: 0.9811\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2927 - auc: 0.9802\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2800 - auc: 0.9805\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2887 - auc: 0.9815\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2954 - auc: 0.9810\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2986 - auc: 0.9817\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2938 - auc: 0.9809\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2977 - auc: 0.9817\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2883 - auc: 0.9828\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2950 - auc: 0.9827\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2913 - auc: 0.9823\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2882 - auc: 0.9829\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2961 - auc: 0.9823\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3034 - auc: 0.9830\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2953 - auc: 0.9837\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2995 - auc: 0.9835\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2967 - auc: 0.9826\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2939 - auc: 0.9829\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2983 - auc: 0.9825\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2983 - auc: 0.9826\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2828 - auc: 0.9831\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2923 - auc: 0.9834\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2827 - auc: 0.9834\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2942 - auc: 0.9830\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2886 - auc: 0.9822\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2913 - auc: 0.9835\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2788 - auc: 0.9823\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2894 - auc: 0.9842\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2944 - auc: 0.9838\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2920 - auc: 0.9831\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2916 - auc: 0.9828\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3039 - auc: 0.9832\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2858 - auc: 0.9832\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2886 - auc: 0.9819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0005434913832470374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.1901761252446184\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0005', 'eer_eval': '0.1901', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0005.hdf5', 'tnow': '2022-05-29 03:08:29.521625'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 36s 19ms/step - loss: 0.8269 - auc: 0.8269\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3874 - auc: 0.9574\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3749 - auc: 0.9650\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3575 - auc: 0.9667\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3557 - auc: 0.9675\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3561 - auc: 0.9690\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3412 - auc: 0.9697\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3377 - auc: 0.9724\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3242 - auc: 0.9731\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3158 - auc: 0.9723\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3150 - auc: 0.9746\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3243 - auc: 0.9728\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3289 - auc: 0.9740\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3161 - auc: 0.9756\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3157 - auc: 0.9755\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3172 - auc: 0.9770\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3139 - auc: 0.9761\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3214 - auc: 0.9754\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3211 - auc: 0.9760\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3105 - auc: 0.9771\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3174 - auc: 0.9755\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3107 - auc: 0.9780\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3055 - auc: 0.9771\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3103 - auc: 0.9793\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3159 - auc: 0.9790\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3087 - auc: 0.9785\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3014 - auc: 0.9783\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3127 - auc: 0.9800\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3055 - auc: 0.9798\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3058 - auc: 0.9786\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2975 - auc: 0.9790\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3084 - auc: 0.9783\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3009 - auc: 0.9798\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3086 - auc: 0.9805\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2861 - auc: 0.9810\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2943 - auc: 0.9804\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3096 - auc: 0.9807\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2984 - auc: 0.9812\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3067 - auc: 0.9809\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.2778 - auc: 0.9814\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 33s 20ms/step - loss: 0.3097 - auc: 0.9812\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2924 - auc: 0.9819\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2991 - auc: 0.9825\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2993 - auc: 0.9811\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2866 - auc: 0.9828\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2896 - auc: 0.9826\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2927 - auc: 0.9826\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2896 - auc: 0.9840\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2829 - auc: 0.9821\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2988 - auc: 0.9823\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2826 - auc: 0.9834\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2969 - auc: 0.9834\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2920 - auc: 0.9828\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2880 - auc: 0.9837\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2901 - auc: 0.9829\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2912 - auc: 0.9827\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.3095 - auc: 0.9822\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2900 - auc: 0.9839\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2943 - auc: 0.9836\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2877 - auc: 0.9840\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2905 - auc: 0.9835\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2885 - auc: 0.9822\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2937 - auc: 0.9825\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2916 - auc: 0.9831\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2865 - auc: 0.9832\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2865 - auc: 0.9830\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 32s 19ms/step - loss: 0.2932 - auc: 0.9831\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2974 - auc: 0.9836\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2758 - auc: 0.9840\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 33s 19ms/step - loss: 0.2947 - auc: 0.9838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 1.922115865143903e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.19089041095890408\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'LCNN_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '1.9221', 'eer_eval': '0.1908', 'saved_model': 'saved_models/model_name!LCNN_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!1.9221.hdf5', 'tnow': '2022-05-29 03:47:02.943369'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 48s 26ms/step - loss: 0.6571 - auc: 0.9392\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0667 - auc: 0.9989\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0401 - auc: 0.9992\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0247 - auc: 0.9996\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0181 - auc: 0.9996\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0113 - auc: 0.9999\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0233 - auc: 0.9996\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0119 - auc: 0.9998\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0051 - auc: 0.9999\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0202 - auc: 0.9996\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0130 - auc: 0.9996\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0093 - auc: 0.9999\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0111 - auc: 0.9999\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0029 - auc: 1.0000\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0208 - auc: 0.9995\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0076 - auc: 0.9998\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0018 - auc: 1.0000\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0086 - auc: 0.9998\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0082 - auc: 0.9998\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0048 - auc: 0.9999\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0059 - auc: 0.9998\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0050 - auc: 1.0000\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0056 - auc: 0.9998\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.0014 - auc: 1.0000\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.0015 - auc: 0.9999\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0064 - auc: 0.9999\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0011 - auc: 1.0000\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0065 - auc: 0.9997 0s - loss: 0.0065 - a\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0070 - auc: 0.9998\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0015 - auc: 1.0000\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0017 - auc: 0.9999\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 4.4953e-04 - auc: 1.0000\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 1.4094e-04 - auc: 1.0000\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 1.0104e-04 - auc: 1.0000\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0028 - auc: 0.9999\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0011 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 4.8295e-04 - auc: 1.0000\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 2.1455e-04 - auc: 1.0000\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 1.6199e-04 - auc: 1.0000\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 1.1973e-05 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0013 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 2.2241e-04 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 7.0507e-05 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 1.7531e-05 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 2.2708e-05 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 1.2450e-05 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 1.1952e-05 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 1.8974e-05 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 5.8192e-06 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 2.3121e-06 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0016 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 2.8738e-06 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 4.5143e-07 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 3.0071e-06 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 1.2702e-06 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 8.0611e-06 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 3.8394e-05 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 1.0328e-06 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 1.7887e-04 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 1.6475e-05 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 7.7672e-04 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 2.2158e-05 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 1.0536e-05 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 7.5626e-05 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0012 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 1.9379e-06 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 2.3468e-05 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 1.3375e-04 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 1.1171e-06 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 1.0229e-04 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00044738558998984226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.22643835616438354\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0004', 'eer_eval': '0.2264', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0004.hdf5', 'tnow': '2022-05-29 04:38:39.469803'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 48s 26ms/step - loss: 0.6505 - auc: 0.9289\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0595 - auc: 0.9989\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0388 - auc: 0.9996\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0330 - auc: 0.9993\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0208 - auc: 0.9997\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0209 - auc: 0.9996\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0092 - auc: 0.9999\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0166 - auc: 0.9997\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0215 - auc: 0.9998\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0152 - auc: 0.9998\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0053 - auc: 1.0000\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.0105 - auc: 0.9999\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0071 - auc: 1.0000\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0057 - auc: 0.9998\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0045 - auc: 0.9998\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0066 - auc: 0.9999\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0056 - auc: 0.9999\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0105 - auc: 0.9997\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0023 - auc: 0.9999\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0049 - auc: 0.9999\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0105 - auc: 0.9997\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0047 - auc: 0.9999\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0060 - auc: 0.9999\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 7.3976e-04 - auc: 1.0000\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0079 - auc: 0.9998\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0059 - auc: 0.9999\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0048 - auc: 1.0000\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0027 - auc: 1.0000\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0032 - auc: 0.9999\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0028 - auc: 1.0000\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0011 - auc: 1.0000\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0017 - auc: 1.0000\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 8.6705e-04 - auc: 1.0000\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0057 - auc: 0.9998\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 6.9037e-04 - auc: 1.0000\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 2.4193e-04 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 1.4858e-04 - auc: 1.0000\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 2.4807e-04 - auc: 1.0000\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0018 - auc: 1.0000\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0017 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0016 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0012 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 1.7829e-04 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 2.9787e-05 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 1.2068e-04 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 2.0680e-04 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 6.0477e-06 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 2.6878e-04 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 1.1505e-05 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 3.8353e-04 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 1.0819e-04 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 1.5305e-04 - auc: 1.0000 0s - loss: 1.5338e-04 - au\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 1.8654e-05 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 3.3672e-05 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 2.8395e-06 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 3.0374e-06 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 1.0734e-05 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 1.4863e-05 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 6.0224e-06 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 3.3971e-05 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 2.8715e-06 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 7.6162e-05 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 3.6175e-06 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 2.1949e-05 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 1.6312e-06 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 8.9822e-05 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 1.5212e-06 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 3.3371e-06 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 8.0442e-06 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 8.1402e-06 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00031283747942971354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.23743639921722112\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0003', 'eer_eval': '0.2374', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0003.hdf5', 'tnow': '2022-05-29 05:29:47.531865'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 48s 26ms/step - loss: 0.9189 - auc: 0.8889\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0712 - auc: 0.9984\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0440 - auc: 0.9991 0s - loss: 0.0441 - auc: 0\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0266 - auc: 0.9995\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0173 - auc: 0.9997\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0243 - auc: 0.9996\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0070 - auc: 0.9999\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0298 - auc: 0.9993\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0180 - auc: 0.9996\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0066 - auc: 1.0000\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0110 - auc: 0.9998\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0025 - auc: 1.0000\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0131 - auc: 0.9997\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0147 - auc: 0.9997\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0091 - auc: 0.9999\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0054 - auc: 0.9999\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0065 - auc: 0.9998\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0070 - auc: 0.9998\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0037 - auc: 0.9999\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0053 - auc: 0.9999\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0040 - auc: 1.0000\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0049 - auc: 0.9998\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0051 - auc: 0.9999\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0073 - auc: 0.9999\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0062 - auc: 0.9999\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0027 - auc: 0.9999\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0015 - auc: 1.0000\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0031 - auc: 0.9999\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0028 - auc: 0.9998\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0042 - auc: 0.9998\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 7.9193e-04 - auc: 1.0000\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 3.6731e-04 - auc: 1.0000\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0034 - auc: 1.0000\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0015 - auc: 1.0000\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 2.7932e-04 - auc: 1.0000\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 6.5180e-04 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0013 - auc: 1.0000\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0037 - auc: 0.9999\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0010 - auc: 1.0000\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 7.0973e-04 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0012 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.0015 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 7.3026e-04 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 5.9266e-04 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 8.2545e-04 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 5.4250e-04 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 5.3606e-05 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 3.8537e-05 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 3.0657e-04 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 4.3289e-05 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 1.8392e-04 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 7.2852e-04 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 1.5299e-04 - auc: 1.0000 1s - loss: 1\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 0.0030 - auc: 0.9999\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 2.2237e-05 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 5.4152e-05 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 5.8043e-05 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 8.3568e-05 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 3.5908e-05 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 7.7023e-05 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 3.8676e-04 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 43s 25ms/step - loss: 1.3739e-05 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 1.2541e-04 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 7.4297e-05 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 0.0021 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 1.1118e-05 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 1.7884e-05 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 7.6264e-04 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 6.8619e-05 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 43s 26ms/step - loss: 1.8669e-05 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 5.766347595431709e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.20559686888454012\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '5.7663', 'eer_eval': '0.2055', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!5.7663.hdf5', 'tnow': '2022-05-29 06:20:48.267788'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 50s 27ms/step - loss: 1.0816 - auc: 0.8620\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.4347 - auc: 0.9565\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3698 - auc: 0.9667\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3438 - auc: 0.9713\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3367 - auc: 0.9724\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3363 - auc: 0.9737\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3301 - auc: 0.9759\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3133 - auc: 0.9768\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3144 - auc: 0.9776\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3185 - auc: 0.9792\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3144 - auc: 0.9794\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3260 - auc: 0.9776\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3021 - auc: 0.9782\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3084 - auc: 0.9788\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3079 - auc: 0.9803\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3106 - auc: 0.9794\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2996 - auc: 0.9815\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3049 - auc: 0.9797\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2883 - auc: 0.9820\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2999 - auc: 0.9808\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3024 - auc: 0.9816\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3051 - auc: 0.9808\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3105 - auc: 0.9820\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3051 - auc: 0.9821\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2966 - auc: 0.9820\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3003 - auc: 0.9821\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2974 - auc: 0.9825\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2971 - auc: 0.9841\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2933 - auc: 0.9841\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2930 - auc: 0.9831\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2977 - auc: 0.9830\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2892 - auc: 0.9836\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2869 - auc: 0.9847\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2916 - auc: 0.9838\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3017 - auc: 0.9843\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2853 - auc: 0.9841\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2850 - auc: 0.9833\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2954 - auc: 0.9853\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3008 - auc: 0.9851\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2918 - auc: 0.9847\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2936 - auc: 0.9851\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2823 - auc: 0.9852\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2879 - auc: 0.9846\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2931 - auc: 0.9858\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2897 - auc: 0.9867\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2955 - auc: 0.9848\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2933 - auc: 0.9850\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2877 - auc: 0.9863\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3000 - auc: 0.9857\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2968 - auc: 0.9864\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2897 - auc: 0.9860\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2774 - auc: 0.9852\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2903 - auc: 0.9845\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2822 - auc: 0.9862\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2813 - auc: 0.9853\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2901 - auc: 0.9851\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2908 - auc: 0.9861\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2850 - auc: 0.9867\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2933 - auc: 0.9858\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2775 - auc: 0.9858\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2848 - auc: 0.9858\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2821 - auc: 0.9861\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2780 - auc: 0.9864\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2755 - auc: 0.9861\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2910 - auc: 0.9864\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2888 - auc: 0.9854\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2843 - auc: 0.9847\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2867 - auc: 0.9850\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2798 - auc: 0.9860\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2896 - auc: 0.9869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00023595284482395745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.1664774951076321\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0002', 'eer_eval': '0.1664', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0002.hdf5', 'tnow': '2022-05-29 07:13:30.649980'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 49s 26ms/step - loss: 1.1304 - auc: 0.8513\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.4349 - auc: 0.9587\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3731 - auc: 0.9674\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3536 - auc: 0.9689\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3383 - auc: 0.9738\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3069 - auc: 0.9740\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3132 - auc: 0.9756\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3264 - auc: 0.9768\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3116 - auc: 0.9761\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3225 - auc: 0.9787\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3168 - auc: 0.9791\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3022 - auc: 0.9789\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3143 - auc: 0.9790\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3040 - auc: 0.9789\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3085 - auc: 0.9811\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3106 - auc: 0.9810\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3106 - auc: 0.9807\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2997 - auc: 0.9819\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3007 - auc: 0.9806\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3049 - auc: 0.9819\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2947 - auc: 0.9833\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2905 - auc: 0.9834\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3004 - auc: 0.9829\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2937 - auc: 0.9831\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2978 - auc: 0.9832\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2939 - auc: 0.9829\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2995 - auc: 0.9843\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3059 - auc: 0.9840\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2876 - auc: 0.9849\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2877 - auc: 0.9851\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3110 - auc: 0.9853\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2944 - auc: 0.9855\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2982 - auc: 0.9849\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2983 - auc: 0.9855\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2933 - auc: 0.9856\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2921 - auc: 0.9867\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2817 - auc: 0.9869\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2909 - auc: 0.9864\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2980 - auc: 0.9866\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2791 - auc: 0.9866\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3007 - auc: 0.9865\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2817 - auc: 0.9868\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2857 - auc: 0.9865\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2908 - auc: 0.9862\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2878 - auc: 0.9867\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2829 - auc: 0.9881\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2917 - auc: 0.9863\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2891 - auc: 0.9873\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2892 - auc: 0.9879\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2823 - auc: 0.9881\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2765 - auc: 0.9875\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2765 - auc: 0.9871\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2869 - auc: 0.9874\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2833 - auc: 0.9873\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2915 - auc: 0.9874\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2875 - auc: 0.9882\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2873 - auc: 0.9863\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2846 - auc: 0.9871\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2795 - auc: 0.9879\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2811 - auc: 0.9877\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2807 - auc: 0.9874\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2794 - auc: 0.9868\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2913 - auc: 0.9889\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2854 - auc: 0.9876\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2784 - auc: 0.9869\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2863 - auc: 0.9874\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2830 - auc: 0.9881\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2972 - auc: 0.9874\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2856 - auc: 0.9882\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2939 - auc: 0.9870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00021673168617251842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.15562622309197652\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0002', 'eer_eval': '0.1556', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0002.hdf5', 'tnow': '2022-05-29 08:05:28.651638'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 51s 27ms/step - loss: 0.9449 - auc: 0.8761\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.4016 - auc: 0.9645\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3574 - auc: 0.9695\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3479 - auc: 0.9727\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3212 - auc: 0.9746\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3420 - auc: 0.9734\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3128 - auc: 0.9773\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3285 - auc: 0.9759\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3308 - auc: 0.9777\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3133 - auc: 0.9766\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3001 - auc: 0.9791\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3135 - auc: 0.9793\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3078 - auc: 0.9802\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3122 - auc: 0.9769\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3028 - auc: 0.9792\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3184 - auc: 0.9789\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3039 - auc: 0.9802\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3003 - auc: 0.9802\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3078 - auc: 0.9803\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3045 - auc: 0.9825\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3012 - auc: 0.9823\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3003 - auc: 0.9816\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2881 - auc: 0.9827\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3027 - auc: 0.9843\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2979 - auc: 0.9829\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2996 - auc: 0.9828\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2956 - auc: 0.9833\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3051 - auc: 0.9835\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2893 - auc: 0.9829\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3117 - auc: 0.9839\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3023 - auc: 0.9840\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2925 - auc: 0.9838\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3031 - auc: 0.9838\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2983 - auc: 0.9832\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2910 - auc: 0.9849\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2929 - auc: 0.9855\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2964 - auc: 0.9845\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2896 - auc: 0.9863\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2833 - auc: 0.9852\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2957 - auc: 0.9853\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2925 - auc: 0.9858\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2848 - auc: 0.9862\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2866 - auc: 0.9860\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3079 - auc: 0.9864\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2692 - auc: 0.9864\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2888 - auc: 0.9862\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2917 - auc: 0.9867\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2961 - auc: 0.9854\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2837 - auc: 0.9866\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2940 - auc: 0.9863\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2797 - auc: 0.9867\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2891 - auc: 0.9853\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2953 - auc: 0.9864\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2841 - auc: 0.9869\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2815 - auc: 0.9862\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2952 - auc: 0.9860\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3032 - auc: 0.9870\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2906 - auc: 0.9873\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2859 - auc: 0.9862\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2862 - auc: 0.9868\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2775 - auc: 0.9865\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2810 - auc: 0.9864\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2904 - auc: 0.9863\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2769 - auc: 0.9868\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2750 - auc: 0.9870\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2912 - auc: 0.9866\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2909 - auc: 0.9868\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2850 - auc: 0.9863\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2906 - auc: 0.9868\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2848 - auc: 0.9858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.15419765166340507\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0', 'eer_eval': '0.1541', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0.hdf5', 'tnow': '2022-05-29 08:58:20.433905'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 49s 26ms/step - loss: 1.0851 - auc: 0.8553\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.4547 - auc: 0.9558\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3854 - auc: 0.9648\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3696 - auc: 0.9696\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3476 - auc: 0.9721\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3405 - auc: 0.9711\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3355 - auc: 0.9741\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3371 - auc: 0.9755\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3334 - auc: 0.9757\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3178 - auc: 0.9756\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3239 - auc: 0.9764\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3171 - auc: 0.9754\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3154 - auc: 0.9761\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3018 - auc: 0.9775\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3105 - auc: 0.9807\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3134 - auc: 0.9788\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3104 - auc: 0.9794\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3098 - auc: 0.9812\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3020 - auc: 0.9814\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2997 - auc: 0.9807\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3014 - auc: 0.9800\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3082 - auc: 0.9821\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3018 - auc: 0.9822\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2957 - auc: 0.9840\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2978 - auc: 0.9836\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3036 - auc: 0.9828\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2913 - auc: 0.9836\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3053 - auc: 0.9836\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2945 - auc: 0.9836\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2947 - auc: 0.9840\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2928 - auc: 0.9842\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2931 - auc: 0.9852\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3046 - auc: 0.9849\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2977 - auc: 0.9829\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2977 - auc: 0.9852\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2864 - auc: 0.9845\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2910 - auc: 0.9856\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2937 - auc: 0.9858\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2883 - auc: 0.9853\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3002 - auc: 0.9854\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2930 - auc: 0.9855\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2964 - auc: 0.9864\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2809 - auc: 0.9856\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2925 - auc: 0.9861\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2802 - auc: 0.9860\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2870 - auc: 0.9874\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2945 - auc: 0.9871\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2802 - auc: 0.9863\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2889 - auc: 0.9863\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2885 - auc: 0.9865\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2892 - auc: 0.9876\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2842 - auc: 0.9878\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2787 - auc: 0.9878\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2867 - auc: 0.9865\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2872 - auc: 0.9870\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2822 - auc: 0.9866\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2749 - auc: 0.9855\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3002 - auc: 0.9866\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2880 - auc: 0.9865\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2950 - auc: 0.9871\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2795 - auc: 0.9878\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2934 - auc: 0.9870\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2890 - auc: 0.9861\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2856 - auc: 0.9870\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2850 - auc: 0.9864\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2848 - auc: 0.9867\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2958 - auc: 0.9866\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2942 - auc: 0.9879\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2820 - auc: 0.9878\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2888 - auc: 0.9870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.1720450097847358\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0', 'eer_eval': '0.1720', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0.hdf5', 'tnow': '2022-05-29 09:50:33.306482'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 51s 27ms/step - loss: 1.0645 - auc: 0.8641\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.4523 - auc: 0.9568\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3909 - auc: 0.9641\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3380 - auc: 0.9690\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3476 - auc: 0.9669\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3335 - auc: 0.9710\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3278 - auc: 0.9723\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3301 - auc: 0.9733\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3302 - auc: 0.9734\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3177 - auc: 0.9755\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3166 - auc: 0.9773\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3158 - auc: 0.9780\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3208 - auc: 0.9748\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3077 - auc: 0.9759\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3185 - auc: 0.9776\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3109 - auc: 0.9792\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3108 - auc: 0.9791\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2999 - auc: 0.9789\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3041 - auc: 0.9798\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3042 - auc: 0.9806\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3149 - auc: 0.9795\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3038 - auc: 0.9814\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2995 - auc: 0.9807\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2879 - auc: 0.9814\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2990 - auc: 0.9814\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3022 - auc: 0.9817\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2936 - auc: 0.9831\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3053 - auc: 0.9830\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2997 - auc: 0.9841\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2845 - auc: 0.9841\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2902 - auc: 0.9835\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2991 - auc: 0.9853\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2992 - auc: 0.9847\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2790 - auc: 0.9833\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2854 - auc: 0.9852\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2843 - auc: 0.9844\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2897 - auc: 0.9839\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2863 - auc: 0.9860\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3009 - auc: 0.9850\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2879 - auc: 0.9853\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2944 - auc: 0.9851\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2981 - auc: 0.9858\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2902 - auc: 0.9851\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2897 - auc: 0.9860\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2905 - auc: 0.9858\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2997 - auc: 0.9855\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2975 - auc: 0.9863\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2852 - auc: 0.9864\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2884 - auc: 0.9856\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2872 - auc: 0.9861\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2950 - auc: 0.9865\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2865 - auc: 0.9868\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2897 - auc: 0.9865\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2877 - auc: 0.9867\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2834 - auc: 0.9857\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3014 - auc: 0.9860\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2881 - auc: 0.9872\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2917 - auc: 0.9869\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2964 - auc: 0.9853\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2898 - auc: 0.9867\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3025 - auc: 0.9859\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2891 - auc: 0.9867\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2938 - auc: 0.9865\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2907 - auc: 0.9862\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2892 - auc: 0.9871\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2882 - auc: 0.9858\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2767 - auc: 0.9868\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2843 - auc: 0.9873\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2878 - auc: 0.9859\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2830 - auc: 0.9866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00021673168617251842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.16504892367906066\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0002', 'eer_eval': '0.1650', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0002.hdf5', 'tnow': '2022-05-29 10:44:02.694232'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 49s 26ms/step - loss: 0.9931 - auc: 0.8614\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.4251 - auc: 0.9583\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3905 - auc: 0.9627\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3642 - auc: 0.9663\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3468 - auc: 0.9691\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3434 - auc: 0.9714\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3233 - auc: 0.9735\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3311 - auc: 0.9754\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3212 - auc: 0.9755\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3119 - auc: 0.9758\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3183 - auc: 0.9776\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3009 - auc: 0.9782\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3107 - auc: 0.9792\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3125 - auc: 0.9800\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3139 - auc: 0.9810\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3187 - auc: 0.9799\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3107 - auc: 0.9798\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3085 - auc: 0.9802\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3057 - auc: 0.9811\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3045 - auc: 0.9815\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3087 - auc: 0.9809\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3075 - auc: 0.9824\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2920 - auc: 0.9822\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2953 - auc: 0.9824\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3051 - auc: 0.9828\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2941 - auc: 0.9824\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3013 - auc: 0.9831\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2928 - auc: 0.9831\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3015 - auc: 0.9841\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2942 - auc: 0.9829\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2966 - auc: 0.9839\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3043 - auc: 0.9833\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2895 - auc: 0.9852\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2939 - auc: 0.9846\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2964 - auc: 0.9841\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2911 - auc: 0.9858\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2878 - auc: 0.9856\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2853 - auc: 0.9853\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2973 - auc: 0.9854\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2825 - auc: 0.9860\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2910 - auc: 0.9860\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2929 - auc: 0.9851\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2873 - auc: 0.9855\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2931 - auc: 0.9852\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2915 - auc: 0.9863\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2836 - auc: 0.9855\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2751 - auc: 0.9860\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2905 - auc: 0.9867\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2778 - auc: 0.9862\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2815 - auc: 0.9867\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2723 - auc: 0.9864\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2867 - auc: 0.9874\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2936 - auc: 0.9862\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2806 - auc: 0.9871\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2927 - auc: 0.9862\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2782 - auc: 0.9863\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2843 - auc: 0.9869\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2909 - auc: 0.9863\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2739 - auc: 0.9873\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2855 - auc: 0.9871\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2846 - auc: 0.9867\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2876 - auc: 0.9864\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2770 - auc: 0.9867\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2836 - auc: 0.9868\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2822 - auc: 0.9863\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2885 - auc: 0.9869\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2817 - auc: 0.9866\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2983 - auc: 0.9865\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2879 - auc: 0.9862\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2874 - auc: 0.9858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00023595284482395745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.15177103718199605\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0002', 'eer_eval': '0.1517', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0002.hdf5', 'tnow': '2022-05-29 11:36:44.859984'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 51s 27ms/step - loss: 1.1226 - auc: 0.8617\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.4296 - auc: 0.9613\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3899 - auc: 0.9679\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3627 - auc: 0.9702\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3426 - auc: 0.9716\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3323 - auc: 0.9720\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3362 - auc: 0.9757\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3196 - auc: 0.9760\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3113 - auc: 0.9768\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3143 - auc: 0.9774\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3169 - auc: 0.9767\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3088 - auc: 0.9790\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3091 - auc: 0.9791\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3013 - auc: 0.9793\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3123 - auc: 0.9801\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2887 - auc: 0.9808\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3199 - auc: 0.9787\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3133 - auc: 0.9798\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3038 - auc: 0.9810\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3100 - auc: 0.9803\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3027 - auc: 0.9794\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3037 - auc: 0.9815\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3103 - auc: 0.9799\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3007 - auc: 0.9814\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3132 - auc: 0.9816\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2940 - auc: 0.9807\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2955 - auc: 0.9824\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3061 - auc: 0.9829\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2994 - auc: 0.9824\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2994 - auc: 0.9824\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2886 - auc: 0.9814\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3101 - auc: 0.9825\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2937 - auc: 0.9831\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3029 - auc: 0.9814\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3221 - auc: 0.9825\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2936 - auc: 0.9839\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2948 - auc: 0.9835\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2966 - auc: 0.9838\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2993 - auc: 0.9838\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2882 - auc: 0.9832\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3064 - auc: 0.9835\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2946 - auc: 0.9834\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2998 - auc: 0.9845\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2924 - auc: 0.9831\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2951 - auc: 0.9846\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2950 - auc: 0.9834\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2882 - auc: 0.9846\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2912 - auc: 0.9841\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2884 - auc: 0.9842\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2919 - auc: 0.9848\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2905 - auc: 0.9840\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2935 - auc: 0.9843\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2890 - auc: 0.9838\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2910 - auc: 0.9847\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2866 - auc: 0.9846\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2913 - auc: 0.9848\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2976 - auc: 0.9854\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3058 - auc: 0.9857\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2877 - auc: 0.9840\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2960 - auc: 0.9842\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2888 - auc: 0.9838\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2983 - auc: 0.9844\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2853 - auc: 0.9862\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2991 - auc: 0.9838\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2877 - auc: 0.9850\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2890 - auc: 0.9844\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2862 - auc: 0.9854\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2906 - auc: 0.9840\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2921 - auc: 0.9851\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2834 - auc: 0.9847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0015151471978325337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.1636203522504892\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0015', 'eer_eval': '0.1636', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0015.hdf5', 'tnow': '2022-05-29 12:29:43.994757'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 49s 26ms/step - loss: 1.0963 - auc: 0.8492\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.4196 - auc: 0.9606\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.4003 - auc: 0.9660\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3558 - auc: 0.9713\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3640 - auc: 0.9707\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3385 - auc: 0.9729\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3290 - auc: 0.9751\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3377 - auc: 0.9755\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3165 - auc: 0.9754\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3099 - auc: 0.9769\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3189 - auc: 0.9782\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3058 - auc: 0.9781\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3099 - auc: 0.9789\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3067 - auc: 0.9791\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3017 - auc: 0.9796\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3134 - auc: 0.9777\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3153 - auc: 0.9787\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3137 - auc: 0.9783\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2986 - auc: 0.9810\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3133 - auc: 0.9809\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3016 - auc: 0.9813\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3004 - auc: 0.9804\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2989 - auc: 0.9809\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3040 - auc: 0.9804\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3126 - auc: 0.9809\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2952 - auc: 0.9824\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3106 - auc: 0.9817\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3075 - auc: 0.9823\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2994 - auc: 0.9812\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3014 - auc: 0.9820\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3033 - auc: 0.9830\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3112 - auc: 0.9832\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2995 - auc: 0.9825\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2989 - auc: 0.9846\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2914 - auc: 0.9847\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3008 - auc: 0.9848\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2957 - auc: 0.9841\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2862 - auc: 0.9843\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2861 - auc: 0.9832\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2876 - auc: 0.9850\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2893 - auc: 0.9845\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2856 - auc: 0.9847\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2910 - auc: 0.9849\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2978 - auc: 0.9847\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2967 - auc: 0.9855\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2879 - auc: 0.9858\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2930 - auc: 0.9845\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2910 - auc: 0.9852\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3006 - auc: 0.9851\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2993 - auc: 0.9850\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2872 - auc: 0.9854\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2939 - auc: 0.9853\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2847 - auc: 0.9851\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2923 - auc: 0.9843\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2854 - auc: 0.9865\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2944 - auc: 0.9859\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2928 - auc: 0.9849\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3023 - auc: 0.9854\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2950 - auc: 0.9855\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2993 - auc: 0.9855\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2803 - auc: 0.9855\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2822 - auc: 0.9849\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2928 - auc: 0.9849\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2909 - auc: 0.9854\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2837 - auc: 0.9856\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2913 - auc: 0.9850\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2851 - auc: 0.9854\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2863 - auc: 0.9855\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2837 - auc: 0.9857\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2918 - auc: 0.9848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.005643022242004943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.18075342465753427\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0056', 'eer_eval': '0.1807', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0056.hdf5', 'tnow': '2022-05-29 13:22:31.125831'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 51s 27ms/step - loss: 1.0840 - auc: 0.8499\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.4299 - auc: 0.9582\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3807 - auc: 0.9656\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3662 - auc: 0.9687\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3495 - auc: 0.9727\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3351 - auc: 0.9726\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3249 - auc: 0.9738\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3326 - auc: 0.9732\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3395 - auc: 0.9756\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3172 - auc: 0.9766\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3137 - auc: 0.9772\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3142 - auc: 0.9777\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3202 - auc: 0.9757\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3062 - auc: 0.9790\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3165 - auc: 0.9782\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3214 - auc: 0.9781\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3089 - auc: 0.9791\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3034 - auc: 0.9794\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3160 - auc: 0.9807\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3128 - auc: 0.9782\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3055 - auc: 0.9804\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3020 - auc: 0.9802\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3035 - auc: 0.9813\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2978 - auc: 0.9813\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2984 - auc: 0.9811\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3001 - auc: 0.9813\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2979 - auc: 0.9809\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3093 - auc: 0.9810\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2996 - auc: 0.9818\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2901 - auc: 0.9813\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2828 - auc: 0.9810\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2966 - auc: 0.9834\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3017 - auc: 0.9834\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2966 - auc: 0.9818\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2894 - auc: 0.9833\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2940 - auc: 0.9825\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2897 - auc: 0.9834\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2919 - auc: 0.9841\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2912 - auc: 0.9843\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2880 - auc: 0.9829\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2849 - auc: 0.9842\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2896 - auc: 0.9833\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2860 - auc: 0.9849\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2982 - auc: 0.9846\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2981 - auc: 0.9840\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2860 - auc: 0.9840\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2980 - auc: 0.9833\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2952 - auc: 0.9837\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2848 - auc: 0.9848\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3001 - auc: 0.9841\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2992 - auc: 0.9841\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3030 - auc: 0.9856\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2899 - auc: 0.9849\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2934 - auc: 0.9855\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2963 - auc: 0.9846\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2948 - auc: 0.9847\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2973 - auc: 0.9830\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3023 - auc: 0.9840\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2900 - auc: 0.9840\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2806 - auc: 0.9833\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2884 - auc: 0.9845\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2951 - auc: 0.9846\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2990 - auc: 0.9856\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2876 - auc: 0.9852\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2974 - auc: 0.9846\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3069 - auc: 0.9849\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2832 - auc: 0.9840\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2974 - auc: 0.9835\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2861 - auc: 0.9841\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2960 - auc: 0.9854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00276119817454481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.1373483365949119\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0027', 'eer_eval': '0.1373', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0027.hdf5', 'tnow': '2022-05-29 14:15:54.989172'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 50s 27ms/step - loss: 1.0598 - auc: 0.8511\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.4596 - auc: 0.9553\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.4049 - auc: 0.9608\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3774 - auc: 0.9672\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3640 - auc: 0.9659\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3615 - auc: 0.9678\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3341 - auc: 0.9736\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3443 - auc: 0.9718\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3497 - auc: 0.9733\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3257 - auc: 0.9749\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3225 - auc: 0.9718\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3194 - auc: 0.9749\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3192 - auc: 0.9773\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3169 - auc: 0.9781\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3122 - auc: 0.9790\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3116 - auc: 0.9779\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3090 - auc: 0.9793\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3065 - auc: 0.9791\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3042 - auc: 0.9788\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3050 - auc: 0.9807\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3046 - auc: 0.9812\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3074 - auc: 0.9795\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3161 - auc: 0.9819\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3036 - auc: 0.9805\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3013 - auc: 0.9810\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3099 - auc: 0.9807\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2965 - auc: 0.9826\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3041 - auc: 0.9815\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2936 - auc: 0.9824\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2963 - auc: 0.9822\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2991 - auc: 0.9832\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2874 - auc: 0.9830\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2875 - auc: 0.9820\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3041 - auc: 0.9826\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2910 - auc: 0.9832\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2918 - auc: 0.9834\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2975 - auc: 0.9824\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3072 - auc: 0.9843\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2939 - auc: 0.9830\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2954 - auc: 0.9832\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3119 - auc: 0.9843\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2838 - auc: 0.9851\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2931 - auc: 0.9842\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2991 - auc: 0.9863\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2853 - auc: 0.9841\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2847 - auc: 0.9855\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2901 - auc: 0.9852\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2963 - auc: 0.9848\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2885 - auc: 0.9859\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2899 - auc: 0.9849\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2973 - auc: 0.9857\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2775 - auc: 0.9863\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2921 - auc: 0.9847\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2929 - auc: 0.9854\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2866 - auc: 0.9851\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2871 - auc: 0.9860\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2989 - auc: 0.9867\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2893 - auc: 0.9848\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2946 - auc: 0.9850\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2892 - auc: 0.9854\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2955 - auc: 0.9861\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2925 - auc: 0.9862\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2927 - auc: 0.9853\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2952 - auc: 0.9850\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2926 - auc: 0.9858\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2953 - auc: 0.9852\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2901 - auc: 0.9855\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3007 - auc: 0.9850\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2857 - auc: 0.9851\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2856 - auc: 0.9854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 3.844231730287806e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.13392367906066532\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '3.8442', 'eer_eval': '0.1339', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!3.8442.hdf5', 'tnow': '2022-05-29 15:08:58.681725'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 50s 27ms/step - loss: 1.1839 - auc: 0.8620\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.4748 - auc: 0.9514\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3903 - auc: 0.9641\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3616 - auc: 0.9688\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3666 - auc: 0.9717\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3477 - auc: 0.9736\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3498 - auc: 0.9739\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3258 - auc: 0.9759\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3189 - auc: 0.9762\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3160 - auc: 0.9773\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3166 - auc: 0.9775\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3253 - auc: 0.9767\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3110 - auc: 0.9770\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3062 - auc: 0.9785\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3041 - auc: 0.9798\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3178 - auc: 0.9792\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3087 - auc: 0.9786\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3130 - auc: 0.9809\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3058 - auc: 0.9794\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2980 - auc: 0.9798\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2948 - auc: 0.9819\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3043 - auc: 0.9817\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2930 - auc: 0.9823\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2996 - auc: 0.9825\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3079 - auc: 0.9820\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2963 - auc: 0.9812\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2919 - auc: 0.9831\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2999 - auc: 0.9838\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3011 - auc: 0.9830\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3099 - auc: 0.9828\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3096 - auc: 0.9826\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3002 - auc: 0.9831\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2947 - auc: 0.9845\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3044 - auc: 0.9828\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2969 - auc: 0.9848\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2885 - auc: 0.9836\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2985 - auc: 0.9845\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2857 - auc: 0.9846\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2920 - auc: 0.9841\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2905 - auc: 0.9846\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2829 - auc: 0.9843\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3019 - auc: 0.9858\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2907 - auc: 0.9843\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2901 - auc: 0.9846\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3026 - auc: 0.9854\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2931 - auc: 0.9871\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2836 - auc: 0.9848\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2865 - auc: 0.9856\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2907 - auc: 0.9868\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2952 - auc: 0.9864\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2902 - auc: 0.9854\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2889 - auc: 0.9867\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2948 - auc: 0.9854\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2939 - auc: 0.9860\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2978 - auc: 0.9861\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2910 - auc: 0.9868\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2832 - auc: 0.9864\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2733 - auc: 0.9862\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2875 - auc: 0.9867\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2857 - auc: 0.9857\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2885 - auc: 0.9849\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2824 - auc: 0.9852\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2946 - auc: 0.9864\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2756 - auc: 0.9862\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2898 - auc: 0.9856\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2855 - auc: 0.9855\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2866 - auc: 0.9855\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2867 - auc: 0.9861\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2965 - auc: 0.9860\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2932 - auc: 0.9852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.14720156555772995\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0', 'eer_eval': '0.1472', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0.hdf5', 'tnow': '2022-05-29 16:01:39.060529'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 51s 27ms/step - loss: 1.0202 - auc: 0.8564\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.4906 - auc: 0.9495\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.4130 - auc: 0.9643\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3760 - auc: 0.9674\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3707 - auc: 0.9686\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3472 - auc: 0.9697\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3461 - auc: 0.9712\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3301 - auc: 0.9741\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3238 - auc: 0.9741\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3324 - auc: 0.9756\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3222 - auc: 0.9736\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3161 - auc: 0.9762\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3236 - auc: 0.9749\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3179 - auc: 0.9773\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3234 - auc: 0.9753\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3177 - auc: 0.9775\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3279 - auc: 0.9767\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3175 - auc: 0.9773\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3077 - auc: 0.9760\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3170 - auc: 0.9797\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3090 - auc: 0.9766\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3065 - auc: 0.9785\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3151 - auc: 0.9788\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3002 - auc: 0.9791\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3142 - auc: 0.9802\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3091 - auc: 0.9788\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 47s 28ms/step - loss: 0.3030 - auc: 0.9806\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3010 - auc: 0.9810\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3029 - auc: 0.9812\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3075 - auc: 0.9789\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 47s 28ms/step - loss: 0.2921 - auc: 0.9811\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2953 - auc: 0.9810\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3064 - auc: 0.9827\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3093 - auc: 0.9831\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3003 - auc: 0.9828\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3027 - auc: 0.9824\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2941 - auc: 0.9830\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2990 - auc: 0.9827\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2975 - auc: 0.9820\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2965 - auc: 0.9835\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2934 - auc: 0.9845\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2877 - auc: 0.9832\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2930 - auc: 0.9854\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2857 - auc: 0.9843\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2877 - auc: 0.9849\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2921 - auc: 0.9839\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2997 - auc: 0.9839\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2869 - auc: 0.9852\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2875 - auc: 0.9837\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2952 - auc: 0.9853\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3054 - auc: 0.9846\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2946 - auc: 0.9849\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2910 - auc: 0.9834\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 47s 28ms/step - loss: 0.3011 - auc: 0.9833\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3002 - auc: 0.9845\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3052 - auc: 0.9849\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2934 - auc: 0.9843\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 47s 28ms/step - loss: 0.2926 - auc: 0.9824\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2951 - auc: 0.9851\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2915 - auc: 0.9843\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 47s 28ms/step - loss: 0.2917 - auc: 0.9851\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 47s 28ms/step - loss: 0.2936 - auc: 0.9850\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3030 - auc: 0.9837\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 47s 28ms/step - loss: 0.2967 - auc: 0.9856\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2934 - auc: 0.9853\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 47s 28ms/step - loss: 0.2913 - auc: 0.9849\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2972 - auc: 0.9839\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2910 - auc: 0.9845\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 47s 28ms/step - loss: 0.2919 - auc: 0.9842\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2940 - auc: 0.9842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0002936163207782745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.13949119373776908\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0002', 'eer_eval': '0.1394', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0002.hdf5', 'tnow': '2022-05-29 16:55:42.553184'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 51s 27ms/step - loss: 1.1184 - auc: 0.8432\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.4709 - auc: 0.9529\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.4150 - auc: 0.9628\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3725 - auc: 0.9661\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3718 - auc: 0.9672\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3473 - auc: 0.9724\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3526 - auc: 0.9709\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3328 - auc: 0.9724\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3459 - auc: 0.9740\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3368 - auc: 0.9735\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3211 - auc: 0.9761\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3242 - auc: 0.9747\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3250 - auc: 0.9772\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3118 - auc: 0.9762\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3112 - auc: 0.9766\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3109 - auc: 0.9779\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3055 - auc: 0.9778\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3175 - auc: 0.9788\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3180 - auc: 0.9799\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3130 - auc: 0.9798\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3113 - auc: 0.9793\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3077 - auc: 0.9793\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2994 - auc: 0.9805\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3036 - auc: 0.9798\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3103 - auc: 0.9821\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2981 - auc: 0.9817\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3114 - auc: 0.9815\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3084 - auc: 0.9817\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2993 - auc: 0.9827\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3044 - auc: 0.9840\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2974 - auc: 0.9834\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3058 - auc: 0.9823\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2945 - auc: 0.9832\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2916 - auc: 0.9841\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3041 - auc: 0.9836\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3016 - auc: 0.9843\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2987 - auc: 0.9847\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3002 - auc: 0.9840\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2985 - auc: 0.9847\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2978 - auc: 0.9854\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2970 - auc: 0.9828\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2992 - auc: 0.9842\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3034 - auc: 0.9854\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2872 - auc: 0.9860\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3031 - auc: 0.9850\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2911 - auc: 0.9853\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2881 - auc: 0.9848\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3011 - auc: 0.9843\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2982 - auc: 0.9861\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2963 - auc: 0.9851\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2851 - auc: 0.9859\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2883 - auc: 0.9846\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2911 - auc: 0.9858\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2934 - auc: 0.9853\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2993 - auc: 0.9851\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2806 - auc: 0.9848\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2942 - auc: 0.9844\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2824 - auc: 0.9845\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3012 - auc: 0.9863\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2976 - auc: 0.9847\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2910 - auc: 0.9842\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2921 - auc: 0.9844\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2905 - auc: 0.9846\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2869 - auc: 0.9858\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2881 - auc: 0.9852\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2948 - auc: 0.9855\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2827 - auc: 0.9865\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2921 - auc: 0.9846\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2990 - auc: 0.9844\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2884 - auc: 0.9861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00038972211403552517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.11607632093933466\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0003', 'eer_eval': '0.1160', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0003.hdf5', 'tnow': '2022-05-29 17:48:53.315179'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 52s 27ms/step - loss: 1.1709 - auc: 0.8445\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.4818 - auc: 0.9499\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.4063 - auc: 0.9605\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 47s 28ms/step - loss: 0.3872 - auc: 0.9650\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3709 - auc: 0.9652\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3505 - auc: 0.9698\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3383 - auc: 0.9713\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3403 - auc: 0.9712\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3309 - auc: 0.9735\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3239 - auc: 0.9734\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3344 - auc: 0.9739\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 47s 27ms/step - loss: 0.3269 - auc: 0.9757\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 47s 27ms/step - loss: 0.3166 - auc: 0.9761\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3237 - auc: 0.9772\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3165 - auc: 0.9769\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3275 - auc: 0.9770\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3169 - auc: 0.9773\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3120 - auc: 0.9792\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3092 - auc: 0.9801\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3207 - auc: 0.9773\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3152 - auc: 0.9795\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3036 - auc: 0.9803\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3031 - auc: 0.9805\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2973 - auc: 0.9796\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3060 - auc: 0.9795\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3123 - auc: 0.9814\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3021 - auc: 0.9808\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3074 - auc: 0.9786\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2909 - auc: 0.9826\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3032 - auc: 0.9812\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3119 - auc: 0.9813\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2990 - auc: 0.9818\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2888 - auc: 0.9802\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3036 - auc: 0.9822\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2947 - auc: 0.9830\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2970 - auc: 0.9824\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2961 - auc: 0.9819\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2956 - auc: 0.9824\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3013 - auc: 0.9835\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2951 - auc: 0.9827\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2945 - auc: 0.9829\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2928 - auc: 0.9831\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2972 - auc: 0.9829\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2958 - auc: 0.9838\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3001 - auc: 0.9829\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3032 - auc: 0.9825\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2867 - auc: 0.9835\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2941 - auc: 0.9835\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2891 - auc: 0.9835\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2931 - auc: 0.9835\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2967 - auc: 0.9843\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2861 - auc: 0.9842\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3001 - auc: 0.9839\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2934 - auc: 0.9845\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2917 - auc: 0.9850\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2945 - auc: 0.9843\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2872 - auc: 0.9841\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2889 - auc: 0.9847\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2874 - auc: 0.9836\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2967 - auc: 0.9848\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3020 - auc: 0.9847\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2996 - auc: 0.9837\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2961 - auc: 0.9837\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3039 - auc: 0.9839\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2960 - auc: 0.9844\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2913 - auc: 0.9845\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2889 - auc: 0.9845\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2887 - auc: 0.9838\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2920 - auc: 0.9853\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2893 - auc: 0.9843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0002936163207782745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.13320939334637966\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0002', 'eer_eval': '0.1332', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0002.hdf5', 'tnow': '2022-05-29 18:42:43.944182'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 49s 26ms/step - loss: 1.1855 - auc: 0.8433\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.4824 - auc: 0.9527\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.4136 - auc: 0.9623\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3898 - auc: 0.9654\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3666 - auc: 0.9694\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3464 - auc: 0.9686\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3502 - auc: 0.9719\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3357 - auc: 0.9731\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3200 - auc: 0.9743\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3379 - auc: 0.9744\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3157 - auc: 0.9749\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3237 - auc: 0.9748\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3216 - auc: 0.9751\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3206 - auc: 0.9782\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3182 - auc: 0.9762\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3150 - auc: 0.9773\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3203 - auc: 0.9781\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3178 - auc: 0.9781\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3018 - auc: 0.9783\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3101 - auc: 0.9798\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3090 - auc: 0.9792\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3156 - auc: 0.9788\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3264 - auc: 0.9789\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3125 - auc: 0.9786\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3160 - auc: 0.9786\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2974 - auc: 0.9808\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3073 - auc: 0.9787\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3170 - auc: 0.9809\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3057 - auc: 0.9814\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3107 - auc: 0.9805\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3046 - auc: 0.9813\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3094 - auc: 0.9816\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3008 - auc: 0.9802\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2903 - auc: 0.9803\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3119 - auc: 0.9800\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3030 - auc: 0.9807\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2989 - auc: 0.9813\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3124 - auc: 0.9821\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2904 - auc: 0.9838\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3111 - auc: 0.9820\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2995 - auc: 0.9838\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3075 - auc: 0.9820\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2929 - auc: 0.9831\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3094 - auc: 0.9835\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2963 - auc: 0.9828\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2984 - auc: 0.9836\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2885 - auc: 0.9835\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3077 - auc: 0.9829\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2976 - auc: 0.9829\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2923 - auc: 0.9830\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2905 - auc: 0.9844\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2984 - auc: 0.9841\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3010 - auc: 0.9833\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3049 - auc: 0.9841\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2943 - auc: 0.9847\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2982 - auc: 0.9828\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2916 - auc: 0.9851\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2922 - auc: 0.9836\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3085 - auc: 0.9834\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2958 - auc: 0.9836\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3009 - auc: 0.9835\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2957 - auc: 0.9847\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3011 - auc: 0.9836\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2960 - auc: 0.9840\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3021 - auc: 0.9840\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2961 - auc: 0.9833\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3003 - auc: 0.9843\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3071 - auc: 0.9835\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2907 - auc: 0.9834\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3073 - auc: 0.9831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0003512797967326471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.11364970645792566\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0003', 'eer_eval': '0.1136', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0003.hdf5', 'tnow': '2022-05-29 19:35:23.960040'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 52s 27ms/step - loss: 1.0249 - auc: 0.8567\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.4834 - auc: 0.9520\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.4118 - auc: 0.9610\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3804 - auc: 0.9662\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3478 - auc: 0.9710\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3426 - auc: 0.9708\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3465 - auc: 0.9701\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3360 - auc: 0.9723\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3270 - auc: 0.9736\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3267 - auc: 0.9734\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3261 - auc: 0.9754\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3272 - auc: 0.9745\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3289 - auc: 0.9741\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3357 - auc: 0.9774\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3092 - auc: 0.9772\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3177 - auc: 0.9771\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3176 - auc: 0.9768\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3097 - auc: 0.9765\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3121 - auc: 0.9781\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3246 - auc: 0.9778\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3243 - auc: 0.9784\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3035 - auc: 0.9790\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3057 - auc: 0.9771\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3009 - auc: 0.9788\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3081 - auc: 0.9777\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3194 - auc: 0.9800\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2980 - auc: 0.9795\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2975 - auc: 0.9811\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3189 - auc: 0.9790\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3072 - auc: 0.9799\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3099 - auc: 0.9802\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2994 - auc: 0.9801\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3044 - auc: 0.9793\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2991 - auc: 0.9802\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3109 - auc: 0.9801\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3033 - auc: 0.9826\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2987 - auc: 0.9805\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3062 - auc: 0.9802\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2931 - auc: 0.9813\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2861 - auc: 0.9817\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2949 - auc: 0.9823\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3030 - auc: 0.9812\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2876 - auc: 0.9823\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2986 - auc: 0.9821\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2985 - auc: 0.9831\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2994 - auc: 0.9823\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3019 - auc: 0.9832\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2976 - auc: 0.9818\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2962 - auc: 0.9825\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3012 - auc: 0.9833\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2971 - auc: 0.9824\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2846 - auc: 0.9833\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2883 - auc: 0.9820\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3089 - auc: 0.9827\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2905 - auc: 0.9828\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2987 - auc: 0.9823\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2861 - auc: 0.9831\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2944 - auc: 0.9828\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2961 - auc: 0.9823\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2908 - auc: 0.9825\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2840 - auc: 0.9833\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2851 - auc: 0.9831\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2936 - auc: 0.9826\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2927 - auc: 0.9834\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2855 - auc: 0.9832\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2983 - auc: 0.9830\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2892 - auc: 0.9832\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2954 - auc: 0.9836\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2916 - auc: 0.9833\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2895 - auc: 0.9841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.001457483721878161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.1230724070450098\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0014', 'eer_eval': '0.1230', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0014.hdf5', 'tnow': '2022-05-29 20:28:46.078591'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 50s 27ms/step - loss: 1.1338 - auc: 0.8421\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.4779 - auc: 0.9485\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.4086 - auc: 0.9624\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3873 - auc: 0.9676\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3641 - auc: 0.9688\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3587 - auc: 0.9703\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3445 - auc: 0.9745\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3442 - auc: 0.9720\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3422 - auc: 0.9734\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3163 - auc: 0.9764\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3263 - auc: 0.9772\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3364 - auc: 0.9741\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3316 - auc: 0.9752\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3104 - auc: 0.9778\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3185 - auc: 0.9784\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3156 - auc: 0.9767\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3186 - auc: 0.9778\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3167 - auc: 0.9766\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2968 - auc: 0.9781\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3079 - auc: 0.9789\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3035 - auc: 0.9782\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2993 - auc: 0.9785\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3026 - auc: 0.9797\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3073 - auc: 0.9802\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3044 - auc: 0.9796\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3041 - auc: 0.9812\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3159 - auc: 0.9815\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3021 - auc: 0.9800\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2956 - auc: 0.9799\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3008 - auc: 0.9813\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2946 - auc: 0.9834\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3068 - auc: 0.9810\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3030 - auc: 0.9804\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3115 - auc: 0.9814\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2913 - auc: 0.9815\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2878 - auc: 0.9820\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2923 - auc: 0.9820\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3046 - auc: 0.9828\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3072 - auc: 0.9841\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3046 - auc: 0.9829\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2945 - auc: 0.9833\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3101 - auc: 0.9831\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2935 - auc: 0.9840\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2876 - auc: 0.9844\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3053 - auc: 0.9832\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2995 - auc: 0.9841\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3040 - auc: 0.9838\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2968 - auc: 0.9844\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2956 - auc: 0.9843\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2884 - auc: 0.9839\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3048 - auc: 0.9827\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2915 - auc: 0.9837\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3022 - auc: 0.9835\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2891 - auc: 0.9853\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3017 - auc: 0.9847\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2903 - auc: 0.9831\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2937 - auc: 0.9833\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2974 - auc: 0.9848\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2906 - auc: 0.9839\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2861 - auc: 0.9849\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2881 - auc: 0.9841\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2911 - auc: 0.9846\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2797 - auc: 0.9850\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2823 - auc: 0.9838\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2966 - auc: 0.9846\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2930 - auc: 0.9854\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2887 - auc: 0.9840\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3065 - auc: 0.9842\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2930 - auc: 0.9843\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2893 - auc: 0.9846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 7.688463460575612e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.1254990215264188\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '7.6884', 'eer_eval': '0.1254', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!7.6884.hdf5', 'tnow': '2022-05-29 21:21:47.266945'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 50s 27ms/step - loss: 0.8998 - auc: 0.8914\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.4347 - auc: 0.9615\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.4011 - auc: 0.9655\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3671 - auc: 0.9695\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3550 - auc: 0.9713\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3453 - auc: 0.9704\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3345 - auc: 0.9729\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3359 - auc: 0.9737\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3169 - auc: 0.9751\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3221 - auc: 0.9754\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3397 - auc: 0.9771\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3251 - auc: 0.9765\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3199 - auc: 0.9775\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3126 - auc: 0.9772\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3114 - auc: 0.9775\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3083 - auc: 0.9765\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3126 - auc: 0.9767\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3189 - auc: 0.9782\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2990 - auc: 0.9796\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3022 - auc: 0.9791\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3041 - auc: 0.9808\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3002 - auc: 0.9817\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2999 - auc: 0.9797\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3212 - auc: 0.9791\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3126 - auc: 0.9795\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3091 - auc: 0.9809\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3058 - auc: 0.9795\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2920 - auc: 0.9814\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3068 - auc: 0.9814\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3066 - auc: 0.9800\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3039 - auc: 0.9810\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3020 - auc: 0.9821\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3072 - auc: 0.9833\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3035 - auc: 0.9811\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2972 - auc: 0.9823\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2943 - auc: 0.9829\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2861 - auc: 0.9834\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2913 - auc: 0.9823\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2914 - auc: 0.9841\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3079 - auc: 0.9846\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2922 - auc: 0.9850\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2987 - auc: 0.9836\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2969 - auc: 0.9849\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2854 - auc: 0.9827\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2881 - auc: 0.9837\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2982 - auc: 0.9835\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2892 - auc: 0.9832\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2868 - auc: 0.9851\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2946 - auc: 0.9844\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3019 - auc: 0.9836\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2971 - auc: 0.9846\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3011 - auc: 0.9835\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3001 - auc: 0.9854\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2921 - auc: 0.9837\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2897 - auc: 0.9838\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2856 - auc: 0.9842\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2956 - auc: 0.9841\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2977 - auc: 0.9851\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2880 - auc: 0.9853\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2928 - auc: 0.9845\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2912 - auc: 0.9862\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2914 - auc: 0.9856\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2882 - auc: 0.9850\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2941 - auc: 0.9845\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2949 - auc: 0.9849\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2851 - auc: 0.9854\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2980 - auc: 0.9841\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2972 - auc: 0.9845\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2975 - auc: 0.9848\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2924 - auc: 0.9851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.13078277886497064\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0', 'eer_eval': '0.1307', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0.hdf5', 'tnow': '2022-05-29 22:14:46.991835'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 50s 27ms/step - loss: 1.0060 - auc: 0.8576\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.4517 - auc: 0.9583\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3835 - auc: 0.9654\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3638 - auc: 0.9695\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3603 - auc: 0.9712\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3446 - auc: 0.9742\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3289 - auc: 0.9740\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3325 - auc: 0.9747\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3196 - auc: 0.9763\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3264 - auc: 0.9761\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3224 - auc: 0.9767\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3195 - auc: 0.9791\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3150 - auc: 0.9781\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3068 - auc: 0.9799\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3054 - auc: 0.9793\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3077 - auc: 0.9797\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3073 - auc: 0.9780\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2988 - auc: 0.9804\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3129 - auc: 0.9803\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3060 - auc: 0.9798\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3050 - auc: 0.9806\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3075 - auc: 0.9800\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3074 - auc: 0.9804\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3113 - auc: 0.9822\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2870 - auc: 0.9829\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3050 - auc: 0.9827\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3012 - auc: 0.9824\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3003 - auc: 0.9818\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3088 - auc: 0.9834\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3007 - auc: 0.9834\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2907 - auc: 0.9829\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2977 - auc: 0.9834\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2997 - auc: 0.9834\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3015 - auc: 0.9836\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2983 - auc: 0.9835\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3002 - auc: 0.9847\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2859 - auc: 0.9848\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2900 - auc: 0.9843\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2845 - auc: 0.9847\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2981 - auc: 0.9857\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2957 - auc: 0.9838\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2920 - auc: 0.9840\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2903 - auc: 0.9856\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2779 - auc: 0.9844\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2776 - auc: 0.9853\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2864 - auc: 0.9856\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2894 - auc: 0.9847\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2950 - auc: 0.9838\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2887 - auc: 0.9847\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2940 - auc: 0.9851\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2881 - auc: 0.9848\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3043 - auc: 0.9861\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2835 - auc: 0.9854\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2943 - auc: 0.9840\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2945 - auc: 0.9864\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2824 - auc: 0.9857\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2967 - auc: 0.9853\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2915 - auc: 0.9870\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2905 - auc: 0.9852\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2872 - auc: 0.9846\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2898 - auc: 0.9852\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2920 - auc: 0.9859\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2871 - auc: 0.9853\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2968 - auc: 0.9860\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2735 - auc: 0.9846\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2756 - auc: 0.9858\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2914 - auc: 0.9862\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2979 - auc: 0.9855\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2916 - auc: 0.9848\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2899 - auc: 0.9855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0020062740461318875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.13635029354207434\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0020', 'eer_eval': '0.1363', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0020.hdf5', 'tnow': '2022-05-29 23:08:17.653764'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 49s 26ms/step - loss: 1.0472 - auc: 0.8589\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.4727 - auc: 0.9509\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3950 - auc: 0.9621\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3642 - auc: 0.9666\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3515 - auc: 0.9675\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3366 - auc: 0.9703\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3371 - auc: 0.9724\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3353 - auc: 0.9726\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3159 - auc: 0.9750\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3179 - auc: 0.9767\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3095 - auc: 0.9774\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3162 - auc: 0.9769\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3326 - auc: 0.9780\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3173 - auc: 0.9789\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3196 - auc: 0.9777\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3163 - auc: 0.9788\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3140 - auc: 0.9795\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3012 - auc: 0.9773\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3148 - auc: 0.9807\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3081 - auc: 0.9799\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3067 - auc: 0.9803\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3116 - auc: 0.9799\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2953 - auc: 0.9805\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2976 - auc: 0.9803\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3070 - auc: 0.9810\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3013 - auc: 0.9810\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3049 - auc: 0.9814\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2881 - auc: 0.9817\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3047 - auc: 0.9812\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3060 - auc: 0.9822\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3002 - auc: 0.9815\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3027 - auc: 0.9825\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3024 - auc: 0.9814\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3014 - auc: 0.9832\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3079 - auc: 0.9843\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2993 - auc: 0.9834\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2953 - auc: 0.9836\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2922 - auc: 0.9840\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3045 - auc: 0.9862\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2941 - auc: 0.9835\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2912 - auc: 0.9836\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2970 - auc: 0.9831\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3056 - auc: 0.9843\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2943 - auc: 0.9844\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2875 - auc: 0.9855\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3063 - auc: 0.9850\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3005 - auc: 0.9846\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2930 - auc: 0.9855\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3042 - auc: 0.9854\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2989 - auc: 0.9849\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2891 - auc: 0.9846\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2889 - auc: 0.9862\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.3030 - auc: 0.9848\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2978 - auc: 0.9853\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3029 - auc: 0.9853\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2922 - auc: 0.9862\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2929 - auc: 0.9854\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2943 - auc: 0.9854\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2888 - auc: 0.9849\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2967 - auc: 0.9858\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2834 - auc: 0.9856\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2798 - auc: 0.9836\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2951 - auc: 0.9858\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2796 - auc: 0.9862\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2960 - auc: 0.9854\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2845 - auc: 0.9860\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2863 - auc: 0.9853\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2799 - auc: 0.9861\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2987 - auc: 0.9857\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2873 - auc: 0.9852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 3.844231730287806e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.17832681017612526\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '3.8442', 'eer_eval': '0.1783', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!3.8442.hdf5', 'tnow': '2022-05-30 00:01:01.048230'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 52s 27ms/step - loss: 1.1116 - auc: 0.8629\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.5045 - auc: 0.9473\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3987 - auc: 0.9606\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3857 - auc: 0.9648\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3558 - auc: 0.9674\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3378 - auc: 0.9712\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3278 - auc: 0.9750\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3249 - auc: 0.9735\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3258 - auc: 0.9740\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3130 - auc: 0.9764\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3176 - auc: 0.9765\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2921 - auc: 0.9773\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3288 - auc: 0.9777\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3041 - auc: 0.9790\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3127 - auc: 0.9791\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2949 - auc: 0.9806\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3105 - auc: 0.9807\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3000 - auc: 0.9801\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3039 - auc: 0.9814\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3011 - auc: 0.9810\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2935 - auc: 0.9820\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3020 - auc: 0.9811\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3087 - auc: 0.9817\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3046 - auc: 0.9829\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2934 - auc: 0.9834\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2962 - auc: 0.9820\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2969 - auc: 0.9823\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3046 - auc: 0.9809\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2933 - auc: 0.9818\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2929 - auc: 0.9827\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2958 - auc: 0.9836\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2948 - auc: 0.9822\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3023 - auc: 0.9828\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3018 - auc: 0.9834\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2936 - auc: 0.9835\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2886 - auc: 0.9842\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2935 - auc: 0.9841\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2944 - auc: 0.9842\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2942 - auc: 0.9858\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2895 - auc: 0.9848\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2917 - auc: 0.9844\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2932 - auc: 0.9859\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2922 - auc: 0.9850\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3024 - auc: 0.9845\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3068 - auc: 0.9855\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3022 - auc: 0.9859\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2879 - auc: 0.9863\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3053 - auc: 0.9856\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2965 - auc: 0.9843\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2973 - auc: 0.9850\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2963 - auc: 0.9842\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2921 - auc: 0.9853\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2877 - auc: 0.9846\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2904 - auc: 0.9860\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2954 - auc: 0.9854\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2918 - auc: 0.9844\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2866 - auc: 0.9862\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2987 - auc: 0.9846\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2982 - auc: 0.9862\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2842 - auc: 0.9853\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2910 - auc: 0.9856\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2867 - auc: 0.9853\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2911 - auc: 0.9863\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2942 - auc: 0.9858\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2995 - auc: 0.9853\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2793 - auc: 0.9855\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2861 - auc: 0.9848\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2892 - auc: 0.9863\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2876 - auc: 0.9859\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2919 - auc: 0.9854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0010100981318883187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.13249510763209393\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0010', 'eer_eval': '0.1324', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0010.hdf5', 'tnow': '2022-05-30 00:54:30.756640'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 50s 27ms/step - loss: 1.2238 - auc: 0.8003\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.4701 - auc: 0.9515\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.4420 - auc: 0.9589\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3705 - auc: 0.9670\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3845 - auc: 0.9626\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3552 - auc: 0.9719\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3506 - auc: 0.9710\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3357 - auc: 0.9713\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3466 - auc: 0.9729\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3327 - auc: 0.9741\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3285 - auc: 0.9733\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3298 - auc: 0.9744\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3363 - auc: 0.9748\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3131 - auc: 0.9760\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3138 - auc: 0.9775\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3169 - auc: 0.9772\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3271 - auc: 0.9780\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3106 - auc: 0.9780\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3154 - auc: 0.9776\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3045 - auc: 0.9796\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3150 - auc: 0.9780\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3264 - auc: 0.9786\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3076 - auc: 0.9794\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3148 - auc: 0.9802\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3133 - auc: 0.9800\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3218 - auc: 0.9796\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3095 - auc: 0.9801\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3092 - auc: 0.9804\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2976 - auc: 0.9807\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3083 - auc: 0.9808\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3109 - auc: 0.9815\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3096 - auc: 0.9800\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2952 - auc: 0.9803\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3100 - auc: 0.9829\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3090 - auc: 0.9825\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3007 - auc: 0.9815\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3011 - auc: 0.9825\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2935 - auc: 0.9838\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2969 - auc: 0.9819\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3060 - auc: 0.9828\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2926 - auc: 0.9821\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2978 - auc: 0.9818\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3034 - auc: 0.9827\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2880 - auc: 0.9832\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2924 - auc: 0.9842\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2972 - auc: 0.9839\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2998 - auc: 0.9843\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2948 - auc: 0.9820\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3016 - auc: 0.9832\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2941 - auc: 0.9835\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2934 - auc: 0.9826\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2892 - auc: 0.9838\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2972 - auc: 0.9836\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3052 - auc: 0.9844\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2923 - auc: 0.9843\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2958 - auc: 0.9829\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3020 - auc: 0.9836\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2774 - auc: 0.9844\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2922 - auc: 0.9842\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2992 - auc: 0.9842\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2957 - auc: 0.9834\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2932 - auc: 0.9841\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2942 - auc: 0.9854\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2853 - auc: 0.9835\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2911 - auc: 0.9840\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2980 - auc: 0.9838\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3001 - auc: 0.9837\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2915 - auc: 0.9835\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2857 - auc: 0.9827\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2989 - auc: 0.9849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0004666067486412813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.13320939334637966\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0004', 'eer_eval': '0.1332', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0004.hdf5', 'tnow': '2022-05-30 01:47:35.606818'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 52s 27ms/step - loss: 1.3936 - auc: 0.8475\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.5160 - auc: 0.9459\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.4563 - auc: 0.9578\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.4138 - auc: 0.9626\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3902 - auc: 0.9656\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3584 - auc: 0.9695\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3567 - auc: 0.9689\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3513 - auc: 0.9717\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3295 - auc: 0.9729\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3335 - auc: 0.9723\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3219 - auc: 0.9748\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3376 - auc: 0.9762\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3217 - auc: 0.9763\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3258 - auc: 0.9767\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3314 - auc: 0.9771\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3198 - auc: 0.9757\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3181 - auc: 0.9769\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3247 - auc: 0.9781\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3115 - auc: 0.9774\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3250 - auc: 0.9775\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3227 - auc: 0.9775\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3091 - auc: 0.9792\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3181 - auc: 0.9786\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3115 - auc: 0.9788\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3057 - auc: 0.9795\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3095 - auc: 0.9804\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2953 - auc: 0.9801\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3184 - auc: 0.9782\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2992 - auc: 0.9802\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3158 - auc: 0.9791\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3037 - auc: 0.9798\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2966 - auc: 0.9813\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2992 - auc: 0.9802\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3075 - auc: 0.9815\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3003 - auc: 0.9817\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3019 - auc: 0.9819\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2949 - auc: 0.9809\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2964 - auc: 0.9817\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2963 - auc: 0.9830\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3056 - auc: 0.9825\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2988 - auc: 0.9825\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2949 - auc: 0.9823\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3004 - auc: 0.9825\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2907 - auc: 0.9835\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3039 - auc: 0.9840\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3001 - auc: 0.9834\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2968 - auc: 0.9847\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2995 - auc: 0.9841\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2835 - auc: 0.9832\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3027 - auc: 0.9826\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2967 - auc: 0.9850\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3044 - auc: 0.9840\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3068 - auc: 0.9827\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3010 - auc: 0.9832\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2902 - auc: 0.9850\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2905 - auc: 0.9840\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2977 - auc: 0.9839\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2936 - auc: 0.9845\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2990 - auc: 0.9847\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2910 - auc: 0.9849\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2864 - auc: 0.9841\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2995 - auc: 0.9828\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2959 - auc: 0.9843\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3063 - auc: 0.9838\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2892 - auc: 0.9841\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3003 - auc: 0.9843\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2925 - auc: 0.9839\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3033 - auc: 0.9836\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2967 - auc: 0.9844\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3017 - auc: 0.9832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.13320939334637966\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0', 'eer_eval': '0.1332', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0.hdf5', 'tnow': '2022-05-30 02:41:14.468485'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 50s 27ms/step - loss: 1.2863 - auc: 0.8365\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.5473 - auc: 0.9414\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.4584 - auc: 0.9548\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.4092 - auc: 0.9611\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3717 - auc: 0.9676\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3566 - auc: 0.9703\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3376 - auc: 0.9727\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3381 - auc: 0.9738\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3278 - auc: 0.9748\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3234 - auc: 0.9747\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3324 - auc: 0.9745\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3235 - auc: 0.9745\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3296 - auc: 0.9773\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3295 - auc: 0.9761\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3303 - auc: 0.9756\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3131 - auc: 0.9785\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3224 - auc: 0.9782\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3040 - auc: 0.9788\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3127 - auc: 0.9789\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3118 - auc: 0.9799\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3104 - auc: 0.9794\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3118 - auc: 0.9795\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3112 - auc: 0.9801\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3118 - auc: 0.9802\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3068 - auc: 0.9803\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3044 - auc: 0.9798\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2924 - auc: 0.9802\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3050 - auc: 0.9807\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3174 - auc: 0.9809\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3198 - auc: 0.9808\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2984 - auc: 0.9822\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3186 - auc: 0.9826\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3009 - auc: 0.9825\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3045 - auc: 0.9823\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2982 - auc: 0.9823\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3052 - auc: 0.9816\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3107 - auc: 0.9826\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3061 - auc: 0.9828\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2988 - auc: 0.9833\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2935 - auc: 0.9840\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2847 - auc: 0.9821\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2953 - auc: 0.9846\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.2982 - auc: 0.9826\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 44s 26ms/step - loss: 0.2987 - auc: 0.9823\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3025 - auc: 0.9826\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3074 - auc: 0.9832\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2970 - auc: 0.9839\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2932 - auc: 0.9838\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2824 - auc: 0.9826\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2930 - auc: 0.9840\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2899 - auc: 0.9836\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2927 - auc: 0.9836\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2958 - auc: 0.9837\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2921 - auc: 0.9832\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2913 - auc: 0.9849\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2987 - auc: 0.9833\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2987 - auc: 0.9835\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2886 - auc: 0.9839\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2933 - auc: 0.9841\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 45s 26ms/step - loss: 0.3020 - auc: 0.9838\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2858 - auc: 0.9845\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2988 - auc: 0.9844\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2920 - auc: 0.9833\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3080 - auc: 0.9843\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3024 - auc: 0.9832\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.2889 - auc: 0.9836\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.3073 - auc: 0.9836\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 45s 27ms/step - loss: 0.3030 - auc: 0.9843\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2965 - auc: 0.9835\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 46s 27ms/step - loss: 0.2883 - auc: 0.9847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00037050095538408614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.11679060665362033\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'BCResMax_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0003', 'eer_eval': '0.1167', 'saved_model': 'saved_models/model_name!BCResMax_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0003.hdf5', 'tnow': '2022-05-30 03:34:30.323981'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 72s 39ms/step - loss: 0.7413 - auc: 0.9001\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0861 - auc: 0.9981\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.0323 - auc: 0.9994\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.0231 - auc: 0.9996\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.0120 - auc: 0.9999\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.0306 - auc: 0.9994\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0191 - auc: 0.9999\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.0077 - auc: 0.9998\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0083 - auc: 0.9999\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0104 - auc: 0.9998\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.0060 - auc: 0.9999\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.0050 - auc: 1.0000\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0047 - auc: 0.9999\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0108 - auc: 0.9998\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.0085 - auc: 1.0000\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 7.8750e-04 - auc: 1.0000\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0173 - auc: 0.9995\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0012 - auc: 1.0000\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0022 - auc: 1.0000\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0095 - auc: 0.9997\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0052 - auc: 0.9999\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 5.2789e-04 - auc: 1.0000\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0061 - auc: 0.9996\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0021 - auc: 0.9999\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 5.2680e-04 - auc: 1.0000\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0033 - auc: 0.9999\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0024 - auc: 0.9999\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 9.9750e-04 - auc: 1.0000\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0029 - auc: 0.9997\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 9.7615e-04 - auc: 1.0000\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 2.0025e-04 - auc: 1.0000\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 9.5222e-04 - auc: 1.0000\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 9.9380e-04 - auc: 1.0000\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0015 - auc: 1.0000\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0011 - auc: 1.0000\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 3.0900e-04 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 6.8155e-04 - auc: 1.0000\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0036 - auc: 0.9999\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 6.4272e-04 - auc: 1.0000\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0078 - auc: 0.9999\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 3.4638e-04 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 1.9801e-04 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 4.1816e-05 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 2.9852e-04 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 1.6720e-04 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 2.4108e-04 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 5.2363e-04 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 6.4319e-06 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 7.7822e-06 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 2.5669e-05 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 6.1339e-06 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 1.1446e-04 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 1.4409e-05 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 2.9562e-06 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 2.0387e-06 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 1.8308e-06 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 3.6927e-05 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 1.4874e-05 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 3.0182e-06 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 1.9584e-06 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 2.9169e-05 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 8.5080e-07 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 9.2423e-05 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 8.7646e-07 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 1.2614e-04 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 2.1010e-05 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0028 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 6.4561e-06 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 5.5907e-07 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 5.6214e-06 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0003512797967326471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.1836105675146771\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0003', 'eer_eval': '0.1836', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0003.hdf5', 'tnow': '2022-05-30 04:52:09.793871'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 73s 40ms/step - loss: 0.6918 - auc: 0.9159\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.0903 - auc: 0.9981\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0396 - auc: 0.9995\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0318 - auc: 0.9996\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.0164 - auc: 0.9999\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0179 - auc: 0.9997\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0110 - auc: 0.9998\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.0120 - auc: 0.9999\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.0067 - auc: 1.0000\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.0138 - auc: 0.9998\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0093 - auc: 0.9999\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.0082 - auc: 0.9999\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.0056 - auc: 1.0000\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0178 - auc: 0.9996\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.0055 - auc: 0.9998\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.0114 - auc: 0.9998\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.0044 - auc: 1.0000\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0051 - auc: 0.9999\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.0122 - auc: 0.9997\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.0034 - auc: 1.0000\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0090 - auc: 0.9997\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.0034 - auc: 0.9999\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0043 - auc: 0.9999\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.0056 - auc: 0.9998\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0012 - auc: 1.0000\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0023 - auc: 1.0000\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0014 - auc: 1.0000\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.0146 - auc: 0.9998\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.0031 - auc: 0.9999\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0035 - auc: 0.9999\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0026 - auc: 1.0000\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0018 - auc: 0.9999\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0011 - auc: 1.0000\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0025 - auc: 0.9999\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 9.4502e-04 - auc: 1.0000\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0085 - auc: 0.9997\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.0025 - auc: 0.9998\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0012 - auc: 1.0000\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 2.5557e-04 - auc: 1.0000\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 1.2336e-04 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 1.8350e-05 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 1.2128e-04 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 1.1429e-04 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 3.9483e-05 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.0020 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 9.8947e-05 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 2.1052e-04 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 8.2366e-05 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 4.8621e-05 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 4.7147e-05 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 1.0630e-05 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 1.0835e-04 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 2.3667e-04 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 1.0640e-05 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 3.9988e-06 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 2.5423e-06 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 4.8512e-05 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 7.2808e-05 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 1.1140e-05 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 1.3399e-05 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 6.2476e-05 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 1.9935e-05 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 8.7924e-05 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.0029 - auc: 0.9999\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 6.8424e-05 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 3.1501e-05 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 1.3901e-05 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 2.7784e-05 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 2.3059e-05 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 1.7149e-05 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 1.922115865143903e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.26327788649706463\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '1.9221', 'eer_eval': '0.2632', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!1.9221.hdf5', 'tnow': '2022-05-30 06:11:04.873942'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 72s 39ms/step - loss: 0.7389 - auc: 0.9109\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.1031 - auc: 0.9975\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0386 - auc: 0.9993\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0408 - auc: 0.9990\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0259 - auc: 0.9996\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0232 - auc: 0.9996\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0242 - auc: 0.9995\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0096 - auc: 0.9999\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0117 - auc: 0.9997\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.0134 - auc: 0.9998\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0122 - auc: 0.9997\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0037 - auc: 1.0000\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.0061 - auc: 1.0000\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.0093 - auc: 0.9999\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.0025 - auc: 1.0000\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.0158 - auc: 0.9996\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.0040 - auc: 1.0000\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.0049 - auc: 0.9999\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.0062 - auc: 0.9999\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0065 - auc: 0.9999\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.0125 - auc: 0.9997\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.0022 - auc: 1.0000\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.0063 - auc: 0.9998\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0015 - auc: 1.0000\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0081 - auc: 0.9998\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.0028 - auc: 1.0000\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.0029 - auc: 1.0000\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0043 - auc: 0.9999\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 6.9076e-04 - auc: 1.0000\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0031 - auc: 0.9999\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 8.1617e-04 - auc: 1.0000\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0031 - auc: 1.0000\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0021 - auc: 0.9999\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 5.9279e-04 - auc: 1.0000\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0019 - auc: 1.0000\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 8.6118e-04 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0087 - auc: 0.9999\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 3.2369e-04 - auc: 1.0000\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 7.1769e-04 - auc: 1.0000\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.0026 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 5.2719e-04 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.0021 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 1.5335e-04 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.0011 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 9.2537e-05 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 2.5066e-05 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 2.0499e-04 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 1.4522e-04 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 3.6258e-05 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 3.3482e-05 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 1.6969e-04 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 3.4424e-04 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 9.1154e-05 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 1.3654e-04 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 4.5273e-05 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.0019 - auc: 0.9999\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 6.7870e-05 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 8.1990e-05 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 1.2481e-04 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 6.4432e-05 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 1.3514e-04 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 4.9055e-05 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.0013 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 3.0269e-05 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 3.1463e-05 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 6.5237e-06 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 3.2635e-04 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 5.6906e-06 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 6.7158e-04 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 7.1495e-05 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0021792644739948943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.22901174168297456\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0021', 'eer_eval': '0.2290', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0021.hdf5', 'tnow': '2022-05-30 07:29:05.170594'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 74s 40ms/step - loss: 1.1572 - auc: 0.8124\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.4673 - auc: 0.9506\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3800 - auc: 0.9657\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3699 - auc: 0.9663\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3417 - auc: 0.9701\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3464 - auc: 0.9731\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3347 - auc: 0.9739\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3173 - auc: 0.9749\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3163 - auc: 0.9758\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3134 - auc: 0.9750\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3067 - auc: 0.9779\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3124 - auc: 0.9777\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3189 - auc: 0.9754\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3156 - auc: 0.9780\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3050 - auc: 0.9768\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3092 - auc: 0.9787\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3086 - auc: 0.9801\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3084 - auc: 0.9803\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3137 - auc: 0.9784\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3005 - auc: 0.9804\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2972 - auc: 0.9800\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3089 - auc: 0.9817\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3095 - auc: 0.9799\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3165 - auc: 0.9809\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2898 - auc: 0.9824\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3042 - auc: 0.9817\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2891 - auc: 0.9825\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2923 - auc: 0.9817\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3063 - auc: 0.9827\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3042 - auc: 0.9834\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2882 - auc: 0.9838\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2869 - auc: 0.9846\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2875 - auc: 0.9835\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3024 - auc: 0.9841\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2955 - auc: 0.9852\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2837 - auc: 0.9858\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2798 - auc: 0.9842\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3088 - auc: 0.9856\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2993 - auc: 0.9849\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2941 - auc: 0.9847\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2808 - auc: 0.9863\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2872 - auc: 0.9849\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2900 - auc: 0.9848\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2945 - auc: 0.9858\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2944 - auc: 0.9849\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2871 - auc: 0.9858\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2810 - auc: 0.9858\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2892 - auc: 0.9859\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2890 - auc: 0.9857\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2944 - auc: 0.9869\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2953 - auc: 0.9875\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2929 - auc: 0.9857\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2836 - auc: 0.9855\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2843 - auc: 0.9863\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2817 - auc: 0.9866\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2786 - auc: 0.9863\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2743 - auc: 0.9861\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2755 - auc: 0.9864\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2839 - auc: 0.9854\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2989 - auc: 0.9861\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2850 - auc: 0.9855\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2951 - auc: 0.9870\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2931 - auc: 0.9866\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2935 - auc: 0.9869\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2938 - auc: 0.9854\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2847 - auc: 0.9863\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2817 - auc: 0.9860\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2813 - auc: 0.9859\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2877 - auc: 0.9866\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2883 - auc: 0.9871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0008563288626768065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.18460861056751465\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0008', 'eer_eval': '0.1846', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0008.hdf5', 'tnow': '2022-05-30 08:48:23.798005'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 72s 40ms/step - loss: 1.1933 - auc: 0.8123\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.5035 - auc: 0.9511\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.4005 - auc: 0.9617\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3769 - auc: 0.9667\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3560 - auc: 0.9712\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3364 - auc: 0.9745\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3342 - auc: 0.9733\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3303 - auc: 0.9757\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3249 - auc: 0.9756\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3130 - auc: 0.9765\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3272 - auc: 0.9770\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3143 - auc: 0.9792\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3122 - auc: 0.9788\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3068 - auc: 0.9777\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3124 - auc: 0.9790\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3146 - auc: 0.9790\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3023 - auc: 0.9808\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2957 - auc: 0.9811\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3045 - auc: 0.9802\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2985 - auc: 0.9804\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2971 - auc: 0.9808\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2964 - auc: 0.9816\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2983 - auc: 0.9826\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3056 - auc: 0.9818\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3052 - auc: 0.9831\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2938 - auc: 0.9832\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2961 - auc: 0.9817\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3025 - auc: 0.9824\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2977 - auc: 0.9829\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3052 - auc: 0.9844\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2980 - auc: 0.9829\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2875 - auc: 0.9838\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2941 - auc: 0.9841\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2927 - auc: 0.9842\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2892 - auc: 0.9850\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2873 - auc: 0.9844\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3106 - auc: 0.9832\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2845 - auc: 0.9845\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2900 - auc: 0.9845\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2913 - auc: 0.9848\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2902 - auc: 0.9861\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2918 - auc: 0.9858\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2922 - auc: 0.9862\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2826 - auc: 0.9849\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2956 - auc: 0.9857\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2914 - auc: 0.9853\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2989 - auc: 0.9856\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2896 - auc: 0.9853\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2928 - auc: 0.9856\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3004 - auc: 0.9856\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2883 - auc: 0.9867\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2856 - auc: 0.9859\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2971 - auc: 0.9863\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2893 - auc: 0.9863\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2847 - auc: 0.9854\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2810 - auc: 0.9870\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2800 - auc: 0.9855\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2908 - auc: 0.9871\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2899 - auc: 0.9855\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2923 - auc: 0.9868\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2795 - auc: 0.9863\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2827 - auc: 0.9857\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2884 - auc: 0.9861\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2849 - auc: 0.9867\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2954 - auc: 0.9869\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2861 - auc: 0.9853\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2860 - auc: 0.9864\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3014 - auc: 0.9863\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2915 - auc: 0.9851\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2920 - auc: 0.9870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0013037144526666488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.17761252446183953\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0013', 'eer_eval': '0.1776', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0013.hdf5', 'tnow': '2022-05-30 10:06:54.605646'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 75s 40ms/step - loss: 0.9902 - auc: 0.8510\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.4459 - auc: 0.9584\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3955 - auc: 0.9636\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3699 - auc: 0.9681\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3640 - auc: 0.9718\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3403 - auc: 0.9748\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3305 - auc: 0.9756\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3314 - auc: 0.9762\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3297 - auc: 0.9762\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3105 - auc: 0.9769\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3198 - auc: 0.9784\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3246 - auc: 0.9783\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3066 - auc: 0.9806\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3145 - auc: 0.9784\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3057 - auc: 0.9789\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3087 - auc: 0.9793\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2925 - auc: 0.9809\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3076 - auc: 0.9814\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2996 - auc: 0.9801\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3016 - auc: 0.9821\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3048 - auc: 0.9809\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3063 - auc: 0.9802\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3129 - auc: 0.9815\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2950 - auc: 0.9824\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3040 - auc: 0.9821\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2990 - auc: 0.9821\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2995 - auc: 0.9819\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2995 - auc: 0.9814\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2829 - auc: 0.9831\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2994 - auc: 0.9824\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2970 - auc: 0.9843\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2880 - auc: 0.9842\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3001 - auc: 0.9827\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2913 - auc: 0.9832\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2920 - auc: 0.9846\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2868 - auc: 0.9835\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2907 - auc: 0.9839\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2741 - auc: 0.9846\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2811 - auc: 0.9840\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2928 - auc: 0.9853\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2904 - auc: 0.9846\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2862 - auc: 0.9855\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2843 - auc: 0.9846\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2957 - auc: 0.9858\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2929 - auc: 0.9855\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2919 - auc: 0.9849\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2817 - auc: 0.9840\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2865 - auc: 0.9853\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2813 - auc: 0.9859\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2949 - auc: 0.9860\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2880 - auc: 0.9862\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2901 - auc: 0.9863\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2884 - auc: 0.9859\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3003 - auc: 0.9862\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2821 - auc: 0.9863\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2891 - auc: 0.9867\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2922 - auc: 0.9863\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2900 - auc: 0.9862\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2969 - auc: 0.9865\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2852 - auc: 0.9860\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2774 - auc: 0.9856\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2943 - auc: 0.9861\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2867 - auc: 0.9860\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2891 - auc: 0.9866\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2877 - auc: 0.9867\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2855 - auc: 0.9861\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2904 - auc: 0.9875\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2785 - auc: 0.9858\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2808 - auc: 0.9862\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2908 - auc: 0.9857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.15348336594911935\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0', 'eer_eval': '0.1534', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0.hdf5', 'tnow': '2022-05-30 11:25:55.942637'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 72s 40ms/step - loss: 1.2152 - auc: 0.7969\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.4953 - auc: 0.9474\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.4158 - auc: 0.9586\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3739 - auc: 0.9636\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3601 - auc: 0.9640\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3411 - auc: 0.9705\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3321 - auc: 0.9715\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3341 - auc: 0.9736\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3084 - auc: 0.9762\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3449 - auc: 0.9749\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3084 - auc: 0.9758\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3001 - auc: 0.9777\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3167 - auc: 0.9776\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3099 - auc: 0.9794\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3106 - auc: 0.9789\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3125 - auc: 0.9797\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3038 - auc: 0.9794\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 69s 41ms/step - loss: 0.3132 - auc: 0.9788\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3048 - auc: 0.9822\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3084 - auc: 0.9816\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3052 - auc: 0.9826\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2942 - auc: 0.9817\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3045 - auc: 0.9812\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3030 - auc: 0.9828\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3069 - auc: 0.9837\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2926 - auc: 0.9847\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2982 - auc: 0.9842\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2987 - auc: 0.9835\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3039 - auc: 0.9842\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2974 - auc: 0.9840\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3048 - auc: 0.9852\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2828 - auc: 0.9852\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2958 - auc: 0.9853\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3037 - auc: 0.9857\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2846 - auc: 0.9860\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2829 - auc: 0.9859\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2866 - auc: 0.9857\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2904 - auc: 0.9861\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2868 - auc: 0.9869\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2931 - auc: 0.9865\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2921 - auc: 0.9869\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2999 - auc: 0.9866\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2845 - auc: 0.9869\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2928 - auc: 0.9865\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2958 - auc: 0.9863\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3054 - auc: 0.9872\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2882 - auc: 0.9865\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2824 - auc: 0.9873\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2846 - auc: 0.9871\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2875 - auc: 0.9873\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2838 - auc: 0.9874\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2804 - auc: 0.9866\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2876 - auc: 0.9869\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2889 - auc: 0.9859\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2805 - auc: 0.9876\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2883 - auc: 0.9872\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2938 - auc: 0.9866\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2886 - auc: 0.9870\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2828 - auc: 0.9866\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2899 - auc: 0.9869\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2856 - auc: 0.9875\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2846 - auc: 0.9869\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2840 - auc: 0.9866\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2957 - auc: 0.9871\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2803 - auc: 0.9881\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2988 - auc: 0.9866\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2817 - auc: 0.9864\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2985 - auc: 0.9878\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2825 - auc: 0.9878\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2990 - auc: 0.9879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 1.922115865143903e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.18218199608610566\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '1.9221', 'eer_eval': '0.1821', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!1.9221.hdf5', 'tnow': '2022-05-30 12:45:00.587181'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 72s 39ms/step - loss: 1.2334 - auc: 0.8328\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.5227 - auc: 0.9458\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.4138 - auc: 0.9587\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3754 - auc: 0.9645\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3545 - auc: 0.9670\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3417 - auc: 0.9727\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3513 - auc: 0.9731\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3248 - auc: 0.9752\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3397 - auc: 0.9758\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3246 - auc: 0.9769\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3140 - auc: 0.9760\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3138 - auc: 0.9767\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3239 - auc: 0.9770\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3142 - auc: 0.9779\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3057 - auc: 0.9784\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3116 - auc: 0.9803\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3066 - auc: 0.9794\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3085 - auc: 0.9805\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3144 - auc: 0.9810\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2981 - auc: 0.9826\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3013 - auc: 0.9819\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3023 - auc: 0.9832\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2960 - auc: 0.9814\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3043 - auc: 0.9836\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2898 - auc: 0.9825\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.3070 - auc: 0.9825\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2969 - auc: 0.9819\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2963 - auc: 0.9836\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3052 - auc: 0.9852\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2922 - auc: 0.9842\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2983 - auc: 0.9828\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2942 - auc: 0.9845\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3069 - auc: 0.9851\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2936 - auc: 0.9857\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3004 - auc: 0.9859\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3056 - auc: 0.9848\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2877 - auc: 0.9857\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2993 - auc: 0.9854\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2805 - auc: 0.9851\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2916 - auc: 0.9860\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2997 - auc: 0.9869\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3008 - auc: 0.9858\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2883 - auc: 0.9863\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2898 - auc: 0.9866\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2871 - auc: 0.9862\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2873 - auc: 0.9867\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2890 - auc: 0.9855\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2852 - auc: 0.9860\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2914 - auc: 0.9854\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2962 - auc: 0.9859\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2829 - auc: 0.9862\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2929 - auc: 0.9872\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2800 - auc: 0.9867\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2883 - auc: 0.9866\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2910 - auc: 0.9859\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2884 - auc: 0.9867\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2840 - auc: 0.9869\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2828 - auc: 0.9878\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2849 - auc: 0.9870\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2815 - auc: 0.9866\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2896 - auc: 0.9867\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2871 - auc: 0.9861\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2795 - auc: 0.9865\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2826 - auc: 0.9873\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2866 - auc: 0.9869\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2796 - auc: 0.9880\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2853 - auc: 0.9869\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2786 - auc: 0.9858\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2834 - auc: 0.9863\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2969 - auc: 0.9870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.15233855185909978\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0', 'eer_eval': '0.1523', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0.hdf5', 'tnow': '2022-05-30 14:03:37.911019'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 73s 40ms/step - loss: 1.2044 - auc: 0.8328\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.4901 - auc: 0.9502\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.4031 - auc: 0.9633\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3727 - auc: 0.9666\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3410 - auc: 0.9714\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3306 - auc: 0.9724\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3150 - auc: 0.9718\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3406 - auc: 0.9732\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3328 - auc: 0.9731\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3195 - auc: 0.9745\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3139 - auc: 0.9763\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3214 - auc: 0.9777\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3137 - auc: 0.9764\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3132 - auc: 0.9768\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3177 - auc: 0.9785\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3142 - auc: 0.9771\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2923 - auc: 0.9783\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3240 - auc: 0.9786\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3082 - auc: 0.9782\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3049 - auc: 0.9804\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3017 - auc: 0.9801\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3079 - auc: 0.9814\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3025 - auc: 0.9806\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3107 - auc: 0.9806\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3030 - auc: 0.9812\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2967 - auc: 0.9833\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2953 - auc: 0.9827\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2875 - auc: 0.9822\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3027 - auc: 0.9821\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3068 - auc: 0.9824\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3011 - auc: 0.9814\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2971 - auc: 0.9826\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2942 - auc: 0.9835\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2962 - auc: 0.9821\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3036 - auc: 0.9828\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2908 - auc: 0.9835\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2930 - auc: 0.9839\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2884 - auc: 0.9839\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2992 - auc: 0.9845\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2940 - auc: 0.9842\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2869 - auc: 0.9841\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2892 - auc: 0.9836\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 69s 40ms/step - loss: 0.2900 - auc: 0.9844\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2929 - auc: 0.9843\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 69s 41ms/step - loss: 0.2838 - auc: 0.9859\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 69s 41ms/step - loss: 0.2913 - auc: 0.9859\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2894 - auc: 0.9843\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 69s 41ms/step - loss: 0.2920 - auc: 0.9855\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 69s 41ms/step - loss: 0.2867 - auc: 0.9849\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2958 - auc: 0.9855\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 69s 41ms/step - loss: 0.2833 - auc: 0.9853\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2984 - auc: 0.9850\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2923 - auc: 0.9841\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2881 - auc: 0.9857\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2944 - auc: 0.9851\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2887 - auc: 0.9851\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2926 - auc: 0.9845\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2824 - auc: 0.9848\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2907 - auc: 0.9853\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2892 - auc: 0.9854\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2934 - auc: 0.9850\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2778 - auc: 0.9847\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2810 - auc: 0.9851\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2809 - auc: 0.9853\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2986 - auc: 0.9859\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2784 - auc: 0.9864\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2876 - auc: 0.9861\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2810 - auc: 0.9852\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2937 - auc: 0.9858\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 69s 41ms/step - loss: 0.2783 - auc: 0.9859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 5.766347595431709e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.1720450097847358\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '5.7663', 'eer_eval': '0.1720', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!5.7663.hdf5', 'tnow': '2022-05-30 15:23:06.164242'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 73s 40ms/step - loss: 1.0860 - auc: 0.8504\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.4610 - auc: 0.9561\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.4009 - auc: 0.9676\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3634 - auc: 0.9714\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3519 - auc: 0.9705\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3553 - auc: 0.9714\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3324 - auc: 0.9746\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3192 - auc: 0.9749\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3289 - auc: 0.9747\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3287 - auc: 0.9740\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3191 - auc: 0.9772\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3195 - auc: 0.9770\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3188 - auc: 0.9762\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3166 - auc: 0.9785\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3028 - auc: 0.9785\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3164 - auc: 0.9790\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3079 - auc: 0.9790\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3154 - auc: 0.9809\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3158 - auc: 0.9817\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3037 - auc: 0.9794\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3031 - auc: 0.9811\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2915 - auc: 0.9808\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3068 - auc: 0.9808\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3011 - auc: 0.9807\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2993 - auc: 0.9817\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3029 - auc: 0.9827\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3001 - auc: 0.9811\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2929 - auc: 0.9834\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3050 - auc: 0.9811\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2923 - auc: 0.9828\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2979 - auc: 0.9838\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3011 - auc: 0.9839\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2941 - auc: 0.9835\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2959 - auc: 0.9845\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2961 - auc: 0.9835\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2934 - auc: 0.9849\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2928 - auc: 0.9844\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2960 - auc: 0.9846\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3021 - auc: 0.9839\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2882 - auc: 0.9837\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3057 - auc: 0.9848\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2898 - auc: 0.9842\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2927 - auc: 0.9855\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2995 - auc: 0.9864\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2991 - auc: 0.9843\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2804 - auc: 0.9848\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2967 - auc: 0.9855\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2933 - auc: 0.9848\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2985 - auc: 0.9854\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3064 - auc: 0.9856\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2905 - auc: 0.9858\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2989 - auc: 0.9856\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2924 - auc: 0.9865\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2952 - auc: 0.9870\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2975 - auc: 0.9858\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2902 - auc: 0.9863\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2903 - auc: 0.9855\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2873 - auc: 0.9844\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2991 - auc: 0.9849\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2969 - auc: 0.9846\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2951 - auc: 0.9855\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2905 - auc: 0.9859\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2955 - auc: 0.9854\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3032 - auc: 0.9846\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2918 - auc: 0.9847\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2886 - auc: 0.9855\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2810 - auc: 0.9851\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2804 - auc: 0.9852\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2882 - auc: 0.9863\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2860 - auc: 0.9861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.16219178082191782\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0', 'eer_eval': '0.1621', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0.hdf5', 'tnow': '2022-05-30 16:42:08.646063'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 75s 40ms/step - loss: 1.3792 - auc: 0.8021\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.5470 - auc: 0.9437\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.4304 - auc: 0.9625\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3963 - auc: 0.9674\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3559 - auc: 0.9735\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3631 - auc: 0.9734\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3580 - auc: 0.9713\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3273 - auc: 0.9746\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3164 - auc: 0.9749\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3290 - auc: 0.9743\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3233 - auc: 0.9760\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 69s 41ms/step - loss: 0.3117 - auc: 0.9761\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3287 - auc: 0.9770\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3186 - auc: 0.9772\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3116 - auc: 0.9778\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3206 - auc: 0.9778\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3088 - auc: 0.9786\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3025 - auc: 0.9794\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3091 - auc: 0.9781\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3086 - auc: 0.9793\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3042 - auc: 0.9794\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3085 - auc: 0.9794\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3168 - auc: 0.9799\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3171 - auc: 0.9801\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3060 - auc: 0.9805\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3154 - auc: 0.9797\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3006 - auc: 0.9814\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3043 - auc: 0.9820\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3157 - auc: 0.9808\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3094 - auc: 0.9822\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2911 - auc: 0.9827\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2911 - auc: 0.9827\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3001 - auc: 0.9820\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2919 - auc: 0.9823\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2819 - auc: 0.9820\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2979 - auc: 0.9817\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2949 - auc: 0.9828\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3101 - auc: 0.9816\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3014 - auc: 0.9829\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2912 - auc: 0.9824\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2890 - auc: 0.9826\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2928 - auc: 0.9832\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2987 - auc: 0.9846\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2919 - auc: 0.9839\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3002 - auc: 0.9833\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2833 - auc: 0.9835\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2947 - auc: 0.9834\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2902 - auc: 0.9838\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2883 - auc: 0.9831\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2959 - auc: 0.9842\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2908 - auc: 0.9864\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2910 - auc: 0.9840\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2857 - auc: 0.9832\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2971 - auc: 0.9847\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2872 - auc: 0.9844\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2952 - auc: 0.9838\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2917 - auc: 0.9851\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2834 - auc: 0.9837\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2857 - auc: 0.9842\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2941 - auc: 0.9837\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2787 - auc: 0.9846\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2873 - auc: 0.9848\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2947 - auc: 0.9852\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2937 - auc: 0.9847\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2958 - auc: 0.9840\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2815 - auc: 0.9845\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2968 - auc: 0.9841\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2970 - auc: 0.9854\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2907 - auc: 0.9847\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3079 - auc: 0.9842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0007078585344718724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.17904109589041098\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0007', 'eer_eval': '0.1790', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0007.hdf5', 'tnow': '2022-05-30 18:01:32.094259'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 72s 39ms/step - loss: 1.1276 - auc: 0.8387\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.4801 - auc: 0.9551\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.4154 - auc: 0.9635\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3914 - auc: 0.9698\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3493 - auc: 0.9700\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3250 - auc: 0.9737\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3274 - auc: 0.9748\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3294 - auc: 0.9759\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3203 - auc: 0.9755\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3108 - auc: 0.9779\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3248 - auc: 0.9779\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3138 - auc: 0.9794\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3117 - auc: 0.9782\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2979 - auc: 0.9797\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3129 - auc: 0.9809\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3074 - auc: 0.9798\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3016 - auc: 0.9798\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3106 - auc: 0.9798\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3095 - auc: 0.9810\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3037 - auc: 0.9814\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2925 - auc: 0.9813\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3031 - auc: 0.9824\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2964 - auc: 0.9818\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2993 - auc: 0.9811\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2937 - auc: 0.9823\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3108 - auc: 0.9808\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3000 - auc: 0.9826\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3085 - auc: 0.9839\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2904 - auc: 0.9845\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2991 - auc: 0.9828\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2954 - auc: 0.9834\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3061 - auc: 0.9840\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2933 - auc: 0.9841\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2962 - auc: 0.9849\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3020 - auc: 0.9859\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2929 - auc: 0.9856\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2858 - auc: 0.9858\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3000 - auc: 0.9856\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2968 - auc: 0.9859\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2828 - auc: 0.9864\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2937 - auc: 0.9850\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2927 - auc: 0.9867\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2868 - auc: 0.9859\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2929 - auc: 0.9865\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2876 - auc: 0.9855\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2796 - auc: 0.9849\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2939 - auc: 0.9864\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2803 - auc: 0.9877\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2844 - auc: 0.9870\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2844 - auc: 0.9874\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2881 - auc: 0.9868\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2835 - auc: 0.9874\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2794 - auc: 0.9866\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2828 - auc: 0.9867\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2865 - auc: 0.9863\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2892 - auc: 0.9865\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2881 - auc: 0.9877\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2745 - auc: 0.9869\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2902 - auc: 0.9861\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2838 - auc: 0.9869\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2821 - auc: 0.9866\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2826 - auc: 0.9872\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2818 - auc: 0.9869\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2828 - auc: 0.9869\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2816 - auc: 0.9867\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2905 - auc: 0.9866\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2755 - auc: 0.9864\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2815 - auc: 0.9864\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2805 - auc: 0.9874\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2865 - auc: 0.9875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0014959260391810946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.17832681017612526\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0014', 'eer_eval': '0.1783', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0014.hdf5', 'tnow': '2022-05-30 19:20:25.599801'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 74s 40ms/step - loss: 1.2808 - auc: 0.7926\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.5411 - auc: 0.9423\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.4071 - auc: 0.9618\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3694 - auc: 0.9657\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3740 - auc: 0.9679\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3472 - auc: 0.9724\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3335 - auc: 0.9720\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3337 - auc: 0.9751\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3312 - auc: 0.9751\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3371 - auc: 0.9756\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3208 - auc: 0.9764\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3263 - auc: 0.9759\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3229 - auc: 0.9781\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3151 - auc: 0.9759\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3169 - auc: 0.9794\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3172 - auc: 0.9782\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3239 - auc: 0.9798\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3011 - auc: 0.9804\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3153 - auc: 0.9797\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2986 - auc: 0.9804\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3107 - auc: 0.9808\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3075 - auc: 0.9811\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3054 - auc: 0.9818\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3053 - auc: 0.9818\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3102 - auc: 0.9813\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3163 - auc: 0.9821\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2966 - auc: 0.9830\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2998 - auc: 0.9826\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3000 - auc: 0.9813\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3016 - auc: 0.9838\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3032 - auc: 0.9827\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2963 - auc: 0.9833\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2952 - auc: 0.9842\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2882 - auc: 0.9836\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3086 - auc: 0.9838\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3081 - auc: 0.9839\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2841 - auc: 0.9851\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2952 - auc: 0.9846\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3032 - auc: 0.9848\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3024 - auc: 0.9848\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2937 - auc: 0.9851\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3014 - auc: 0.9854\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2857 - auc: 0.9852\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3020 - auc: 0.9851\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2914 - auc: 0.9857\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2954 - auc: 0.9855\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2976 - auc: 0.9860\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2965 - auc: 0.9842\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2921 - auc: 0.9870\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2946 - auc: 0.9870\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3004 - auc: 0.9852\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3011 - auc: 0.9858\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2982 - auc: 0.9861\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2933 - auc: 0.9876\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2939 - auc: 0.9860\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3047 - auc: 0.9862\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2968 - auc: 0.9854\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3032 - auc: 0.9851\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2868 - auc: 0.9866\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3054 - auc: 0.9865\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2939 - auc: 0.9855\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2983 - auc: 0.9855\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2975 - auc: 0.9853\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2869 - auc: 0.9858\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2945 - auc: 0.9865\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2834 - auc: 0.9871\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2860 - auc: 0.9852\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2898 - auc: 0.9866\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2965 - auc: 0.9864\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2885 - auc: 0.9867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0008371077040253674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.1377788649706458\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0008', 'eer_eval': '0.1377', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0008.hdf5', 'tnow': '2022-05-30 20:39:17.280538'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 72s 40ms/step - loss: 1.2793 - auc: 0.7987\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.4683 - auc: 0.9524\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.4005 - auc: 0.9608\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3818 - auc: 0.9654\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3736 - auc: 0.9680\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3358 - auc: 0.9718\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3445 - auc: 0.9705\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3354 - auc: 0.9735\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3365 - auc: 0.9740\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3306 - auc: 0.9750\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3278 - auc: 0.9757\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3170 - auc: 0.9781\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3154 - auc: 0.9781\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3244 - auc: 0.9775\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3169 - auc: 0.9775\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3168 - auc: 0.9793\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3182 - auc: 0.9781\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3185 - auc: 0.9796\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3145 - auc: 0.9783\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3104 - auc: 0.9801\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3114 - auc: 0.9805\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3047 - auc: 0.9793\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3127 - auc: 0.9801\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3198 - auc: 0.9804\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2964 - auc: 0.9808\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3011 - auc: 0.9813\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3016 - auc: 0.9799\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3065 - auc: 0.9815\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3064 - auc: 0.9813\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3022 - auc: 0.9819\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2975 - auc: 0.9830\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2972 - auc: 0.9836\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2928 - auc: 0.9839\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2974 - auc: 0.9829\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2919 - auc: 0.9826\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2957 - auc: 0.9843\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3004 - auc: 0.9831\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2959 - auc: 0.9836\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2968 - auc: 0.9844\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2907 - auc: 0.9840\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3088 - auc: 0.9838\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2903 - auc: 0.9842\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2922 - auc: 0.9833\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2998 - auc: 0.9840\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2948 - auc: 0.9843\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3018 - auc: 0.9838\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2919 - auc: 0.9845\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2948 - auc: 0.9842\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3072 - auc: 0.9846\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2969 - auc: 0.9847\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2979 - auc: 0.9858\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2916 - auc: 0.9855\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2870 - auc: 0.9845\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2882 - auc: 0.9856\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3016 - auc: 0.9853\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3035 - auc: 0.9857\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2846 - auc: 0.9852\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2925 - auc: 0.9854\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2975 - auc: 0.9861\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2965 - auc: 0.9857\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3112 - auc: 0.9842\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2966 - auc: 0.9850\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3039 - auc: 0.9843\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2917 - auc: 0.9864\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2829 - auc: 0.9850\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2922 - auc: 0.9861\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2960 - auc: 0.9852\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2833 - auc: 0.9846\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2906 - auc: 0.9862\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2842 - auc: 0.9859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0007986653867224894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.11993150684931506\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0007', 'eer_eval': '0.1199', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0007.hdf5', 'tnow': '2022-05-30 21:58:19.170018'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 74s 40ms/step - loss: 1.3140 - auc: 0.8114\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.5450 - auc: 0.9384\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.4449 - auc: 0.9571\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3955 - auc: 0.9641\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3922 - auc: 0.9666\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3696 - auc: 0.9692\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3524 - auc: 0.9704\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3509 - auc: 0.9722\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3349 - auc: 0.9735\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3304 - auc: 0.9733\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3192 - auc: 0.9753\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3263 - auc: 0.9790\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3169 - auc: 0.9755\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3193 - auc: 0.9752\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3185 - auc: 0.9760\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3132 - auc: 0.9785\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3230 - auc: 0.9775\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3134 - auc: 0.9793\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3063 - auc: 0.9785\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2996 - auc: 0.9798\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3058 - auc: 0.9792\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3111 - auc: 0.9803\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2917 - auc: 0.9810\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2992 - auc: 0.9799\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2966 - auc: 0.9817\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3039 - auc: 0.9808\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3064 - auc: 0.9816\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3011 - auc: 0.9821\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3016 - auc: 0.9815\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2978 - auc: 0.9824\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2943 - auc: 0.9831\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2996 - auc: 0.9828\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2986 - auc: 0.9841\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2929 - auc: 0.9846\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2993 - auc: 0.9837\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3053 - auc: 0.9836\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2993 - auc: 0.9847\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2949 - auc: 0.9830\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2952 - auc: 0.9837\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2939 - auc: 0.9854\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3135 - auc: 0.9842\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2918 - auc: 0.9849\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2870 - auc: 0.9843\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3040 - auc: 0.9845\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2998 - auc: 0.9848\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2887 - auc: 0.9852\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2949 - auc: 0.9851\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2875 - auc: 0.9857\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2869 - auc: 0.9857\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2839 - auc: 0.9857\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2786 - auc: 0.9858\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3091 - auc: 0.9838\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2950 - auc: 0.9864\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2966 - auc: 0.9859\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2927 - auc: 0.9869\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3064 - auc: 0.9872\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2910 - auc: 0.9856\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2905 - auc: 0.9861\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3017 - auc: 0.9863\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2931 - auc: 0.9852\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2876 - auc: 0.9846\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2926 - auc: 0.9871\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2851 - auc: 0.9851\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2928 - auc: 0.9854\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2932 - auc: 0.9852\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2944 - auc: 0.9856\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2906 - auc: 0.9859\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2910 - auc: 0.9856\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2979 - auc: 0.9863\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3060 - auc: 0.9859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.14434442270058712\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0', 'eer_eval': '0.1443', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0.hdf5', 'tnow': '2022-05-30 23:17:41.969004'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 73s 40ms/step - loss: 1.2560 - auc: 0.7908\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.5266 - auc: 0.9402\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.4357 - auc: 0.9551\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3930 - auc: 0.9597\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3774 - auc: 0.9618\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3761 - auc: 0.9634\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3529 - auc: 0.9684\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3372 - auc: 0.9712\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3400 - auc: 0.9709\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3293 - auc: 0.9718\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3322 - auc: 0.9726\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3227 - auc: 0.9730\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3287 - auc: 0.9745\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3258 - auc: 0.9749\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3129 - auc: 0.9747\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3226 - auc: 0.9766\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3228 - auc: 0.9754\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3193 - auc: 0.9785\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3100 - auc: 0.9784\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3145 - auc: 0.9766\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3177 - auc: 0.9780\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3095 - auc: 0.9772\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3084 - auc: 0.9779\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3186 - auc: 0.9798\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3105 - auc: 0.9790\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3123 - auc: 0.9791\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2935 - auc: 0.9814\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3067 - auc: 0.9805\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2999 - auc: 0.9798\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2974 - auc: 0.9815\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3046 - auc: 0.9794\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3030 - auc: 0.9811\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3005 - auc: 0.9800\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3010 - auc: 0.9829\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2985 - auc: 0.9818\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2898 - auc: 0.9825\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2913 - auc: 0.9820\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2864 - auc: 0.9825\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2989 - auc: 0.9821\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2991 - auc: 0.9832\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3114 - auc: 0.9817\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2984 - auc: 0.9832\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2978 - auc: 0.9833\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2971 - auc: 0.9837\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3055 - auc: 0.9838\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3049 - auc: 0.9836\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3043 - auc: 0.9834\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2967 - auc: 0.9833\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2962 - auc: 0.9842\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2888 - auc: 0.9831\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2876 - auc: 0.9846\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2951 - auc: 0.9838\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3028 - auc: 0.9838\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2933 - auc: 0.9848\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2976 - auc: 0.9844\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2995 - auc: 0.9840\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3008 - auc: 0.9843\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2989 - auc: 0.9838\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2971 - auc: 0.9844\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2868 - auc: 0.9830\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2947 - auc: 0.9846\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2789 - auc: 0.9849\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2807 - auc: 0.9841\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2960 - auc: 0.9838\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2961 - auc: 0.9842\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3006 - auc: 0.9844\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2976 - auc: 0.9844\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2911 - auc: 0.9853\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3029 - auc: 0.9849\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2903 - auc: 0.9858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0005050490659441593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.17761252446183953\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0005', 'eer_eval': '0.1776', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0005.hdf5', 'tnow': '2022-05-31 00:36:35.398836'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 72s 39ms/step - loss: 1.1012 - auc: 0.8301\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.4986 - auc: 0.9478\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.4446 - auc: 0.9574\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3957 - auc: 0.9629\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3799 - auc: 0.9647\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3526 - auc: 0.9684\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3518 - auc: 0.9697\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3584 - auc: 0.9703\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3439 - auc: 0.9737\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3314 - auc: 0.9733\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3406 - auc: 0.9735\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3327 - auc: 0.9746\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3380 - auc: 0.9740\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3288 - auc: 0.9739\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3246 - auc: 0.9754\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3237 - auc: 0.9749\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3190 - auc: 0.9773\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.3239 - auc: 0.9754\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3022 - auc: 0.9782\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.3177 - auc: 0.9771\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3151 - auc: 0.9773\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2935 - auc: 0.9775\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3134 - auc: 0.9777\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3142 - auc: 0.9785\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3048 - auc: 0.9788\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3116 - auc: 0.9793\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3100 - auc: 0.9791\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3089 - auc: 0.9792\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3113 - auc: 0.9797\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3002 - auc: 0.9805\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3125 - auc: 0.9792\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3118 - auc: 0.9811\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3020 - auc: 0.9796\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3029 - auc: 0.9806\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.2986 - auc: 0.9808\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2982 - auc: 0.9820\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.3063 - auc: 0.9814\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2897 - auc: 0.9818\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.2941 - auc: 0.9819\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2905 - auc: 0.9829\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3006 - auc: 0.9830\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2960 - auc: 0.9819\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2895 - auc: 0.9837\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2943 - auc: 0.9834\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3068 - auc: 0.9833\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3136 - auc: 0.9845\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.2956 - auc: 0.9827\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3042 - auc: 0.9830\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3002 - auc: 0.9844\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3033 - auc: 0.9818\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2902 - auc: 0.9840\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2981 - auc: 0.9834\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3057 - auc: 0.9832\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3036 - auc: 0.9835\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3030 - auc: 0.9838\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3046 - auc: 0.9830\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3096 - auc: 0.9839\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2809 - auc: 0.9844\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2952 - auc: 0.9836\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.2932 - auc: 0.9835\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3063 - auc: 0.9846\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.2906 - auc: 0.9836\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.2891 - auc: 0.9836\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.3024 - auc: 0.9833\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2995 - auc: 0.9849\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3003 - auc: 0.9835\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2952 - auc: 0.9831\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2999 - auc: 0.9835\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2946 - auc: 0.9839\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3002 - auc: 0.9831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0009332134972825626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.12621330724070448\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0009', 'eer_eval': '0.1262', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0009.hdf5', 'tnow': '2022-05-31 01:54:53.361370'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 76s 40ms/step - loss: 1.2681 - auc: 0.8194\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.5378 - auc: 0.9424\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.4353 - auc: 0.9560\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3986 - auc: 0.9628\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3653 - auc: 0.9667\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3524 - auc: 0.9678\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3504 - auc: 0.9696\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3395 - auc: 0.9703\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3439 - auc: 0.9727\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3468 - auc: 0.9723\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3371 - auc: 0.9730\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3311 - auc: 0.9733\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3356 - auc: 0.9746\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3225 - auc: 0.9753\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3302 - auc: 0.9767\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3162 - auc: 0.9767\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3112 - auc: 0.9767\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3113 - auc: 0.9772\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3156 - auc: 0.9775\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3004 - auc: 0.9779\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3268 - auc: 0.9758\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3090 - auc: 0.9786\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3215 - auc: 0.9769\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3140 - auc: 0.9791\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3094 - auc: 0.9784\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3197 - auc: 0.9786\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3018 - auc: 0.9793\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3033 - auc: 0.9796\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3108 - auc: 0.9811\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2929 - auc: 0.9816\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3073 - auc: 0.9826\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3093 - auc: 0.9814\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2959 - auc: 0.9806\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3046 - auc: 0.9816\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2891 - auc: 0.9829\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2955 - auc: 0.9826\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2949 - auc: 0.9827\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2995 - auc: 0.9810\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2974 - auc: 0.9824\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2940 - auc: 0.9824\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3021 - auc: 0.9839\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2916 - auc: 0.9836\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2980 - auc: 0.9834\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3009 - auc: 0.9844\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2895 - auc: 0.9838\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3043 - auc: 0.9843\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3002 - auc: 0.9839\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2848 - auc: 0.9848\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3023 - auc: 0.9839\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2988 - auc: 0.9839\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2969 - auc: 0.9850\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2914 - auc: 0.9843\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2878 - auc: 0.9842\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2962 - auc: 0.9832\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2992 - auc: 0.9840\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2997 - auc: 0.9846\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2971 - auc: 0.9838\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2965 - auc: 0.9844\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2963 - auc: 0.9838\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2935 - auc: 0.9841\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2904 - auc: 0.9842\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3063 - auc: 0.9838\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2858 - auc: 0.9842\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2945 - auc: 0.9850\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2872 - auc: 0.9828\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2956 - auc: 0.9846\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3077 - auc: 0.9826\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2834 - auc: 0.9830\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2910 - auc: 0.9835\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2820 - auc: 0.9849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00037050095538408614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.16190802348336591\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0003', 'eer_eval': '0.1619', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0003.hdf5', 'tnow': '2022-05-31 03:14:12.478369'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 72s 40ms/step - loss: 1.1860 - auc: 0.8053\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.5376 - auc: 0.9420\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.4409 - auc: 0.9586\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.4041 - auc: 0.9624\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3723 - auc: 0.9642\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3583 - auc: 0.9678\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3573 - auc: 0.9696\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3585 - auc: 0.9728\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3363 - auc: 0.9733\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3220 - auc: 0.9715\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3251 - auc: 0.9742\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3294 - auc: 0.9752\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3168 - auc: 0.9741\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3283 - auc: 0.9734\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3251 - auc: 0.9754\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3252 - auc: 0.9729\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3269 - auc: 0.9756\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3263 - auc: 0.9771\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3257 - auc: 0.9751\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3215 - auc: 0.9768\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3213 - auc: 0.9786\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3116 - auc: 0.9761\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3076 - auc: 0.9772\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3070 - auc: 0.9778\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3197 - auc: 0.9776\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3231 - auc: 0.9790\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3118 - auc: 0.9781\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3204 - auc: 0.9793\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3092 - auc: 0.9798\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3150 - auc: 0.9802\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3115 - auc: 0.9785\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2995 - auc: 0.9797\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3200 - auc: 0.9794\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3051 - auc: 0.9804\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3088 - auc: 0.9806\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2997 - auc: 0.9802\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3019 - auc: 0.9824\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3049 - auc: 0.9815\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3043 - auc: 0.9812\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2963 - auc: 0.9811\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3075 - auc: 0.9814\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3019 - auc: 0.9829\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3074 - auc: 0.9831\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2980 - auc: 0.9825\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3010 - auc: 0.9833\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3001 - auc: 0.9825\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3002 - auc: 0.9827\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2847 - auc: 0.9834\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3043 - auc: 0.9824\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3095 - auc: 0.9837\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3034 - auc: 0.9829\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2922 - auc: 0.9836\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2950 - auc: 0.9844\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2975 - auc: 0.9839\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2962 - auc: 0.9833\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2989 - auc: 0.9837\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2915 - auc: 0.9837\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3106 - auc: 0.9829\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3074 - auc: 0.9828\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2983 - auc: 0.9828\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2991 - auc: 0.9832\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2918 - auc: 0.9838\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3013 - auc: 0.9829\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3007 - auc: 0.9828\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2933 - auc: 0.9821\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2994 - auc: 0.9848\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3045 - auc: 0.9833\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2978 - auc: 0.9837\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3082 - auc: 0.9828\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2952 - auc: 0.9826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0008755500213282455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.15348336594911935\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0008', 'eer_eval': '0.1534', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0008.hdf5', 'tnow': '2022-05-31 04:32:56.692525'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 76s 40ms/step - loss: 1.3005 - auc: 0.7910\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.5348 - auc: 0.9463\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.4408 - auc: 0.9602\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3888 - auc: 0.9664\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3632 - auc: 0.9685\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3634 - auc: 0.9696\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3529 - auc: 0.9715\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3448 - auc: 0.9741\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 69s 41ms/step - loss: 0.3470 - auc: 0.9742\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3307 - auc: 0.9770\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3299 - auc: 0.9759\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3295 - auc: 0.9766\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3089 - auc: 0.9777\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 69s 40ms/step - loss: 0.3178 - auc: 0.9788\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3163 - auc: 0.9779\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3069 - auc: 0.9783\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3129 - auc: 0.9795\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3087 - auc: 0.9798\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3061 - auc: 0.9810\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3096 - auc: 0.9802\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3163 - auc: 0.9804\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3106 - auc: 0.9812\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2981 - auc: 0.9814\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3164 - auc: 0.9810\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3065 - auc: 0.9811\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2954 - auc: 0.9833\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2990 - auc: 0.9821\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3146 - auc: 0.9813\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3031 - auc: 0.9831\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3018 - auc: 0.9832\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3033 - auc: 0.9831\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3061 - auc: 0.9829\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3051 - auc: 0.9833\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2942 - auc: 0.9829\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3035 - auc: 0.9839\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2924 - auc: 0.9835\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2887 - auc: 0.9835\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3059 - auc: 0.9838\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2968 - auc: 0.9837\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2985 - auc: 0.9846\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3010 - auc: 0.9843\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2987 - auc: 0.9846\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2871 - auc: 0.9850\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2960 - auc: 0.9846\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3002 - auc: 0.9845\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3028 - auc: 0.9856\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2895 - auc: 0.9836\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3051 - auc: 0.9851\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3006 - auc: 0.9851\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2866 - auc: 0.9855\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3066 - auc: 0.9845\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2888 - auc: 0.9848\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3003 - auc: 0.9856\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2847 - auc: 0.9862\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2930 - auc: 0.9848\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2953 - auc: 0.9849\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2921 - auc: 0.9862\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2993 - auc: 0.9868\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2944 - auc: 0.9853\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2872 - auc: 0.9871\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2860 - auc: 0.9847\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2861 - auc: 0.9847\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2807 - auc: 0.9859\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2891 - auc: 0.9853\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3016 - auc: 0.9862\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2830 - auc: 0.9852\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2976 - auc: 0.9844\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2927 - auc: 0.9848\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2848 - auc: 0.9857\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2902 - auc: 0.9859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.17133072407045008\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0', 'eer_eval': '0.1713', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0.hdf5', 'tnow': '2022-05-31 05:52:25.340267'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 72s 40ms/step - loss: 1.2315 - auc: 0.8141\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.5309 - auc: 0.9444\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.4447 - auc: 0.9585\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.4053 - auc: 0.9614\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3693 - auc: 0.9635\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3617 - auc: 0.9665\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3727 - auc: 0.9691\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3386 - auc: 0.9713\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3441 - auc: 0.9715\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3324 - auc: 0.9723\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3209 - auc: 0.9723\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3273 - auc: 0.9739\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3176 - auc: 0.9755\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3389 - auc: 0.9737\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3270 - auc: 0.9766\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3117 - auc: 0.9784\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3191 - auc: 0.9785\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3174 - auc: 0.9772\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3195 - auc: 0.9772\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3106 - auc: 0.9784\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3109 - auc: 0.9788\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3140 - auc: 0.9785\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3110 - auc: 0.9797\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3151 - auc: 0.9785\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3143 - auc: 0.9792\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3143 - auc: 0.9799\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2952 - auc: 0.9807\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3138 - auc: 0.9818\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3093 - auc: 0.9813\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3040 - auc: 0.9820\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2983 - auc: 0.9811\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2984 - auc: 0.9825\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3024 - auc: 0.9814\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3063 - auc: 0.9832\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3020 - auc: 0.9832\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2950 - auc: 0.9822\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3101 - auc: 0.9828\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3056 - auc: 0.9834\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3063 - auc: 0.9840\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3010 - auc: 0.9841\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2901 - auc: 0.9839\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3007 - auc: 0.9848\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2930 - auc: 0.9838\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3029 - auc: 0.9838\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2967 - auc: 0.9833\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3019 - auc: 0.9847\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2893 - auc: 0.9847\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3015 - auc: 0.9840\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3000 - auc: 0.9856\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2902 - auc: 0.9849\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2990 - auc: 0.9849\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2872 - auc: 0.9843\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3046 - auc: 0.9839\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2933 - auc: 0.9852\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2940 - auc: 0.9840\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2880 - auc: 0.9847\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2908 - auc: 0.9843\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2860 - auc: 0.9844\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2985 - auc: 0.9853\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2853 - auc: 0.9861\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2920 - auc: 0.9844\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3175 - auc: 0.9858\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2966 - auc: 0.9844\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2990 - auc: 0.9846\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2920 - auc: 0.9843\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2905 - auc: 0.9848\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2980 - auc: 0.9849\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2973 - auc: 0.9836\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2938 - auc: 0.9844\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3054 - auc: 0.9853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 9.610579325719515e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.14334637964774954\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '9.6105', 'eer_eval': '0.1433', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!9.6105.hdf5', 'tnow': '2022-05-31 07:11:31.774476'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 72s 40ms/step - loss: 1.1824 - auc: 0.8271\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.4983 - auc: 0.9490\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.4385 - auc: 0.9606\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3915 - auc: 0.9641\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3760 - auc: 0.9675\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3510 - auc: 0.9694\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3439 - auc: 0.9708\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3330 - auc: 0.9721\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3284 - auc: 0.9743\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3265 - auc: 0.9754\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3337 - auc: 0.9752\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3166 - auc: 0.9781\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3185 - auc: 0.9764\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3222 - auc: 0.9776\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3196 - auc: 0.9778\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3102 - auc: 0.9771\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3080 - auc: 0.9757\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2957 - auc: 0.9769\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3104 - auc: 0.9792\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3140 - auc: 0.9802\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3109 - auc: 0.9787\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3087 - auc: 0.9802\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3046 - auc: 0.9796\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3053 - auc: 0.9795\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3165 - auc: 0.9810\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3078 - auc: 0.9809\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3062 - auc: 0.9821\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2967 - auc: 0.9810\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3035 - auc: 0.9823\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2921 - auc: 0.9809\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2972 - auc: 0.9816\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2942 - auc: 0.9818\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3063 - auc: 0.9841\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3030 - auc: 0.9829\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2871 - auc: 0.9826\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2902 - auc: 0.9839\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3004 - auc: 0.9839\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2921 - auc: 0.9833\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2951 - auc: 0.9842\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2909 - auc: 0.9848\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2878 - auc: 0.9836\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2941 - auc: 0.9850\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2932 - auc: 0.9851\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3016 - auc: 0.9844\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3034 - auc: 0.9845\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3024 - auc: 0.9844\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2931 - auc: 0.9844\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2901 - auc: 0.9849\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2879 - auc: 0.9846\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3079 - auc: 0.9853\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2850 - auc: 0.9858\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2947 - auc: 0.9857\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2869 - auc: 0.9855\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2889 - auc: 0.9843\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2892 - auc: 0.9863\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3041 - auc: 0.9859\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2969 - auc: 0.9853\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2832 - auc: 0.9860\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3031 - auc: 0.9855\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2945 - auc: 0.9859\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2927 - auc: 0.9854\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2823 - auc: 0.9866\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2695 - auc: 0.9859\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3028 - auc: 0.9853\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2990 - auc: 0.9856\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2898 - auc: 0.9857\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2912 - auc: 0.9866\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3050 - auc: 0.9864\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2959 - auc: 0.9846\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2843 - auc: 0.9857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 3.844231730287806e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.16119373776908025\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '3.8442', 'eer_eval': '0.1611', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!3.8442.hdf5', 'tnow': '2022-05-31 08:30:04.320745'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 73s 40ms/step - loss: 1.0990 - auc: 0.8217\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.4971 - auc: 0.9462\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.4489 - auc: 0.9556\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3782 - auc: 0.9627\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3687 - auc: 0.9655\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3548 - auc: 0.9674\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3501 - auc: 0.9715\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3264 - auc: 0.9739\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3181 - auc: 0.9738\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3157 - auc: 0.9751\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3265 - auc: 0.9762\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3214 - auc: 0.9764\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3135 - auc: 0.9776\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3101 - auc: 0.9778\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3126 - auc: 0.9775\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3132 - auc: 0.9791\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3258 - auc: 0.9798\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3295 - auc: 0.9790\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3108 - auc: 0.9798\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3162 - auc: 0.9796\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3047 - auc: 0.9800\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2935 - auc: 0.9816\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2993 - auc: 0.9816\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3006 - auc: 0.9821\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3123 - auc: 0.9817\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3127 - auc: 0.9820\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3020 - auc: 0.9816\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3041 - auc: 0.9828\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3015 - auc: 0.9821\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3002 - auc: 0.9830\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2961 - auc: 0.9827\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2893 - auc: 0.9836\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2981 - auc: 0.9839\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2964 - auc: 0.9822\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3095 - auc: 0.9844\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3024 - auc: 0.9848\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2909 - auc: 0.9852\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3139 - auc: 0.9843\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2896 - auc: 0.9839\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2954 - auc: 0.9840\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2860 - auc: 0.9850\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2900 - auc: 0.9854\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3059 - auc: 0.9853\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2982 - auc: 0.9866\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2819 - auc: 0.9857\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2884 - auc: 0.9858\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2855 - auc: 0.9856\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2958 - auc: 0.9856\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2930 - auc: 0.9864\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2906 - auc: 0.9857\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2826 - auc: 0.9861\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2963 - auc: 0.9863\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2899 - auc: 0.9870\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2902 - auc: 0.9865\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2968 - auc: 0.9859\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2882 - auc: 0.9864\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2853 - auc: 0.9874\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2880 - auc: 0.9851\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2866 - auc: 0.9859\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2960 - auc: 0.9867\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2744 - auc: 0.9872\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2962 - auc: 0.9855\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2918 - auc: 0.9859\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2880 - auc: 0.9867\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2915 - auc: 0.9850\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2854 - auc: 0.9861\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2952 - auc: 0.9861\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3009 - auc: 0.9851\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2848 - auc: 0.9867\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2946 - auc: 0.9863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00033205863808115257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.14791585127201567\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0003', 'eer_eval': '0.1479', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0003.hdf5', 'tnow': '2022-05-31 09:49:27.776013'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 73s 40ms/step - loss: 1.3051 - auc: 0.7953\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.4535 - auc: 0.9538\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3938 - auc: 0.9639\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3607 - auc: 0.9702\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3450 - auc: 0.9695\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3568 - auc: 0.9740\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3316 - auc: 0.9731\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3189 - auc: 0.9756\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3230 - auc: 0.9749\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3135 - auc: 0.9775\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3179 - auc: 0.9777\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3142 - auc: 0.9790\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3236 - auc: 0.9791\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3121 - auc: 0.9804\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3079 - auc: 0.9807\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3069 - auc: 0.9784\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3124 - auc: 0.9802\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3067 - auc: 0.9806\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3081 - auc: 0.9803\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3174 - auc: 0.9817\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3032 - auc: 0.9802\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3001 - auc: 0.9819\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3044 - auc: 0.9821\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3034 - auc: 0.9808\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3007 - auc: 0.9807\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3034 - auc: 0.9815\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3053 - auc: 0.9827\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2883 - auc: 0.9816\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3099 - auc: 0.9827\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3054 - auc: 0.9823\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3130 - auc: 0.9840\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2798 - auc: 0.9837\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3041 - auc: 0.9833\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2835 - auc: 0.9836\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2919 - auc: 0.9828\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3042 - auc: 0.9848\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2865 - auc: 0.9849\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2997 - auc: 0.9828\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3028 - auc: 0.9855\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2914 - auc: 0.9843\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2921 - auc: 0.9850\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2868 - auc: 0.9849\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2872 - auc: 0.9836\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2770 - auc: 0.9853\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3039 - auc: 0.9859\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2955 - auc: 0.9846\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 69s 40ms/step - loss: 0.2884 - auc: 0.9848\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2836 - auc: 0.9846\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2841 - auc: 0.9851\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2825 - auc: 0.9858\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2881 - auc: 0.9856\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3014 - auc: 0.9861\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2938 - auc: 0.9844\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2883 - auc: 0.9845\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2824 - auc: 0.9861\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3063 - auc: 0.9859\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2997 - auc: 0.9840\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2892 - auc: 0.9862\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2916 - auc: 0.9858\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2909 - auc: 0.9866\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2948 - auc: 0.9859\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2969 - auc: 0.9861\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2887 - auc: 0.9858\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2870 - auc: 0.9854\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2802 - auc: 0.9851\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2885 - auc: 0.9850\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2879 - auc: 0.9859\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2834 - auc: 0.9854\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2897 - auc: 0.9852\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2903 - auc: 0.9856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.000581933700549971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.1706164383561644\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0005', 'eer_eval': '0.1706', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0005.hdf5', 'tnow': '2022-05-31 11:09:10.156245'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 76s 40ms/step - loss: 1.2060 - auc: 0.8171\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.5333 - auc: 0.9429\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.4526 - auc: 0.9576\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3986 - auc: 0.9649\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.4012 - auc: 0.9660\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3555 - auc: 0.9698\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3503 - auc: 0.9705\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3393 - auc: 0.9706\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3303 - auc: 0.9723\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3599 - auc: 0.9748\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3357 - auc: 0.9732\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3450 - auc: 0.9751\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3296 - auc: 0.9756\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3333 - auc: 0.9758\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3242 - auc: 0.9754\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3132 - auc: 0.9773\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3200 - auc: 0.9771\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3123 - auc: 0.9766\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3050 - auc: 0.9780\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3127 - auc: 0.9792\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3137 - auc: 0.9778\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3134 - auc: 0.9801\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3121 - auc: 0.9800\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3023 - auc: 0.9791\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3182 - auc: 0.9786\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3132 - auc: 0.9805\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3117 - auc: 0.9809\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3127 - auc: 0.9790\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3123 - auc: 0.9798\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3045 - auc: 0.9812\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3021 - auc: 0.9830\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3052 - auc: 0.9826\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3159 - auc: 0.9816\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3074 - auc: 0.9818\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2965 - auc: 0.9825\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3078 - auc: 0.9837\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2938 - auc: 0.9828\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3046 - auc: 0.9812\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3021 - auc: 0.9831\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2996 - auc: 0.9832\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3118 - auc: 0.9830\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3101 - auc: 0.9820\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2946 - auc: 0.9828\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2962 - auc: 0.9824\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2968 - auc: 0.9833\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3086 - auc: 0.9830\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3057 - auc: 0.9848\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2883 - auc: 0.9833\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2882 - auc: 0.9834\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3000 - auc: 0.9837\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2965 - auc: 0.9837\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2929 - auc: 0.9832\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3029 - auc: 0.9841\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2995 - auc: 0.9841\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2996 - auc: 0.9851\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2922 - auc: 0.9836\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3062 - auc: 0.9838\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2964 - auc: 0.9849\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2957 - auc: 0.9841\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3003 - auc: 0.9854\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2882 - auc: 0.9847\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2951 - auc: 0.9845\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2874 - auc: 0.9836\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2967 - auc: 0.9838\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2877 - auc: 0.9849\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3004 - auc: 0.9832\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2940 - auc: 0.9846\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3130 - auc: 0.9833\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2952 - auc: 0.9842\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2938 - auc: 0.9849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 5.766347595431709e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.1636203522504892\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '5.7663', 'eer_eval': '0.1636', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!5.7663.hdf5', 'tnow': '2022-05-31 12:28:30.819025'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 72s 40ms/step - loss: 1.1758 - auc: 0.8196\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.5198 - auc: 0.9412\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.4417 - auc: 0.9523\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.4051 - auc: 0.9602\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3766 - auc: 0.9643\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3732 - auc: 0.9661\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3469 - auc: 0.9686\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3480 - auc: 0.9710\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3474 - auc: 0.9721\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3207 - auc: 0.9743\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3420 - auc: 0.9725\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3259 - auc: 0.9754\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3304 - auc: 0.9732\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3274 - auc: 0.9755\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3245 - auc: 0.9755\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3276 - auc: 0.9764\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3201 - auc: 0.9752\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3250 - auc: 0.9754\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3108 - auc: 0.9788\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3061 - auc: 0.9772\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3027 - auc: 0.9782\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3181 - auc: 0.9782\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3078 - auc: 0.9795\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3073 - auc: 0.9802\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3145 - auc: 0.9797\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3032 - auc: 0.9796\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3086 - auc: 0.9809\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3086 - auc: 0.9802\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2952 - auc: 0.9806\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3173 - auc: 0.9814\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3140 - auc: 0.9808\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3049 - auc: 0.9813\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3035 - auc: 0.9823\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3160 - auc: 0.9816\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3006 - auc: 0.9840\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3129 - auc: 0.9821\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2942 - auc: 0.9833\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3006 - auc: 0.9818\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2924 - auc: 0.9833\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2988 - auc: 0.9828\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2935 - auc: 0.9832\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3029 - auc: 0.9831\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3093 - auc: 0.9837\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2889 - auc: 0.9829\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2984 - auc: 0.9836\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2874 - auc: 0.9854\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2996 - auc: 0.9845\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2958 - auc: 0.9827\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2983 - auc: 0.9842\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2892 - auc: 0.9843\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2907 - auc: 0.9842\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3026 - auc: 0.9846\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2918 - auc: 0.9841\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2978 - auc: 0.9852\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3024 - auc: 0.9848\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2977 - auc: 0.9842\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2978 - auc: 0.9850\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2955 - auc: 0.9847\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2937 - auc: 0.9841\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2996 - auc: 0.9847\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2898 - auc: 0.9848\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2913 - auc: 0.9851\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2850 - auc: 0.9843\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2938 - auc: 0.9854\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3028 - auc: 0.9845\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2975 - auc: 0.9844\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2951 - auc: 0.9852\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2890 - auc: 0.9844\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2942 - auc: 0.9847\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.2935 - auc: 0.9857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00042816443133840323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.17761252446183953\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0004', 'eer_eval': '0.1776', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0004.hdf5', 'tnow': '2022-05-31 13:47:45.218907'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1692/1692 [==============================] - 72s 40ms/step - loss: 1.4962 - auc: 0.7556\n",
      "Epoch 2/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.5778 - auc: 0.9364\n",
      "Epoch 3/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.4940 - auc: 0.9511\n",
      "Epoch 4/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.4151 - auc: 0.9607\n",
      "Epoch 5/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.4188 - auc: 0.9614\n",
      "Epoch 6/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3727 - auc: 0.9654\n",
      "Epoch 7/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3754 - auc: 0.9673\n",
      "Epoch 8/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3675 - auc: 0.9710\n",
      "Epoch 9/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3578 - auc: 0.9702\n",
      "Epoch 10/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3423 - auc: 0.9711\n",
      "Epoch 11/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3469 - auc: 0.9703\n",
      "Epoch 12/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3364 - auc: 0.9730\n",
      "Epoch 13/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3366 - auc: 0.9739\n",
      "Epoch 14/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3429 - auc: 0.9763\n",
      "Epoch 15/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3358 - auc: 0.9734\n",
      "Epoch 16/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3325 - auc: 0.9756\n",
      "Epoch 17/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3300 - auc: 0.9748\n",
      "Epoch 18/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3319 - auc: 0.9753\n",
      "Epoch 19/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3146 - auc: 0.9747\n",
      "Epoch 20/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3145 - auc: 0.9769\n",
      "Epoch 21/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3228 - auc: 0.9761\n",
      "Epoch 22/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3144 - auc: 0.9769\n",
      "Epoch 23/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3139 - auc: 0.9765\n",
      "Epoch 24/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3178 - auc: 0.9776\n",
      "Epoch 25/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3102 - auc: 0.9783\n",
      "Epoch 26/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3220 - auc: 0.9783\n",
      "Epoch 27/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3230 - auc: 0.9781\n",
      "Epoch 28/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3164 - auc: 0.9778\n",
      "Epoch 29/70\n",
      "1692/1692 [==============================] - 68s 40ms/step - loss: 0.3129 - auc: 0.9794\n",
      "Epoch 30/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3192 - auc: 0.9805\n",
      "Epoch 31/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3128 - auc: 0.9807\n",
      "Epoch 32/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.3150 - auc: 0.9807\n",
      "Epoch 33/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3070 - auc: 0.9810\n",
      "Epoch 34/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3017 - auc: 0.9809\n",
      "Epoch 35/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.3156 - auc: 0.9818\n",
      "Epoch 36/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3217 - auc: 0.9807\n",
      "Epoch 37/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3210 - auc: 0.9807\n",
      "Epoch 38/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3045 - auc: 0.9818\n",
      "Epoch 39/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3055 - auc: 0.9805\n",
      "Epoch 40/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3165 - auc: 0.9816\n",
      "Epoch 41/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3038 - auc: 0.9805\n",
      "Epoch 42/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3117 - auc: 0.9816\n",
      "Epoch 43/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3047 - auc: 0.9829\n",
      "Epoch 44/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2984 - auc: 0.9827\n",
      "Epoch 45/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3052 - auc: 0.9843\n",
      "Epoch 46/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3046 - auc: 0.9833\n",
      "Epoch 47/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2871 - auc: 0.9832\n",
      "Epoch 48/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3105 - auc: 0.9824\n",
      "Epoch 49/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2938 - auc: 0.9832\n",
      "Epoch 50/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2995 - auc: 0.9834\n",
      "Epoch 51/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3005 - auc: 0.9829\n",
      "Epoch 52/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3134 - auc: 0.9847\n",
      "Epoch 53/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.3063 - auc: 0.9835\n",
      "Epoch 54/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2894 - auc: 0.9843\n",
      "Epoch 55/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2889 - auc: 0.9828\n",
      "Epoch 56/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.3019 - auc: 0.9850\n",
      "Epoch 57/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2999 - auc: 0.9835\n",
      "Epoch 58/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3043 - auc: 0.9845\n",
      "Epoch 59/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.3004 - auc: 0.9839\n",
      "Epoch 60/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2983 - auc: 0.9829\n",
      "Epoch 61/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2992 - auc: 0.9831\n",
      "Epoch 62/70\n",
      "1692/1692 [==============================] - 67s 40ms/step - loss: 0.2919 - auc: 0.9843\n",
      "Epoch 63/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2894 - auc: 0.9831\n",
      "Epoch 64/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.2953 - auc: 0.9838\n",
      "Epoch 65/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.2909 - auc: 0.9835\n",
      "Epoch 66/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2865 - auc: 0.9836\n",
      "Epoch 67/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.2905 - auc: 0.9840\n",
      "Epoch 68/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2915 - auc: 0.9821\n",
      "Epoch 69/70\n",
      "1692/1692 [==============================] - 67s 39ms/step - loss: 0.2985 - auc: 0.9843\n",
      "Epoch 70/70\n",
      "1692/1692 [==============================] - 66s 39ms/step - loss: 0.2974 - auc: 0.9841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.000548790324253671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.1597651663405088\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/ADD/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_ADD_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0005', 'eer_eval': '0.1597', 'saved_model': 'saved_models/model_name!DDWSseq_ADD_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0005.hdf5', 'tnow': '2022-05-31 15:06:08.177898'}\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from utils.DataLoader import data_loader\n",
    "from utils.Generator0 import DataGenerator, feature_extract_cqt, evalEER,  evalScore, evalEER_f, evalEER_f2, gen_fname\n",
    "from models.models import get_ResMax, get_LCNN, sigmoidal_decay\n",
    "from models.models2 import get_BCResMax, get_DDWSseq\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import add,concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, maximum, DepthwiseConv2D, AveragePooling2D, UpSampling2D\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, SpatialDropout2D\n",
    "from tensorflow.keras.layers import Convolution2D, GlobalAveragePooling2D, MaxPool2D, ZeroPadding2D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.activations import relu, softmax, swish\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import pickle\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "add2022 = '/home/ubuntu/data/ADD/'\n",
    "asv2019 = '/home/ubuntu/data/asv2019/'\n",
    "\n",
    "pathset = { 'add2022' : add2022 , 'asv2019':asv2019}\n",
    "        \n",
    "dl = data_loader(pathset)\n",
    "\n",
    "#dl.get_data(data_pick = '2', tde_pick = 't', pl_pick = 'l', to = 't')\n",
    "#dl.get_data(data_pick = '2', tde_pick = 'd', pl_pick = 'l', to = 't')\n",
    "#dl.get_data(data_pick = '2', tde_pick = 'e', pl_pick = 'l', to = 'd')\n",
    "\n",
    "\n",
    "datapick = '1' ## 1:ADD, 2:LA\n",
    "\n",
    "dl.get_data(data_pick = datapick, tde_pick = 't', to = 't')\n",
    "dl.get_data(data_pick = datapick, tde_pick = 'd', to = 'd')\n",
    "dl.get_data(data_pick = datapick, tde_pick = 'e', to = 'e')\n",
    "\n",
    "#track1 = data_loader(pathset)\n",
    "#track1_generator = DataGenerator(track1.eval, track1.labels, **params_no_shuffle)\n",
    "\n",
    "#################################################\n",
    "### get_ResMax\n",
    "mname = 'ResMax_ADD_'\n",
    "#################################################\n",
    "\n",
    "### None\n",
    "\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = False\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :BC_ResMax\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "### Mixup\n",
    "\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False # np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### LP         \n",
    "\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "#    ru = np.random.uniform(.1, .9)\n",
    "    ru = 0.5\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,ones1\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP        \n",
    "\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "#    ru = np.random.uniform(.1, .9)\n",
    "    ru = 0.5\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### RP\n",
    "\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "### LP + RP\n",
    "\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### HP + RP\n",
    "\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #[2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################\n",
    "mname = \"LCNN_ADD_\"\n",
    "################################\n",
    "\n",
    "## None\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = False\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        \n",
    "### Mixup\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "### LP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "### LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #[2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "\n",
    "###############################################\n",
    "mname = \"BCResMax_ADD_\"\n",
    "###############################################\n",
    "\n",
    "### None\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = False\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### mixup\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### LP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "        \n",
    "### LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### HP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### HP + LP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #[2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "\n",
    "###############################################\n",
    "mname = \"DDWSseq_ADD_\"\n",
    "###############################################\n",
    "\n",
    "### None\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = False\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### Mixup\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### LP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "### LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #[2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': add2022,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': add2022\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_ADD/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11dc40e",
   "metadata": {},
   "source": [
    "## 2. ASV- LA Data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5961d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 44s 26ms/step - loss: 0.4505 - auc: 0.9175\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0875 - auc: 0.9973\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0540 - auc: 0.9987\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0476 - auc: 0.9990\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0341 - auc: 0.9992\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0239 - auc: 0.9996\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0275 - auc: 0.9995\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0344 - auc: 0.9994\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0133 - auc: 0.9997\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0139 - auc: 0.9997\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0141 - auc: 0.9998\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0257 - auc: 0.9997\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0123 - auc: 0.9996\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0095 - auc: 0.9997\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0061 - auc: 0.9999\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0129 - auc: 0.9996\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0107 - auc: 0.9999\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0043 - auc: 1.0000\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0114 - auc: 0.9997\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0042 - auc: 1.0000\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0075 - auc: 0.9999\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0032 - auc: 1.0000\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0048 - auc: 0.9999\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0043 - auc: 0.9999\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0022 - auc: 1.0000\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0059 - auc: 0.9997\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0024 - auc: 1.0000\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.4274e-04 - auc: 1.0000\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0041 - auc: 0.9999\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 8.8402e-04 - auc: 1.0000\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0021 - auc: 1.0000\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0038 - auc: 0.9999\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0042 - auc: 0.9999\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.4172e-04 - auc: 1.0000\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.0794e-04 - auc: 1.0000\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0023 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0012 - auc: 1.0000\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.2136e-04 - auc: 1.0000\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.0470e-05 - auc: 1.0000\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0012 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.0369e-05 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 4.5907e-05 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.0198e-04 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.1934e-05 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.7239e-05 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 7.3424e-06 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 7.7048e-06 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 7.3067e-05 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 4.8097e-06 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 4.1225e-04 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.2371e-04 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.0096e-06 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.0768e-05 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.7911e-06 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 1.7807e-06 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.7091e-06 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 9.9708e-07 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 1.0125e-06 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.4979e-06 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 6.9668e-07 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 9.5189e-07 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 6.2220e-07 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.6899e-06 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 6.9923e-07 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.2987e-06 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 1.4478e-06 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.0138e-06 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.0788e-07 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 9.6695e-07 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 8.8142e-07 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.007021038811945797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0431435167783205\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0070', 'eer_eval': '0.0431', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0070.hdf5', 'tnow': '2022-05-31 15:55:16.140401'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 43s 26ms/step - loss: 0.3574 - auc: 0.9419\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0883 - auc: 0.9975\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0596 - auc: 0.9979\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0362 - auc: 0.9992\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0430 - auc: 0.9988\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 0.0362 - auc: 0.9989\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0293 - auc: 0.9992\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0187 - auc: 0.9995\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0246 - auc: 0.9996\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0099 - auc: 0.9998\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0116 - auc: 0.9999\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0190 - auc: 0.9994\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0212 - auc: 0.9993\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0085 - auc: 0.9999\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0123 - auc: 0.9998\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0114 - auc: 0.9998\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0031 - auc: 1.0000\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0138 - auc: 0.9997\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0159 - auc: 0.9997\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0030 - auc: 0.9999\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0111 - auc: 0.9998\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0028 - auc: 1.0000\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0255 - auc: 0.9993\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0077 - auc: 0.9998\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0054 - auc: 0.9998\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0031 - auc: 1.0000\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0053 - auc: 0.9998\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0014 - auc: 1.0000\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0018 - auc: 1.0000\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0017 - auc: 1.0000\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 7.4386e-04 - auc: 1.0000\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0016 - auc: 0.9999\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 5.3096e-04 - auc: 1.0000\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0010 - auc: 1.0000\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 6.3410e-04 - auc: 1.0000\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.2933e-04 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.2737e-04 - auc: 1.0000\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0023 - auc: 1.0000\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.7760e-04 - auc: 1.0000\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.6382e-05 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 5.5614e-04 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.0031e-05 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 2.5475e-05 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 9.3512e-06 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 7.6039e-06 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.0864e-05 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 4.0989e-06 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 2.4337e-06 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.2694e-06 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 9.3081e-07 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 1.3247e-05 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 4.2149e-06 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.0522e-05 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.0618e-06 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.1392e-05 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.1715e-07 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.4751e-06 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 6.3086e-07 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.0410e-05 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 8.7757e-06 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.1095e-06 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.6679e-07 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 7.4317e-07 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.2014e-06 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.2913e-06 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 9.0888e-07 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.5321e-07 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 4.9047e-07 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.0457e-07 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.2634e-07 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.007677436162319629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.04503478498072544\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0076', 'eer_eval': '0.0450', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0076.hdf5', 'tnow': '2022-05-31 16:44:12.803687'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 43s 25ms/step - loss: 0.3662 - auc: 0.9374\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 0.0842 - auc: 0.9972\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0527 - auc: 0.9989\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 0.0427 - auc: 0.9987\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0373 - auc: 0.9993\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0286 - auc: 0.9994\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0337 - auc: 0.9988\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0198 - auc: 0.9997\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0193 - auc: 0.9995\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0204 - auc: 0.9998\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 0.0156 - auc: 0.9997\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0163 - auc: 0.9996\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0139 - auc: 0.9997\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 0.0091 - auc: 0.9997\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0092 - auc: 0.9999\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0080 - auc: 0.9999\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 0.0035 - auc: 1.0000\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0092 - auc: 0.9998\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0050 - auc: 1.0000\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0103 - auc: 0.9997\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0055 - auc: 0.9999\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0231 - auc: 0.9995\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0030 - auc: 0.9999\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0062 - auc: 0.9999\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0013 - auc: 1.0000\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0057 - auc: 0.9999\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0031 - auc: 0.9999\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.4418e-04 - auc: 1.0000\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 7.4721e-05 - auc: 1.0000\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0023 - auc: 1.0000\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.0032 - auc: 1.0000\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0010 - auc: 1.0000\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 0.0027 - auc: 0.9999\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0016 - auc: 1.0000\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.6200e-04 - auc: 1.0000\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 2.7570e-04 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 4.4529e-04 - auc: 1.0000\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0027 - auc: 1.0000\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.5170e-04 - auc: 1.0000\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.5334e-04 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.0049e-05 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 2.7081e-04 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 8.0344e-05 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 3.9000e-05 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 1.6285e-05 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 6.6809e-06 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.3031e-06 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 6.7052e-04 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 4.9205e-05 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 6.0348e-06 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.3907e-06 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.1120e-05 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.1524e-06 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 2.8183e-06 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.7131e-06 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 1.1351e-06 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.2365e-06 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 2.0637e-06 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.2083e-06 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 6.7255e-07 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.1156e-06 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.1117e-05 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 1.0815e-06 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 9.3900e-07 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 1.8329e-06 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.1842e-06 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 9.9597e-07 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 7.3540e-07 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 7.5285e-06 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.7405e-06 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.008681422944058522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.047678451052549406\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0086', 'eer_eval': '0.0476', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0086.hdf5', 'tnow': '2022-05-31 17:32:35.909266'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 44s 26ms/step - loss: 0.3826 - auc: 0.9328\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0839 - auc: 0.9976\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0623 - auc: 0.9987\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0596 - auc: 0.9986\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0381 - auc: 0.9990\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0385 - auc: 0.9994\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0194 - auc: 0.9997\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0150 - auc: 0.9997\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0126 - auc: 0.9998\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0194 - auc: 0.9996\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0174 - auc: 0.9995\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0110 - auc: 0.9999\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0132 - auc: 0.9996\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0158 - auc: 0.9995\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0056 - auc: 0.9999\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0080 - auc: 0.9998\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0055 - auc: 0.9999\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0096 - auc: 0.9999\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0038 - auc: 1.0000\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.0036 - auc: 0.9999\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.0024 - auc: 1.0000\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0101 - auc: 0.9996\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.0019 - auc: 1.0000\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 7.8419e-04 - auc: 1.0000\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0142 - auc: 0.9997\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0043 - auc: 0.9999\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 4.5245e-04 - auc: 1.0000\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0099 - auc: 0.9997\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 6.9876e-04 - auc: 1.0000\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0029 - auc: 0.9999\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0027 - auc: 1.0000\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.5925e-04 - auc: 1.0000\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0053 - auc: 0.9999\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 8.7511e-04 - auc: 1.0000\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.1615e-04 - auc: 1.0000\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.5396e-04 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0055 - auc: 1.0000\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 6.1920e-04 - auc: 1.0000\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.0578e-05 - auc: 1.0000\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.5002e-05 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.1909e-05 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.3110e-05 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.0890e-06 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 4.8743e-06 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.3916e-06 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 8.4617e-07 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 7.6327e-07 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.6773e-07 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 7.3276e-07 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.1003e-07 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 4.6612e-07 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.1498e-07 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.1270e-07 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.4808e-07 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 1.5590e-07 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.8833e-07 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.3723e-07 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.4442e-07 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.0759e-07 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 6.3709e-08 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.3353e-07 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 7.3473e-08 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.6807e-07 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.5299e-07 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 7.3682e-08 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.1329e-07 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 6.5996e-08 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 8.3288e-08 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 6.2166e-08 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 6.4751e-08 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.007788461890700512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03971369741276137\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0077', 'eer_eval': '0.0397', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0077.hdf5', 'tnow': '2022-05-31 18:21:29.670170'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 43s 26ms/step - loss: 0.3771 - auc: 0.9329\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0804 - auc: 0.9977\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0699 - auc: 0.9984\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0474 - auc: 0.9988\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0390 - auc: 0.9991\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0258 - auc: 0.9995\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0178 - auc: 0.9996\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0258 - auc: 0.9995\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0128 - auc: 0.9998\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0235 - auc: 0.9997\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0090 - auc: 0.9999\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0136 - auc: 0.9996\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0041 - auc: 0.9999\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0132 - auc: 0.9997\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0115 - auc: 0.9999\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0046 - auc: 1.0000\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0036 - auc: 1.0000\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0060 - auc: 0.9998\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0054 - auc: 0.9999\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0085 - auc: 0.9998\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0010 - auc: 1.0000\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0037 - auc: 1.0000\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0121 - auc: 0.9998\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0053 - auc: 0.9999\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0023 - auc: 0.9999\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0087 - auc: 0.9999\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0021 - auc: 1.0000\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0017 - auc: 1.0000\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0023 - auc: 1.0000\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.9234e-04 - auc: 1.0000\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 8.5485e-04 - auc: 1.0000\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0022 - auc: 1.0000\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.0652e-04 - auc: 1.0000\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0020 - auc: 1.0000\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.2976e-04 - auc: 1.0000\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 4.3958e-04 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 6.2514e-04 - auc: 1.0000\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 9.6745e-04 - auc: 1.0000\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.9425e-04 - auc: 1.0000\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 7.9705e-05 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.1932e-05 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 9.4210e-06 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 4.6266e-06 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.0586e-04 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 7.1772e-06 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.8079e-06 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 4.6061e-06 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.3480e-06 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 9.6548e-06 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 3.9791e-06 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.9317e-06 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.0432e-06 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.6457e-06 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 7.0732e-07 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.0636e-06 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 6.2458e-07 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.0063e-07 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 4.3952e-07 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.2570e-07 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.0109e-07 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 7.1456e-07 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 2.3155e-06 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 1.5654e-06 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.9765e-07 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.6511e-07 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.6108e-07 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 2.3182e-07 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 4.1339e-07 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.0160e-07 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.4758e-07 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.007727630217821745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0535533191900341\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0077', 'eer_eval': '0.0535', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0077.hdf5', 'tnow': '2022-05-31 19:10:18.004284'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 44s 26ms/step - loss: 0.3734 - auc: 0.9379\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0774 - auc: 0.9979\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.0503 - auc: 0.9987\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0352 - auc: 0.9993\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0479 - auc: 0.9990\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.0216 - auc: 0.9997\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0251 - auc: 0.9994\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.0282 - auc: 0.9995\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0154 - auc: 0.9995\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0216 - auc: 0.9997\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0148 - auc: 0.9997\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0346 - auc: 0.9992\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.0080 - auc: 0.9999\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0115 - auc: 0.9996\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0073 - auc: 0.9999\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0091 - auc: 0.9999\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.0087 - auc: 0.9999\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0089 - auc: 0.9998\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0068 - auc: 0.9999\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0103 - auc: 0.9997\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.0025 - auc: 1.0000\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0063 - auc: 0.9998\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0052 - auc: 0.9999\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0051 - auc: 0.9999\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0043 - auc: 0.9999\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0013 - auc: 1.0000\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0045 - auc: 0.9999\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0054 - auc: 1.0000\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 8.8233e-04 - auc: 1.0000\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0032 - auc: 1.0000\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 7.1669e-04 - auc: 1.0000\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 0.0027 - auc: 1.0000\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.1081e-04 - auc: 1.0000\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.1871e-05 - auc: 1.0000\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.0065 - auc: 0.9998\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.4510e-04 - auc: 1.0000 0s - loss: 5.3874e-04 - auc: 1.0\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.4230e-04 - auc: 1.0000\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.2444e-04 - auc: 1.0000\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.6470e-04 - auc: 1.0000\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.2986e-05 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.2551e-05 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.1251e-05 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 6.1524e-06 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.8702e-06 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.4630e-05 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 8.6136e-07 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.7380e-06 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.5047e-06 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 8.4571e-06 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.9373e-06 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.4988e-06 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.2569e-06 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 4.6241e-06 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 4.8199e-06 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 9.4835e-07 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.8540e-07 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 5.6614e-07 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.9285e-07 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.2121e-07 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.1822e-07 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.5687e-07 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.4761e-07 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.9418e-07 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.6238e-07 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.2738e-07 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 3.4191e-07 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 9.7125e-07 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 1.3363e-07 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.3311e-07 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 2.1234e-07 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.006700818349791369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.037913910561819364\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0067', 'eer_eval': '0.0379', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0067.hdf5', 'tnow': '2022-05-31 19:59:18.558858'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 44s 26ms/step - loss: 0.6550 - auc: 0.8786\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3984 - auc: 0.9572\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3495 - auc: 0.9657\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3380 - auc: 0.9644\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3391 - auc: 0.9679\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3188 - auc: 0.9688\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3190 - auc: 0.9705\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3167 - auc: 0.9709\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3068 - auc: 0.9714\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3075 - auc: 0.9728\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2991 - auc: 0.9722\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3028 - auc: 0.9754\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3008 - auc: 0.9755\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3029 - auc: 0.9753\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2935 - auc: 0.9773\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2943 - auc: 0.9784\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2858 - auc: 0.9793\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2922 - auc: 0.9798\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2796 - auc: 0.9791\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2914 - auc: 0.9783\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2886 - auc: 0.9783\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2803 - auc: 0.9804\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2841 - auc: 0.9811\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2778 - auc: 0.9797\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2775 - auc: 0.9798\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2731 - auc: 0.9811\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2802 - auc: 0.9796\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2748 - auc: 0.9806\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2765 - auc: 0.9827\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2785 - auc: 0.9821\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2728 - auc: 0.9830\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2787 - auc: 0.9837\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2766 - auc: 0.9838\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2609 - auc: 0.9838\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2808 - auc: 0.9829\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2716 - auc: 0.9840\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2683 - auc: 0.9854\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2730 - auc: 0.9844\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2758 - auc: 0.9857\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2650 - auc: 0.9852\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2728 - auc: 0.9850\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2738 - auc: 0.9851\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2649 - auc: 0.9854\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2669 - auc: 0.9863\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2649 - auc: 0.9865\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2596 - auc: 0.9858\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2714 - auc: 0.9867\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2627 - auc: 0.9865\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2662 - auc: 0.9865\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2629 - auc: 0.9869\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2546 - auc: 0.9865\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2618 - auc: 0.9866\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2776 - auc: 0.9859\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2654 - auc: 0.9871\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2671 - auc: 0.9870\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2595 - auc: 0.9880\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2706 - auc: 0.9867\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2751 - auc: 0.9855\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2595 - auc: 0.9872\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2567 - auc: 0.9873\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2600 - auc: 0.9870 1s - l\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2630 - auc: 0.9862\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2712 - auc: 0.9867\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2586 - auc: 0.9863\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2662 - auc: 0.9873\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2533 - auc: 0.9873\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2639 - auc: 0.9872\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2642 - auc: 0.9865\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2614 - auc: 0.9859\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2738 - auc: 0.9875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.007710898865987707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.037130203498455625\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0077', 'eer_eval': '0.0371', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0077.hdf5', 'tnow': '2022-05-31 20:48:42.736172'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 44s 26ms/step - loss: 0.6460 - auc: 0.8838\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3742 - auc: 0.9604\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3714 - auc: 0.9626\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3478 - auc: 0.9634\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3314 - auc: 0.9671\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3322 - auc: 0.9681\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3230 - auc: 0.9709\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3059 - auc: 0.9715\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3136 - auc: 0.9732\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3043 - auc: 0.9747\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3077 - auc: 0.9754\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3068 - auc: 0.9738\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2937 - auc: 0.9782\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2856 - auc: 0.9771\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3063 - auc: 0.9756\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2899 - auc: 0.9760\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2962 - auc: 0.9765\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2881 - auc: 0.9790\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2767 - auc: 0.9786\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2915 - auc: 0.9798\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2814 - auc: 0.9792\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2944 - auc: 0.9792\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2837 - auc: 0.9786\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2887 - auc: 0.9807\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2852 - auc: 0.9812\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2846 - auc: 0.9811\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2823 - auc: 0.9830\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2854 - auc: 0.9810\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2716 - auc: 0.9830\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2844 - auc: 0.9822\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2676 - auc: 0.9826\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2801 - auc: 0.9832\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2714 - auc: 0.9821\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2756 - auc: 0.9829\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2658 - auc: 0.9833\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2894 - auc: 0.9849\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2637 - auc: 0.9832\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2775 - auc: 0.9842\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2819 - auc: 0.9855\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2651 - auc: 0.9844\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2749 - auc: 0.9845\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2797 - auc: 0.9852\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2702 - auc: 0.9857\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2657 - auc: 0.9859\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2750 - auc: 0.9854\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2613 - auc: 0.9865\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2709 - auc: 0.9849\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2726 - auc: 0.9867\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2600 - auc: 0.9868\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2553 - auc: 0.9862\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2711 - auc: 0.9864\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2623 - auc: 0.9866\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2722 - auc: 0.9873\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2594 - auc: 0.9872\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2721 - auc: 0.9868\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2619 - auc: 0.9875\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2628 - auc: 0.9854\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2667 - auc: 0.9872\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2615 - auc: 0.9869\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2703 - auc: 0.9872\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2753 - auc: 0.9878\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2568 - auc: 0.9869\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2730 - auc: 0.9872\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2617 - auc: 0.9867\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2580 - auc: 0.9875\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2591 - auc: 0.9869\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2647 - auc: 0.9873\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2639 - auc: 0.9859\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2586 - auc: 0.9863\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2520 - auc: 0.9870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0062809847024017165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03223227865611822\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0062', 'eer_eval': '0.0322', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0062.hdf5', 'tnow': '2022-05-31 21:38:09.842918'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 45s 27ms/step - loss: 0.6208 - auc: 0.8844\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3871 - auc: 0.9593\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3560 - auc: 0.9632\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3585 - auc: 0.9638\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3318 - auc: 0.9684\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3274 - auc: 0.9685\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3220 - auc: 0.9696\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3054 - auc: 0.9730\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3033 - auc: 0.9726\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2997 - auc: 0.9714\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3266 - auc: 0.9746\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3118 - auc: 0.9733\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2850 - auc: 0.9780\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2950 - auc: 0.9763\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2883 - auc: 0.9765\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2980 - auc: 0.9765\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2865 - auc: 0.9792\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2825 - auc: 0.9800\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2837 - auc: 0.9788\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2897 - auc: 0.9788\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2862 - auc: 0.9792\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2891 - auc: 0.9811\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2907 - auc: 0.9814\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2786 - auc: 0.9812\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2707 - auc: 0.9801\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2785 - auc: 0.9819\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2675 - auc: 0.9817\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2789 - auc: 0.9812\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2734 - auc: 0.9833\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2813 - auc: 0.9817\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2725 - auc: 0.9831\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2743 - auc: 0.9830\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2743 - auc: 0.9843\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2760 - auc: 0.9837\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2727 - auc: 0.9836\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2630 - auc: 0.9849\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2743 - auc: 0.9844\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2678 - auc: 0.9840\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2782 - auc: 0.9851\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2766 - auc: 0.9866\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2682 - auc: 0.9858\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2572 - auc: 0.9867\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2785 - auc: 0.9863\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2708 - auc: 0.9860\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2626 - auc: 0.9862\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2671 - auc: 0.9857\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2668 - auc: 0.9855\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2635 - auc: 0.9860\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2584 - auc: 0.9880\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2680 - auc: 0.9866\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2659 - auc: 0.9861\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2636 - auc: 0.9864\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2627 - auc: 0.9862\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2575 - auc: 0.9860\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2580 - auc: 0.9859\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2608 - auc: 0.9871\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2638 - auc: 0.9859\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2649 - auc: 0.9871\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2525 - auc: 0.9873\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 39s 25ms/step - loss: 0.2626 - auc: 0.9866\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2625 - auc: 0.9877\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2553 - auc: 0.9884\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2734 - auc: 0.9866\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 0.2710 - auc: 0.9868\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 40s 25ms/step - loss: 0.2542 - auc: 0.9873\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2583 - auc: 0.9889\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2655 - auc: 0.9863\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2642 - auc: 0.9873\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2592 - auc: 0.9874\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2671 - auc: 0.9875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.006050902196759598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0386296181691787\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0060', 'eer_eval': '0.0386', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0060.hdf5', 'tnow': '2022-05-31 22:27:49.375764'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 44s 26ms/step - loss: 0.6444 - auc: 0.8771\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3988 - auc: 0.9593\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3647 - auc: 0.9647\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3503 - auc: 0.9641\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3500 - auc: 0.9660\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3243 - auc: 0.9685\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3276 - auc: 0.9707\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3160 - auc: 0.9704\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3223 - auc: 0.9685\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3242 - auc: 0.9699\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3054 - auc: 0.9722\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3074 - auc: 0.9723\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3009 - auc: 0.9731\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3015 - auc: 0.9729\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3130 - auc: 0.9748\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3080 - auc: 0.9751\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3039 - auc: 0.9748\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2900 - auc: 0.9763\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2816 - auc: 0.9767\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3026 - auc: 0.9762\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2914 - auc: 0.9783\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2941 - auc: 0.9779\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2784 - auc: 0.9793\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2885 - auc: 0.9818\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2913 - auc: 0.9782\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2808 - auc: 0.9789\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2757 - auc: 0.9796\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2848 - auc: 0.9800\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2978 - auc: 0.9790\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2836 - auc: 0.9796\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2729 - auc: 0.9813\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2859 - auc: 0.9816\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2740 - auc: 0.9829\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2669 - auc: 0.9824\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2650 - auc: 0.9818\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2654 - auc: 0.9816\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2833 - auc: 0.9830\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2820 - auc: 0.9818\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2683 - auc: 0.9833\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2732 - auc: 0.9844\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2839 - auc: 0.9832\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2726 - auc: 0.9855\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2646 - auc: 0.9853\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2631 - auc: 0.9844\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2695 - auc: 0.9854\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2648 - auc: 0.9851\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2818 - auc: 0.9853\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2691 - auc: 0.9856\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2655 - auc: 0.9850\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2623 - auc: 0.9849\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2693 - auc: 0.9873\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2721 - auc: 0.9865\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2698 - auc: 0.9854\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2625 - auc: 0.9869\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2709 - auc: 0.9861\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2669 - auc: 0.9858\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2632 - auc: 0.9861\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2569 - auc: 0.9850\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2653 - auc: 0.9876\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2639 - auc: 0.9855\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2464 - auc: 0.9865\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2655 - auc: 0.9871\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2622 - auc: 0.9867\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2583 - auc: 0.9869\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2709 - auc: 0.9865\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2640 - auc: 0.9871\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2604 - auc: 0.9865\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2674 - auc: 0.9871\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2619 - auc: 0.9838\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2696 - auc: 0.9854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00284880324691077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.01946108152545572\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0028', 'eer_eval': '0.0194', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0028.hdf5', 'tnow': '2022-05-31 23:17:22.482337'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 43s 26ms/step - loss: 0.6104 - auc: 0.8873\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3771 - auc: 0.9606\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3729 - auc: 0.9629\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3570 - auc: 0.9642\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3333 - auc: 0.9671\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3367 - auc: 0.9668\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3212 - auc: 0.9691\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3253 - auc: 0.9700\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3170 - auc: 0.9735\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3220 - auc: 0.9716\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3099 - auc: 0.9722\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3064 - auc: 0.9733\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2995 - auc: 0.9734\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3041 - auc: 0.9750\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2844 - auc: 0.9765\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2900 - auc: 0.9759\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2903 - auc: 0.9775\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2916 - auc: 0.9775\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2866 - auc: 0.9778\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2833 - auc: 0.9788\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2829 - auc: 0.9799\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2856 - auc: 0.9782\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2882 - auc: 0.9797\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2731 - auc: 0.9800\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2821 - auc: 0.9797\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2822 - auc: 0.9799\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2829 - auc: 0.9790\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2907 - auc: 0.9817\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2773 - auc: 0.9816\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2774 - auc: 0.9805\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2833 - auc: 0.9826\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2860 - auc: 0.9818\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2703 - auc: 0.9836\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2804 - auc: 0.9818\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2846 - auc: 0.9844\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2832 - auc: 0.9830\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2808 - auc: 0.9833\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2741 - auc: 0.9845\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2634 - auc: 0.9844\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2671 - auc: 0.9845\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2833 - auc: 0.9843\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2726 - auc: 0.9851\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2756 - auc: 0.9854\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2689 - auc: 0.9850\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2599 - auc: 0.9856\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2804 - auc: 0.9866\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2570 - auc: 0.9844\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2615 - auc: 0.9863\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2706 - auc: 0.9858\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2667 - auc: 0.9862\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2651 - auc: 0.9860\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2614 - auc: 0.9858\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2752 - auc: 0.9867\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2743 - auc: 0.9860\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2516 - auc: 0.9853\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2681 - auc: 0.9871\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2615 - auc: 0.9872\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2731 - auc: 0.9861\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2711 - auc: 0.9868\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2733 - auc: 0.9851\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2713 - auc: 0.9868\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2578 - auc: 0.9863\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2714 - auc: 0.9860\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2632 - auc: 0.9867\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2576 - auc: 0.9861\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2746 - auc: 0.9867\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2683 - auc: 0.9858\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2692 - auc: 0.9870\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2729 - auc: 0.9867\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2491 - auc: 0.9870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0044023180706772025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.02159010352019003\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0044', 'eer_eval': '0.0215', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0044.hdf5', 'tnow': '2022-06-01 00:06:27.564182'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 43s 26ms/step - loss: 0.6536 - auc: 0.8794\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 40s 26ms/step - loss: 0.3866 - auc: 0.9609\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3707 - auc: 0.9631\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3630 - auc: 0.9647\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3499 - auc: 0.9655\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3228 - auc: 0.9685\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3242 - auc: 0.9678\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3208 - auc: 0.9691\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3246 - auc: 0.9710\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3103 - auc: 0.9720\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3260 - auc: 0.9722\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3167 - auc: 0.9728\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3075 - auc: 0.9756\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3102 - auc: 0.9747\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2955 - auc: 0.9733\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2917 - auc: 0.9772\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2895 - auc: 0.9757\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3031 - auc: 0.9759\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2902 - auc: 0.9752\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2931 - auc: 0.9805\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2788 - auc: 0.9766\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2917 - auc: 0.9772\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2802 - auc: 0.9801\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2912 - auc: 0.9808\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2886 - auc: 0.9809\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2753 - auc: 0.9795\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2857 - auc: 0.9810\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2828 - auc: 0.9811\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2774 - auc: 0.9813\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2731 - auc: 0.9809\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2665 - auc: 0.9821\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2719 - auc: 0.9817\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2747 - auc: 0.9816\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2829 - auc: 0.9818\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2670 - auc: 0.9827\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2659 - auc: 0.9834\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2843 - auc: 0.9816\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2666 - auc: 0.9830\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2868 - auc: 0.9842\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2787 - auc: 0.9850\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2706 - auc: 0.9844\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2643 - auc: 0.9859\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2692 - auc: 0.9836\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2585 - auc: 0.9855\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2593 - auc: 0.9850\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2633 - auc: 0.9862\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2584 - auc: 0.9857\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2705 - auc: 0.9853\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2678 - auc: 0.9863\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2733 - auc: 0.9860\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2586 - auc: 0.9861\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2644 - auc: 0.9845\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2608 - auc: 0.9859\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2656 - auc: 0.9870\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2555 - auc: 0.9852\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2643 - auc: 0.9868\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2635 - auc: 0.9851\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2592 - auc: 0.9850\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2689 - auc: 0.9865\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2688 - auc: 0.9860\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2769 - auc: 0.9862\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2619 - auc: 0.9875\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2578 - auc: 0.9859\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2742 - auc: 0.9862\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2647 - auc: 0.9856\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2641 - auc: 0.9855\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2642 - auc: 0.9862\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2669 - auc: 0.9859\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2600 - auc: 0.9857\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2654 - auc: 0.9863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.005995001869684541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.02159010352019003\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0059', 'eer_eval': '0.0215', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0059.hdf5', 'tnow': '2022-06-01 00:55:32.854036'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 45s 27ms/step - loss: 0.6702 - auc: 0.8747\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.4040 - auc: 0.9579\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3765 - auc: 0.9592\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3638 - auc: 0.9624\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3351 - auc: 0.9666\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3175 - auc: 0.9691\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3298 - auc: 0.9674\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3161 - auc: 0.9700\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3150 - auc: 0.9699\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3066 - auc: 0.9706\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3232 - auc: 0.9712\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3287 - auc: 0.9706\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3115 - auc: 0.9711\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3098 - auc: 0.9752\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2941 - auc: 0.9762\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2984 - auc: 0.9747\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3043 - auc: 0.9751\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3046 - auc: 0.9754\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2933 - auc: 0.9739\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2926 - auc: 0.9761\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2932 - auc: 0.9765\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3019 - auc: 0.9766\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2909 - auc: 0.9771\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2932 - auc: 0.9781\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2928 - auc: 0.9791\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2790 - auc: 0.9780\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2701 - auc: 0.9791\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2810 - auc: 0.9813\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2858 - auc: 0.9780\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2817 - auc: 0.9803\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2846 - auc: 0.9808\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2862 - auc: 0.9821\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2848 - auc: 0.9811\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2836 - auc: 0.9814\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2882 - auc: 0.9811\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2775 - auc: 0.9824\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2796 - auc: 0.9828\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2912 - auc: 0.9829\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2590 - auc: 0.9840\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2693 - auc: 0.9829\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2804 - auc: 0.9831\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2794 - auc: 0.9831\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2764 - auc: 0.9831\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2722 - auc: 0.9840\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2726 - auc: 0.9833\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2719 - auc: 0.9832\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2731 - auc: 0.9846\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2845 - auc: 0.9848\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2694 - auc: 0.9857\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2648 - auc: 0.9844\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2567 - auc: 0.9844\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2723 - auc: 0.9836\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2550 - auc: 0.9863\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2655 - auc: 0.9847\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2761 - auc: 0.9846\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2718 - auc: 0.9853\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2599 - auc: 0.9848\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2644 - auc: 0.9847\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2512 - auc: 0.9857\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2698 - auc: 0.9853\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2660 - auc: 0.9850\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2649 - auc: 0.9853\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2649 - auc: 0.9844\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2670 - auc: 0.9845\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2700 - auc: 0.9850\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2729 - auc: 0.9855\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2682 - auc: 0.9861\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2692 - auc: 0.9868\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2631 - auc: 0.9853\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2608 - auc: 0.9839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.008625135154098906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.04531950256397198\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0086', 'eer_eval': '0.0453', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0086.hdf5', 'tnow': '2022-06-01 01:45:46.348218'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 44s 26ms/step - loss: 0.6595 - auc: 0.8840\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.4264 - auc: 0.9561\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3706 - auc: 0.9621\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3597 - auc: 0.9634\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3432 - auc: 0.9640\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3213 - auc: 0.9651\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3354 - auc: 0.9686\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3231 - auc: 0.9681\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3113 - auc: 0.9702\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3061 - auc: 0.9728\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3109 - auc: 0.9723\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3010 - auc: 0.9739\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3066 - auc: 0.9717\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2852 - auc: 0.9739\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3039 - auc: 0.9745\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3208 - auc: 0.9751\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3017 - auc: 0.9772\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3037 - auc: 0.9773\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2930 - auc: 0.9748\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2965 - auc: 0.9776\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2774 - auc: 0.9767\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2920 - auc: 0.9767\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2912 - auc: 0.9773\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2776 - auc: 0.9796\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2899 - auc: 0.9774\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2974 - auc: 0.9784\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2819 - auc: 0.9815\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2951 - auc: 0.9795\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2832 - auc: 0.9801\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2837 - auc: 0.9808\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2840 - auc: 0.9815\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2811 - auc: 0.9819\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2715 - auc: 0.9817\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2828 - auc: 0.9802\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2742 - auc: 0.9816\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2860 - auc: 0.9815\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2676 - auc: 0.9826\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2777 - auc: 0.9824\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2779 - auc: 0.9833\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2644 - auc: 0.9841\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2664 - auc: 0.9841\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2643 - auc: 0.9842\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2758 - auc: 0.9840\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2539 - auc: 0.9846\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2742 - auc: 0.9847\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2776 - auc: 0.9851\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2715 - auc: 0.9856\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2627 - auc: 0.9853\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2662 - auc: 0.9862\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2609 - auc: 0.9845\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2611 - auc: 0.9853\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2650 - auc: 0.9846\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2740 - auc: 0.9868\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2633 - auc: 0.9853\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2735 - auc: 0.9851\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2637 - auc: 0.9868\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2692 - auc: 0.9856\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2704 - auc: 0.9863\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2719 - auc: 0.9865\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2693 - auc: 0.9859\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2632 - auc: 0.9851\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2680 - auc: 0.9856\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2663 - auc: 0.9861\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2540 - auc: 0.9860\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2695 - auc: 0.9856\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2598 - auc: 0.9857\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2662 - auc: 0.9844\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2615 - auc: 0.9852\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2678 - auc: 0.9857\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2877 - auc: 0.9852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.006151677770648446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.039274880090162334\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0061', 'eer_eval': '0.0392', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0061.hdf5', 'tnow': '2022-06-01 02:35:47.173695'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 45s 27ms/step - loss: 0.6793 - auc: 0.8710\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.4060 - auc: 0.9570\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3686 - auc: 0.9617\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3536 - auc: 0.9628\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3414 - auc: 0.9641\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3352 - auc: 0.9682\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3347 - auc: 0.9694\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3221 - auc: 0.9698\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3181 - auc: 0.9710\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3130 - auc: 0.9679\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3191 - auc: 0.9713\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3024 - auc: 0.9728\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3090 - auc: 0.9719\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3018 - auc: 0.9735\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2912 - auc: 0.9751\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3116 - auc: 0.9751\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2941 - auc: 0.9767\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2965 - auc: 0.9776\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2809 - auc: 0.9782\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2905 - auc: 0.9787\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3047 - auc: 0.9773\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2802 - auc: 0.9789\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2915 - auc: 0.9775\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2907 - auc: 0.9761\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2889 - auc: 0.9797\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2772 - auc: 0.9809\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2842 - auc: 0.9808\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2834 - auc: 0.9812\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2884 - auc: 0.9810\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2825 - auc: 0.9817\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2885 - auc: 0.9803\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2871 - auc: 0.9809\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2718 - auc: 0.9824\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2841 - auc: 0.9807\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2761 - auc: 0.9837\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2567 - auc: 0.9835\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2918 - auc: 0.9837\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2770 - auc: 0.9837\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2753 - auc: 0.9848\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2677 - auc: 0.9841\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2632 - auc: 0.9840\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2637 - auc: 0.9851\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2736 - auc: 0.9844\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2660 - auc: 0.9847\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2675 - auc: 0.9844\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2664 - auc: 0.9837\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2813 - auc: 0.9853\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2787 - auc: 0.9847\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2712 - auc: 0.9856\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2645 - auc: 0.9833\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2677 - auc: 0.9854\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2686 - auc: 0.9844\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2611 - auc: 0.9852\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2625 - auc: 0.9858\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2709 - auc: 0.9863\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2741 - auc: 0.9857\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2681 - auc: 0.9865\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2686 - auc: 0.9862\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2615 - auc: 0.9855\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2654 - auc: 0.9856\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2659 - auc: 0.9863\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2567 - auc: 0.9855\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2567 - auc: 0.9864\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2669 - auc: 0.9871\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2663 - auc: 0.9865\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2735 - auc: 0.9862\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2762 - auc: 0.9845\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2667 - auc: 0.9858\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2631 - auc: 0.9864\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2781 - auc: 0.9854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0062809847024017165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.052568548596400616\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0062', 'eer_eval': '0.0525', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0062.hdf5', 'tnow': '2022-06-01 03:25:30.034474'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 43s 26ms/step - loss: 0.6885 - auc: 0.8722\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.4198 - auc: 0.9557\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3880 - auc: 0.9594\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3546 - auc: 0.9630\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3514 - auc: 0.9647\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3329 - auc: 0.9658\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3394 - auc: 0.9670\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3230 - auc: 0.9674\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3020 - auc: 0.9673\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3297 - auc: 0.9692\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3245 - auc: 0.9710\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3099 - auc: 0.9705\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3064 - auc: 0.9724\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3037 - auc: 0.9739\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3015 - auc: 0.9742\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3127 - auc: 0.9739\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2951 - auc: 0.9775\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2948 - auc: 0.9772\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2836 - auc: 0.9772\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2899 - auc: 0.9770\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3013 - auc: 0.9754\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2829 - auc: 0.9772\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2872 - auc: 0.9787\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2774 - auc: 0.9794\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2875 - auc: 0.9785\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2903 - auc: 0.9779\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2854 - auc: 0.9802\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2932 - auc: 0.9800\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2762 - auc: 0.9791\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2699 - auc: 0.9805\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2873 - auc: 0.9798\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2801 - auc: 0.9787\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2775 - auc: 0.9813\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2862 - auc: 0.9822\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2758 - auc: 0.9812\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2738 - auc: 0.9809\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2769 - auc: 0.9822\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2742 - auc: 0.9836\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2771 - auc: 0.9833\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2693 - auc: 0.9824\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2606 - auc: 0.9829\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2759 - auc: 0.9841\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2816 - auc: 0.9833\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2731 - auc: 0.9836\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2705 - auc: 0.9846\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2731 - auc: 0.9844\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2646 - auc: 0.9849\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2701 - auc: 0.9841\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2710 - auc: 0.9846\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2710 - auc: 0.9863\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2646 - auc: 0.9840\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2704 - auc: 0.9862\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2657 - auc: 0.9849\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2657 - auc: 0.9859\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2618 - auc: 0.9865\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2690 - auc: 0.9860\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2538 - auc: 0.9863\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2541 - auc: 0.9850\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2713 - auc: 0.9862\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2817 - auc: 0.9863\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2592 - auc: 0.9856\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2730 - auc: 0.9856\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2647 - auc: 0.9853\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2743 - auc: 0.9857\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2797 - auc: 0.9861\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2673 - auc: 0.9856\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2651 - auc: 0.9849\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2746 - auc: 0.9854\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2658 - auc: 0.9858\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2714 - auc: 0.9863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.008271839451160959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.04368947004935493\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0082', 'eer_eval': '0.0436', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0082.hdf5', 'tnow': '2022-06-01 04:14:48.401581'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 45s 26ms/step - loss: 0.7049 - auc: 0.8691\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.4098 - auc: 0.9548\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3838 - auc: 0.9598\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3723 - auc: 0.9618\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3685 - auc: 0.9650\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3445 - auc: 0.9648\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3332 - auc: 0.9684\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3134 - auc: 0.9683\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3280 - auc: 0.9685\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3091 - auc: 0.9722\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3120 - auc: 0.9711\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3141 - auc: 0.9722\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3111 - auc: 0.9722\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2934 - auc: 0.9716\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3003 - auc: 0.9753\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2899 - auc: 0.9740\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2993 - auc: 0.9750\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3055 - auc: 0.9749\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2853 - auc: 0.9768\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2878 - auc: 0.9766\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2937 - auc: 0.9760\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2900 - auc: 0.9755\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2879 - auc: 0.9778\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2920 - auc: 0.9801\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2820 - auc: 0.9765\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2795 - auc: 0.9774\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2855 - auc: 0.9806\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2957 - auc: 0.9791\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2752 - auc: 0.9802\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2908 - auc: 0.9797\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2790 - auc: 0.9793\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2773 - auc: 0.9795\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2819 - auc: 0.9798\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2825 - auc: 0.9824\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2846 - auc: 0.9816\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2740 - auc: 0.9815\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2726 - auc: 0.9819\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2812 - auc: 0.9820\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2700 - auc: 0.9832\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2796 - auc: 0.9815\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2828 - auc: 0.9826\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2619 - auc: 0.9828\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2751 - auc: 0.9840\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2673 - auc: 0.9833\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2725 - auc: 0.9836\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2711 - auc: 0.9830\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2694 - auc: 0.9841\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2820 - auc: 0.9843\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2840 - auc: 0.9849\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2648 - auc: 0.9839\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2655 - auc: 0.9850\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2633 - auc: 0.9851\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2614 - auc: 0.9853\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2680 - auc: 0.9849\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2714 - auc: 0.9845\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2615 - auc: 0.9845\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2749 - auc: 0.9855\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2700 - auc: 0.9845\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2682 - auc: 0.9850\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2673 - auc: 0.9851\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2644 - auc: 0.9839\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2725 - auc: 0.9841\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2663 - auc: 0.9849\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2591 - auc: 0.9863\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2585 - auc: 0.9871\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2709 - auc: 0.9846\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2685 - auc: 0.9858\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2605 - auc: 0.9856\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2622 - auc: 0.9850\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2686 - auc: 0.9852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.007054888978498491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.057228719646408716\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0070', 'eer_eval': '0.0572', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0070.hdf5', 'tnow': '2022-06-01 05:04:42.045568'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 44s 26ms/step - loss: 0.7221 - auc: 0.8623\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.4297 - auc: 0.9527\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.4011 - auc: 0.9600\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3520 - auc: 0.9652\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3676 - auc: 0.9634\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3506 - auc: 0.9628\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3271 - auc: 0.9675\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3247 - auc: 0.9682\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3250 - auc: 0.9681\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3061 - auc: 0.9710\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3089 - auc: 0.9693\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3142 - auc: 0.9700\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3269 - auc: 0.9702\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3048 - auc: 0.9738\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2986 - auc: 0.9739\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3137 - auc: 0.9746\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2961 - auc: 0.9757\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3025 - auc: 0.9738\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2968 - auc: 0.9745\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2949 - auc: 0.9767\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2973 - auc: 0.9771\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2972 - auc: 0.9760\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2858 - auc: 0.9761\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2879 - auc: 0.9790\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2904 - auc: 0.9765\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2917 - auc: 0.9778\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2842 - auc: 0.9789\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2799 - auc: 0.9785\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2909 - auc: 0.9781\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2901 - auc: 0.9796\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2818 - auc: 0.9789\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2818 - auc: 0.9802\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2815 - auc: 0.9811\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2792 - auc: 0.9810\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2773 - auc: 0.9823\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2761 - auc: 0.9827\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2642 - auc: 0.9823\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2694 - auc: 0.9820\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2749 - auc: 0.9826\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2486 - auc: 0.9832\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2757 - auc: 0.9819\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2632 - auc: 0.9834\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2745 - auc: 0.9848\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2748 - auc: 0.9836\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2655 - auc: 0.9850\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2676 - auc: 0.9842\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2780 - auc: 0.9852\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2651 - auc: 0.9841\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2665 - auc: 0.9832\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2671 - auc: 0.9839\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2722 - auc: 0.9854\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2827 - auc: 0.9861\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2610 - auc: 0.9852\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2642 - auc: 0.9850\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2610 - auc: 0.9860\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2662 - auc: 0.9862\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2615 - auc: 0.9847\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2671 - auc: 0.9860\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2609 - auc: 0.9836\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2556 - auc: 0.9858\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2597 - auc: 0.9837\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2667 - auc: 0.9849\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2693 - auc: 0.9841\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2712 - auc: 0.9846\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2694 - auc: 0.9846\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2597 - auc: 0.9842\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2781 - auc: 0.9847\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2674 - auc: 0.9856\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2665 - auc: 0.9849\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2834 - auc: 0.9849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.006477217041491199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.04838633136142254\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0064', 'eer_eval': '0.0483', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0064.hdf5', 'tnow': '2022-06-01 05:54:24.164915'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 44s 26ms/step - loss: 0.6896 - auc: 0.8756\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.4069 - auc: 0.9558\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3815 - auc: 0.9599\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3568 - auc: 0.9636\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3549 - auc: 0.9664\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3603 - auc: 0.9637\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3480 - auc: 0.9647\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3447 - auc: 0.9666 0s - loss: 0.3449 - a\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3241 - auc: 0.9683\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3195 - auc: 0.9690\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3145 - auc: 0.9701\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3172 - auc: 0.9706\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3069 - auc: 0.9706\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3027 - auc: 0.9746\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3032 - auc: 0.9745\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3122 - auc: 0.9729\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3014 - auc: 0.9747\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3016 - auc: 0.9741\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2900 - auc: 0.9752\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2907 - auc: 0.9763\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2979 - auc: 0.9760\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2975 - auc: 0.9757\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2898 - auc: 0.9779\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2768 - auc: 0.9789\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2791 - auc: 0.9778\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2759 - auc: 0.9774\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2774 - auc: 0.9783\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3016 - auc: 0.9793\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2925 - auc: 0.9796\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2807 - auc: 0.9800\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2830 - auc: 0.9794\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2791 - auc: 0.9806\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2818 - auc: 0.9809\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2814 - auc: 0.9821\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2716 - auc: 0.9817\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2749 - auc: 0.9829\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2734 - auc: 0.9823\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2625 - auc: 0.9838\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2715 - auc: 0.9841\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2726 - auc: 0.9820\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2768 - auc: 0.9813\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2871 - auc: 0.9834\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2603 - auc: 0.9822\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2719 - auc: 0.9849\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2657 - auc: 0.9839\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2718 - auc: 0.9838\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2744 - auc: 0.9838\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2750 - auc: 0.9838\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2679 - auc: 0.9834\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2670 - auc: 0.9856\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2687 - auc: 0.9841\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2594 - auc: 0.9852\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2726 - auc: 0.9837\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2761 - auc: 0.9859\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2693 - auc: 0.9845\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2766 - auc: 0.9852\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2727 - auc: 0.9848\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2623 - auc: 0.9851\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2586 - auc: 0.9855\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2704 - auc: 0.9844\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2762 - auc: 0.9848\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2708 - auc: 0.9853\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2773 - auc: 0.9855\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2763 - auc: 0.9851\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2688 - auc: 0.9860\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2691 - auc: 0.9860\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2681 - auc: 0.9856\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2701 - auc: 0.9845\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2586 - auc: 0.9859\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2681 - auc: 0.9857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.006522092288305101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.02573563049310848\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0065', 'eer_eval': '0.0257', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0065.hdf5', 'tnow': '2022-06-01 06:43:33.700856'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 44s 26ms/step - loss: 0.6742 - auc: 0.8761\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.4231 - auc: 0.9553\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.4040 - auc: 0.9588\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3539 - auc: 0.9642\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3367 - auc: 0.9647\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3700 - auc: 0.9634\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3386 - auc: 0.9658\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3301 - auc: 0.9692\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3277 - auc: 0.9694\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3134 - auc: 0.9707\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3177 - auc: 0.9694\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3241 - auc: 0.9704\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3140 - auc: 0.9713\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3138 - auc: 0.9727\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3038 - auc: 0.9716\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2971 - auc: 0.9742\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3115 - auc: 0.9744\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3190 - auc: 0.9737\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3030 - auc: 0.9753\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3142 - auc: 0.9751\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2887 - auc: 0.9769\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2970 - auc: 0.9778\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3117 - auc: 0.9770\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2933 - auc: 0.9796\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2906 - auc: 0.9760\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2954 - auc: 0.9778\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2955 - auc: 0.9790\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2822 - auc: 0.9788\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2734 - auc: 0.9800\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2923 - auc: 0.9794\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2940 - auc: 0.9809\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2772 - auc: 0.9801\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2901 - auc: 0.9809\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2746 - auc: 0.9832\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2760 - auc: 0.9812\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2777 - auc: 0.9825\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2687 - auc: 0.9825\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2810 - auc: 0.9833\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2848 - auc: 0.9826\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2687 - auc: 0.9819\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2741 - auc: 0.9822\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2760 - auc: 0.9818\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2714 - auc: 0.9826\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2760 - auc: 0.9836\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2753 - auc: 0.9844\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2747 - auc: 0.9840\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2667 - auc: 0.9840\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2608 - auc: 0.9842\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2803 - auc: 0.9838\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2697 - auc: 0.9846\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2734 - auc: 0.9845\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2782 - auc: 0.9832\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2579 - auc: 0.9843\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2586 - auc: 0.9844\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2612 - auc: 0.9853\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2656 - auc: 0.9836\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2743 - auc: 0.9841\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2619 - auc: 0.9848\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2680 - auc: 0.9840\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2730 - auc: 0.9854\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2662 - auc: 0.9851\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2663 - auc: 0.9850\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2689 - auc: 0.9854\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2697 - auc: 0.9853\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2770 - auc: 0.9843\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2715 - auc: 0.9846\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2650 - auc: 0.9853\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2671 - auc: 0.9845\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2750 - auc: 0.9854\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2778 - auc: 0.9839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.007408184681436492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03774660245586582\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0074', 'eer_eval': '0.0377', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0074.hdf5', 'tnow': '2022-06-01 07:32:42.023228'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 44s 26ms/step - loss: 0.7051 - auc: 0.8673\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.4268 - auc: 0.9554\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3943 - auc: 0.9610\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3669 - auc: 0.9629\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3741 - auc: 0.9624\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3514 - auc: 0.9653\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3363 - auc: 0.9674\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3271 - auc: 0.9681\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3205 - auc: 0.9695\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3153 - auc: 0.9711\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3156 - auc: 0.9718\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3086 - auc: 0.9723\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3122 - auc: 0.9714\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3133 - auc: 0.9728\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3146 - auc: 0.9731\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3050 - auc: 0.9731\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2924 - auc: 0.9753\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2965 - auc: 0.9754\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2898 - auc: 0.9742\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2965 - auc: 0.9762\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2992 - auc: 0.9742\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3064 - auc: 0.9759\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3075 - auc: 0.9773\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3024 - auc: 0.9776\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2985 - auc: 0.9767\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2851 - auc: 0.9788\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2884 - auc: 0.9777\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2894 - auc: 0.9784\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2867 - auc: 0.9796\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2784 - auc: 0.9806\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2704 - auc: 0.9784\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2901 - auc: 0.9801\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2890 - auc: 0.9812\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2877 - auc: 0.9814\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2833 - auc: 0.9817\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2685 - auc: 0.9814\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2696 - auc: 0.9812\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2742 - auc: 0.9826\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2762 - auc: 0.9829\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2845 - auc: 0.9819\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2791 - auc: 0.9818\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2808 - auc: 0.9846\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2673 - auc: 0.9841\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2779 - auc: 0.9833\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2768 - auc: 0.9834\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2740 - auc: 0.9833\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2748 - auc: 0.9841\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2628 - auc: 0.9849\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2671 - auc: 0.9839\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2745 - auc: 0.9845\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2744 - auc: 0.9846\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2669 - auc: 0.9842\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2764 - auc: 0.9840\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2719 - auc: 0.9841\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2583 - auc: 0.9842\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2685 - auc: 0.9863\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2692 - auc: 0.9844\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2643 - auc: 0.9853\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2702 - auc: 0.9859\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2854 - auc: 0.9851\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2594 - auc: 0.9847\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2639 - auc: 0.9847\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2626 - auc: 0.9865\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2698 - auc: 0.9838\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2640 - auc: 0.9859\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2612 - auc: 0.9846\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2670 - auc: 0.9857\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2726 - auc: 0.9852\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2590 - auc: 0.9864\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2695 - auc: 0.9844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.006039877116498388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03281736841958363\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0060', 'eer_eval': '0.0328', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0060.hdf5', 'tnow': '2022-06-01 08:22:14.765194'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 45s 27ms/step - loss: 0.6684 - auc: 0.8760\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3888 - auc: 0.9597\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3661 - auc: 0.9640\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3641 - auc: 0.9652\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3505 - auc: 0.9664\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3301 - auc: 0.9694\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3400 - auc: 0.9690\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3287 - auc: 0.9714\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3328 - auc: 0.9717\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3089 - auc: 0.9729\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3160 - auc: 0.9735\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3044 - auc: 0.9745\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2990 - auc: 0.9750\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2956 - auc: 0.9740\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2965 - auc: 0.9749\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2908 - auc: 0.9756\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2947 - auc: 0.9762\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2987 - auc: 0.9766\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2963 - auc: 0.9781\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3006 - auc: 0.9790\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2957 - auc: 0.9758\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2881 - auc: 0.9796\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2801 - auc: 0.9800\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2904 - auc: 0.9786\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2771 - auc: 0.9802\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2910 - auc: 0.9800\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2815 - auc: 0.9816\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2737 - auc: 0.9795\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2785 - auc: 0.9811\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2876 - auc: 0.9817\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2837 - auc: 0.9804\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2764 - auc: 0.9820\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2754 - auc: 0.9828\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2730 - auc: 0.9819\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2821 - auc: 0.9819\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2743 - auc: 0.9824\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2604 - auc: 0.9834\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2702 - auc: 0.9844\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2733 - auc: 0.9841\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2736 - auc: 0.9832\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2743 - auc: 0.9844\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2726 - auc: 0.9841\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2685 - auc: 0.9841\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2656 - auc: 0.9851\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2725 - auc: 0.9836\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2690 - auc: 0.9855\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2613 - auc: 0.9853\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2848 - auc: 0.9836\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2848 - auc: 0.9856\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2736 - auc: 0.9841\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2677 - auc: 0.9862\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2684 - auc: 0.9856\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2693 - auc: 0.9858\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2798 - auc: 0.9870\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2711 - auc: 0.9853\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2660 - auc: 0.9868\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2718 - auc: 0.9855\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2580 - auc: 0.9875\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2677 - auc: 0.9856\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2594 - auc: 0.9871\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2774 - auc: 0.9855\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2689 - auc: 0.9860\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2713 - auc: 0.9867\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2723 - auc: 0.9865\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2783 - auc: 0.9853\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2752 - auc: 0.9864\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2708 - auc: 0.9864\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2688 - auc: 0.9868\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2598 - auc: 0.9859\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2649 - auc: 0.9861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0056192685433396165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.020552988067524588\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0056', 'eer_eval': '0.0205', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0056.hdf5', 'tnow': '2022-06-01 09:12:13.718237'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 44s 26ms/step - loss: 0.6855 - auc: 0.8766\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3998 - auc: 0.9576\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3854 - auc: 0.9624\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3777 - auc: 0.9641\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3423 - auc: 0.9666\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3206 - auc: 0.9664\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3186 - auc: 0.9677\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3381 - auc: 0.9693\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3033 - auc: 0.9716\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3128 - auc: 0.9707\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3183 - auc: 0.9719\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3059 - auc: 0.9732\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2987 - auc: 0.9741\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3008 - auc: 0.9750\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3062 - auc: 0.9733\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3100 - auc: 0.9736\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2859 - auc: 0.9750\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3004 - auc: 0.9771\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3026 - auc: 0.9762\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2924 - auc: 0.9766\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2779 - auc: 0.9788\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2944 - auc: 0.9764\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2964 - auc: 0.9780\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2853 - auc: 0.9791\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2902 - auc: 0.9794\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3057 - auc: 0.9798\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2780 - auc: 0.9796\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2850 - auc: 0.9803\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2856 - auc: 0.9813\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2798 - auc: 0.9820\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2748 - auc: 0.9796\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2840 - auc: 0.9817\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2840 - auc: 0.9801\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2702 - auc: 0.9814\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2902 - auc: 0.9809\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2953 - auc: 0.9830\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2695 - auc: 0.9821\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2812 - auc: 0.9829\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2698 - auc: 0.9832\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2711 - auc: 0.9840\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2845 - auc: 0.9845\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2789 - auc: 0.9821\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2778 - auc: 0.9855\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2723 - auc: 0.9853\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2752 - auc: 0.9854 1s \n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2729 - auc: 0.9856\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2664 - auc: 0.9844\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2755 - auc: 0.9842\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2694 - auc: 0.9855\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2685 - auc: 0.9859\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2717 - auc: 0.9847\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2666 - auc: 0.9863\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2638 - auc: 0.9861\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2683 - auc: 0.9853\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2607 - auc: 0.9853\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2532 - auc: 0.9859\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2610 - auc: 0.9853\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2681 - auc: 0.9853\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2646 - auc: 0.9847\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2668 - auc: 0.9856\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2758 - auc: 0.9861\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2605 - auc: 0.9856\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2601 - auc: 0.9862\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2703 - auc: 0.9861\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2591 - auc: 0.9841\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2708 - auc: 0.9856\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2661 - auc: 0.9861\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2701 - auc: 0.9853\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2711 - auc: 0.9864\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2608 - auc: 0.9858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.007099764225312338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.018405865245446417\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0070', 'eer_eval': '0.0184', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0070.hdf5', 'tnow': '2022-06-01 10:01:27.028539'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 44s 26ms/step - loss: 0.6691 - auc: 0.8749\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.4172 - auc: 0.9592\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3753 - auc: 0.9638\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3753 - auc: 0.9624\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3381 - auc: 0.9645\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3352 - auc: 0.9682\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3259 - auc: 0.9710\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3406 - auc: 0.9697\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3142 - auc: 0.9710\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3199 - auc: 0.9714\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3125 - auc: 0.9736\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3022 - auc: 0.9732\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3005 - auc: 0.9747\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3135 - auc: 0.9744\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3013 - auc: 0.9753\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2967 - auc: 0.9753\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2844 - auc: 0.9773\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3046 - auc: 0.9767\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2917 - auc: 0.9769\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2825 - auc: 0.9804\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2887 - auc: 0.9770\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2833 - auc: 0.9784\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2907 - auc: 0.9788\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2860 - auc: 0.9792\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2738 - auc: 0.9810\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2893 - auc: 0.9797\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2802 - auc: 0.9819\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2904 - auc: 0.9800\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2681 - auc: 0.9807\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2937 - auc: 0.9820\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2734 - auc: 0.9816\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2697 - auc: 0.9803\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2775 - auc: 0.9824\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2793 - auc: 0.9819\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2733 - auc: 0.9818\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2758 - auc: 0.9834\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2684 - auc: 0.9843\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2765 - auc: 0.9843\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2753 - auc: 0.9846\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2715 - auc: 0.9841\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2773 - auc: 0.9846\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2678 - auc: 0.9845\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2604 - auc: 0.9842\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2622 - auc: 0.9844\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2667 - auc: 0.9849\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2710 - auc: 0.9858\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2676 - auc: 0.9858\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2655 - auc: 0.9856\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2578 - auc: 0.9860\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2661 - auc: 0.9838\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2656 - auc: 0.9852\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2638 - auc: 0.9857\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2646 - auc: 0.9848\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2772 - auc: 0.9854\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2598 - auc: 0.9860\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2670 - auc: 0.9866\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2727 - auc: 0.9861\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2665 - auc: 0.9849\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2660 - auc: 0.9861\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2680 - auc: 0.9872\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2731 - auc: 0.9865\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2701 - auc: 0.9853\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2709 - auc: 0.9858\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2555 - auc: 0.9866\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2589 - auc: 0.9855\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2610 - auc: 0.9860\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2611 - auc: 0.9864\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2644 - auc: 0.9861\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2588 - auc: 0.9852\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2646 - auc: 0.9865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.005507080426304999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.02553456696283874\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0055', 'eer_eval': '0.0255', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0055.hdf5', 'tnow': '2022-06-01 10:50:58.351405'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 45s 26ms/step - loss: 0.6705 - auc: 0.8727\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.4223 - auc: 0.9518\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3816 - auc: 0.9586\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3661 - auc: 0.9631\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3491 - auc: 0.9650\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3558 - auc: 0.9655\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3406 - auc: 0.9660\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3231 - auc: 0.9691\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3304 - auc: 0.9694\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3284 - auc: 0.9669\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3228 - auc: 0.9709\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3221 - auc: 0.9706\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3158 - auc: 0.9701\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2973 - auc: 0.9725\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3085 - auc: 0.9722\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3050 - auc: 0.9734\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2999 - auc: 0.9736\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2949 - auc: 0.9742\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2861 - auc: 0.9747\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2942 - auc: 0.9748\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2979 - auc: 0.9740\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2995 - auc: 0.9764\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3071 - auc: 0.9761\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2977 - auc: 0.9771\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2860 - auc: 0.9774\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2975 - auc: 0.9777\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2834 - auc: 0.9791\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2882 - auc: 0.9789\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2995 - auc: 0.9787\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2756 - auc: 0.9792\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2852 - auc: 0.9767\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2841 - auc: 0.9783\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2789 - auc: 0.9779\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2860 - auc: 0.9801\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2832 - auc: 0.9794\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2901 - auc: 0.9807\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2724 - auc: 0.9817\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2724 - auc: 0.9820\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2680 - auc: 0.9808\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2795 - auc: 0.9828\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2770 - auc: 0.9819\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2738 - auc: 0.9835\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2811 - auc: 0.9847\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2794 - auc: 0.9832\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2832 - auc: 0.9821\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2842 - auc: 0.9827\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2719 - auc: 0.9839\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2794 - auc: 0.9828\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2731 - auc: 0.9839\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2807 - auc: 0.9847\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2811 - auc: 0.9833\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2777 - auc: 0.9844\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2731 - auc: 0.9851\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2746 - auc: 0.9834\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2797 - auc: 0.9839\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2632 - auc: 0.9861\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2782 - auc: 0.9850\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2681 - auc: 0.9831\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2787 - auc: 0.9838\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2662 - auc: 0.9844\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2773 - auc: 0.9838\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2653 - auc: 0.9848\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2751 - auc: 0.9846\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2730 - auc: 0.9844\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2651 - auc: 0.9843\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2788 - auc: 0.9840\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2620 - auc: 0.9854\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2677 - auc: 0.9850\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2784 - auc: 0.9851\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2656 - auc: 0.9834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.003291849443476466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.037130203498455625\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0032', 'eer_eval': '0.0371', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0032.hdf5', 'tnow': '2022-06-01 11:40:34.276599'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 44s 26ms/step - loss: 0.7114 - auc: 0.8628\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.4219 - auc: 0.9539\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3909 - auc: 0.9589\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3892 - auc: 0.9607\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3499 - auc: 0.9636\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3576 - auc: 0.9620\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3288 - auc: 0.9660\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3270 - auc: 0.9684\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3455 - auc: 0.9689\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3098 - auc: 0.9708\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3268 - auc: 0.9695\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3083 - auc: 0.9710\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3162 - auc: 0.9694 0s - loss: 0.316\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3178 - auc: 0.9733\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3047 - auc: 0.9746\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3089 - auc: 0.9740\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3178 - auc: 0.9745\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3065 - auc: 0.9756\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3103 - auc: 0.9737\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2963 - auc: 0.9749\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2976 - auc: 0.9757\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3117 - auc: 0.9755\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3003 - auc: 0.9777\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2918 - auc: 0.9786\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2822 - auc: 0.9802\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2923 - auc: 0.9764\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2916 - auc: 0.9780\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2856 - auc: 0.9778\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2806 - auc: 0.9817\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2948 - auc: 0.9786\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2803 - auc: 0.9797\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2993 - auc: 0.9791\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2874 - auc: 0.9797\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2918 - auc: 0.9801\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2759 - auc: 0.9794\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2733 - auc: 0.9827\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2812 - auc: 0.9815\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2766 - auc: 0.9810\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2709 - auc: 0.9815\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2847 - auc: 0.9835\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2631 - auc: 0.9836\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2756 - auc: 0.9835\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2677 - auc: 0.9843\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2736 - auc: 0.9843\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2788 - auc: 0.9849\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2694 - auc: 0.9829\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2711 - auc: 0.9838\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2752 - auc: 0.9843\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2791 - auc: 0.9855\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2709 - auc: 0.9846\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2661 - auc: 0.9848\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2698 - auc: 0.9842\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2761 - auc: 0.9838\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2743 - auc: 0.9835\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2771 - auc: 0.9852\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2726 - auc: 0.9851\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2628 - auc: 0.9849\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2797 - auc: 0.9844\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2694 - auc: 0.9840\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2731 - auc: 0.9849\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2696 - auc: 0.9845\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2747 - auc: 0.9850\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2663 - auc: 0.9835\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2784 - auc: 0.9850\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2715 - auc: 0.9852\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2750 - auc: 0.9845\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2640 - auc: 0.9836\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2866 - auc: 0.9846\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2650 - auc: 0.9849\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2684 - auc: 0.9848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.005372454685863403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03522328069907823\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0053', 'eer_eval': '0.0352', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0053.hdf5', 'tnow': '2022-06-01 12:30:22.067457'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 44s 26ms/step - loss: 0.7268 - auc: 0.8589\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.4337 - auc: 0.9540\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3949 - auc: 0.9587\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3692 - auc: 0.9640\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3478 - auc: 0.9637\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3325 - auc: 0.9652\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3497 - auc: 0.9667\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3346 - auc: 0.9691\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3052 - auc: 0.9693\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3107 - auc: 0.9700\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3275 - auc: 0.9715\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3075 - auc: 0.9742\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3290 - auc: 0.9707\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3161 - auc: 0.9722\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3089 - auc: 0.9754\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3086 - auc: 0.9730\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3062 - auc: 0.9746\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3029 - auc: 0.9746\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2955 - auc: 0.9743\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2939 - auc: 0.9751\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3031 - auc: 0.9751\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2912 - auc: 0.9753\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2956 - auc: 0.9764\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3004 - auc: 0.9770\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2875 - auc: 0.9772\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2993 - auc: 0.9777\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2847 - auc: 0.9787\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3013 - auc: 0.9783\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2931 - auc: 0.9783\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2849 - auc: 0.9793\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2814 - auc: 0.9790\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2936 - auc: 0.9789\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2844 - auc: 0.9817\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2736 - auc: 0.9794\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2825 - auc: 0.9795\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2716 - auc: 0.9808\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2762 - auc: 0.9813\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2825 - auc: 0.9812\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2723 - auc: 0.9810\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2787 - auc: 0.9817\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2815 - auc: 0.9834\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2853 - auc: 0.9826\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2664 - auc: 0.9812\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2713 - auc: 0.9825\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2752 - auc: 0.9834\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2853 - auc: 0.9825\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2772 - auc: 0.9838\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2627 - auc: 0.9838\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2687 - auc: 0.9845\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2648 - auc: 0.9825\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2646 - auc: 0.9835\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2784 - auc: 0.9854\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2781 - auc: 0.9840\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2765 - auc: 0.9831\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2686 - auc: 0.9841\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2752 - auc: 0.9836\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2738 - auc: 0.9839\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2643 - auc: 0.9854\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2703 - auc: 0.9844\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2602 - auc: 0.9841\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2682 - auc: 0.9845\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2582 - auc: 0.9844\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2725 - auc: 0.9820\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2573 - auc: 0.9844\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2669 - auc: 0.9831\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2632 - auc: 0.9861\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2682 - auc: 0.9838\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2785 - auc: 0.9846\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2697 - auc: 0.9851\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2661 - auc: 0.9830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.005748188012208328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.04129676613646126\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'ResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0057', 'eer_eval': '0.0412', 'saved_model': 'saved_models/model_name!ResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0057.hdf5', 'tnow': '2022-06-01 13:19:42.560150'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 33s 19ms/step - loss: 0.5870 - auc: 0.8733\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.1086 - auc: 0.9954\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0820 - auc: 0.9975\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0587 - auc: 0.9988\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0675 - auc: 0.9981\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0517 - auc: 0.9990\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0321 - auc: 0.9993\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0295 - auc: 0.9993\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0433 - auc: 0.9988\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0382 - auc: 0.9994\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0257 - auc: 0.9994\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0240 - auc: 0.9994\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0152 - auc: 0.9997\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0206 - auc: 0.9998\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0211 - auc: 0.9995\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0093 - auc: 0.9999\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0283 - auc: 0.9995\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0127 - auc: 0.9997\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0133 - auc: 0.9998\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0086 - auc: 0.9999\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0140 - auc: 0.9995\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0069 - auc: 0.9999\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0063 - auc: 0.9999\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0145 - auc: 0.9996\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0108 - auc: 1.0000\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0033 - auc: 1.0000\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0092 - auc: 0.9997\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0083 - auc: 0.9998\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0052 - auc: 0.9998\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0038 - auc: 1.0000\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0035 - auc: 1.0000\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0085 - auc: 0.9999\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0026 - auc: 1.0000\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0069 - auc: 0.9999\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0037 - auc: 1.0000\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0011 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0043 - auc: 0.9999\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0018 - auc: 1.0000\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 7.2276e-04 - auc: 1.0000\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 9.1743e-04 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 4.9457e-04 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 8.0424e-04 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0012 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0017 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 9.5856e-04 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 5.8285e-04 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 4.9434e-04 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 3.0679e-04 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 2.6840e-04 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 6.4766e-04 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 4.7239e-04 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 4.0848e-04 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 1.8404e-04 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 2.7144e-04 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 1.3353e-04 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 1.9801e-04 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 1.7005e-04 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 5.2285e-04 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 1.0024e-04 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 1.4429e-04 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 2.2257e-04 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 2.2047e-04 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 1.3366e-04 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 1.5575e-04 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 1.6559e-04 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 1.0577e-04 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 8.9478e-05 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 4.5480e-04 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 1.1643e-04 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 1.7242e-04 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.005041596606332379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.025965556986951594\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0050', 'eer_eval': '0.0259', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0050.hdf5', 'tnow': '2022-06-01 13:56:49.342953'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 33s 19ms/step - loss: 0.6347 - auc: 0.8566\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.1189 - auc: 0.9955\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0876 - auc: 0.9974\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0751 - auc: 0.9980\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0640 - auc: 0.9986\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0580 - auc: 0.9987\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0367 - auc: 0.9995\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0330 - auc: 0.9993\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0351 - auc: 0.9994\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0295 - auc: 0.9994\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0174 - auc: 0.9995\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0270 - auc: 0.9993\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0315 - auc: 0.9995\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0103 - auc: 0.9998\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0169 - auc: 0.9997\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0091 - auc: 0.9999\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0207 - auc: 0.9997\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0149 - auc: 0.9995\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0185 - auc: 0.9995\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0089 - auc: 0.9999\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0110 - auc: 0.9998\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0102 - auc: 0.9998\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0079 - auc: 0.9999\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0091 - auc: 0.9999\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0074 - auc: 0.9998\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0075 - auc: 0.9999\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0066 - auc: 0.9999\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0085 - auc: 1.0000\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0033 - auc: 1.0000\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 30s 19ms/step - loss: 0.0172 - auc: 0.9996\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0086 - auc: 0.9998\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0020 - auc: 1.0000\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0064 - auc: 0.9999\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0029 - auc: 0.9999\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 30s 19ms/step - loss: 0.0011 - auc: 1.0000\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0040 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0050 - auc: 0.9998\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0024 - auc: 0.9999\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 30s 19ms/step - loss: 0.0021 - auc: 1.0000\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 7.2341e-04 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0030 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0027 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0014 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 7.8700e-04 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0011 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0014 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 4.2498e-04 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0010 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 4.1652e-04 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 6.6212e-04 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 8.8009e-04 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 2.0965e-04 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 2.5691e-04 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 5.0009e-04 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 6.4895e-04 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 1.9225e-04 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 1.6614e-04 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 1.8064e-04 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 2.0456e-04 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 2.3975e-04 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 8.2707e-05 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 1.0443e-04 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 1.3074e-04 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 3.8579e-04 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 2.1568e-04 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 4.1256e-04 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 1.2669e-04 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 1.6290e-04 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 2.3619e-04 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 1.2041e-04 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.004935114760870591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03427764659787573\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0049', 'eer_eval': '0.0342', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0049.hdf5', 'tnow': '2022-06-01 14:33:52.084514'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 33s 20ms/step - loss: 0.5621 - auc: 0.8705\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.1157 - auc: 0.9952\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0735 - auc: 0.9982\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0766 - auc: 0.9981\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0669 - auc: 0.9978\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0326 - auc: 0.9993\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0402 - auc: 0.9993\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0323 - auc: 0.9993\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0325 - auc: 0.9993\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0269 - auc: 0.9995\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0203 - auc: 0.9996\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0255 - auc: 0.9995\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0229 - auc: 0.9996\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0198 - auc: 0.9998\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0220 - auc: 0.9994\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0130 - auc: 0.9998\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0173 - auc: 0.9995\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0089 - auc: 1.0000\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0171 - auc: 0.9996\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0135 - auc: 0.9998\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0102 - auc: 0.9999\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0100 - auc: 0.9998\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0088 - auc: 0.9999\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0092 - auc: 0.9998\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0053 - auc: 0.9999\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0048 - auc: 0.9999\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0083 - auc: 0.9998\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0114 - auc: 0.9999\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0130 - auc: 0.9999\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0026 - auc: 1.0000\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0054 - auc: 0.9999\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0062 - auc: 0.9999\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0043 - auc: 0.9998\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0045 - auc: 0.9999\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0019 - auc: 1.0000\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0038 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0019 - auc: 1.0000\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0055 - auc: 0.9999\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 7.2980e-04 - auc: 1.0000\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0013 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0013 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0019 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0018 - auc: 0.9999\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0011 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0015 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 4.1318e-04 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 4.8331e-04 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 7.5178e-04 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 3.4282e-04 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 4.2374e-04 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 3.2323e-04 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.0037 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 3.5242e-04 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 2.8960e-04 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.0017 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 3.8585e-04 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 2.1424e-04 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 2.5571e-04 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 3.8185e-04 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 3.3618e-04 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 4.1039e-04 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 2.5015e-04 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 1.2843e-04 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 4.9225e-04 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 3.0800e-04 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 3.6107e-04 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 2.1590e-04 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 1.1075e-04 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 2.8727e-04 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 2.2959e-04 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.005108909476553149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03522328069907823\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0051', 'eer_eval': '0.0352', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0051.hdf5', 'tnow': '2022-06-01 15:10:59.897279'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 33s 20ms/step - loss: 0.8928 - auc: 0.7974\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.4469 - auc: 0.9524\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.4102 - auc: 0.9561\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3774 - auc: 0.9601\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3684 - auc: 0.9612\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3507 - auc: 0.9629\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3399 - auc: 0.9659\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3365 - auc: 0.9666\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3415 - auc: 0.9645\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3309 - auc: 0.9666\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3277 - auc: 0.9669\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3425 - auc: 0.9667\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3298 - auc: 0.9689\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3234 - auc: 0.9705\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3347 - auc: 0.9702\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3196 - auc: 0.9711\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3354 - auc: 0.9705\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3147 - auc: 0.9719\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3171 - auc: 0.9708\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3076 - auc: 0.9736\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3138 - auc: 0.9750\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3049 - auc: 0.9713\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3135 - auc: 0.9734\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2953 - auc: 0.9733\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3089 - auc: 0.9740\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2973 - auc: 0.9753\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3040 - auc: 0.9740\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3015 - auc: 0.9742\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2936 - auc: 0.9750\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3156 - auc: 0.9745\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2989 - auc: 0.9737\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2974 - auc: 0.9759\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2952 - auc: 0.9746\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2978 - auc: 0.9752\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3025 - auc: 0.9753\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2975 - auc: 0.9763\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2862 - auc: 0.9764\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2842 - auc: 0.9777\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3018 - auc: 0.9762\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3065 - auc: 0.9762\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2821 - auc: 0.9780\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2926 - auc: 0.9784\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2764 - auc: 0.9791\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2934 - auc: 0.9781\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2854 - auc: 0.9787\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2824 - auc: 0.9796\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2822 - auc: 0.9787\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2813 - auc: 0.9794\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2856 - auc: 0.9776\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2937 - auc: 0.9789\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2774 - auc: 0.9788\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2818 - auc: 0.9794\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2913 - auc: 0.9795\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2849 - auc: 0.9811\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2686 - auc: 0.9798\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2764 - auc: 0.9793\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2822 - auc: 0.9801\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2817 - auc: 0.9803\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2886 - auc: 0.9808\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2855 - auc: 0.9785\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2844 - auc: 0.9787\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2728 - auc: 0.9804\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2955 - auc: 0.9779\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2853 - auc: 0.9797\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2692 - auc: 0.9805\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2727 - auc: 0.9789\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2778 - auc: 0.9799\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2832 - auc: 0.9808\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2905 - auc: 0.9805\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2797 - auc: 0.9798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.004088191342980163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03236289650001213\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0040', 'eer_eval': '0.0323', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0040.hdf5', 'tnow': '2022-06-01 15:48:18.248103'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 33s 20ms/step - loss: 0.8434 - auc: 0.8049\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.4464 - auc: 0.9495\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3983 - auc: 0.9587\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3750 - auc: 0.9607\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3649 - auc: 0.9610\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3565 - auc: 0.9614\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3444 - auc: 0.9648\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3398 - auc: 0.9648\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3392 - auc: 0.9662\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3276 - auc: 0.9668\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3444 - auc: 0.9692\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3302 - auc: 0.9672\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3056 - auc: 0.9706\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3270 - auc: 0.9698\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3298 - auc: 0.9696\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3115 - auc: 0.9711\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3247 - auc: 0.9704\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3107 - auc: 0.9723\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3205 - auc: 0.9718\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3096 - auc: 0.9726\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3011 - auc: 0.9725\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3104 - auc: 0.9736\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3048 - auc: 0.9749\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3154 - auc: 0.9735\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3139 - auc: 0.9727\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2941 - auc: 0.9741\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2904 - auc: 0.9751\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2960 - auc: 0.9744\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2982 - auc: 0.9745\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2919 - auc: 0.9738\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2957 - auc: 0.9760\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2964 - auc: 0.9769\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2882 - auc: 0.9771\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2989 - auc: 0.9769\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2902 - auc: 0.9769\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2899 - auc: 0.9777\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2984 - auc: 0.9777\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2811 - auc: 0.9787\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2896 - auc: 0.9770\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2840 - auc: 0.9789\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3000 - auc: 0.9779\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2863 - auc: 0.9789\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2878 - auc: 0.9787\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2887 - auc: 0.9796\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2835 - auc: 0.9812\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2785 - auc: 0.9791\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2776 - auc: 0.9791\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2782 - auc: 0.9813\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2805 - auc: 0.9780\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2869 - auc: 0.9806\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2826 - auc: 0.9799\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2947 - auc: 0.9805\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2887 - auc: 0.9798\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2832 - auc: 0.9800\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2789 - auc: 0.9801\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2729 - auc: 0.9793\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2761 - auc: 0.9809\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2907 - auc: 0.9809\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2761 - auc: 0.9791\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2887 - auc: 0.9810\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2699 - auc: 0.9809\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2807 - auc: 0.9808\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2768 - auc: 0.9796\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2861 - auc: 0.9806\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2824 - auc: 0.9803\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2810 - auc: 0.9819\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2742 - auc: 0.9812\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2721 - auc: 0.9812\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2695 - auc: 0.9801\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2793 - auc: 0.9801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.003628413794580429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.029134140664722814\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0036', 'eer_eval': '0.0291', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0036.hdf5', 'tnow': '2022-06-01 16:25:32.724159'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 33s 20ms/step - loss: 0.8784 - auc: 0.7927\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.4243 - auc: 0.9540\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3952 - auc: 0.9574\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3777 - auc: 0.9589\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3598 - auc: 0.9599\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3762 - auc: 0.9628\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3542 - auc: 0.9646\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3446 - auc: 0.9645\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3514 - auc: 0.9663\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3499 - auc: 0.9641\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3105 - auc: 0.9688\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3391 - auc: 0.9673\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3348 - auc: 0.9688\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3156 - auc: 0.9689\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3079 - auc: 0.9684\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3255 - auc: 0.9717\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3185 - auc: 0.9697\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3050 - auc: 0.9715\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3155 - auc: 0.9723\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2971 - auc: 0.9709\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3163 - auc: 0.9731\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3280 - auc: 0.9704\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3198 - auc: 0.9724\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3062 - auc: 0.9738\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3053 - auc: 0.9733\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3093 - auc: 0.9724\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3058 - auc: 0.9744\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3003 - auc: 0.9736\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2984 - auc: 0.9736\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2941 - auc: 0.9766\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3049 - auc: 0.9758\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2972 - auc: 0.9756\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2895 - auc: 0.9752\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2930 - auc: 0.9762\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3075 - auc: 0.9765\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3021 - auc: 0.9781\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2932 - auc: 0.9765\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2987 - auc: 0.9766\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2860 - auc: 0.9784\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2800 - auc: 0.9794\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2964 - auc: 0.9774\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2780 - auc: 0.9773\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2929 - auc: 0.9796\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2783 - auc: 0.9790\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2754 - auc: 0.9812\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2883 - auc: 0.9789\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2867 - auc: 0.9799\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2836 - auc: 0.9796\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2704 - auc: 0.9793\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2769 - auc: 0.9805\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2690 - auc: 0.9786\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2795 - auc: 0.9795\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2876 - auc: 0.9801\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2850 - auc: 0.9808\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2897 - auc: 0.9803\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2779 - auc: 0.9817\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2671 - auc: 0.9789\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2841 - auc: 0.9795\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2759 - auc: 0.9807\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2871 - auc: 0.9806\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2920 - auc: 0.9802\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2763 - auc: 0.9798\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2767 - auc: 0.9804\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2798 - auc: 0.9793\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2832 - auc: 0.9795\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2762 - auc: 0.9806\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2637 - auc: 0.9794\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2925 - auc: 0.9809\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2847 - auc: 0.9806\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2810 - auc: 0.9801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0033367246902903684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03184825242292254\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0033', 'eer_eval': '0.0318', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0033.hdf5', 'tnow': '2022-06-01 17:02:49.518042'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 33s 20ms/step - loss: 0.8537 - auc: 0.8005\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4307 - auc: 0.9497\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.4120 - auc: 0.9575\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3592 - auc: 0.9606\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3573 - auc: 0.9625\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3723 - auc: 0.9631\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3406 - auc: 0.9652\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3544 - auc: 0.9648\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3360 - auc: 0.9657\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3400 - auc: 0.9667\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3246 - auc: 0.9666\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3330 - auc: 0.9679\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3148 - auc: 0.9668\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3263 - auc: 0.9676\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3222 - auc: 0.9698\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3230 - auc: 0.9695\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 30s 19ms/step - loss: 0.3108 - auc: 0.9706\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3029 - auc: 0.9703\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3173 - auc: 0.9718\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3182 - auc: 0.9705\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3098 - auc: 0.9716\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3104 - auc: 0.9727\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3089 - auc: 0.9718\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3156 - auc: 0.9734\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3101 - auc: 0.9735\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3033 - auc: 0.9731\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3021 - auc: 0.9730\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3049 - auc: 0.9739\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3016 - auc: 0.9750\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3036 - auc: 0.9738\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2967 - auc: 0.9748\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3031 - auc: 0.9750\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2994 - auc: 0.9753\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2839 - auc: 0.9754\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2818 - auc: 0.9774\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2927 - auc: 0.9760\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3056 - auc: 0.9761\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2881 - auc: 0.9773\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2966 - auc: 0.9769\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2841 - auc: 0.9785\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3137 - auc: 0.9788\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2877 - auc: 0.9783\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2831 - auc: 0.9786\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2963 - auc: 0.9795\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2884 - auc: 0.9769\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2850 - auc: 0.9796\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2785 - auc: 0.9793\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2894 - auc: 0.9773\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2811 - auc: 0.9780\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2842 - auc: 0.9788\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2934 - auc: 0.9790\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2935 - auc: 0.9798\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2885 - auc: 0.9794\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2777 - auc: 0.9794\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2795 - auc: 0.9803\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2794 - auc: 0.9803\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2788 - auc: 0.9803\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2850 - auc: 0.9804\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2935 - auc: 0.9797\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.2801 - auc: 0.9801\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2924 - auc: 0.9802\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2926 - auc: 0.9794\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2761 - auc: 0.9801\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2854 - auc: 0.9802\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.2793 - auc: 0.9802\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.2924 - auc: 0.9792\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3026 - auc: 0.9808\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2875 - auc: 0.9795\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2821 - auc: 0.9794\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2842 - auc: 0.9798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.004245254706828683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.027441489762216137\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0042', 'eer_eval': '0.0274', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0042.hdf5', 'tnow': '2022-06-01 17:40:11.515167'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 34s 20ms/step - loss: 0.8240 - auc: 0.8047\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.4099 - auc: 0.9519\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3955 - auc: 0.9565\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3702 - auc: 0.9581\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3631 - auc: 0.9622\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3599 - auc: 0.9623\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3464 - auc: 0.9649\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3498 - auc: 0.9648\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3337 - auc: 0.9672\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3446 - auc: 0.9655\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3330 - auc: 0.9668\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3347 - auc: 0.9677\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3071 - auc: 0.9698\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3357 - auc: 0.9678\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3261 - auc: 0.9700\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3167 - auc: 0.9690\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3128 - auc: 0.9706\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3098 - auc: 0.9707\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3195 - auc: 0.9712\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3041 - auc: 0.9713\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3052 - auc: 0.9737\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3201 - auc: 0.9728\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2937 - auc: 0.9728\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2994 - auc: 0.9728\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2973 - auc: 0.9749\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3022 - auc: 0.9741\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3122 - auc: 0.9719\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2878 - auc: 0.9756\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2989 - auc: 0.9732\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3023 - auc: 0.9730\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3041 - auc: 0.9757\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2995 - auc: 0.9745\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3021 - auc: 0.9773\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3064 - auc: 0.9766\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2998 - auc: 0.9762\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2836 - auc: 0.9765\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2900 - auc: 0.9761\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2975 - auc: 0.9764\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2999 - auc: 0.9756\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2877 - auc: 0.9782\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2912 - auc: 0.9756\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2845 - auc: 0.9774\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3015 - auc: 0.9782\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2699 - auc: 0.9788\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2928 - auc: 0.9784\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2845 - auc: 0.9770\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2794 - auc: 0.9787\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2893 - auc: 0.9796\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2920 - auc: 0.9807\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2879 - auc: 0.9790\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.2847 - auc: 0.9788\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2787 - auc: 0.9789\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2772 - auc: 0.9806\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2783 - auc: 0.9803\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2829 - auc: 0.9796\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2866 - auc: 0.9791\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2810 - auc: 0.9786\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2814 - auc: 0.9793\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2904 - auc: 0.9781\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2848 - auc: 0.9803\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2823 - auc: 0.9794\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2781 - auc: 0.9796\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2800 - auc: 0.9802\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3005 - auc: 0.9792\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2909 - auc: 0.9783\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2819 - auc: 0.9790\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2751 - auc: 0.9801\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2811 - auc: 0.9795\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2902 - auc: 0.9783\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2728 - auc: 0.9798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0046209880331736074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03281736841958363\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0046', 'eer_eval': '0.0328', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0046.hdf5', 'tnow': '2022-06-01 18:17:34.017111'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 33s 19ms/step - loss: 0.8513 - auc: 0.7979\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.4045 - auc: 0.9554\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3917 - auc: 0.9559\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3864 - auc: 0.9618\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3601 - auc: 0.9602\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3525 - auc: 0.9653\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3558 - auc: 0.9627\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3427 - auc: 0.9631\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3309 - auc: 0.9654\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3481 - auc: 0.9651\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3211 - auc: 0.9665\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3276 - auc: 0.9667\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3356 - auc: 0.9682\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3287 - auc: 0.9681\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3271 - auc: 0.9708\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3284 - auc: 0.9695\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3115 - auc: 0.9703\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3149 - auc: 0.9703\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3143 - auc: 0.9724\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3215 - auc: 0.9720\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3024 - auc: 0.9702\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3085 - auc: 0.9714\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3033 - auc: 0.9718\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3200 - auc: 0.9722\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.3157 - auc: 0.9733\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3093 - auc: 0.9726\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2930 - auc: 0.9738\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2935 - auc: 0.9745\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3073 - auc: 0.9737\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2981 - auc: 0.9741\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2954 - auc: 0.9755\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3011 - auc: 0.9757\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2911 - auc: 0.9745\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2917 - auc: 0.9769\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3024 - auc: 0.9771\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2839 - auc: 0.9765\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2877 - auc: 0.9745\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2942 - auc: 0.9776\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2859 - auc: 0.9774\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2893 - auc: 0.9774\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2869 - auc: 0.9790\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2898 - auc: 0.9796\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2992 - auc: 0.9789\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2796 - auc: 0.9797\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2934 - auc: 0.9796\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2958 - auc: 0.9775\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2826 - auc: 0.9794\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2728 - auc: 0.9805\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2820 - auc: 0.9798\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2866 - auc: 0.9795\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2870 - auc: 0.9791\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2851 - auc: 0.9790\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2815 - auc: 0.9799\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2847 - auc: 0.9798\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2867 - auc: 0.9803\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2915 - auc: 0.9798\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2757 - auc: 0.9810\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2824 - auc: 0.9798\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2776 - auc: 0.9806\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2821 - auc: 0.9799\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.2893 - auc: 0.9790\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2887 - auc: 0.9806\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2751 - auc: 0.9807\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2855 - auc: 0.9792\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2942 - auc: 0.9789\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2882 - auc: 0.9813\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2903 - auc: 0.9800\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2865 - auc: 0.9788\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2663 - auc: 0.9793\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2974 - auc: 0.9796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0044023180706772025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.026396547011064503\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0044', 'eer_eval': '0.0263', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0044.hdf5', 'tnow': '2022-06-01 18:54:52.053062'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 33s 19ms/step - loss: 0.8636 - auc: 0.7954\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4286 - auc: 0.9518\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4124 - auc: 0.9571\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4021 - auc: 0.9583\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3551 - auc: 0.9604\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3505 - auc: 0.9641\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3603 - auc: 0.9630\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3498 - auc: 0.9638\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3445 - auc: 0.9661\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3666 - auc: 0.9656\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3450 - auc: 0.9668\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3275 - auc: 0.9656\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3395 - auc: 0.9690\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3329 - auc: 0.9695\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3177 - auc: 0.9690\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3215 - auc: 0.9695\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3288 - auc: 0.9707\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3243 - auc: 0.9697\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3159 - auc: 0.9695\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3265 - auc: 0.9721\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3172 - auc: 0.9696\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3102 - auc: 0.9706\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3000 - auc: 0.9719\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2957 - auc: 0.9729\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3090 - auc: 0.9720\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3138 - auc: 0.9723\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3045 - auc: 0.9733\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2999 - auc: 0.9736\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2983 - auc: 0.9737\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3044 - auc: 0.9747\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2927 - auc: 0.9744\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2972 - auc: 0.9750\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3069 - auc: 0.9747\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2917 - auc: 0.9754\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2921 - auc: 0.9766\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2811 - auc: 0.9753\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2888 - auc: 0.9771\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2859 - auc: 0.9765\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2999 - auc: 0.9764\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2913 - auc: 0.9768\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2842 - auc: 0.9772\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2923 - auc: 0.9780\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2832 - auc: 0.9777\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2957 - auc: 0.9777\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2830 - auc: 0.9786\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2896 - auc: 0.9768\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2791 - auc: 0.9780\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2856 - auc: 0.9781\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2879 - auc: 0.9781\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2913 - auc: 0.9790\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2842 - auc: 0.9786\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2729 - auc: 0.9784\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2760 - auc: 0.9812\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2832 - auc: 0.9775\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2924 - auc: 0.9790\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2824 - auc: 0.9786\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2869 - auc: 0.9806\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2893 - auc: 0.9796\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2960 - auc: 0.9779\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2748 - auc: 0.9803\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3005 - auc: 0.9809\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2837 - auc: 0.9787\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2812 - auc: 0.9801\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2809 - auc: 0.9799\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2973 - auc: 0.9804\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2940 - auc: 0.9795\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2868 - auc: 0.9800\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2831 - auc: 0.9799\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2845 - auc: 0.9784\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2765 - auc: 0.9792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.003465644159159024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.022574874113823515\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0034', 'eer_eval': '0.0225', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0034.hdf5', 'tnow': '2022-06-01 19:31:59.560384'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 33s 19ms/step - loss: 0.9068 - auc: 0.7874\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4363 - auc: 0.9495\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4177 - auc: 0.9554\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3865 - auc: 0.9589\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3835 - auc: 0.9607\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3708 - auc: 0.9622\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3547 - auc: 0.9634\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3501 - auc: 0.9656\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3473 - auc: 0.9647\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3483 - auc: 0.9672\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3391 - auc: 0.9657\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3493 - auc: 0.9656\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3263 - auc: 0.9654\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3286 - auc: 0.9697\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3099 - auc: 0.9705\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3259 - auc: 0.9700\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3165 - auc: 0.9690\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3329 - auc: 0.9690\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 30s 19ms/step - loss: 0.3104 - auc: 0.9713\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3395 - auc: 0.9702\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3387 - auc: 0.9706\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3077 - auc: 0.9712\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3202 - auc: 0.9717\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3175 - auc: 0.9696\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3028 - auc: 0.9721\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3062 - auc: 0.9713\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3068 - auc: 0.9726\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2983 - auc: 0.9730\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3133 - auc: 0.9724\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3022 - auc: 0.9735\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3131 - auc: 0.9721\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3010 - auc: 0.9754\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3000 - auc: 0.9759\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3069 - auc: 0.9745\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2906 - auc: 0.9738\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2988 - auc: 0.9757\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3023 - auc: 0.9762\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2866 - auc: 0.9771\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2838 - auc: 0.9768\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2815 - auc: 0.9785\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2814 - auc: 0.9777\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2770 - auc: 0.9785\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2843 - auc: 0.9790\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2817 - auc: 0.9778\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2740 - auc: 0.9785\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2907 - auc: 0.9808\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2923 - auc: 0.9776\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2880 - auc: 0.9805\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2945 - auc: 0.9788\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2950 - auc: 0.9799\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2795 - auc: 0.9787\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2990 - auc: 0.9804\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2870 - auc: 0.9797\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2891 - auc: 0.9794\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2807 - auc: 0.9793\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2818 - auc: 0.9797\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2930 - auc: 0.9772\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2839 - auc: 0.9802\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2795 - auc: 0.9797\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2740 - auc: 0.9793\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2758 - auc: 0.9799\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2753 - auc: 0.9794\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2853 - auc: 0.9792\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2787 - auc: 0.9803\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2722 - auc: 0.9792\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2925 - auc: 0.9803\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2831 - auc: 0.9794\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2779 - auc: 0.9791\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2792 - auc: 0.9806\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2765 - auc: 0.9816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0022878626617375726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.019905279916169548\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0022', 'eer_eval': '0.0199', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0022.hdf5', 'tnow': '2022-06-01 20:08:56.740313'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 33s 19ms/step - loss: 0.9231 - auc: 0.7842\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.4404 - auc: 0.9508\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4171 - auc: 0.9579\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3923 - auc: 0.9597\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3872 - auc: 0.9600\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3606 - auc: 0.9624\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3647 - auc: 0.9633\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3655 - auc: 0.9626\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3652 - auc: 0.9644\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3417 - auc: 0.9650\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3356 - auc: 0.9652\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3402 - auc: 0.9667\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3304 - auc: 0.9665\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3164 - auc: 0.9680\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3039 - auc: 0.9692\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3274 - auc: 0.9690\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3250 - auc: 0.9702\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3359 - auc: 0.9688\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3130 - auc: 0.9685\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3128 - auc: 0.9718\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3122 - auc: 0.9713\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3106 - auc: 0.9712\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3174 - auc: 0.9714\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3191 - auc: 0.9723\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3075 - auc: 0.9722\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3233 - auc: 0.9737\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3008 - auc: 0.9735\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2957 - auc: 0.9756\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3156 - auc: 0.9727\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2971 - auc: 0.9730\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3123 - auc: 0.9743\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3006 - auc: 0.9761\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3044 - auc: 0.9732\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2939 - auc: 0.9747\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2945 - auc: 0.9763\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3025 - auc: 0.9754\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2951 - auc: 0.9762\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2906 - auc: 0.9774\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 30s 19ms/step - loss: 0.3136 - auc: 0.9763\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 30s 19ms/step - loss: 0.2960 - auc: 0.9779\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2905 - auc: 0.9774\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2936 - auc: 0.9781\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2935 - auc: 0.9781\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2838 - auc: 0.9777\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2893 - auc: 0.9783\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2771 - auc: 0.9786\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2868 - auc: 0.9773\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2899 - auc: 0.9785\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2735 - auc: 0.9788\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2784 - auc: 0.9776\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2756 - auc: 0.9798\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2711 - auc: 0.9789\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2824 - auc: 0.9805\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2877 - auc: 0.9784\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2938 - auc: 0.9794\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2835 - auc: 0.9801\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2899 - auc: 0.9807\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3020 - auc: 0.9794\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2867 - auc: 0.9792\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2764 - auc: 0.9802\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2801 - auc: 0.9793\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2904 - auc: 0.9794\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2877 - auc: 0.9795\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2789 - auc: 0.9797\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2700 - auc: 0.9794\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2931 - auc: 0.9797\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3035 - auc: 0.9801\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2912 - auc: 0.9801\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2780 - auc: 0.9804\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2775 - auc: 0.9798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.004463924669325088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.018714064724151547\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0044', 'eer_eval': '0.0187', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0044.hdf5', 'tnow': '2022-06-01 20:46:02.099877'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 33s 19ms/step - loss: 0.8636 - auc: 0.7991\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.4522 - auc: 0.9486\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4069 - auc: 0.9570\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3931 - auc: 0.9563\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3743 - auc: 0.9604\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3778 - auc: 0.9616\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3748 - auc: 0.9604\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3584 - auc: 0.9644\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3632 - auc: 0.9648\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3607 - auc: 0.9646\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3350 - auc: 0.9655\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3368 - auc: 0.9655\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3261 - auc: 0.9654\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3296 - auc: 0.9669\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3343 - auc: 0.9684\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3210 - auc: 0.9674\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3196 - auc: 0.9676\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3160 - auc: 0.9690\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3208 - auc: 0.9690\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3206 - auc: 0.9707\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3107 - auc: 0.9717\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3264 - auc: 0.9701\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3132 - auc: 0.9728\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3239 - auc: 0.9720\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3094 - auc: 0.9731\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3147 - auc: 0.9721\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3083 - auc: 0.9724\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3208 - auc: 0.9726\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2951 - auc: 0.9729\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3041 - auc: 0.9744\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3055 - auc: 0.9716\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2981 - auc: 0.9754\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2962 - auc: 0.9748\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3065 - auc: 0.9759\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3207 - auc: 0.9749\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2952 - auc: 0.9761\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2956 - auc: 0.9747\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3080 - auc: 0.9742\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2893 - auc: 0.9739\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2901 - auc: 0.9761\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2789 - auc: 0.9774\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2870 - auc: 0.9758\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3062 - auc: 0.9754\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2998 - auc: 0.9778\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2825 - auc: 0.9777\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2925 - auc: 0.9769\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2838 - auc: 0.9782\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3007 - auc: 0.9771\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2768 - auc: 0.9785\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3031 - auc: 0.9782\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3024 - auc: 0.9779\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2880 - auc: 0.9770\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2823 - auc: 0.9790\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2754 - auc: 0.9777\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3023 - auc: 0.9795\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2990 - auc: 0.9786\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2941 - auc: 0.9792\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3014 - auc: 0.9790\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2935 - auc: 0.9773\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2838 - auc: 0.9769\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2949 - auc: 0.9791\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2816 - auc: 0.9788\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2749 - auc: 0.9773\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2878 - auc: 0.9785\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2841 - auc: 0.9778\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2934 - auc: 0.9777\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2900 - auc: 0.9779\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3054 - auc: 0.9772\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2986 - auc: 0.9789\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2948 - auc: 0.9786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0036675827698213906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03250134164239231\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0036', 'eer_eval': '0.0325', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0036.hdf5', 'tnow': '2022-06-01 21:23:16.239009'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 33s 19ms/step - loss: 0.8962 - auc: 0.7925\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.4802 - auc: 0.9415\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.4305 - auc: 0.9522\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3734 - auc: 0.9582\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3862 - auc: 0.9572\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3706 - auc: 0.9621\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3452 - auc: 0.9628\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3612 - auc: 0.9627\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3443 - auc: 0.9638\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3359 - auc: 0.9648\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3383 - auc: 0.9642\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3582 - auc: 0.9661\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3398 - auc: 0.9674\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3334 - auc: 0.9671\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3164 - auc: 0.9673\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3292 - auc: 0.9680\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3204 - auc: 0.9689\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3365 - auc: 0.9665\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3270 - auc: 0.9668\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3278 - auc: 0.9721\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.3208 - auc: 0.9713\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3170 - auc: 0.9693\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3205 - auc: 0.9710\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3070 - auc: 0.9713\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3188 - auc: 0.9718\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3123 - auc: 0.9706\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3257 - auc: 0.9715\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3078 - auc: 0.9728\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3213 - auc: 0.9720\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3060 - auc: 0.9734\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3289 - auc: 0.9739 1s - loss\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3113 - auc: 0.9739\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.3063 - auc: 0.9726\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2982 - auc: 0.9726\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3004 - auc: 0.9705\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3026 - auc: 0.9724\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2969 - auc: 0.9753\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2957 - auc: 0.9748\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2981 - auc: 0.9764\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2900 - auc: 0.9759\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2907 - auc: 0.9779\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2985 - auc: 0.9762\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2852 - auc: 0.9768\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2979 - auc: 0.9745\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2951 - auc: 0.9767\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2921 - auc: 0.9764\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2817 - auc: 0.9759\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2867 - auc: 0.9773\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2886 - auc: 0.9776\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2767 - auc: 0.9778\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2843 - auc: 0.9790\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2951 - auc: 0.9776\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2870 - auc: 0.9779\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.2964 - auc: 0.9780\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2886 - auc: 0.9782\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2891 - auc: 0.9783\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2874 - auc: 0.9785\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2909 - auc: 0.9784\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2937 - auc: 0.9788\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2836 - auc: 0.9781\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2914 - auc: 0.9781\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2920 - auc: 0.9795\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2961 - auc: 0.9792\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2837 - auc: 0.9773\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2830 - auc: 0.9768\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2885 - auc: 0.9781\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2813 - auc: 0.9785\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2845 - auc: 0.9794\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2730 - auc: 0.9765\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2843 - auc: 0.9787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.006656718028746642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03769181136646245\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0066', 'eer_eval': '0.0376', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0066.hdf5', 'tnow': '2022-06-01 22:00:42.325706'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 33s 20ms/step - loss: 0.8544 - auc: 0.7890\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4603 - auc: 0.9459\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4367 - auc: 0.9536\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4131 - auc: 0.9555\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3784 - auc: 0.9583\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3796 - auc: 0.9612\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3666 - auc: 0.9616\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3644 - auc: 0.9623\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3416 - auc: 0.9638\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3573 - auc: 0.9644\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3349 - auc: 0.9654\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3383 - auc: 0.9654\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3293 - auc: 0.9677\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3268 - auc: 0.9666\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3223 - auc: 0.9672\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3335 - auc: 0.9699\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3405 - auc: 0.9684\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3337 - auc: 0.9681\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3245 - auc: 0.9683\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3504 - auc: 0.9691\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3177 - auc: 0.9713\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3242 - auc: 0.9699\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3223 - auc: 0.9717\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3102 - auc: 0.9709\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3155 - auc: 0.9706\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3107 - auc: 0.9724\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3163 - auc: 0.9710\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3098 - auc: 0.9737\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3060 - auc: 0.9724\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3076 - auc: 0.9721\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3030 - auc: 0.9727\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3012 - auc: 0.9741\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3072 - auc: 0.9734\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3070 - auc: 0.9738\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.3101 - auc: 0.9742\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2937 - auc: 0.9753\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3020 - auc: 0.9756\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 30s 19ms/step - loss: 0.3013 - auc: 0.9753\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2999 - auc: 0.9765\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3028 - auc: 0.9757\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2936 - auc: 0.9765\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2858 - auc: 0.9762\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2791 - auc: 0.9770\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3012 - auc: 0.9768\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2804 - auc: 0.9770\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2811 - auc: 0.9771\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2994 - auc: 0.9774\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2885 - auc: 0.9777\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2943 - auc: 0.9775\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2949 - auc: 0.9776\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2932 - auc: 0.9784\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2882 - auc: 0.9763\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3081 - auc: 0.9769\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2894 - auc: 0.9777\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2774 - auc: 0.9773\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3007 - auc: 0.9780\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3005 - auc: 0.9776\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3014 - auc: 0.9784\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2915 - auc: 0.9774\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2857 - auc: 0.9772\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2811 - auc: 0.9780\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2916 - auc: 0.9789\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2943 - auc: 0.9789\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2864 - auc: 0.9764\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2833 - auc: 0.9779\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2933 - auc: 0.9776\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3014 - auc: 0.9783\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2853 - auc: 0.9775\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2907 - auc: 0.9777\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2831 - auc: 0.9778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0041106289663870865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03550799828232472\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0041', 'eer_eval': '0.0355', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0041.hdf5', 'tnow': '2022-06-01 22:37:54.017803'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 33s 19ms/step - loss: 0.8699 - auc: 0.7924\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4379 - auc: 0.9496\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.4125 - auc: 0.9542\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3931 - auc: 0.9584\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3840 - auc: 0.9595\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3751 - auc: 0.9609\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3668 - auc: 0.9627\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3638 - auc: 0.9632\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3452 - auc: 0.9628\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3494 - auc: 0.9649\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3433 - auc: 0.9653\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3342 - auc: 0.9631\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3506 - auc: 0.9670\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3179 - auc: 0.9678\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3345 - auc: 0.9676\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3097 - auc: 0.9717\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3267 - auc: 0.9674\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3290 - auc: 0.9686\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3169 - auc: 0.9682\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3140 - auc: 0.9697\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3075 - auc: 0.9696\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3139 - auc: 0.9707\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3210 - auc: 0.9686\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3122 - auc: 0.9714\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3221 - auc: 0.9722\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3074 - auc: 0.9703\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3018 - auc: 0.9729\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3066 - auc: 0.9728\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3042 - auc: 0.9732\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3084 - auc: 0.9731\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3030 - auc: 0.9745\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3168 - auc: 0.9737\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3080 - auc: 0.9738\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3052 - auc: 0.9736\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2964 - auc: 0.9738\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3107 - auc: 0.9729\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3050 - auc: 0.9746\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2844 - auc: 0.9762\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3073 - auc: 0.9765\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2932 - auc: 0.9747\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2851 - auc: 0.9791\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2912 - auc: 0.9764\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2916 - auc: 0.9766\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2924 - auc: 0.9759\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2837 - auc: 0.9786\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2902 - auc: 0.9776\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2881 - auc: 0.9771\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2951 - auc: 0.9774\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2918 - auc: 0.9781\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2874 - auc: 0.9758\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2884 - auc: 0.9766\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2974 - auc: 0.9773\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2864 - auc: 0.9769\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2851 - auc: 0.9765\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2933 - auc: 0.9776\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2904 - auc: 0.9775\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2732 - auc: 0.9774\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2972 - auc: 0.9774\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2839 - auc: 0.9771\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2800 - auc: 0.9787\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2927 - auc: 0.9777\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3066 - auc: 0.9787\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2825 - auc: 0.9781\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2970 - auc: 0.9782\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2932 - auc: 0.9786\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2967 - auc: 0.9775\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2857 - auc: 0.9779\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2866 - auc: 0.9795\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2806 - auc: 0.9773\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2827 - auc: 0.9770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.004733176150208225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03727647593932194\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0047', 'eer_eval': '0.0372', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0047.hdf5', 'tnow': '2022-06-01 23:14:58.966001'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 33s 20ms/step - loss: 0.8661 - auc: 0.7855\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.4494 - auc: 0.9449\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4240 - auc: 0.9530\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4047 - auc: 0.9562\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3973 - auc: 0.9558\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3790 - auc: 0.9591\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3704 - auc: 0.9623\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3531 - auc: 0.9619\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3690 - auc: 0.9592\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3549 - auc: 0.9667\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3332 - auc: 0.9662\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3453 - auc: 0.9649\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3330 - auc: 0.9666\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3299 - auc: 0.9664\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3348 - auc: 0.9703\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3262 - auc: 0.9680\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3335 - auc: 0.9657\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3233 - auc: 0.9692\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3174 - auc: 0.9704\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3129 - auc: 0.9698\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3215 - auc: 0.9705\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3261 - auc: 0.9685\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3306 - auc: 0.9696\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3151 - auc: 0.9708\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3122 - auc: 0.9732\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3118 - auc: 0.9718\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3133 - auc: 0.9724\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3079 - auc: 0.9727\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3021 - auc: 0.9713\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3107 - auc: 0.9729\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3121 - auc: 0.9750\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3083 - auc: 0.9727\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3011 - auc: 0.9733\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2971 - auc: 0.9742\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2996 - auc: 0.9743\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3085 - auc: 0.9748\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3011 - auc: 0.9742\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 30s 19ms/step - loss: 0.2953 - auc: 0.9757\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2977 - auc: 0.9741\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2979 - auc: 0.9758\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2967 - auc: 0.9763\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2899 - auc: 0.9766\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2931 - auc: 0.9764\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3091 - auc: 0.9763\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2750 - auc: 0.9769\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2912 - auc: 0.9773\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2923 - auc: 0.9778\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2906 - auc: 0.9787\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3015 - auc: 0.9773\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2945 - auc: 0.9763\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2977 - auc: 0.9769\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2927 - auc: 0.9784\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2897 - auc: 0.9796\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2949 - auc: 0.9778\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2902 - auc: 0.9770\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2794 - auc: 0.9787\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2928 - auc: 0.9778\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2862 - auc: 0.9783\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2924 - auc: 0.9794\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2849 - auc: 0.9786\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2870 - auc: 0.9779\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2944 - auc: 0.9786\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2788 - auc: 0.9781\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2895 - auc: 0.9795\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2959 - auc: 0.9781\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2853 - auc: 0.9788\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2815 - auc: 0.9776\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2980 - auc: 0.9781\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2753 - auc: 0.9767\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2903 - auc: 0.9783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.004306861305476568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.030455973700634742\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0043', 'eer_eval': '0.0304', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0043.hdf5', 'tnow': '2022-06-01 23:52:07.374819'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 33s 20ms/step - loss: 1.0047 - auc: 0.7745\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4755 - auc: 0.9450\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.4085 - auc: 0.9534\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.4002 - auc: 0.9584\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3926 - auc: 0.9558\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3715 - auc: 0.9598\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3566 - auc: 0.9607\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3570 - auc: 0.9622\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3539 - auc: 0.9618\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3400 - auc: 0.9656\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3469 - auc: 0.9624\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3307 - auc: 0.9681\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3322 - auc: 0.9661\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3378 - auc: 0.9659\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3253 - auc: 0.9678\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3242 - auc: 0.9684\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3090 - auc: 0.9688\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3323 - auc: 0.9686\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3384 - auc: 0.9699\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3131 - auc: 0.9694\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3254 - auc: 0.9711\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3128 - auc: 0.9710\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3074 - auc: 0.9691\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3204 - auc: 0.9711\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3149 - auc: 0.9715\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2998 - auc: 0.9711\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3073 - auc: 0.9713\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.3019 - auc: 0.9721\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.3096 - auc: 0.9712\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3225 - auc: 0.9721\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3122 - auc: 0.9712\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2938 - auc: 0.9723\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2903 - auc: 0.9724\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2946 - auc: 0.9733\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3027 - auc: 0.9742\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2885 - auc: 0.9758\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2989 - auc: 0.9757\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 30s 19ms/step - loss: 0.2866 - auc: 0.9756\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2898 - auc: 0.9760\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2949 - auc: 0.9747\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2944 - auc: 0.9759\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2913 - auc: 0.9734\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2874 - auc: 0.9761\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3025 - auc: 0.9765\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2998 - auc: 0.9776\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2903 - auc: 0.9769\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2947 - auc: 0.9774\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2927 - auc: 0.9770\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2829 - auc: 0.9768\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2846 - auc: 0.9772\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2822 - auc: 0.9773\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2908 - auc: 0.9781\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2925 - auc: 0.9786\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2912 - auc: 0.9783\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2909 - auc: 0.9787\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2877 - auc: 0.9792\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2941 - auc: 0.9770\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2850 - auc: 0.9793\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2952 - auc: 0.9776\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2794 - auc: 0.9780\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2862 - auc: 0.9782\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.2988 - auc: 0.9771\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.3047 - auc: 0.9789\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2909 - auc: 0.9768\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2770 - auc: 0.9791\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.2987 - auc: 0.9781\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2814 - auc: 0.9785\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2874 - auc: 0.9773\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.2747 - auc: 0.9781\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2941 - auc: 0.9786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.004710738526801301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03138595320486485\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0047', 'eer_eval': '0.0313', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0047.hdf5', 'tnow': '2022-06-02 00:29:37.610124'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 33s 20ms/step - loss: 0.9525 - auc: 0.7752\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.4585 - auc: 0.9454\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.4132 - auc: 0.9544\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.4064 - auc: 0.9580\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4080 - auc: 0.9585\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3976 - auc: 0.9605\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3643 - auc: 0.9629\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3483 - auc: 0.9616\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3608 - auc: 0.9620\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3570 - auc: 0.9647\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3505 - auc: 0.9656\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3558 - auc: 0.9647\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3400 - auc: 0.9657\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3279 - auc: 0.9667\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3337 - auc: 0.9686\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3293 - auc: 0.9668\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3349 - auc: 0.9671\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3401 - auc: 0.9657\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3209 - auc: 0.9688\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3270 - auc: 0.9707\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3146 - auc: 0.9702\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3102 - auc: 0.9714\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3232 - auc: 0.9712\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3176 - auc: 0.9691\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3070 - auc: 0.9685\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3241 - auc: 0.9703\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3208 - auc: 0.9703\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3208 - auc: 0.9708\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3114 - auc: 0.9736\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3139 - auc: 0.9726\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2960 - auc: 0.9739\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.2985 - auc: 0.9732\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3089 - auc: 0.9744\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3107 - auc: 0.9727\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2979 - auc: 0.9733\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2947 - auc: 0.9747\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3150 - auc: 0.9734\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2882 - auc: 0.9744\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2877 - auc: 0.9738\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3107 - auc: 0.9762\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2985 - auc: 0.9744\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2948 - auc: 0.9748\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.3060 - auc: 0.9756\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2921 - auc: 0.9767\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2999 - auc: 0.9765\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2930 - auc: 0.9753\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2922 - auc: 0.9771\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2986 - auc: 0.9770\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2919 - auc: 0.9781\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2755 - auc: 0.9764\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2907 - auc: 0.9773\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.2914 - auc: 0.9761\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.2996 - auc: 0.9776\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3005 - auc: 0.9767\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2967 - auc: 0.9776\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2951 - auc: 0.9765\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2953 - auc: 0.9786\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2931 - auc: 0.9781\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2811 - auc: 0.9786\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2891 - auc: 0.9765\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.2878 - auc: 0.9778\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2900 - auc: 0.9783\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2944 - auc: 0.9791\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2942 - auc: 0.9777\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2870 - auc: 0.9779\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2775 - auc: 0.9786\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2655 - auc: 0.9768\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2947 - auc: 0.9768\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2887 - auc: 0.9779\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2961 - auc: 0.9774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0031180547277939626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.028810286589045296\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0031', 'eer_eval': '0.0288', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0031.hdf5', 'tnow': '2022-06-02 01:07:03.063753'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 33s 20ms/step - loss: 0.8937 - auc: 0.7839\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.4594 - auc: 0.9430\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.4232 - auc: 0.9549\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3958 - auc: 0.9586\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3984 - auc: 0.9594\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3914 - auc: 0.9572\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3814 - auc: 0.9609\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3545 - auc: 0.9627\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3604 - auc: 0.9626\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3623 - auc: 0.9621\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3482 - auc: 0.9631\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3457 - auc: 0.9660\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3408 - auc: 0.9648\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3368 - auc: 0.9657\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3255 - auc: 0.9672\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3316 - auc: 0.9677\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3360 - auc: 0.9679\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3241 - auc: 0.9660\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3312 - auc: 0.9692\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3213 - auc: 0.9698\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3307 - auc: 0.9673\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3293 - auc: 0.9706\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3223 - auc: 0.9699\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3282 - auc: 0.9693\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3253 - auc: 0.9710\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3126 - auc: 0.9712\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3122 - auc: 0.9727\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2965 - auc: 0.9715\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.3097 - auc: 0.9691\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3087 - auc: 0.9744\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2991 - auc: 0.9705\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3054 - auc: 0.9731\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3047 - auc: 0.9716\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.3085 - auc: 0.9733\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.3081 - auc: 0.9720\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2933 - auc: 0.9732\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2885 - auc: 0.9749\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2978 - auc: 0.9745\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.3005 - auc: 0.9741\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3034 - auc: 0.9740\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.2931 - auc: 0.9746\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2927 - auc: 0.9769\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3007 - auc: 0.9769\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2911 - auc: 0.9773\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.2889 - auc: 0.9772\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.2866 - auc: 0.9771\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2944 - auc: 0.9780\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2864 - auc: 0.9748\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3113 - auc: 0.9768\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2912 - auc: 0.9772\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2889 - auc: 0.9773\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2938 - auc: 0.9768\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2877 - auc: 0.9767\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2898 - auc: 0.9782\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2892 - auc: 0.9775\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2970 - auc: 0.9773\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2992 - auc: 0.9785\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2902 - auc: 0.9769\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2936 - auc: 0.9772\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2789 - auc: 0.9779\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2913 - auc: 0.9774\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2854 - auc: 0.9772\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2913 - auc: 0.9779\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2838 - auc: 0.9778\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2888 - auc: 0.9787\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2846 - auc: 0.9799\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2837 - auc: 0.9775\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2838 - auc: 0.9796\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2899 - auc: 0.9779\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2891 - auc: 0.9789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0030956171043869836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.025996866180896434\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0030', 'eer_eval': '0.0259', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0030.hdf5', 'tnow': '2022-06-02 01:44:32.276278'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 33s 20ms/step - loss: 0.9008 - auc: 0.7786\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.4820 - auc: 0.9439\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4188 - auc: 0.9521\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4239 - auc: 0.9556\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3945 - auc: 0.9602\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3782 - auc: 0.9600\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3760 - auc: 0.9609\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3746 - auc: 0.9627\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3676 - auc: 0.9619\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3557 - auc: 0.9646\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3457 - auc: 0.9630\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3268 - auc: 0.9649\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3454 - auc: 0.9668\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3394 - auc: 0.9668\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3294 - auc: 0.9656\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3357 - auc: 0.9659\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3399 - auc: 0.9677\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3307 - auc: 0.9676\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3190 - auc: 0.9696\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3178 - auc: 0.9692\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3245 - auc: 0.9698\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3184 - auc: 0.9685\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3251 - auc: 0.9686\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3174 - auc: 0.9683\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3088 - auc: 0.9685\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3133 - auc: 0.9700\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3172 - auc: 0.9709\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3043 - auc: 0.9717\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3110 - auc: 0.9698\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3188 - auc: 0.9703\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2946 - auc: 0.9721\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3047 - auc: 0.9721\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3161 - auc: 0.9701\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3035 - auc: 0.9748\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3005 - auc: 0.9729\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3087 - auc: 0.9738\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3004 - auc: 0.9737\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2896 - auc: 0.9752\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3088 - auc: 0.9740\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2997 - auc: 0.9748\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3018 - auc: 0.9763\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2887 - auc: 0.9766\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2885 - auc: 0.9765\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2857 - auc: 0.9781\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2868 - auc: 0.9756\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2918 - auc: 0.9764\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2969 - auc: 0.9766\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2958 - auc: 0.9778\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2807 - auc: 0.9784\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2875 - auc: 0.9763\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2882 - auc: 0.9780\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2904 - auc: 0.9780\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2888 - auc: 0.9764\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2792 - auc: 0.9782\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2846 - auc: 0.9758\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2917 - auc: 0.9762\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3038 - auc: 0.9769\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2828 - auc: 0.9768\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2843 - auc: 0.9782\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2811 - auc: 0.9776\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2836 - auc: 0.9789\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2910 - auc: 0.9779\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2860 - auc: 0.9788\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2909 - auc: 0.9778\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2847 - auc: 0.9783\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2751 - auc: 0.9765\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2872 - auc: 0.9777\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2941 - auc: 0.9768\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2839 - auc: 0.9791\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2882 - auc: 0.9771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.003914396627297604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.02216736598516925\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0039', 'eer_eval': '0.0221', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0039.hdf5', 'tnow': '2022-06-02 02:21:39.360018'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 33s 19ms/step - loss: 0.9116 - auc: 0.7849\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4289 - auc: 0.9493\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4146 - auc: 0.9575\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3911 - auc: 0.9586\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3821 - auc: 0.9613\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3694 - auc: 0.9630\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3646 - auc: 0.9615\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3580 - auc: 0.9627\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3525 - auc: 0.9643\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3314 - auc: 0.9649\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3548 - auc: 0.9652\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3386 - auc: 0.9655\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3220 - auc: 0.9675\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3141 - auc: 0.9651\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3483 - auc: 0.9691\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3303 - auc: 0.9699\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3183 - auc: 0.9698\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3249 - auc: 0.9686\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3179 - auc: 0.9702\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3264 - auc: 0.9703\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3199 - auc: 0.9729\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3021 - auc: 0.9715\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3059 - auc: 0.9723\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3105 - auc: 0.9725\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3139 - auc: 0.9721\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3308 - auc: 0.9697\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3134 - auc: 0.9714\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3088 - auc: 0.9737\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3072 - auc: 0.9737\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2989 - auc: 0.9733\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2973 - auc: 0.9754\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2986 - auc: 0.9761\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2943 - auc: 0.9769\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3166 - auc: 0.9736\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3003 - auc: 0.9755\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3047 - auc: 0.9770\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2937 - auc: 0.9779\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2958 - auc: 0.9774\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2957 - auc: 0.9765\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2810 - auc: 0.9770\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3021 - auc: 0.9782\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2933 - auc: 0.9789\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2847 - auc: 0.9789\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2797 - auc: 0.9796\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2888 - auc: 0.9780\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2933 - auc: 0.9778\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2915 - auc: 0.9787\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2782 - auc: 0.9786\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2799 - auc: 0.9788\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2841 - auc: 0.9794\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2768 - auc: 0.9802\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2862 - auc: 0.9790\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2851 - auc: 0.9802\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2863 - auc: 0.9802\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2774 - auc: 0.9796\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2919 - auc: 0.9803\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2904 - auc: 0.9801\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2846 - auc: 0.9798\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2885 - auc: 0.9801\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2906 - auc: 0.9788\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2802 - auc: 0.9793\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2874 - auc: 0.9783\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2774 - auc: 0.9790\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2923 - auc: 0.9794\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2794 - auc: 0.9788\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2843 - auc: 0.9799\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2899 - auc: 0.9798\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2848 - auc: 0.9785\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2861 - auc: 0.9800\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2893 - auc: 0.9779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.004177941836607912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.021268695674883924\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0041', 'eer_eval': '0.0212', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0041.hdf5', 'tnow': '2022-06-02 02:58:45.186613'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 33s 20ms/step - loss: 0.8719 - auc: 0.7883\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4410 - auc: 0.9514\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4016 - auc: 0.9579\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3903 - auc: 0.9597\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3817 - auc: 0.9616\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3764 - auc: 0.9620\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3655 - auc: 0.9652\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3445 - auc: 0.9642\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3491 - auc: 0.9639\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3339 - auc: 0.9675\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3331 - auc: 0.9659\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3396 - auc: 0.9680\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3310 - auc: 0.9690\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3262 - auc: 0.9686\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3424 - auc: 0.9688\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3232 - auc: 0.9710\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3142 - auc: 0.9699\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3238 - auc: 0.9697\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3226 - auc: 0.9686\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3132 - auc: 0.9716\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3092 - auc: 0.9724\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3143 - auc: 0.9705\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3116 - auc: 0.9715\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3121 - auc: 0.9733\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3056 - auc: 0.9727\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3029 - auc: 0.9741\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3096 - auc: 0.9738\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3127 - auc: 0.9747\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2931 - auc: 0.9744\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2928 - auc: 0.9742\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3110 - auc: 0.9724\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2950 - auc: 0.9757\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3010 - auc: 0.9747\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2963 - auc: 0.9757\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2951 - auc: 0.9757\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2997 - auc: 0.9764\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2995 - auc: 0.9761\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2941 - auc: 0.9774\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2856 - auc: 0.9770\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2947 - auc: 0.9770\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2902 - auc: 0.9764\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2947 - auc: 0.9779\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2852 - auc: 0.9780\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2999 - auc: 0.9782\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2939 - auc: 0.9792\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2928 - auc: 0.9769\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2924 - auc: 0.9774\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2732 - auc: 0.9790\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2884 - auc: 0.9784\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2986 - auc: 0.9806\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2706 - auc: 0.9804\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2828 - auc: 0.9783\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2825 - auc: 0.9785\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2832 - auc: 0.9806\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2765 - auc: 0.9792\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2819 - auc: 0.9799\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2823 - auc: 0.9794\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2862 - auc: 0.9794\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2818 - auc: 0.9798\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2847 - auc: 0.9794\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2758 - auc: 0.9791\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2923 - auc: 0.9798\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2871 - auc: 0.9792\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3009 - auc: 0.9797\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2788 - auc: 0.9800\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2831 - auc: 0.9797\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2772 - auc: 0.9783\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2802 - auc: 0.9801\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2918 - auc: 0.9797\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2652 - auc: 0.9793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.003140492351200886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.017245959247373197\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0031', 'eer_eval': '0.0172', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0031.hdf5', 'tnow': '2022-06-02 03:35:58.644356'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 34s 20ms/step - loss: 0.8090 - auc: 0.8042\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.4443 - auc: 0.9478\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.4137 - auc: 0.9542\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3804 - auc: 0.9604\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3654 - auc: 0.9622\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3438 - auc: 0.9610\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3482 - auc: 0.9615\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3391 - auc: 0.9644\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3465 - auc: 0.9635\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3440 - auc: 0.9666\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3312 - auc: 0.9644\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3407 - auc: 0.9654\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3333 - auc: 0.9678\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3369 - auc: 0.9677\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3293 - auc: 0.9693\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3317 - auc: 0.9680\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3228 - auc: 0.9683\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3264 - auc: 0.9684\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3275 - auc: 0.9703\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3225 - auc: 0.9709\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3166 - auc: 0.9702\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3276 - auc: 0.9710\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3273 - auc: 0.9707\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3030 - auc: 0.9739\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3035 - auc: 0.9714\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3056 - auc: 0.9728\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3089 - auc: 0.9723\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3096 - auc: 0.9734\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3044 - auc: 0.9723\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3066 - auc: 0.9752\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3103 - auc: 0.9729\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2979 - auc: 0.9732\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2984 - auc: 0.9752\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2976 - auc: 0.9737\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2995 - auc: 0.9744\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3004 - auc: 0.9761\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3044 - auc: 0.9775\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2997 - auc: 0.9773\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2817 - auc: 0.9773\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2996 - auc: 0.9774\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2881 - auc: 0.9786\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2911 - auc: 0.9779\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2882 - auc: 0.9775\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2766 - auc: 0.9757\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2799 - auc: 0.9782\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2856 - auc: 0.9780\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2921 - auc: 0.9771\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2815 - auc: 0.9781\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2991 - auc: 0.9785\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2879 - auc: 0.9790\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2863 - auc: 0.9787\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2782 - auc: 0.9787\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2752 - auc: 0.9784\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2877 - auc: 0.9792\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2802 - auc: 0.9794\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2717 - auc: 0.9798\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2880 - auc: 0.9784\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2895 - auc: 0.9785\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2945 - auc: 0.9792\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2962 - auc: 0.9797\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2799 - auc: 0.9788\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2855 - auc: 0.9786\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2796 - auc: 0.9785\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2751 - auc: 0.9799\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2964 - auc: 0.9792\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2890 - auc: 0.9791\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2865 - auc: 0.9799\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2859 - auc: 0.9794\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2780 - auc: 0.9786\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2811 - auc: 0.9790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0030283042341662132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.01946108152545572\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0030', 'eer_eval': '0.0194', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0030.hdf5', 'tnow': '2022-06-02 04:13:22.854985'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 33s 19ms/step - loss: 0.9794 - auc: 0.7740\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.5153 - auc: 0.9343\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.4299 - auc: 0.9547\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.4115 - auc: 0.9565\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3997 - auc: 0.9600\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3941 - auc: 0.9600\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3639 - auc: 0.9599\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3729 - auc: 0.9602\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3677 - auc: 0.9631\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3679 - auc: 0.9632\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3488 - auc: 0.9651\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3451 - auc: 0.9647\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3522 - auc: 0.9640\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3340 - auc: 0.9671\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3355 - auc: 0.9661\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3344 - auc: 0.9676\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3353 - auc: 0.9665\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3346 - auc: 0.9658\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3196 - auc: 0.9669\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3451 - auc: 0.9673\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3186 - auc: 0.9682\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3209 - auc: 0.9673\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3348 - auc: 0.9685\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3129 - auc: 0.9695\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3228 - auc: 0.9703\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3171 - auc: 0.9700\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3019 - auc: 0.9715\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3205 - auc: 0.9710\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3025 - auc: 0.9714\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3162 - auc: 0.9722\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3158 - auc: 0.9719\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3068 - auc: 0.9732\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3039 - auc: 0.9744\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.2979 - auc: 0.9738\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3092 - auc: 0.9750\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3050 - auc: 0.9752\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2990 - auc: 0.9727\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3001 - auc: 0.9731\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2986 - auc: 0.9753\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2931 - auc: 0.9767\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3134 - auc: 0.9745\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2952 - auc: 0.9762\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2893 - auc: 0.9748\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2994 - auc: 0.9764\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2850 - auc: 0.9758\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2880 - auc: 0.9760\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2911 - auc: 0.9763\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2994 - auc: 0.9765\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2895 - auc: 0.9774\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2823 - auc: 0.9753\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2941 - auc: 0.9766\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2950 - auc: 0.9763\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2795 - auc: 0.9773\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2981 - auc: 0.9768\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2976 - auc: 0.9775\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2947 - auc: 0.9759\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2832 - auc: 0.9778\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2830 - auc: 0.9777\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3032 - auc: 0.9766\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2924 - auc: 0.9776\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3061 - auc: 0.9774\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2837 - auc: 0.9784\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2847 - auc: 0.9766\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3071 - auc: 0.9785\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2784 - auc: 0.9766\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2809 - auc: 0.9780\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2942 - auc: 0.9768\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2889 - auc: 0.9774\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3036 - auc: 0.9782\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2953 - auc: 0.9786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0027647590248559614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.02176768515500118\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0027', 'eer_eval': '0.0217', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0027.hdf5', 'tnow': '2022-06-02 04:50:47.672712'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 33s 19ms/step - loss: 0.9404 - auc: 0.7903\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.4839 - auc: 0.9436\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.4321 - auc: 0.9539\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4040 - auc: 0.9576\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4105 - auc: 0.9586\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3812 - auc: 0.9604\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3744 - auc: 0.9608\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3647 - auc: 0.9625\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3518 - auc: 0.9649\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3550 - auc: 0.9638\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3490 - auc: 0.9629\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3438 - auc: 0.9654\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3496 - auc: 0.9656\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3475 - auc: 0.9650\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3509 - auc: 0.9652\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3417 - auc: 0.9671\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3333 - auc: 0.9677\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3246 - auc: 0.9682\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3257 - auc: 0.9676\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3302 - auc: 0.9675\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3227 - auc: 0.9683\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3282 - auc: 0.9696\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3280 - auc: 0.9681\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3277 - auc: 0.9689\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3009 - auc: 0.9698\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3125 - auc: 0.9673\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3202 - auc: 0.9703\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3111 - auc: 0.9713\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3086 - auc: 0.9716\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3107 - auc: 0.9714\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3146 - auc: 0.9722\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3064 - auc: 0.9713\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2972 - auc: 0.9730\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3089 - auc: 0.9720\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 30s 19ms/step - loss: 0.3084 - auc: 0.9722\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2991 - auc: 0.9741\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3040 - auc: 0.9740\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2980 - auc: 0.9754\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2948 - auc: 0.9742\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3036 - auc: 0.9736\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2986 - auc: 0.9761\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2858 - auc: 0.9762\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2914 - auc: 0.9759\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2861 - auc: 0.9754\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2901 - auc: 0.9763\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2906 - auc: 0.9758\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2916 - auc: 0.9762\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2995 - auc: 0.9754\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3005 - auc: 0.9777\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2812 - auc: 0.9773\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2944 - auc: 0.9764\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2999 - auc: 0.9784\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2897 - auc: 0.9779\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2997 - auc: 0.9770\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2836 - auc: 0.9771\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2809 - auc: 0.9790\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2925 - auc: 0.9773\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2883 - auc: 0.9767\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3001 - auc: 0.9771\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2893 - auc: 0.9778\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2966 - auc: 0.9781\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2918 - auc: 0.9781\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3074 - auc: 0.9769\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2766 - auc: 0.9771\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2791 - auc: 0.9776\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2808 - auc: 0.9777\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2888 - auc: 0.9759\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2866 - auc: 0.9785\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2940 - auc: 0.9772\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2857 - auc: 0.9775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00315151743146204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.02623461997322574\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0031', 'eer_eval': '0.0262', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0031.hdf5', 'tnow': '2022-06-02 05:27:55.857696'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 33s 20ms/step - loss: 0.9560 - auc: 0.7829\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4838 - auc: 0.9443\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4043 - auc: 0.9533\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.4233 - auc: 0.9553\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3905 - auc: 0.9591\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3849 - auc: 0.9612\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3856 - auc: 0.9589\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3611 - auc: 0.9621\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3675 - auc: 0.9610\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3449 - auc: 0.9643\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3453 - auc: 0.9653\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3475 - auc: 0.9650\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3352 - auc: 0.9667\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3298 - auc: 0.9668\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3471 - auc: 0.9668\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3337 - auc: 0.9649\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3290 - auc: 0.9680\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3202 - auc: 0.9679\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3351 - auc: 0.9676\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3414 - auc: 0.9666\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3223 - auc: 0.9693\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3234 - auc: 0.9689\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3221 - auc: 0.9719\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3191 - auc: 0.9699\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 32s 20ms/step - loss: 0.3123 - auc: 0.9713\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3180 - auc: 0.9699\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3178 - auc: 0.9719\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3114 - auc: 0.9712\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3087 - auc: 0.9735\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3177 - auc: 0.9720\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3179 - auc: 0.9723\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3034 - auc: 0.9733\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3074 - auc: 0.9735\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 30s 19ms/step - loss: 0.3092 - auc: 0.9740\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3010 - auc: 0.9743\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2900 - auc: 0.9749\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3097 - auc: 0.9727\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3029 - auc: 0.9745\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3069 - auc: 0.9747\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3019 - auc: 0.9737\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2950 - auc: 0.9754\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2922 - auc: 0.9768\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2956 - auc: 0.9754\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2941 - auc: 0.9775\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2968 - auc: 0.9747\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2948 - auc: 0.9772\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2887 - auc: 0.9777\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2987 - auc: 0.9779\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2933 - auc: 0.9778\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2870 - auc: 0.9767\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2871 - auc: 0.9773\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2904 - auc: 0.9781\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2938 - auc: 0.9783\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2860 - auc: 0.9784\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2784 - auc: 0.9785\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2843 - auc: 0.9788\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2855 - auc: 0.9771\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2836 - auc: 0.9771\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2927 - auc: 0.9784\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2844 - auc: 0.9768\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2831 - auc: 0.9790\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2913 - auc: 0.9781\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2969 - auc: 0.9766\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2878 - auc: 0.9782\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.3003 - auc: 0.9785\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2881 - auc: 0.9783\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.3006 - auc: 0.9777\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 31s 19ms/step - loss: 0.2921 - auc: 0.9764\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2867 - auc: 0.9777\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 31s 20ms/step - loss: 0.2892 - auc: 0.9774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0037124580166352375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.025565876156783525\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'LCNN_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0037', 'eer_eval': '0.0255', 'saved_model': 'saved_models/model_name!LCNN_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0037.hdf5', 'tnow': '2022-06-02 06:05:12.752295'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 48s 27ms/step - loss: 1.1462 - auc: 0.8175\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2095 - auc: 0.9904\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.1292 - auc: 0.9963\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0940 - auc: 0.9977\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0746 - auc: 0.9984\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0612 - auc: 0.9985\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0481 - auc: 0.9991\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0554 - auc: 0.9989\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0685 - auc: 0.9987\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0273 - auc: 0.9993\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0422 - auc: 0.9989\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0230 - auc: 0.9998\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0272 - auc: 0.9995\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0392 - auc: 0.9992\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0243 - auc: 0.9998\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0259 - auc: 0.9993\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0128 - auc: 0.9998\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0189 - auc: 0.9995\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0299 - auc: 0.9993\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0179 - auc: 0.9998\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0176 - auc: 0.9994\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0178 - auc: 0.9997\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0372 - auc: 0.9995\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0130 - auc: 0.9997\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0130 - auc: 0.9999\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0155 - auc: 0.9998\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.0164 - auc: 0.9999\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 0.0139 - auc: 0.9998\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0095 - auc: 0.9999\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0099 - auc: 0.9999\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0064 - auc: 0.9999\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0121 - auc: 0.9998\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0038 - auc: 1.0000\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0061 - auc: 0.9998\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0073 - auc: 0.9999\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0041 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0040 - auc: 1.0000\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.0147 - auc: 0.9998\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0040 - auc: 0.9999\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0024 - auc: 0.9999\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0034 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0022 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0015 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0014 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0015 - auc: 0.9999\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 5.6395e-04 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0016 - auc: 0.9999\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0014 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 6.1171e-04 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0028 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 5.2373e-04 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 0.0024 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.0025 - auc: 0.9999\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 4.1324e-04 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0021 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 8.0059e-04 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 4.2891e-04 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0011 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0012 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 0.0017 - auc: 0.9999\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 8.7771e-04 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 2.6722e-04 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0019 - auc: 0.9999\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 4.7662e-04 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 3.2507e-04 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 4.7771e-04 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 1.6690e-04 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 1.4463e-04 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 4.1168e-04 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 3.1971e-04 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0043574428238633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03429330119484812\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0043', 'eer_eval': '0.0342', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0043.hdf5', 'tnow': '2022-06-02 06:56:42.255912'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 48s 27ms/step - loss: 1.3112 - auc: 0.8139\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.1915 - auc: 0.9917\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.1110 - auc: 0.9969\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.0700 - auc: 0.9986\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0710 - auc: 0.9987\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0522 - auc: 0.9989\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0424 - auc: 0.9992\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0346 - auc: 0.9992\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0343 - auc: 0.9995\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0280 - auc: 0.9992\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0204 - auc: 0.9997\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0274 - auc: 0.9994\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0310 - auc: 0.9997\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0370 - auc: 0.9992\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0243 - auc: 0.9997\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0252 - auc: 0.9993\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0179 - auc: 0.9998\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0125 - auc: 0.9997\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0259 - auc: 0.9997\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0118 - auc: 0.9999\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0127 - auc: 0.9998\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0151 - auc: 0.9996\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0286 - auc: 0.9995\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0065 - auc: 0.9998\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0168 - auc: 0.9996\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.0186 - auc: 0.9993\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0044 - auc: 0.9999\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0158 - auc: 0.9995\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0086 - auc: 0.9999\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0067 - auc: 0.9999\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0052 - auc: 1.0000\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0126 - auc: 0.9997\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0070 - auc: 1.0000\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0080 - auc: 1.0000\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0034 - auc: 1.0000\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0039 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0048 - auc: 1.0000\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0045 - auc: 1.0000\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0036 - auc: 0.9999\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0037 - auc: 0.9999\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0063 - auc: 0.9999\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0010 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0019 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0035 - auc: 0.9999\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0011 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0018 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0031 - auc: 0.9999\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 8.8598e-04 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0014 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 7.0151e-04 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 6.9012e-04 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 8.5661e-04 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0011 - auc: 0.9999\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 3.9803e-04 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0011 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 3.8730e-04 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0011 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0047 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 3.8233e-04 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0018 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 2.1092e-04 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 6.5717e-04 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 6.2019e-04 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 4.5634e-04 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 2.6446e-04 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 4.1942e-04 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 6.3689e-04 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 3.2908e-04 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 2.0527e-04 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 3.5070e-04 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0050640342297393025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03683765861672289\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0050', 'eer_eval': '0.0368', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0050.hdf5', 'tnow': '2022-06-02 07:47:49.429506'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 50s 27ms/step - loss: 1.3129 - auc: 0.8156\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2656 - auc: 0.9840\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.1132 - auc: 0.9966\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0737 - auc: 0.9984\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0625 - auc: 0.9986\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.0591 - auc: 0.9990\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0523 - auc: 0.9990\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.0352 - auc: 0.9994\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0350 - auc: 0.9994\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0382 - auc: 0.9991\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0232 - auc: 0.9992\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.0278 - auc: 0.9996\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.0244 - auc: 0.9996\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0355 - auc: 0.9992\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0202 - auc: 0.9996\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0259 - auc: 0.9995\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.0127 - auc: 0.9997\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0231 - auc: 0.9998\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.0175 - auc: 0.9998\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.0253 - auc: 0.9994\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0239 - auc: 0.9997\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0141 - auc: 0.9998\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0177 - auc: 0.9995\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0169 - auc: 0.9999\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.0137 - auc: 0.9998\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0122 - auc: 0.9997\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0152 - auc: 0.9999\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0113 - auc: 0.9999\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0118 - auc: 0.9998\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0083 - auc: 0.9997\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0085 - auc: 0.9999\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0050 - auc: 1.0000\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0154 - auc: 0.9996\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0042 - auc: 0.9999\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0108 - auc: 0.9997\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0049 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.0034 - auc: 0.9999\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0037 - auc: 1.0000\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0038 - auc: 0.9998\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0058 - auc: 0.9999\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0040 - auc: 0.9999\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0014 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 7.5944e-04 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0021 - auc: 0.9999\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 5.9251e-04 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0012 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 4.1543e-04 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.0034 - auc: 0.9999\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 6.8598e-04 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 6.4286e-04 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 7.2385e-04 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0019 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 7.6945e-04 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0013 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 3.3450e-04 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 5.2599e-04 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 5.7463e-04 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0012 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 3.5195e-04 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 9.2834e-04 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 6.0254e-04 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 2.6163e-04 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 3.2262e-04 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 3.4309e-04 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.0022 - auc: 0.9999\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 3.3379e-04 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 1.1666e-04 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 4.0617e-04 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.0013 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 2.4786e-04 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.005484642802898076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.04385139708719363\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0054', 'eer_eval': '0.0438', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0054.hdf5', 'tnow': '2022-06-02 08:38:18.328327'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 47s 27ms/step - loss: 1.2962 - auc: 0.8067\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.6194 - auc: 0.9194\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.5140 - auc: 0.9393\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.4218 - auc: 0.9561\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3778 - auc: 0.9626\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3628 - auc: 0.9636\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3508 - auc: 0.9647\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3489 - auc: 0.9653\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3634 - auc: 0.9662\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3361 - auc: 0.9686\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3372 - auc: 0.9673\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3163 - auc: 0.9693\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3279 - auc: 0.9712\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3067 - auc: 0.9699\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3225 - auc: 0.9702\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3186 - auc: 0.9728\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3200 - auc: 0.9698\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3232 - auc: 0.9698\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3366 - auc: 0.9713\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3124 - auc: 0.9725\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3159 - auc: 0.9712\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3105 - auc: 0.9711\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3145 - auc: 0.9740\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3199 - auc: 0.9733\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3140 - auc: 0.9712\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3117 - auc: 0.9747\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3037 - auc: 0.9754\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3214 - auc: 0.9759\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3142 - auc: 0.9721\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2934 - auc: 0.9736\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2957 - auc: 0.9751\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3016 - auc: 0.9743\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2935 - auc: 0.9745\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2983 - auc: 0.9742\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3045 - auc: 0.9763\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3003 - auc: 0.9762\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2854 - auc: 0.9760\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2891 - auc: 0.9761\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2841 - auc: 0.9769\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3010 - auc: 0.9768\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2799 - auc: 0.9767\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2958 - auc: 0.9773\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2951 - auc: 0.9773\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2818 - auc: 0.9779\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2935 - auc: 0.9776\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2913 - auc: 0.9785\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2963 - auc: 0.9775\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2952 - auc: 0.9778\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2996 - auc: 0.9783\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2921 - auc: 0.9777\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2795 - auc: 0.9774\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2946 - auc: 0.9785\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2926 - auc: 0.9793\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2991 - auc: 0.9789\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2898 - auc: 0.9778\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2942 - auc: 0.9790\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2885 - auc: 0.9781\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2864 - auc: 0.9782\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2803 - auc: 0.9791\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2856 - auc: 0.9788\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2914 - auc: 0.9785\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2865 - auc: 0.9795\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2843 - auc: 0.9803\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2881 - auc: 0.9787\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2822 - auc: 0.9786\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2789 - auc: 0.9794\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2757 - auc: 0.9778\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2991 - auc: 0.9783\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2968 - auc: 0.9779\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2907 - auc: 0.9795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00818208895753321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03672269536980136\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0081', 'eer_eval': '0.0367', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0081.hdf5', 'tnow': '2022-06-02 09:28:43.909409'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 46s 26ms/step - loss: 1.2884 - auc: 0.8038\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.5776 - auc: 0.9318\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.4463 - auc: 0.9528\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3977 - auc: 0.9588\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3735 - auc: 0.9624\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3722 - auc: 0.9621\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3428 - auc: 0.9649\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3399 - auc: 0.9667\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3335 - auc: 0.9669\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3349 - auc: 0.9677\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3345 - auc: 0.9676\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3278 - auc: 0.9683\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3222 - auc: 0.9700\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3374 - auc: 0.9721\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3153 - auc: 0.9694\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3297 - auc: 0.9714\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3206 - auc: 0.9735\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3195 - auc: 0.9719\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3168 - auc: 0.9724\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3128 - auc: 0.9721\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3076 - auc: 0.9724\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3082 - auc: 0.9726\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3110 - auc: 0.9724\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3186 - auc: 0.9734\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3209 - auc: 0.9736\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3006 - auc: 0.9747\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3087 - auc: 0.9731\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3011 - auc: 0.9742\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2944 - auc: 0.9763\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2996 - auc: 0.9756\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2954 - auc: 0.9763\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2968 - auc: 0.9759\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3004 - auc: 0.9739\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2998 - auc: 0.9763\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2827 - auc: 0.9762\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3029 - auc: 0.9758\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3056 - auc: 0.9753\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2951 - auc: 0.9778\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2923 - auc: 0.9774\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2966 - auc: 0.9776\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2842 - auc: 0.9782\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2994 - auc: 0.9778\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2786 - auc: 0.9792\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2894 - auc: 0.9782\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3036 - auc: 0.9790\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2910 - auc: 0.9783\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2841 - auc: 0.9779\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2950 - auc: 0.9786\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2953 - auc: 0.9782\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2830 - auc: 0.9782\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2736 - auc: 0.9804\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2900 - auc: 0.9785\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2872 - auc: 0.9796\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2852 - auc: 0.9797\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2939 - auc: 0.9791\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2726 - auc: 0.9788\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2963 - auc: 0.9803\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2835 - auc: 0.9801\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2859 - auc: 0.9796\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2909 - auc: 0.9787\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2917 - auc: 0.9810\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2762 - auc: 0.9793\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2833 - auc: 0.9808\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2814 - auc: 0.9803\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3020 - auc: 0.9794\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2910 - auc: 0.9798\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3085 - auc: 0.9797\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2978 - auc: 0.9791\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2793 - auc: 0.9808\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2895 - auc: 0.9794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.007385747058029569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03902147170086057\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0073', 'eer_eval': '0.0390', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0073.hdf5', 'tnow': '2022-06-02 10:19:06.156432'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 50s 27ms/step - loss: 1.2487 - auc: 0.8176\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.5208 - auc: 0.9442\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4774 - auc: 0.9510\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4198 - auc: 0.9543\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3750 - auc: 0.9620\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3823 - auc: 0.9632\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3553 - auc: 0.9637\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3471 - auc: 0.9630\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3469 - auc: 0.9657\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3363 - auc: 0.9668\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3441 - auc: 0.9665\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3303 - auc: 0.9700\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3109 - auc: 0.9704\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3224 - auc: 0.9713\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3299 - auc: 0.9690\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3167 - auc: 0.9695\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3205 - auc: 0.9726\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3289 - auc: 0.9715\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3262 - auc: 0.9710\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3052 - auc: 0.9711\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3126 - auc: 0.9716\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3077 - auc: 0.9722\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3216 - auc: 0.9736\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3091 - auc: 0.9725\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3110 - auc: 0.9728\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3000 - auc: 0.9736\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3047 - auc: 0.9742\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3097 - auc: 0.9726\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3110 - auc: 0.9748\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3124 - auc: 0.9751\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2809 - auc: 0.9763\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3095 - auc: 0.9747\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3013 - auc: 0.9749\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2906 - auc: 0.9756\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2960 - auc: 0.9746\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3049 - auc: 0.9767\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2942 - auc: 0.9775\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3104 - auc: 0.9764\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2897 - auc: 0.9758\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2925 - auc: 0.9767\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2940 - auc: 0.9761\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2991 - auc: 0.9778\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2863 - auc: 0.9782\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2905 - auc: 0.9781\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2974 - auc: 0.9783\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2933 - auc: 0.9797\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2893 - auc: 0.9774\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2984 - auc: 0.9773\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2850 - auc: 0.9785\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2921 - auc: 0.9779\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3072 - auc: 0.9787\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2859 - auc: 0.9814\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2889 - auc: 0.9788\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2964 - auc: 0.9776\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2919 - auc: 0.9781\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2869 - auc: 0.9788\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2860 - auc: 0.9787\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2771 - auc: 0.9788\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2911 - auc: 0.9786\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2924 - auc: 0.9784\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2971 - auc: 0.9784\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3023 - auc: 0.9798\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2851 - auc: 0.9796\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2935 - auc: 0.9790\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2845 - auc: 0.9791\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2837 - auc: 0.9793\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2922 - auc: 0.9782\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2886 - auc: 0.9791\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2810 - auc: 0.9787\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2941 - auc: 0.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.007144639472126185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03450219202360411\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0071', 'eer_eval': '0.0345', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0071.hdf5', 'tnow': '2022-06-02 11:09:50.141425'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 47s 27ms/step - loss: 1.1868 - auc: 0.8215\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.5402 - auc: 0.9365\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.4349 - auc: 0.9556\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.4015 - auc: 0.9582\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3637 - auc: 0.9625\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3684 - auc: 0.9630\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3529 - auc: 0.9637\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3293 - auc: 0.9648\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3308 - auc: 0.9686\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3424 - auc: 0.9678\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3303 - auc: 0.9694\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3374 - auc: 0.9683\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3288 - auc: 0.9689\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3192 - auc: 0.9696\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3271 - auc: 0.9685\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3278 - auc: 0.9691\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3183 - auc: 0.9698\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3109 - auc: 0.9716\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3311 - auc: 0.9714\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3176 - auc: 0.9713\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3060 - auc: 0.9725\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3213 - auc: 0.9689\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3089 - auc: 0.9729\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3116 - auc: 0.9737\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3110 - auc: 0.9736\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3032 - auc: 0.9738\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3174 - auc: 0.9725\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3166 - auc: 0.9726\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3136 - auc: 0.9736\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3060 - auc: 0.9737\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2897 - auc: 0.9745\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3037 - auc: 0.9758\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3118 - auc: 0.9740\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2982 - auc: 0.9760\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3132 - auc: 0.9737\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2909 - auc: 0.9770\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3044 - auc: 0.9761\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2958 - auc: 0.9789\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2872 - auc: 0.9762\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2899 - auc: 0.9781\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3092 - auc: 0.9770\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2856 - auc: 0.9794\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3023 - auc: 0.9772\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2915 - auc: 0.9751\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2810 - auc: 0.9764\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2952 - auc: 0.9769\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2931 - auc: 0.9767\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2983 - auc: 0.9776\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2908 - auc: 0.9791\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2936 - auc: 0.9785\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2935 - auc: 0.9795\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3035 - auc: 0.9784\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2915 - auc: 0.9776\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2867 - auc: 0.9794\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2893 - auc: 0.9789\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2868 - auc: 0.9792\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2930 - auc: 0.9779\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2940 - auc: 0.9795\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3071 - auc: 0.9796\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2922 - auc: 0.9808\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2876 - auc: 0.9786\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2864 - auc: 0.9776\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2895 - auc: 0.9790\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2989 - auc: 0.9783\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2945 - auc: 0.9788\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2826 - auc: 0.9787\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2864 - auc: 0.9785\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2848 - auc: 0.9785\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2991 - auc: 0.9792\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2896 - auc: 0.9793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.005507080426304999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03118978213533799\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0055', 'eer_eval': '0.0311', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0055.hdf5', 'tnow': '2022-06-02 12:00:20.079994'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 47s 27ms/step - loss: 1.3455 - auc: 0.7991\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.6342 - auc: 0.9187\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4727 - auc: 0.9464\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4212 - auc: 0.9562\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3858 - auc: 0.9597\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3890 - auc: 0.9601\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3628 - auc: 0.9645\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3347 - auc: 0.9666\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3329 - auc: 0.9642\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3554 - auc: 0.9666\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3330 - auc: 0.9675\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3339 - auc: 0.9697\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3326 - auc: 0.9695\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3205 - auc: 0.9704\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3244 - auc: 0.9696\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3163 - auc: 0.9712\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3138 - auc: 0.9726\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3226 - auc: 0.9708\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3041 - auc: 0.9746\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3096 - auc: 0.9716\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3139 - auc: 0.9719\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3102 - auc: 0.9731\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3086 - auc: 0.9730\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2855 - auc: 0.9765\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3040 - auc: 0.9731\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2971 - auc: 0.9755\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2973 - auc: 0.9740\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2927 - auc: 0.9759\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3000 - auc: 0.9749\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3067 - auc: 0.9734\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2922 - auc: 0.9760\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2831 - auc: 0.9767\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3046 - auc: 0.9757\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2885 - auc: 0.9749\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2954 - auc: 0.9765\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3046 - auc: 0.9764\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2883 - auc: 0.9777\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2945 - auc: 0.9768\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3053 - auc: 0.9763\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2819 - auc: 0.9778\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2921 - auc: 0.9775\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2893 - auc: 0.9784\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2776 - auc: 0.9772\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2825 - auc: 0.9790\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2930 - auc: 0.9794\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2808 - auc: 0.9778\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2846 - auc: 0.9799\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2758 - auc: 0.9792\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2816 - auc: 0.9804\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2892 - auc: 0.9794\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2875 - auc: 0.9812\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2847 - auc: 0.9795\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2788 - auc: 0.9802\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2934 - auc: 0.9783\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.2824 - auc: 0.9804\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2920 - auc: 0.9800\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2883 - auc: 0.9788\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2818 - auc: 0.9799\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2946 - auc: 0.9814\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2926 - auc: 0.9782\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2906 - auc: 0.9802\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2840 - auc: 0.9790\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2877 - auc: 0.9781\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2857 - auc: 0.9787\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2881 - auc: 0.9803\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2902 - auc: 0.9791\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2788 - auc: 0.9798\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3058 - auc: 0.9790\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2908 - auc: 0.9802\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2764 - auc: 0.9810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00398170949751843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.028133715474116885\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0039', 'eer_eval': '0.0281', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0039.hdf5', 'tnow': '2022-06-02 12:50:30.706626'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 49s 27ms/step - loss: 1.1779 - auc: 0.8269\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.5445 - auc: 0.9385\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4426 - auc: 0.9545\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3963 - auc: 0.9600\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3729 - auc: 0.9628\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3710 - auc: 0.9624\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3478 - auc: 0.9651\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3408 - auc: 0.9671\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3405 - auc: 0.9695\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3336 - auc: 0.9684\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3365 - auc: 0.9666\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3442 - auc: 0.9690\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3414 - auc: 0.9690\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3294 - auc: 0.9678\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3071 - auc: 0.9720\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3230 - auc: 0.9696\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3173 - auc: 0.9720\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3190 - auc: 0.9717\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3184 - auc: 0.9717\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3115 - auc: 0.9717\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3313 - auc: 0.9708\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3192 - auc: 0.9725\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3284 - auc: 0.9704\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3144 - auc: 0.9726\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3095 - auc: 0.9719\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3282 - auc: 0.9739\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3099 - auc: 0.9727\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3063 - auc: 0.9737\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3157 - auc: 0.9747\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2891 - auc: 0.9762\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3042 - auc: 0.9750\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2922 - auc: 0.9751\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2923 - auc: 0.9742\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3158 - auc: 0.9754\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2836 - auc: 0.9749\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2953 - auc: 0.9754\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2921 - auc: 0.9773\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2947 - auc: 0.9746\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3018 - auc: 0.9759\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2924 - auc: 0.9769\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2920 - auc: 0.9773\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2944 - auc: 0.9793\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2971 - auc: 0.9764\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.2860 - auc: 0.9785\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.2993 - auc: 0.9772\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2838 - auc: 0.9777\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 0.2983 - auc: 0.9788\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 0.2886 - auc: 0.9792\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2921 - auc: 0.9792\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2982 - auc: 0.9775\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2895 - auc: 0.9761\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2689 - auc: 0.9785\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2938 - auc: 0.9789\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3036 - auc: 0.9773\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2965 - auc: 0.9782\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.2857 - auc: 0.9787\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.2890 - auc: 0.9789\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.2890 - auc: 0.9790\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2787 - auc: 0.9788\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2845 - auc: 0.9796\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.2929 - auc: 0.9799\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2796 - auc: 0.9781\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2948 - auc: 0.9780\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2885 - auc: 0.9783\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2776 - auc: 0.9779\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2970 - auc: 0.9779\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2951 - auc: 0.9774\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2870 - auc: 0.9791\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2799 - auc: 0.9784\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2779 - auc: 0.9793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.007122201848719261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03698393105758926\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0071', 'eer_eval': '0.0369', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0071.hdf5', 'tnow': '2022-06-02 13:41:59.403274'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 48s 27ms/step - loss: 1.3020 - auc: 0.8014\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.5216 - auc: 0.9413\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4260 - auc: 0.9550\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4073 - auc: 0.9595\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3877 - auc: 0.9621\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3809 - auc: 0.9623\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3617 - auc: 0.9663\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3674 - auc: 0.9657\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3486 - auc: 0.9659\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3576 - auc: 0.9655\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3373 - auc: 0.9688\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3524 - auc: 0.9681\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3402 - auc: 0.9668\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3229 - auc: 0.9685\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3429 - auc: 0.9674\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3458 - auc: 0.9685\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3241 - auc: 0.9698\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3206 - auc: 0.9710\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3188 - auc: 0.9712\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3235 - auc: 0.9708\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3138 - auc: 0.9702\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3071 - auc: 0.9725\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3169 - auc: 0.9708\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3285 - auc: 0.9712\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3183 - auc: 0.9720\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3207 - auc: 0.9730\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3129 - auc: 0.9712\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3182 - auc: 0.9737\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3014 - auc: 0.9729\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3199 - auc: 0.9721\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3096 - auc: 0.9719\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3249 - auc: 0.9727\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2976 - auc: 0.9734\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3087 - auc: 0.9750\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2900 - auc: 0.9748\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3029 - auc: 0.9738\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3003 - auc: 0.9761\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2980 - auc: 0.9771\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3085 - auc: 0.9751\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3041 - auc: 0.9759\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3007 - auc: 0.9754\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2970 - auc: 0.9763\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2812 - auc: 0.9763\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3049 - auc: 0.9758\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3031 - auc: 0.9745\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3005 - auc: 0.9757\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2792 - auc: 0.9773\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2932 - auc: 0.9778\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2924 - auc: 0.9781\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2832 - auc: 0.9779\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2874 - auc: 0.9783\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2913 - auc: 0.9775\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2961 - auc: 0.9767\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2889 - auc: 0.9788\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2968 - auc: 0.9802\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2933 - auc: 0.9762\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3007 - auc: 0.9776\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3010 - auc: 0.9779\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3015 - auc: 0.9764\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2946 - auc: 0.9784\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3025 - auc: 0.9772\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2911 - auc: 0.9765\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2910 - auc: 0.9786\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2928 - auc: 0.9790\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2873 - auc: 0.9770\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2947 - auc: 0.9780\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2922 - auc: 0.9787\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2925 - auc: 0.9783\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2964 - auc: 0.9783\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2818 - auc: 0.9783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.005966857974704733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03290884977104657\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0059', 'eer_eval': '0.0329', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0059.hdf5', 'tnow': '2022-06-02 14:33:16.135674'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 47s 27ms/step - loss: 1.2292 - auc: 0.8146\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.6612 - auc: 0.9193\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.4502 - auc: 0.9551\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.4288 - auc: 0.9588\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3926 - auc: 0.9628\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3931 - auc: 0.9629\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3761 - auc: 0.9651\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3608 - auc: 0.9675\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3458 - auc: 0.9675\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3454 - auc: 0.9687\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3402 - auc: 0.9687\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3438 - auc: 0.9667\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3283 - auc: 0.9688\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3289 - auc: 0.9709\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3305 - auc: 0.9684\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3199 - auc: 0.9704\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3225 - auc: 0.9721\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3415 - auc: 0.9691\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3382 - auc: 0.9716\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3201 - auc: 0.9718\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3201 - auc: 0.9712\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3296 - auc: 0.9721\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3196 - auc: 0.9718\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3177 - auc: 0.9717\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3137 - auc: 0.9737\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3329 - auc: 0.9713\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3113 - auc: 0.9716\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3148 - auc: 0.9727\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3237 - auc: 0.9728\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3189 - auc: 0.9737\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3142 - auc: 0.9738\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3101 - auc: 0.9739\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3030 - auc: 0.9737\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3128 - auc: 0.9735\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3073 - auc: 0.9737\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3057 - auc: 0.9748\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3007 - auc: 0.9760\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3042 - auc: 0.9750\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3027 - auc: 0.9760\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3090 - auc: 0.9762\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3013 - auc: 0.9760\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2973 - auc: 0.9769\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2918 - auc: 0.9745\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3080 - auc: 0.9769\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2944 - auc: 0.9752\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2921 - auc: 0.9764\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2941 - auc: 0.9769\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2887 - auc: 0.9773\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3097 - auc: 0.9762\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2816 - auc: 0.9746\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2944 - auc: 0.9776\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3015 - auc: 0.9780\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3039 - auc: 0.9770\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2833 - auc: 0.9781\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2990 - auc: 0.9769\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3021 - auc: 0.9770\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2891 - auc: 0.9774\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2853 - auc: 0.9770\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2970 - auc: 0.9775\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2847 - auc: 0.9776\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2868 - auc: 0.9772\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2924 - auc: 0.9772\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2991 - auc: 0.9785\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2955 - auc: 0.9789\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2976 - auc: 0.9779\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2833 - auc: 0.9785\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3115 - auc: 0.9770\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2901 - auc: 0.9798\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2976 - auc: 0.9771\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2860 - auc: 0.9786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0053948923092703265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.02363547146194754\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0053', 'eer_eval': '0.0236', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0053.hdf5', 'tnow': '2022-06-02 15:23:35.225792'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 50s 27ms/step - loss: 1.4152 - auc: 0.7909\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.6325 - auc: 0.9222\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.5704 - auc: 0.9288\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4592 - auc: 0.9486\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4229 - auc: 0.9566\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3716 - auc: 0.9631\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3845 - auc: 0.9620\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3691 - auc: 0.9629\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3575 - auc: 0.9653\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3613 - auc: 0.9656\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3408 - auc: 0.9661\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3427 - auc: 0.9672\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3374 - auc: 0.9679\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3360 - auc: 0.9672\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3344 - auc: 0.9662\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3432 - auc: 0.9677\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3293 - auc: 0.9679\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3270 - auc: 0.9692\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3292 - auc: 0.9694\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3307 - auc: 0.9689\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3221 - auc: 0.9707\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3188 - auc: 0.9711\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3137 - auc: 0.9693\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3199 - auc: 0.9718\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3247 - auc: 0.9710\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3333 - auc: 0.9713\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3109 - auc: 0.9726\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3185 - auc: 0.9710\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3178 - auc: 0.9720\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3060 - auc: 0.9730\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3157 - auc: 0.9737\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3074 - auc: 0.9727\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3155 - auc: 0.9742\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3002 - auc: 0.9741\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3192 - auc: 0.9734\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3077 - auc: 0.9746\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3041 - auc: 0.9756\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3028 - auc: 0.9761\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3005 - auc: 0.9754\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2871 - auc: 0.9753\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3079 - auc: 0.9746\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3081 - auc: 0.9766\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3170 - auc: 0.9754\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2875 - auc: 0.9767\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3045 - auc: 0.9767\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2905 - auc: 0.9770\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2933 - auc: 0.9769\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2936 - auc: 0.9772\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2896 - auc: 0.9762\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2973 - auc: 0.9771\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2932 - auc: 0.9782\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2895 - auc: 0.9770\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2880 - auc: 0.9779\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2885 - auc: 0.9777\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2943 - auc: 0.9778\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2935 - auc: 0.9780\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2868 - auc: 0.9783\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2894 - auc: 0.9762\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2745 - auc: 0.9770\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3002 - auc: 0.9769\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2875 - auc: 0.9777\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3049 - auc: 0.9772\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3097 - auc: 0.9776\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2966 - auc: 0.9773\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2813 - auc: 0.9786\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2913 - auc: 0.9759\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2827 - auc: 0.9796\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2880 - auc: 0.9781\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2887 - auc: 0.9768\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2931 - auc: 0.9765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.005607856000193846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.02539612182045857\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0056', 'eer_eval': '0.0253', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0056.hdf5', 'tnow': '2022-06-02 16:14:35.745591'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 48s 27ms/step - loss: 1.3640 - auc: 0.8006\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.6791 - auc: 0.9144\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.5509 - auc: 0.9331\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.5039 - auc: 0.9421\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4515 - auc: 0.9537\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4197 - auc: 0.9578\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4179 - auc: 0.9577\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3935 - auc: 0.9605\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3690 - auc: 0.9635\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3697 - auc: 0.9635\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3710 - auc: 0.9617\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3504 - auc: 0.9643\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3439 - auc: 0.9645\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3422 - auc: 0.9645\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3283 - auc: 0.9636\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3422 - auc: 0.9668\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3457 - auc: 0.9644\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3378 - auc: 0.9666\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3398 - auc: 0.9660\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3406 - auc: 0.9674\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3407 - auc: 0.9671\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3364 - auc: 0.9672\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3453 - auc: 0.9678\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3354 - auc: 0.9685\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3219 - auc: 0.9692\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3393 - auc: 0.9675\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3435 - auc: 0.9674\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3245 - auc: 0.9699\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3236 - auc: 0.9715\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3254 - auc: 0.9707\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3219 - auc: 0.9715\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3015 - auc: 0.9725\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3027 - auc: 0.9720\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3280 - auc: 0.9706\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3230 - auc: 0.9726\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2985 - auc: 0.9717\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2920 - auc: 0.9734\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3228 - auc: 0.9726\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3019 - auc: 0.9745\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2949 - auc: 0.9748\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2870 - auc: 0.9746\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3045 - auc: 0.9741\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3057 - auc: 0.9762\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2950 - auc: 0.9741\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2972 - auc: 0.9755\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2946 - auc: 0.9742\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3094 - auc: 0.9752\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3011 - auc: 0.9740\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2986 - auc: 0.9762\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3043 - auc: 0.9754\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2954 - auc: 0.9742\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2946 - auc: 0.9764\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3069 - auc: 0.9748\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2968 - auc: 0.9745\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2968 - auc: 0.9753\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3047 - auc: 0.9738\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3013 - auc: 0.9758\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2999 - auc: 0.9755\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3130 - auc: 0.9743\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3112 - auc: 0.9751\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3073 - auc: 0.9752\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2915 - auc: 0.9747\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3099 - auc: 0.9751\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3019 - auc: 0.9751\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2993 - auc: 0.9748\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2978 - auc: 0.9739\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3001 - auc: 0.9763\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2915 - auc: 0.9757\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3061 - auc: 0.9754\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3110 - auc: 0.9754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.007279265212567781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.058498207823288684\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0072', 'eer_eval': '0.0584', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0072.hdf5', 'tnow': '2022-06-02 17:05:36.995641'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 47s 27ms/step - loss: 1.4848 - auc: 0.7608\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.6835 - auc: 0.9149\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4985 - auc: 0.9449\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.4562 - auc: 0.9530\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3999 - auc: 0.9577\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3963 - auc: 0.9593\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3857 - auc: 0.9596\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3786 - auc: 0.9628\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3686 - auc: 0.9626\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3625 - auc: 0.9652\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3537 - auc: 0.9643\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3525 - auc: 0.9659\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3477 - auc: 0.9662\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3562 - auc: 0.9664\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3477 - auc: 0.9647\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3378 - auc: 0.9686\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3475 - auc: 0.9667\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3377 - auc: 0.9664\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3279 - auc: 0.9696\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3378 - auc: 0.9691\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3440 - auc: 0.9709\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3345 - auc: 0.9695\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3340 - auc: 0.9705\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3224 - auc: 0.9714\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3141 - auc: 0.9703\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3250 - auc: 0.9707\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3125 - auc: 0.9689\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3117 - auc: 0.9701\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3048 - auc: 0.9731\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3023 - auc: 0.9731\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3062 - auc: 0.9717\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3279 - auc: 0.9726\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3126 - auc: 0.9715\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3170 - auc: 0.9709\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3011 - auc: 0.9726\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3140 - auc: 0.9741\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3152 - auc: 0.9737\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3126 - auc: 0.9727\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3133 - auc: 0.9748\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3163 - auc: 0.9743\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3006 - auc: 0.9744\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3020 - auc: 0.9746\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3139 - auc: 0.9769\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3107 - auc: 0.9743\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3064 - auc: 0.9743\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3068 - auc: 0.9756\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3002 - auc: 0.9743\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3125 - auc: 0.9762\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2933 - auc: 0.9758\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2971 - auc: 0.9759\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3043 - auc: 0.9765\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2995 - auc: 0.9760\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2941 - auc: 0.9768\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2938 - auc: 0.9760\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2967 - auc: 0.9767\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3062 - auc: 0.9763\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2952 - auc: 0.9753\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2899 - auc: 0.9752\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2946 - auc: 0.9756\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3041 - auc: 0.9744\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2826 - auc: 0.9771\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2955 - auc: 0.9758\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2987 - auc: 0.9759\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2985 - auc: 0.9746\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2919 - auc: 0.9749\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3068 - auc: 0.9769\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2935 - auc: 0.9763\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2921 - auc: 0.9763\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2974 - auc: 0.9778\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2982 - auc: 0.9743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.007453059928250339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.05156274233767996\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0074', 'eer_eval': '0.0515', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0074.hdf5', 'tnow': '2022-06-02 17:56:24.028809'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 51s 27ms/step - loss: 1.3150 - auc: 0.7989\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.6636 - auc: 0.9161\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.5263 - auc: 0.9389\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4715 - auc: 0.9508\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.4371 - auc: 0.9549\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4052 - auc: 0.9577\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3882 - auc: 0.9608\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3806 - auc: 0.9618\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3924 - auc: 0.9625\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3684 - auc: 0.9628\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3683 - auc: 0.9626\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3607 - auc: 0.9654\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3548 - auc: 0.9635\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3620 - auc: 0.9663\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3397 - auc: 0.9676\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3344 - auc: 0.9666\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3451 - auc: 0.9675\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3464 - auc: 0.9658\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3396 - auc: 0.9684\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3444 - auc: 0.9666\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3380 - auc: 0.9695\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3157 - auc: 0.9704\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3255 - auc: 0.9681\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3297 - auc: 0.9699\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3263 - auc: 0.9692\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3140 - auc: 0.9706\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3229 - auc: 0.9692\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3303 - auc: 0.9691\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3358 - auc: 0.9693\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3192 - auc: 0.9697\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3133 - auc: 0.9727\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3144 - auc: 0.9721\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3172 - auc: 0.9732\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3189 - auc: 0.9712\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3217 - auc: 0.9728\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3025 - auc: 0.9738\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3148 - auc: 0.9713\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3004 - auc: 0.9738\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2966 - auc: 0.9736\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3079 - auc: 0.9730\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2967 - auc: 0.9748\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2908 - auc: 0.9754\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3070 - auc: 0.9719\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3002 - auc: 0.9747\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3009 - auc: 0.9740\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2963 - auc: 0.9749\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3065 - auc: 0.9764\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2913 - auc: 0.9768\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3026 - auc: 0.9741\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3053 - auc: 0.9750\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3081 - auc: 0.9758\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3094 - auc: 0.9759\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2971 - auc: 0.9758\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3005 - auc: 0.9750\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2822 - auc: 0.9772\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2953 - auc: 0.9753\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2945 - auc: 0.9757\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3121 - auc: 0.9762\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3032 - auc: 0.9748\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3128 - auc: 0.9760\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3087 - auc: 0.9762\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2883 - auc: 0.9751\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3017 - auc: 0.9768\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3121 - auc: 0.9755\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2965 - auc: 0.9752\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2938 - auc: 0.9771\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2992 - auc: 0.9751\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3031 - auc: 0.9749\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2981 - auc: 0.9757\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2987 - auc: 0.9755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.006987576108277721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.045303847966999586\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0069', 'eer_eval': '0.0453', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0069.hdf5', 'tnow': '2022-06-02 18:47:34.493397'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 48s 27ms/step - loss: 1.3939 - auc: 0.8041\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.6506 - auc: 0.9209\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.5508 - auc: 0.9335\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4744 - auc: 0.9470\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4394 - auc: 0.9514\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4295 - auc: 0.9561\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4010 - auc: 0.9590\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3931 - auc: 0.9599\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3929 - auc: 0.9598\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.3763 - auc: 0.9630\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3671 - auc: 0.9648\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3563 - auc: 0.9653\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3443 - auc: 0.9643\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3496 - auc: 0.9661\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3631 - auc: 0.9672\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3460 - auc: 0.9664\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3402 - auc: 0.9676\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.3490 - auc: 0.9668\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3369 - auc: 0.9675\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3496 - auc: 0.9675\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3329 - auc: 0.9676\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3420 - auc: 0.9687\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3329 - auc: 0.9681\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3282 - auc: 0.9707\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3290 - auc: 0.9693\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3192 - auc: 0.9729\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3202 - auc: 0.9721\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3271 - auc: 0.9712\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3098 - auc: 0.9729\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3262 - auc: 0.9706\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3262 - auc: 0.9713\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3135 - auc: 0.9717\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3101 - auc: 0.9724\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3045 - auc: 0.9747\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3035 - auc: 0.9713\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3140 - auc: 0.9727\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3216 - auc: 0.9715\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3158 - auc: 0.9731\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3115 - auc: 0.9738\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3099 - auc: 0.9739\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3107 - auc: 0.9728\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2886 - auc: 0.9750\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3084 - auc: 0.9748\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3101 - auc: 0.9740\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2960 - auc: 0.9742\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3141 - auc: 0.9744\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3029 - auc: 0.9758\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3076 - auc: 0.9743\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2965 - auc: 0.9751\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3022 - auc: 0.9736\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2992 - auc: 0.9744\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.3025 - auc: 0.9755\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3068 - auc: 0.9764\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3099 - auc: 0.9765\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3040 - auc: 0.9769\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3146 - auc: 0.9766\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3089 - auc: 0.9751\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3095 - auc: 0.9764\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2895 - auc: 0.9750\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3117 - auc: 0.9752\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3092 - auc: 0.9761\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3030 - auc: 0.9762\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3043 - auc: 0.9755\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3030 - auc: 0.9755\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2896 - auc: 0.9756\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2974 - auc: 0.9766\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3089 - auc: 0.9771\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2934 - auc: 0.9758\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3064 - auc: 0.9773\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3064 - auc: 0.9754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0053500170624564795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.04842546785385358\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0053', 'eer_eval': '0.0484', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0053.hdf5', 'tnow': '2022-06-02 19:38:43.580402'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 47s 27ms/step - loss: 1.2666 - auc: 0.8207\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.6783 - auc: 0.9111\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.5783 - auc: 0.9227\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.5470 - auc: 0.9308\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.4828 - auc: 0.9455\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.4398 - auc: 0.9561\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.4233 - auc: 0.9592\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.4217 - auc: 0.9589\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3953 - auc: 0.9605\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3887 - auc: 0.9632\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3877 - auc: 0.9618\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3853 - auc: 0.9614\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3662 - auc: 0.9635\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3547 - auc: 0.9676\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3646 - auc: 0.9669\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3559 - auc: 0.9667\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3517 - auc: 0.9653\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3415 - auc: 0.9678\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3538 - auc: 0.9662\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3358 - auc: 0.9685\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3246 - auc: 0.9681\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3334 - auc: 0.9700\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3370 - auc: 0.9693\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3392 - auc: 0.9676\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3225 - auc: 0.9686\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3365 - auc: 0.9701\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3287 - auc: 0.9686\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3315 - auc: 0.9709\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3301 - auc: 0.9716\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3189 - auc: 0.9702\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3164 - auc: 0.9716\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3026 - auc: 0.9734\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3316 - auc: 0.9730\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3269 - auc: 0.9716\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3052 - auc: 0.9731\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3158 - auc: 0.9734\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3285 - auc: 0.9729\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3089 - auc: 0.9704\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3025 - auc: 0.9743\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3127 - auc: 0.9738\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3116 - auc: 0.9735\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2984 - auc: 0.9738\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3000 - auc: 0.9740\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3106 - auc: 0.9737\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3040 - auc: 0.9751\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2935 - auc: 0.9744\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3112 - auc: 0.9761\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2868 - auc: 0.9752\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2920 - auc: 0.9738\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2933 - auc: 0.9765\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2997 - auc: 0.9743\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3016 - auc: 0.9752\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3143 - auc: 0.9747\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3062 - auc: 0.9755\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2991 - auc: 0.9760\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3057 - auc: 0.9748\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3011 - auc: 0.9742\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3127 - auc: 0.9753\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2880 - auc: 0.9755\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3120 - auc: 0.9747\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3028 - auc: 0.9762\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3019 - auc: 0.9758\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3013 - auc: 0.9745\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2995 - auc: 0.9764\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2997 - auc: 0.9756\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3012 - auc: 0.9744\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2943 - auc: 0.9744\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2982 - auc: 0.9757\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3044 - auc: 0.9759\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2967 - auc: 0.9752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.007408184681436492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.052377758594988486\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0074', 'eer_eval': '0.0523', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0074.hdf5', 'tnow': '2022-06-02 20:29:15.121301'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 47s 27ms/step - loss: 1.2766 - auc: 0.7988\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.6866 - auc: 0.9167\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.5699 - auc: 0.9305\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.5438 - auc: 0.9366\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.4934 - auc: 0.9429\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.4338 - auc: 0.9532\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.4246 - auc: 0.9558\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3775 - auc: 0.9604\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3910 - auc: 0.9604\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3664 - auc: 0.9638\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3664 - auc: 0.9631\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3743 - auc: 0.9652\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3492 - auc: 0.9675\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3389 - auc: 0.9667\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3546 - auc: 0.9668\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3359 - auc: 0.9669\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3451 - auc: 0.9664\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3440 - auc: 0.9665\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3402 - auc: 0.9666\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3348 - auc: 0.9698\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3345 - auc: 0.9682\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3196 - auc: 0.9704\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3265 - auc: 0.9697\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3316 - auc: 0.9705\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3180 - auc: 0.9700\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3236 - auc: 0.9701\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3190 - auc: 0.9715\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3238 - auc: 0.9689\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3134 - auc: 0.9722\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3239 - auc: 0.9707\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3231 - auc: 0.9700\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3160 - auc: 0.9726\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3219 - auc: 0.9717\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3158 - auc: 0.9721\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3075 - auc: 0.9735\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3161 - auc: 0.9733\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3105 - auc: 0.9737\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3150 - auc: 0.9735\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3115 - auc: 0.9744\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3008 - auc: 0.9742\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3065 - auc: 0.9741\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3027 - auc: 0.9742\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2972 - auc: 0.9747\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3055 - auc: 0.9745\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3115 - auc: 0.9765\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3034 - auc: 0.9741\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3023 - auc: 0.9748\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3005 - auc: 0.9744\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3057 - auc: 0.9754\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2945 - auc: 0.9768\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3037 - auc: 0.9748\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3070 - auc: 0.9764\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2937 - auc: 0.9775\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2849 - auc: 0.9748\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3143 - auc: 0.9774\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2965 - auc: 0.9759\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2946 - auc: 0.9755\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3053 - auc: 0.9745\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3021 - auc: 0.9762\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2938 - auc: 0.9776\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3039 - auc: 0.9766\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3065 - auc: 0.9759\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2978 - auc: 0.9762\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2909 - auc: 0.9767\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3014 - auc: 0.9756\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3062 - auc: 0.9774\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3009 - auc: 0.9761\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3013 - auc: 0.9744\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2943 - auc: 0.9757\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3108 - auc: 0.9768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.007430622304843416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.04897142112488802\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0074', 'eer_eval': '0.0489', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0074.hdf5', 'tnow': '2022-06-02 21:19:20.311691'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 48s 27ms/step - loss: 1.3108 - auc: 0.8231\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.6278 - auc: 0.9262\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4735 - auc: 0.9508\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.4355 - auc: 0.9552\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4194 - auc: 0.9537\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4092 - auc: 0.9591\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.4040 - auc: 0.9574\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 0.3792 - auc: 0.9630\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 0.3762 - auc: 0.9601\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 0.3551 - auc: 0.9646\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3596 - auc: 0.9647\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.3421 - auc: 0.9665\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.3750 - auc: 0.9627\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 0.3498 - auc: 0.9673\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3602 - auc: 0.9647\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3602 - auc: 0.9655\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3429 - auc: 0.9674\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3287 - auc: 0.9673\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3489 - auc: 0.9671\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3369 - auc: 0.9680\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3388 - auc: 0.9680\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3355 - auc: 0.9687\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3420 - auc: 0.9671\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3335 - auc: 0.9685\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3308 - auc: 0.9690\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3204 - auc: 0.9698\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3181 - auc: 0.9677\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3425 - auc: 0.9707\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3506 - auc: 0.9690\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3157 - auc: 0.9728\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3224 - auc: 0.9701\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3284 - auc: 0.9683\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3318 - auc: 0.9720\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3143 - auc: 0.9709\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3259 - auc: 0.9745\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3170 - auc: 0.9734\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3144 - auc: 0.9726\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3175 - auc: 0.9737\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3064 - auc: 0.9735\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3086 - auc: 0.9735\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3099 - auc: 0.9734\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3071 - auc: 0.9739\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3155 - auc: 0.9748\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3207 - auc: 0.9748\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3013 - auc: 0.9724\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3065 - auc: 0.9754\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3028 - auc: 0.9766\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3065 - auc: 0.9748\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3156 - auc: 0.9749\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3004 - auc: 0.9748\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3026 - auc: 0.9748\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2983 - auc: 0.9753\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3044 - auc: 0.9752\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3002 - auc: 0.9744\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2914 - auc: 0.9755\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2837 - auc: 0.9745\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2971 - auc: 0.9744\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3071 - auc: 0.9749\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3051 - auc: 0.9747\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2982 - auc: 0.9746\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3136 - auc: 0.9739\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3044 - auc: 0.9766\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3082 - auc: 0.9766\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3024 - auc: 0.9765\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3042 - auc: 0.9760\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2954 - auc: 0.9774\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2925 - auc: 0.9766\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2969 - auc: 0.9758\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3032 - auc: 0.9756\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2863 - auc: 0.9779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0053948923092703265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.05149229665130414\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0053', 'eer_eval': '0.0514', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0053.hdf5', 'tnow': '2022-06-02 22:10:41.285087'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 47s 27ms/step - loss: 1.3518 - auc: 0.8098\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.6804 - auc: 0.9146\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.5214 - auc: 0.9385\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4447 - auc: 0.9552\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4312 - auc: 0.9544\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4128 - auc: 0.9568\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3771 - auc: 0.9603\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3674 - auc: 0.9621\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3751 - auc: 0.9614\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3530 - auc: 0.9626\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3678 - auc: 0.9655\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3642 - auc: 0.9631\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3482 - auc: 0.9640\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3617 - auc: 0.9629\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3549 - auc: 0.9674\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3520 - auc: 0.9657\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3379 - auc: 0.9659\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3404 - auc: 0.9686\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.3408 - auc: 0.9658\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3441 - auc: 0.9663\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3378 - auc: 0.9678\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3519 - auc: 0.9671\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3340 - auc: 0.9674\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 0.3351 - auc: 0.9694\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.3540 - auc: 0.9695\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3317 - auc: 0.9695\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3312 - auc: 0.9712\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3165 - auc: 0.9700\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3258 - auc: 0.9708\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3322 - auc: 0.9707\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3140 - auc: 0.9705\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3337 - auc: 0.9717\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 0.3204 - auc: 0.9699\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3222 - auc: 0.9711\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3089 - auc: 0.9741\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3211 - auc: 0.9736\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3052 - auc: 0.9720\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3179 - auc: 0.9738\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3055 - auc: 0.9720\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.3066 - auc: 0.9744\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 0.3119 - auc: 0.9737\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3116 - auc: 0.9728\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3154 - auc: 0.9741\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3087 - auc: 0.9721\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3116 - auc: 0.9711\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3047 - auc: 0.9753\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3048 - auc: 0.9736\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3062 - auc: 0.9738\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2868 - auc: 0.9753\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3127 - auc: 0.9736\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3035 - auc: 0.9749\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3182 - auc: 0.9732\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3070 - auc: 0.9766\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2974 - auc: 0.9742\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2945 - auc: 0.9750\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3204 - auc: 0.9748\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2898 - auc: 0.9740\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3003 - auc: 0.9746\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3128 - auc: 0.9754\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2982 - auc: 0.9741\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 0.2988 - auc: 0.9759\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3173 - auc: 0.9749\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2911 - auc: 0.9752\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3047 - auc: 0.9760\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3112 - auc: 0.9768\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.3117 - auc: 0.9757\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3049 - auc: 0.9758\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2995 - auc: 0.9750\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 0.3031 - auc: 0.9729\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.3059 - auc: 0.9748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0050640342297393025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03834490058593222\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0050', 'eer_eval': '0.0383', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0050.hdf5', 'tnow': '2022-06-02 23:02:07.146082'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 47s 27ms/step - loss: 1.3691 - auc: 0.7862\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.6727 - auc: 0.9175\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.5293 - auc: 0.9423\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.4649 - auc: 0.9499\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.4224 - auc: 0.9583\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4176 - auc: 0.9584\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3931 - auc: 0.9586\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3944 - auc: 0.9607\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3641 - auc: 0.9642\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3765 - auc: 0.9626\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3785 - auc: 0.9630\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3655 - auc: 0.9665\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3529 - auc: 0.9661\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3738 - auc: 0.9668\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3573 - auc: 0.9654\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3491 - auc: 0.9669\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3542 - auc: 0.9665\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3643 - auc: 0.9639\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3531 - auc: 0.9691\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3458 - auc: 0.9699\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3465 - auc: 0.9663\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3330 - auc: 0.9689\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3379 - auc: 0.9701\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3380 - auc: 0.9675\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3363 - auc: 0.9686\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3216 - auc: 0.9672\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3242 - auc: 0.9696\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3357 - auc: 0.9690\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3211 - auc: 0.9698\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3294 - auc: 0.9685\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3281 - auc: 0.9710\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3228 - auc: 0.9694\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3249 - auc: 0.9715\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3394 - auc: 0.9701\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3159 - auc: 0.9702\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3226 - auc: 0.9722\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3210 - auc: 0.9720\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3201 - auc: 0.9732\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3103 - auc: 0.9725\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3201 - auc: 0.9746\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3144 - auc: 0.9723\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3069 - auc: 0.9710\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3112 - auc: 0.9733\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3172 - auc: 0.9740\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3194 - auc: 0.9742\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3070 - auc: 0.9724\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2990 - auc: 0.9731\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2992 - auc: 0.9739\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3033 - auc: 0.9739\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3009 - auc: 0.9725\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3087 - auc: 0.9746\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3000 - auc: 0.9744\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3205 - auc: 0.9750\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3209 - auc: 0.9730\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3045 - auc: 0.9750\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3213 - auc: 0.9719\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3059 - auc: 0.9752\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3091 - auc: 0.9745\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3030 - auc: 0.9732\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3016 - auc: 0.9726\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3095 - auc: 0.9741\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3068 - auc: 0.9747\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2992 - auc: 0.9762\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2931 - auc: 0.9737\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3074 - auc: 0.9751\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3082 - auc: 0.9732\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3112 - auc: 0.9741\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3167 - auc: 0.9734\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3166 - auc: 0.9736\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3064 - auc: 0.9750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0070773266019054145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0321540056712562\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0070', 'eer_eval': '0.0321', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0070.hdf5', 'tnow': '2022-06-02 23:52:51.193805'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 50s 27ms/step - loss: 1.3609 - auc: 0.8067\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.5856 - auc: 0.9352\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4460 - auc: 0.9547\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4200 - auc: 0.9578\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3982 - auc: 0.9605\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3661 - auc: 0.9634\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3699 - auc: 0.9632\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3742 - auc: 0.9627\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3552 - auc: 0.9652\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3513 - auc: 0.9651\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3356 - auc: 0.9675\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3430 - auc: 0.9667\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3366 - auc: 0.9687\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3319 - auc: 0.9684\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3249 - auc: 0.9688\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3324 - auc: 0.9687\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3361 - auc: 0.9709\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3166 - auc: 0.9704\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3271 - auc: 0.9708\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3202 - auc: 0.9699\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3258 - auc: 0.9726\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3290 - auc: 0.9687\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3227 - auc: 0.9718\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3194 - auc: 0.9715\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3074 - auc: 0.9726\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3154 - auc: 0.9717\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3137 - auc: 0.9694\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3018 - auc: 0.9725\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3124 - auc: 0.9739\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3029 - auc: 0.9725\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3153 - auc: 0.9731\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3134 - auc: 0.9739\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3114 - auc: 0.9745\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2984 - auc: 0.9750\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3205 - auc: 0.9743\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2982 - auc: 0.9748\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3136 - auc: 0.9727\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3084 - auc: 0.9729\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3084 - auc: 0.9738\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2953 - auc: 0.9758\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3012 - auc: 0.9741\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3110 - auc: 0.9752\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3045 - auc: 0.9753\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2879 - auc: 0.9746\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3167 - auc: 0.9757\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2917 - auc: 0.9747\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2949 - auc: 0.9755\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3039 - auc: 0.9754\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2982 - auc: 0.9760\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2798 - auc: 0.9760\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2926 - auc: 0.9762\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3089 - auc: 0.9769\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2973 - auc: 0.9763\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2892 - auc: 0.9764\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2969 - auc: 0.9775\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2989 - auc: 0.9768\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2887 - auc: 0.9777\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3063 - auc: 0.9777\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3049 - auc: 0.9777\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2868 - auc: 0.9774\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2912 - auc: 0.9775\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2928 - auc: 0.9764\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2930 - auc: 0.9757\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2969 - auc: 0.9780\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3055 - auc: 0.9774\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2843 - auc: 0.9779\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2841 - auc: 0.9779\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2876 - auc: 0.9764\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2937 - auc: 0.9769\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2936 - auc: 0.9777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0066791556521535655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.02419707932995437\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0066', 'eer_eval': '0.0241', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0066.hdf5', 'tnow': '2022-06-03 00:44:03.971331'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 48s 27ms/step - loss: 1.4071 - auc: 0.7822\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.6200 - auc: 0.9221\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.5036 - auc: 0.9440\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4439 - auc: 0.9548\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4097 - auc: 0.9597\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4087 - auc: 0.9612\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3779 - auc: 0.9619\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3699 - auc: 0.9633\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3492 - auc: 0.9679\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3573 - auc: 0.9667\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3417 - auc: 0.9693\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3513 - auc: 0.9683\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3548 - auc: 0.9679\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3337 - auc: 0.9705\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3513 - auc: 0.9669\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3472 - auc: 0.9676\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3454 - auc: 0.9676\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3287 - auc: 0.9700\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3277 - auc: 0.9713\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3133 - auc: 0.9714\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3295 - auc: 0.9715\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3078 - auc: 0.9718\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3271 - auc: 0.9714\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3136 - auc: 0.9696\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3244 - auc: 0.9708\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3223 - auc: 0.9728\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3188 - auc: 0.9717\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3246 - auc: 0.9719\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3202 - auc: 0.9737\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3005 - auc: 0.9750\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2991 - auc: 0.9732\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3093 - auc: 0.9737\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3152 - auc: 0.9741\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3077 - auc: 0.9748\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3185 - auc: 0.9738\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3097 - auc: 0.9755\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2921 - auc: 0.9762\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3028 - auc: 0.9766\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2995 - auc: 0.9756\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 0.2997 - auc: 0.9760\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 0.3061 - auc: 0.9772\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.2908 - auc: 0.9759\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2965 - auc: 0.9776\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.2935 - auc: 0.9768\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 0.2957 - auc: 0.9765\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.3003 - auc: 0.9776\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.2882 - auc: 0.9776\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 0.2972 - auc: 0.9771\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 0.3017 - auc: 0.9775\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 0.2903 - auc: 0.9769\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 0.2905 - auc: 0.9769\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 0.2901 - auc: 0.9791\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2992 - auc: 0.9777\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3023 - auc: 0.9771\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2757 - auc: 0.9778\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2864 - auc: 0.9780\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2787 - auc: 0.9785\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2932 - auc: 0.9773\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2991 - auc: 0.9780\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2838 - auc: 0.9786\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.2802 - auc: 0.9782\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2979 - auc: 0.9768\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2893 - auc: 0.9767\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3011 - auc: 0.9765\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2935 - auc: 0.9772\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3029 - auc: 0.9788\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.2945 - auc: 0.9769\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2893 - auc: 0.9793\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2900 - auc: 0.9794\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.2942 - auc: 0.9765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.005507080426304999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.028972213626884055\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0055', 'eer_eval': '0.0289', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0055.hdf5', 'tnow': '2022-06-03 01:35:27.305966'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 47s 27ms/step - loss: 1.2055 - auc: 0.8244\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.6171 - auc: 0.9206\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.5269 - auc: 0.9358\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4744 - auc: 0.9482\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.4072 - auc: 0.9572\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3934 - auc: 0.9606\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3721 - auc: 0.9643\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3482 - auc: 0.9635\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3655 - auc: 0.9656\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3520 - auc: 0.9658\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3329 - auc: 0.9653\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3376 - auc: 0.9665\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3334 - auc: 0.9682\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3388 - auc: 0.9696\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3185 - auc: 0.9704\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3312 - auc: 0.9677\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3262 - auc: 0.9698\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3293 - auc: 0.9719\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3267 - auc: 0.9689\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3161 - auc: 0.9701\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3097 - auc: 0.9726\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3031 - auc: 0.9740\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3169 - auc: 0.9712\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3176 - auc: 0.9731\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3134 - auc: 0.9711\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3306 - auc: 0.9705\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3274 - auc: 0.9719\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3159 - auc: 0.9732\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2999 - auc: 0.9727\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3183 - auc: 0.9737\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2950 - auc: 0.9753\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3159 - auc: 0.9724\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3058 - auc: 0.9742\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3033 - auc: 0.9738\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3082 - auc: 0.9763\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3059 - auc: 0.9752\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2997 - auc: 0.9740\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2946 - auc: 0.9750\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2991 - auc: 0.9755\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2931 - auc: 0.9755\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2915 - auc: 0.9751\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2976 - auc: 0.9762\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2983 - auc: 0.9767\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2855 - auc: 0.9755\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2891 - auc: 0.9774\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3092 - auc: 0.9772\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2945 - auc: 0.9773\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2852 - auc: 0.9761\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2984 - auc: 0.9765\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2944 - auc: 0.9755\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2915 - auc: 0.9774\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2871 - auc: 0.9768\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2851 - auc: 0.9774\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2895 - auc: 0.9792\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3027 - auc: 0.9770 0s - loss: 0.3028 - auc:\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2969 - auc: 0.9778\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2912 - auc: 0.9771\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3027 - auc: 0.9781\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3016 - auc: 0.9782\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2891 - auc: 0.9782\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2975 - auc: 0.9786\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2957 - auc: 0.9784\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3065 - auc: 0.9768\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2869 - auc: 0.9779\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2934 - auc: 0.9779\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2858 - auc: 0.9769\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3010 - auc: 0.9773\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3024 - auc: 0.9781\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2929 - auc: 0.9778\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2947 - auc: 0.9770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.006920263238056895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.021091114040072773\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0069', 'eer_eval': '0.0210', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0069.hdf5', 'tnow': '2022-06-03 02:25:51.285488'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 47s 27ms/step - loss: 1.2214 - auc: 0.8090\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.7085 - auc: 0.9153\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.5417 - auc: 0.9404\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.4701 - auc: 0.9500\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.4368 - auc: 0.9547\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.4188 - auc: 0.9581\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4090 - auc: 0.9605\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3858 - auc: 0.9620\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3798 - auc: 0.9603\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3905 - auc: 0.9617\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3621 - auc: 0.9621\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3623 - auc: 0.9639\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3514 - auc: 0.9651\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 41s 26ms/step - loss: 0.3621 - auc: 0.9648\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3726 - auc: 0.9652\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3352 - auc: 0.9658\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3480 - auc: 0.9666\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3630 - auc: 0.9654\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3461 - auc: 0.9692\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3663 - auc: 0.9682\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3437 - auc: 0.9676\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3430 - auc: 0.9684\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3477 - auc: 0.9691\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3334 - auc: 0.9687\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3371 - auc: 0.9691\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3355 - auc: 0.9694\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3345 - auc: 0.9691\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3326 - auc: 0.9705\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3383 - auc: 0.9696\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3399 - auc: 0.9702\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3342 - auc: 0.9708\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3246 - auc: 0.9680\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3298 - auc: 0.9695\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3196 - auc: 0.9721\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3051 - auc: 0.9719\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3265 - auc: 0.9721\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3232 - auc: 0.9737\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3362 - auc: 0.9707\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3139 - auc: 0.9719\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3037 - auc: 0.9727\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3106 - auc: 0.9738\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3090 - auc: 0.9747\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3185 - auc: 0.9735\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3151 - auc: 0.9739\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.2902 - auc: 0.9753\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3113 - auc: 0.9741\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3108 - auc: 0.9764\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3023 - auc: 0.9747\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3101 - auc: 0.9728\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2998 - auc: 0.9751\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3136 - auc: 0.9723\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3101 - auc: 0.9740\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3163 - auc: 0.9730\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3034 - auc: 0.9747\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3144 - auc: 0.9754\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3017 - auc: 0.9745\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.2997 - auc: 0.9752\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3158 - auc: 0.9753\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3046 - auc: 0.9740\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3019 - auc: 0.9734\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3140 - auc: 0.9750\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3035 - auc: 0.9755\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3191 - auc: 0.9728\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3005 - auc: 0.9740\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3043 - auc: 0.9743\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3019 - auc: 0.9761\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3123 - auc: 0.9748\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3147 - auc: 0.9740\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.3123 - auc: 0.9744\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3040 - auc: 0.9750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.008159651334126286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.044896339838345324\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0081', 'eer_eval': '0.0448', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0081.hdf5', 'tnow': '2022-06-03 03:16:06.387343'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 48s 27ms/step - loss: 1.4125 - auc: 0.7786\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.6666 - auc: 0.9169\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.5608 - auc: 0.9329\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4790 - auc: 0.9492\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4400 - auc: 0.9557\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4028 - auc: 0.9580\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4018 - auc: 0.9610\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3801 - auc: 0.9628\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3841 - auc: 0.9625\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3815 - auc: 0.9625\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3645 - auc: 0.9631\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 0.3626 - auc: 0.9654\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.3595 - auc: 0.9653\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 0.3673 - auc: 0.9651\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3504 - auc: 0.9679\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3587 - auc: 0.9684\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 0.3356 - auc: 0.9677\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3495 - auc: 0.9667\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.3466 - auc: 0.9683\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3461 - auc: 0.9678\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3306 - auc: 0.9694\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3326 - auc: 0.9690\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3309 - auc: 0.9691\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3379 - auc: 0.9686\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3391 - auc: 0.9678\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3436 - auc: 0.9697\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3308 - auc: 0.9711\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3325 - auc: 0.9695\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3266 - auc: 0.9701\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3270 - auc: 0.9699\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3190 - auc: 0.9705\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3272 - auc: 0.9713\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3309 - auc: 0.9704\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3319 - auc: 0.9714\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3180 - auc: 0.9707\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3171 - auc: 0.9698\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3117 - auc: 0.9728\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3206 - auc: 0.9719\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3176 - auc: 0.9709\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3072 - auc: 0.9732\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3020 - auc: 0.9723\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3173 - auc: 0.9704\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3061 - auc: 0.9732\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3139 - auc: 0.9734\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3063 - auc: 0.9737\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3097 - auc: 0.9737\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3147 - auc: 0.9736\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3095 - auc: 0.9727\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3044 - auc: 0.9726\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3021 - auc: 0.9739\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3140 - auc: 0.9743\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3124 - auc: 0.9761\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3006 - auc: 0.9726\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.2927 - auc: 0.9749\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2998 - auc: 0.9741\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3085 - auc: 0.9734\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3042 - auc: 0.9729\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3065 - auc: 0.9736\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3097 - auc: 0.9740\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3198 - auc: 0.9735\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3123 - auc: 0.9751\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3065 - auc: 0.9744\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3120 - auc: 0.9730\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3090 - auc: 0.9750\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3028 - auc: 0.9743\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 44s 27ms/step - loss: 0.2953 - auc: 0.9743\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 44s 28ms/step - loss: 0.3149 - auc: 0.9740\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3082 - auc: 0.9734\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3008 - auc: 0.9732\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3137 - auc: 0.9741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.005462205179491152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.02981071177965117\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0054', 'eer_eval': '0.0298', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0054.hdf5', 'tnow': '2022-06-03 04:07:29.679211'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 48s 27ms/step - loss: 1.2792 - auc: 0.8305\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.7630 - auc: 0.9145\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.5360 - auc: 0.9387\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4569 - auc: 0.9506\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4568 - auc: 0.9504\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.4266 - auc: 0.9563\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.4056 - auc: 0.9586\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 42s 26ms/step - loss: 0.4090 - auc: 0.9574\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3929 - auc: 0.9599\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3828 - auc: 0.9620\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3825 - auc: 0.9613\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3731 - auc: 0.9632\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3705 - auc: 0.9630\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3692 - auc: 0.9628\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3781 - auc: 0.9634\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3613 - auc: 0.9639\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3641 - auc: 0.9636\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3716 - auc: 0.9656\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3530 - auc: 0.9643\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3460 - auc: 0.9686\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3507 - auc: 0.9673\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3366 - auc: 0.9679\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3496 - auc: 0.9662\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3303 - auc: 0.9685\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3326 - auc: 0.9670\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3343 - auc: 0.9696\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3370 - auc: 0.9677\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3248 - auc: 0.9696\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3551 - auc: 0.9672\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3281 - auc: 0.9696\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3316 - auc: 0.9695\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3461 - auc: 0.9666\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3326 - auc: 0.9692\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3392 - auc: 0.9698\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3332 - auc: 0.9715\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3211 - auc: 0.9729\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3186 - auc: 0.9711\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3153 - auc: 0.9711\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3180 - auc: 0.9724\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3232 - auc: 0.9727\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3122 - auc: 0.9720\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3220 - auc: 0.9713\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3205 - auc: 0.9718\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3046 - auc: 0.9723\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3012 - auc: 0.9721\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3138 - auc: 0.9731\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3077 - auc: 0.9737\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3320 - auc: 0.9734\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3122 - auc: 0.9731\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3020 - auc: 0.9745\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3176 - auc: 0.9740\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3277 - auc: 0.9719\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3088 - auc: 0.9733\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3060 - auc: 0.9734\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3142 - auc: 0.9747\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3220 - auc: 0.9737\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3017 - auc: 0.9736\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3059 - auc: 0.9745\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2947 - auc: 0.9738\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3017 - auc: 0.9753\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3073 - auc: 0.9728\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3173 - auc: 0.9734\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3098 - auc: 0.9729\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3096 - auc: 0.9745\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3042 - auc: 0.9744\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3002 - auc: 0.9733\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.3062 - auc: 0.9740\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 43s 27ms/step - loss: 0.2993 - auc: 0.9731\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3152 - auc: 0.9730\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 42s 27ms/step - loss: 0.3093 - auc: 0.9745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.007806355631188285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.05574495957265798\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0078', 'eer_eval': '0.0557', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0078.hdf5', 'tnow': '2022-06-03 04:58:22.554916'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 68s 39ms/step - loss: 1.3992 - auc: 0.7375\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.4601 - auc: 0.9536\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.1856 - auc: 0.9926\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.1180 - auc: 0.9964\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.0887 - auc: 0.9978\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0866 - auc: 0.9978\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0747 - auc: 0.9982\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0549 - auc: 0.9989\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0500 - auc: 0.9988\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0474 - auc: 0.9989\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0331 - auc: 0.9994\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0601 - auc: 0.9990\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0381 - auc: 0.9995\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0343 - auc: 0.9996\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0336 - auc: 0.9994\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0302 - auc: 0.9993\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0445 - auc: 0.9994\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0272 - auc: 0.9995\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0406 - auc: 0.9990\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0202 - auc: 0.9995\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0196 - auc: 0.9997\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0283 - auc: 0.9994\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.0214 - auc: 0.9997\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.0155 - auc: 0.9998\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.0160 - auc: 0.9999\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.0166 - auc: 0.9998\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0129 - auc: 0.9999\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.0209 - auc: 0.9994\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.0102 - auc: 0.9998\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0169 - auc: 0.9998\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0133 - auc: 0.9998\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.0127 - auc: 0.9996\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.0159 - auc: 0.9997\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.0100 - auc: 0.9999\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0095 - auc: 0.9999\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.0093 - auc: 0.9998\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0071 - auc: 0.9999\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.0119 - auc: 0.9997\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.0093 - auc: 0.9999\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.0030 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0031 - auc: 0.9999\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.0086 - auc: 0.9997\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.0018 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.0046 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0024 - auc: 0.9999\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0021 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.0038 - auc: 0.9999\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0015 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.0022 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.0017 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.0022 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.0019 - auc: 0.9998\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0014 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0026 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0014 - auc: 0.9999\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 7.1064e-04 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0017 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 7.3839e-04 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0012 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0058 - auc: 0.9999\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.0012 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.0020 - auc: 0.9999\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0011 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 8.2425e-04 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0013 - auc: 0.9999\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0012 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.0020 - auc: 0.9999\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 7.6481e-04 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.0012 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.0012 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.004688300903394378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.021067632144614185\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0046', 'eer_eval': '0.0210', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0046.hdf5', 'tnow': '2022-06-03 06:12:42.624353'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 70s 40ms/step - loss: 1.2832 - auc: 0.7414\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.4151 - auc: 0.9598\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2088 - auc: 0.9906\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.1216 - auc: 0.9962\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0888 - auc: 0.9979\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0972 - auc: 0.9973\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0675 - auc: 0.9985\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0532 - auc: 0.9987\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0592 - auc: 0.9986\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0494 - auc: 0.9990\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0384 - auc: 0.9989\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0429 - auc: 0.9992\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0419 - auc: 0.9990\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0336 - auc: 0.9994\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0304 - auc: 0.9995\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0321 - auc: 0.9996\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0300 - auc: 0.9993\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0286 - auc: 0.9994\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0194 - auc: 0.9995\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0191 - auc: 0.9996\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0226 - auc: 0.9995\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0177 - auc: 0.9998\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0199 - auc: 0.9995\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0174 - auc: 0.9996\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 64s 41ms/step - loss: 0.0232 - auc: 0.9997\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0196 - auc: 0.9998\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0192 - auc: 0.9996\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0180 - auc: 0.9998\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.0188 - auc: 0.9994\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0183 - auc: 0.9997\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0200 - auc: 0.9995\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0171 - auc: 0.9996\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0141 - auc: 0.9997\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0073 - auc: 1.0000\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0089 - auc: 0.9999\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0102 - auc: 0.9998\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0082 - auc: 0.9998\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0050 - auc: 0.9998\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0050 - auc: 0.9999\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0103 - auc: 0.9998\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0072 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0057 - auc: 0.9999\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0047 - auc: 0.9999\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0027 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0015 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0054 - auc: 0.9999\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0022 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0031 - auc: 0.9999\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0011 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0032 - auc: 0.9998\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0018 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0012 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0018 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0012 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0012 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0011 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 9.9031e-04 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0018 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 6.5829e-04 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 8.8232e-04 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0042 - auc: 0.9998\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0016 - auc: 0.9998\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0018 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0013 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 5.5486e-04 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0015 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0026 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 8.2749e-04 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0015 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0011 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0036059761711735054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.031916251878926896\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0036', 'eer_eval': '0.0319', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0036.hdf5', 'tnow': '2022-06-03 07:27:53.148267'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 69s 40ms/step - loss: 1.2309 - auc: 0.7742\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3380 - auc: 0.9761\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.1885 - auc: 0.9923\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.1344 - auc: 0.9955\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0952 - auc: 0.9977\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0816 - auc: 0.9978\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0762 - auc: 0.9983\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0656 - auc: 0.9982\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0603 - auc: 0.9986\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0522 - auc: 0.9991\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0610 - auc: 0.9988\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0419 - auc: 0.9992\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0392 - auc: 0.9991\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0407 - auc: 0.9994\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0407 - auc: 0.9994\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0336 - auc: 0.9993\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0259 - auc: 0.9995\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0487 - auc: 0.9993\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0377 - auc: 0.9991\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0331 - auc: 0.9995\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0321 - auc: 0.9991\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0308 - auc: 0.9994\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0258 - auc: 0.9995\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0248 - auc: 0.9995\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0281 - auc: 0.9993\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0195 - auc: 0.9997\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0210 - auc: 0.9997\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0143 - auc: 0.9998\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0200 - auc: 0.9997\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0145 - auc: 0.9999\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0110 - auc: 0.9997\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0134 - auc: 0.9999\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0083 - auc: 0.9998\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0127 - auc: 0.9995\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0100 - auc: 0.9999\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0071 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0112 - auc: 0.9998\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0070 - auc: 0.9999\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0101 - auc: 0.9999\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0046 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0050 - auc: 0.9999\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0054 - auc: 0.9999\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0036 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0031 - auc: 0.9999\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0038 - auc: 0.9999\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0025 - auc: 0.9999\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0038 - auc: 0.9999\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0033 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.0035 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0030 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0025 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.0014 - auc: 0.9999\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0027 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0019 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0024 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0017 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0024 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0021 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0024 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0013 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0022 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0035 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0019 - auc: 0.9999\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 9.8123e-04 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0010 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0022 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0021 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 9.3080e-04 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0022 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.0018 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.005686581413560387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.02600469347938263\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0056', 'eer_eval': '0.0260', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0056.hdf5', 'tnow': '2022-06-03 08:42:44.988369'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 68s 40ms/step - loss: 1.2571 - auc: 0.7942\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.6767 - auc: 0.9192\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.5004 - auc: 0.9475\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.4346 - auc: 0.9582\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.4041 - auc: 0.9603\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3826 - auc: 0.9622\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3644 - auc: 0.9635\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3674 - auc: 0.9627\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3763 - auc: 0.9625\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.3481 - auc: 0.9654\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3462 - auc: 0.9669\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3422 - auc: 0.9657\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3392 - auc: 0.9673\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3537 - auc: 0.9674\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3471 - auc: 0.9662\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3296 - auc: 0.9689\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3522 - auc: 0.9678\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3496 - auc: 0.9688\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3370 - auc: 0.9700\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3324 - auc: 0.9694\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3311 - auc: 0.9700\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3419 - auc: 0.9688\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3295 - auc: 0.9691\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3291 - auc: 0.9718\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3241 - auc: 0.9718\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3094 - auc: 0.9716\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3243 - auc: 0.9716\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3224 - auc: 0.9732\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3172 - auc: 0.9723\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3208 - auc: 0.9721\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3107 - auc: 0.9719\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3177 - auc: 0.9717\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2983 - auc: 0.9746\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3117 - auc: 0.9728\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3111 - auc: 0.9747\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3005 - auc: 0.9739\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3170 - auc: 0.9729\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3079 - auc: 0.9749\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3069 - auc: 0.9739\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2972 - auc: 0.9741\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3023 - auc: 0.9757\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.2939 - auc: 0.9772\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.2948 - auc: 0.9760\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3059 - auc: 0.9756\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2963 - auc: 0.9767\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.2994 - auc: 0.9774\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2979 - auc: 0.9764\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.2930 - auc: 0.9767\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3003 - auc: 0.9761\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.3111 - auc: 0.9776\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2986 - auc: 0.9770\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.2995 - auc: 0.9775\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.2910 - auc: 0.9756\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2925 - auc: 0.9773\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3047 - auc: 0.9767\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.2916 - auc: 0.9770\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2907 - auc: 0.9760\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2850 - auc: 0.9769\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2914 - auc: 0.9776\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2968 - auc: 0.9777\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2911 - auc: 0.9771\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3020 - auc: 0.9768\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3007 - auc: 0.9758\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.2945 - auc: 0.9767\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.2993 - auc: 0.9763\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2939 - auc: 0.9768\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2924 - auc: 0.9788\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2878 - auc: 0.9771\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2860 - auc: 0.9773\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2936 - auc: 0.9771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.007083032873478299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.04039809582617593\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0070', 'eer_eval': '0.0403', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0070.hdf5', 'tnow': '2022-06-03 09:57:14.860205'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 72s 40ms/step - loss: 1.3065 - auc: 0.8011\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.6734 - auc: 0.9160\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.4856 - auc: 0.9483\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.4217 - auc: 0.9557\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.4101 - auc: 0.9577\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3929 - auc: 0.9593\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3742 - auc: 0.9611\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3803 - auc: 0.9617\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3660 - auc: 0.9625\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3718 - auc: 0.9620\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.3703 - auc: 0.9637\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3508 - auc: 0.9647\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3531 - auc: 0.9676\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3460 - auc: 0.9681\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3231 - auc: 0.9677\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3417 - auc: 0.9671\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3193 - auc: 0.9700\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3330 - auc: 0.9682\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3244 - auc: 0.9677\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3083 - auc: 0.9714\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3194 - auc: 0.9705\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3292 - auc: 0.9706\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3075 - auc: 0.9710\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.3230 - auc: 0.9705\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3157 - auc: 0.9710\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3092 - auc: 0.9728\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3070 - auc: 0.9736\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3185 - auc: 0.9727\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3114 - auc: 0.9749\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3139 - auc: 0.9743\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3121 - auc: 0.9727\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3003 - auc: 0.9739\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2915 - auc: 0.9748\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3149 - auc: 0.9741\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2908 - auc: 0.9758\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2960 - auc: 0.9757\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2894 - auc: 0.9753\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3087 - auc: 0.9761\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3106 - auc: 0.9762\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3118 - auc: 0.9783\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3029 - auc: 0.9760\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2919 - auc: 0.9767\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2870 - auc: 0.9776\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2928 - auc: 0.9766\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2948 - auc: 0.9776\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2904 - auc: 0.9777\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2994 - auc: 0.9759\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2986 - auc: 0.9775\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2854 - auc: 0.9788\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2814 - auc: 0.9793\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2873 - auc: 0.9795\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2800 - auc: 0.9786\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2882 - auc: 0.9775\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2902 - auc: 0.9789\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2921 - auc: 0.9800\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2968 - auc: 0.9790\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2827 - auc: 0.9800\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2837 - auc: 0.9780\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2812 - auc: 0.9784\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2867 - auc: 0.9793\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2938 - auc: 0.9784\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2970 - auc: 0.9774\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2811 - auc: 0.9774\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2813 - auc: 0.9787\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2766 - auc: 0.9784\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2804 - auc: 0.9784\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2955 - auc: 0.9796\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2812 - auc: 0.9781\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2881 - auc: 0.9784\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2895 - auc: 0.9776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.005086471853146226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.04528036607154094\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0050', 'eer_eval': '0.0452', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0050.hdf5', 'tnow': '2022-06-03 11:12:06.513459'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 69s 40ms/step - loss: 1.2677 - auc: 0.8039\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.7230 - auc: 0.9152\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.5217 - auc: 0.9391\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.4322 - auc: 0.9548\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.4043 - auc: 0.9571\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3906 - auc: 0.9584\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3792 - auc: 0.9617\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3788 - auc: 0.9630\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3601 - auc: 0.9636\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3694 - auc: 0.9622\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3546 - auc: 0.9657\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3429 - auc: 0.9667\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3547 - auc: 0.9649\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3355 - auc: 0.9678\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3428 - auc: 0.9687\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3260 - auc: 0.9680\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3261 - auc: 0.9700\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3278 - auc: 0.9713\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3281 - auc: 0.9692\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3371 - auc: 0.9711\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3194 - auc: 0.9701\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3153 - auc: 0.9720\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3290 - auc: 0.9712\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3374 - auc: 0.9725\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3299 - auc: 0.9699\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3065 - auc: 0.9727\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3240 - auc: 0.9723\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3240 - auc: 0.9722\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3190 - auc: 0.9731\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3141 - auc: 0.9717\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3017 - auc: 0.9746\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3074 - auc: 0.9740\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2996 - auc: 0.9740\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3030 - auc: 0.9754\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2958 - auc: 0.9749\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3065 - auc: 0.9758\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3015 - auc: 0.9746\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3087 - auc: 0.9755\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2900 - auc: 0.9758\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3003 - auc: 0.9743\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2973 - auc: 0.9768\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2970 - auc: 0.9765\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2941 - auc: 0.9776\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2960 - auc: 0.9766\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2954 - auc: 0.9771\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2984 - auc: 0.9786\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2968 - auc: 0.9788\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2798 - auc: 0.9784\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2933 - auc: 0.9774\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2931 - auc: 0.9765\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2942 - auc: 0.9787\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2936 - auc: 0.9777\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2950 - auc: 0.9776\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2815 - auc: 0.9788\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2944 - auc: 0.9780\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2982 - auc: 0.9773\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2957 - auc: 0.9782\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2960 - auc: 0.9781\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.3030 - auc: 0.9787\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2794 - auc: 0.9783\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2855 - auc: 0.9777\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2944 - auc: 0.9784\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2908 - auc: 0.9784\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2845 - auc: 0.9796\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2875 - auc: 0.9785\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2804 - auc: 0.9780\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.2820 - auc: 0.9776\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2919 - auc: 0.9780\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2858 - auc: 0.9791\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2813 - auc: 0.9785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.006174502856939984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03628387804720226\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0061', 'eer_eval': '0.0362', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0061.hdf5', 'tnow': '2022-06-03 12:26:53.016722'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 67s 39ms/step - loss: 1.3444 - auc: 0.7840\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.8010 - auc: 0.9168\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.6238 - auc: 0.9228\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.4934 - auc: 0.9426\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.4533 - auc: 0.9499\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.4060 - auc: 0.9554\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.4139 - auc: 0.9561\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3895 - auc: 0.9594\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3834 - auc: 0.9612\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3509 - auc: 0.9632\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3637 - auc: 0.9642\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3540 - auc: 0.9645\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3571 - auc: 0.9648\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3584 - auc: 0.9657\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.3679 - auc: 0.9671\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3317 - auc: 0.9675\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.3445 - auc: 0.9685\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3345 - auc: 0.9684\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3264 - auc: 0.9693\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3342 - auc: 0.9670\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3327 - auc: 0.9699\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3249 - auc: 0.9696\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3248 - auc: 0.9712\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3377 - auc: 0.9711\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.3214 - auc: 0.9725\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3327 - auc: 0.9728\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3249 - auc: 0.9713\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3082 - auc: 0.9729\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3287 - auc: 0.9738\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3247 - auc: 0.9739\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3217 - auc: 0.9738\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3049 - auc: 0.9738\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3147 - auc: 0.9738\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3261 - auc: 0.9736\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3038 - auc: 0.9741\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3199 - auc: 0.9747\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2889 - auc: 0.9737\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3011 - auc: 0.9752\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2943 - auc: 0.9733\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3134 - auc: 0.9752\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2943 - auc: 0.9746\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2968 - auc: 0.9752\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3062 - auc: 0.9755\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2963 - auc: 0.9764\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3037 - auc: 0.9748\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2929 - auc: 0.9753\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2866 - auc: 0.9764\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3001 - auc: 0.9768\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3018 - auc: 0.9736\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2851 - auc: 0.9757\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2894 - auc: 0.9756\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2954 - auc: 0.9758\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2904 - auc: 0.9756\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3085 - auc: 0.9777\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2904 - auc: 0.9777\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3002 - auc: 0.9757\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3113 - auc: 0.9763\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2996 - auc: 0.9766\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2831 - auc: 0.9769\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2950 - auc: 0.9759\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2905 - auc: 0.9764\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3006 - auc: 0.9763\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2950 - auc: 0.9753\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2992 - auc: 0.9780\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3013 - auc: 0.9759\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2892 - auc: 0.9759\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2839 - auc: 0.9770\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3075 - auc: 0.9763\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3067 - auc: 0.9761\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2964 - auc: 0.9782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.004312567577049453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.030079774765925316\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0043', 'eer_eval': '0.0300', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0043.hdf5', 'tnow': '2022-06-03 13:41:29.897474'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 72s 40ms/step - loss: 1.2591 - auc: 0.7895\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.7411 - auc: 0.9162\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.5085 - auc: 0.9451\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.4657 - auc: 0.9518\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.4003 - auc: 0.9570\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3801 - auc: 0.9595\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3701 - auc: 0.9620\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3890 - auc: 0.9633\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3661 - auc: 0.9656\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3476 - auc: 0.9661\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3533 - auc: 0.9657\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3396 - auc: 0.9658\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3319 - auc: 0.9690\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3512 - auc: 0.9660\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3331 - auc: 0.9679\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3484 - auc: 0.9687\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3225 - auc: 0.9699\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3407 - auc: 0.9684\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3435 - auc: 0.9677\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 64s 41ms/step - loss: 0.3354 - auc: 0.9709\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3239 - auc: 0.9708\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3230 - auc: 0.9728\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3219 - auc: 0.9711\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3135 - auc: 0.9723\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3204 - auc: 0.9712\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3186 - auc: 0.9705\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3058 - auc: 0.9743\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - ETA: 0s - loss: 0.2986 - auc: 0.975 - 64s 40ms/step - loss: 0.2986 - auc: 0.9754\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3070 - auc: 0.9734\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3211 - auc: 0.9745\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3076 - auc: 0.9740\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2992 - auc: 0.9742\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3065 - auc: 0.9732\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3044 - auc: 0.9732\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2951 - auc: 0.9757\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2994 - auc: 0.9750\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3038 - auc: 0.9755\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3008 - auc: 0.9746\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2997 - auc: 0.9751\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3071 - auc: 0.9754\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2962 - auc: 0.9760\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2953 - auc: 0.9766\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2891 - auc: 0.9768\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2924 - auc: 0.9766\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2940 - auc: 0.9787\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2877 - auc: 0.9783\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2945 - auc: 0.9787\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2736 - auc: 0.9760\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3024 - auc: 0.9772\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2880 - auc: 0.9786\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2930 - auc: 0.9784\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2940 - auc: 0.9769\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2989 - auc: 0.9773\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 64s 41ms/step - loss: 0.2944 - auc: 0.9774\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3010 - auc: 0.9790\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2917 - auc: 0.9791\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2932 - auc: 0.9793\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2756 - auc: 0.9774\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2998 - auc: 0.9772\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2901 - auc: 0.9769\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2999 - auc: 0.9775\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3002 - auc: 0.9768\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2868 - auc: 0.9777\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3019 - auc: 0.9783\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2743 - auc: 0.9801\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2942 - auc: 0.9806\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2973 - auc: 0.9795\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2917 - auc: 0.9774\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2865 - auc: 0.9802\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2825 - auc: 0.9791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.006174502856939984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.031156026711021738\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0061', 'eer_eval': '0.0311', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0061.hdf5', 'tnow': '2022-06-03 14:57:00.503664'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 69s 40ms/step - loss: 1.2905 - auc: 0.7897\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.6853 - auc: 0.9172\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.5176 - auc: 0.9438\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.4746 - auc: 0.9500\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.4460 - auc: 0.9544\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.4026 - auc: 0.9586\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.4068 - auc: 0.9575\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3912 - auc: 0.9581\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3669 - auc: 0.9599\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3840 - auc: 0.9619\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3595 - auc: 0.9639\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3598 - auc: 0.9634\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3642 - auc: 0.9651\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3550 - auc: 0.9657\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3429 - auc: 0.9644\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3381 - auc: 0.9684\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3203 - auc: 0.9695\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3418 - auc: 0.9683\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3253 - auc: 0.9692\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3443 - auc: 0.9681\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3162 - auc: 0.9713\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3322 - auc: 0.9690\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3262 - auc: 0.9713\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3307 - auc: 0.9715\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3190 - auc: 0.9731\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3094 - auc: 0.9724\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - ETA: 0s - loss: 0.3310 - auc: 0.969 - 64s 40ms/step - loss: 0.3310 - auc: 0.9694\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3093 - auc: 0.9737\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3141 - auc: 0.9732\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3187 - auc: 0.9712\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3196 - auc: 0.9724\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3097 - auc: 0.9728\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3048 - auc: 0.9734\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2980 - auc: 0.9733\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3132 - auc: 0.9719\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3064 - auc: 0.9752\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2976 - auc: 0.9746\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2986 - auc: 0.9757\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2939 - auc: 0.9758\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3199 - auc: 0.9766\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3061 - auc: 0.9759\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3045 - auc: 0.9748\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3131 - auc: 0.9768\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3048 - auc: 0.9762\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3066 - auc: 0.9768\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2961 - auc: 0.9756\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3100 - auc: 0.9759\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3064 - auc: 0.9765\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3025 - auc: 0.9762\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2985 - auc: 0.9765\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2959 - auc: 0.9769\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2923 - auc: 0.9759\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2895 - auc: 0.9772\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2840 - auc: 0.9764\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3046 - auc: 0.9769\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3041 - auc: 0.9768\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2943 - auc: 0.9770\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2969 - auc: 0.9762\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2938 - auc: 0.9778\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2927 - auc: 0.9777\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2958 - auc: 0.9782\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3039 - auc: 0.9774\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2982 - auc: 0.9766\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2878 - auc: 0.9768\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2894 - auc: 0.9774\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3039 - auc: 0.9782\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3035 - auc: 0.9765\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2889 - auc: 0.9765\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 64s 41ms/step - loss: 0.2959 - auc: 0.9770\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2946 - auc: 0.9786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0093207014797137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.03722951214840477\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': [[0.5, 0.5], [7, 8, 9, 10, 11, 12]], 'highpass': False, 'ranfilter2': False, 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0093', 'eer_eval': '0.0372', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0093.hdf5', 'tnow': '2022-06-03 16:12:23.474912'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 68s 40ms/step - loss: 1.6117 - auc: 0.7295\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.6857 - auc: 0.9062\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.4862 - auc: 0.9490\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.4218 - auc: 0.9570\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3918 - auc: 0.9595\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3972 - auc: 0.9610\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3699 - auc: 0.9627\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3704 - auc: 0.9620\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3703 - auc: 0.9620\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3495 - auc: 0.9650\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3627 - auc: 0.9682\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3580 - auc: 0.9688\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3349 - auc: 0.9684\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3278 - auc: 0.9685\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3404 - auc: 0.9681\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3402 - auc: 0.9690\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3310 - auc: 0.9695\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3116 - auc: 0.9692\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3321 - auc: 0.9692\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3234 - auc: 0.9700\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3328 - auc: 0.9712\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3318 - auc: 0.9706\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3350 - auc: 0.9716\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3249 - auc: 0.9703\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3207 - auc: 0.9711\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3111 - auc: 0.9734\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3251 - auc: 0.9733\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3160 - auc: 0.9730\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3186 - auc: 0.9729\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3300 - auc: 0.9699\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3029 - auc: 0.9732\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3092 - auc: 0.9758\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3095 - auc: 0.9746\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3080 - auc: 0.9718\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3126 - auc: 0.9758\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2935 - auc: 0.9771\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.2995 - auc: 0.9768\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3118 - auc: 0.9765\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2865 - auc: 0.9763\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2919 - auc: 0.9767\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3015 - auc: 0.9761\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3055 - auc: 0.9783\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2889 - auc: 0.9760\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2854 - auc: 0.9782\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3164 - auc: 0.9768\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3020 - auc: 0.9773\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2956 - auc: 0.9779\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2991 - auc: 0.9775\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2967 - auc: 0.9777\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2854 - auc: 0.9777\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2979 - auc: 0.9785\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2963 - auc: 0.9776\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3034 - auc: 0.9796\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2963 - auc: 0.9775\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2858 - auc: 0.9773\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2948 - auc: 0.9765\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2974 - auc: 0.9769\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2917 - auc: 0.9791\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2919 - auc: 0.9801\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2889 - auc: 0.9779\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3011 - auc: 0.9778\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3071 - auc: 0.9771\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3052 - auc: 0.9790\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2936 - auc: 0.9800\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3033 - auc: 0.9788\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2868 - auc: 0.9780\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3046 - auc: 0.9792\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2918 - auc: 0.9779\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2999 - auc: 0.9793\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2826 - auc: 0.9787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.004519824996400145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.024089943381519038\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0045', 'eer_eval': '0.0240', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0045.hdf5', 'tnow': '2022-06-03 17:27:15.223318'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 72s 40ms/step - loss: 1.3670 - auc: 0.7713\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.7425 - auc: 0.9252\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.5111 - auc: 0.9475\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.4650 - auc: 0.9531\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.4223 - auc: 0.9588\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.4024 - auc: 0.9600\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3871 - auc: 0.9617\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3777 - auc: 0.9626\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3522 - auc: 0.9651\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3531 - auc: 0.9661\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3365 - auc: 0.9656\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3401 - auc: 0.9678\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3408 - auc: 0.9682\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3339 - auc: 0.9684\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3366 - auc: 0.9696\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3491 - auc: 0.9681\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3297 - auc: 0.9696\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3263 - auc: 0.9700\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3245 - auc: 0.9716\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3333 - auc: 0.9698\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3225 - auc: 0.9715\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3334 - auc: 0.9718\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3242 - auc: 0.9731\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3311 - auc: 0.9725\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3173 - auc: 0.9725\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3136 - auc: 0.9742\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3091 - auc: 0.9729\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3110 - auc: 0.9730\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3215 - auc: 0.9740\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3014 - auc: 0.9736\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3021 - auc: 0.9754\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3170 - auc: 0.9731\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3120 - auc: 0.9756\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3034 - auc: 0.9751\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3141 - auc: 0.9738\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3091 - auc: 0.9740\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3043 - auc: 0.9762\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2960 - auc: 0.9760\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2963 - auc: 0.9763\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3117 - auc: 0.9765\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3022 - auc: 0.9774\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2950 - auc: 0.9777\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2780 - auc: 0.9776\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2977 - auc: 0.9766\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2993 - auc: 0.9772\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2835 - auc: 0.9779\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2951 - auc: 0.9780\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2888 - auc: 0.9771\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3033 - auc: 0.9773\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2944 - auc: 0.9774\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3107 - auc: 0.9779\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3029 - auc: 0.9776\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2813 - auc: 0.9797\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2830 - auc: 0.9786\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2917 - auc: 0.9776\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2878 - auc: 0.9800\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2839 - auc: 0.9785\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3052 - auc: 0.9763\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2967 - auc: 0.9796\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3083 - auc: 0.9772\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2916 - auc: 0.9770\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2877 - auc: 0.9789\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2900 - auc: 0.9791\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2904 - auc: 0.9785\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2924 - auc: 0.9777\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2977 - auc: 0.9781\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2932 - auc: 0.9767\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2978 - auc: 0.9774\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2988 - auc: 0.9778\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2923 - auc: 0.9781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00758768566869188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.025680839403705108\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0075', 'eer_eval': '0.0256', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0075.hdf5', 'tnow': '2022-06-03 18:42:24.274335'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 70s 40ms/step - loss: 1.5766 - auc: 0.7358\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.8201 - auc: 0.9171\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.5213 - auc: 0.9454\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.4416 - auc: 0.9540\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.4197 - auc: 0.9569\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.4001 - auc: 0.9607\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3734 - auc: 0.9624\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3709 - auc: 0.9632\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3535 - auc: 0.9652\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3903 - auc: 0.9651\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3504 - auc: 0.9658\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3662 - auc: 0.9618\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3527 - auc: 0.9640\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3351 - auc: 0.9678\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3396 - auc: 0.9684\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3348 - auc: 0.9705\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3228 - auc: 0.9704\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3420 - auc: 0.9686\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3400 - auc: 0.9681\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3240 - auc: 0.9704\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3274 - auc: 0.9692\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3236 - auc: 0.9709\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3157 - auc: 0.9712\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3132 - auc: 0.9700\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3348 - auc: 0.9724\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3207 - auc: 0.9719\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3300 - auc: 0.9717\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3206 - auc: 0.9730\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3197 - auc: 0.9727\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3221 - auc: 0.9723\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3038 - auc: 0.9722\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3064 - auc: 0.9730\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3098 - auc: 0.9752\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3189 - auc: 0.9744\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3004 - auc: 0.9752\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3129 - auc: 0.9737\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3001 - auc: 0.9756\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3139 - auc: 0.9746\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3117 - auc: 0.9761\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3084 - auc: 0.9750\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2992 - auc: 0.9754\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3048 - auc: 0.9759\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3151 - auc: 0.9745\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3037 - auc: 0.9761\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3038 - auc: 0.9757\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.2975 - auc: 0.9773\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2999 - auc: 0.9756\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3050 - auc: 0.9775\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2961 - auc: 0.9775\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2922 - auc: 0.9764\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2978 - auc: 0.9769\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2898 - auc: 0.9764\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3102 - auc: 0.9765\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2990 - auc: 0.9770\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3009 - auc: 0.9778\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2978 - auc: 0.9755\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.2990 - auc: 0.9773\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2954 - auc: 0.9769\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.2856 - auc: 0.9773\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2755 - auc: 0.9778\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.2966 - auc: 0.9774\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.2928 - auc: 0.9768\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3018 - auc: 0.9772\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2977 - auc: 0.9768\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2997 - auc: 0.9764\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2913 - auc: 0.9776\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2945 - auc: 0.9776\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2879 - auc: 0.9770\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2853 - auc: 0.9763\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2921 - auc: 0.9775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0062809847024017165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.030325355856740822\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': [[0.5, 0.5], [80, 81, 82, 83, 84, 85, 86, 87]], 'ranfilter2': False, 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0062', 'eer_eval': '0.0303', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0062.hdf5', 'tnow': '2022-06-03 19:57:25.459429'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 68s 39ms/step - loss: 1.4064 - auc: 0.7856\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.7911 - auc: 0.9072\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.6129 - auc: 0.9256\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.5085 - auc: 0.9411\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.4787 - auc: 0.9495\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.4560 - auc: 0.9510\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.4119 - auc: 0.9574\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.4101 - auc: 0.9572\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3883 - auc: 0.9605\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3729 - auc: 0.9635\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3821 - auc: 0.9603\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3551 - auc: 0.9628\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3738 - auc: 0.9635\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3746 - auc: 0.9633\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3637 - auc: 0.9659\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3652 - auc: 0.9653\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3421 - auc: 0.9678\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3604 - auc: 0.9651\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3454 - auc: 0.9683\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3378 - auc: 0.9684\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3348 - auc: 0.9666\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3513 - auc: 0.9680\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3540 - auc: 0.9666\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3413 - auc: 0.9681\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3370 - auc: 0.9693\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3349 - auc: 0.9703\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3249 - auc: 0.9694\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3321 - auc: 0.9694\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3453 - auc: 0.9706\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3307 - auc: 0.9706\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3406 - auc: 0.9706\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3170 - auc: 0.9696\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.3269 - auc: 0.9692\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3230 - auc: 0.9716\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3312 - auc: 0.9708\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3218 - auc: 0.9702\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3155 - auc: 0.9717\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.2895 - auc: 0.9739\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3288 - auc: 0.9722\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3140 - auc: 0.9731\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3195 - auc: 0.9724\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3111 - auc: 0.9726\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3137 - auc: 0.9742\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3059 - auc: 0.9745\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3140 - auc: 0.9744\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3191 - auc: 0.9726\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3103 - auc: 0.9738\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3084 - auc: 0.9736\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2978 - auc: 0.9748\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3130 - auc: 0.9759\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2992 - auc: 0.9751\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3200 - auc: 0.9726\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3067 - auc: 0.9742\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2976 - auc: 0.9751\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3005 - auc: 0.9754\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3136 - auc: 0.9767\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3134 - auc: 0.9749\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3072 - auc: 0.9750\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2958 - auc: 0.9743\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2919 - auc: 0.9734\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3184 - auc: 0.9761\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.2996 - auc: 0.9736\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3162 - auc: 0.9747\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2963 - auc: 0.9747\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3092 - auc: 0.9749\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3005 - auc: 0.9754\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3008 - auc: 0.9748\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3154 - auc: 0.9752\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2960 - auc: 0.9763\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3171 - auc: 0.9748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.00880463614135435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.07575982166763433\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0088', 'eer_eval': '0.0757', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0088.hdf5', 'tnow': '2022-06-03 21:11:34.213062'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 67s 39ms/step - loss: 1.4162 - auc: 0.7650\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.7814 - auc: 0.9036\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.6328 - auc: 0.9161\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.5510 - auc: 0.9309\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4913 - auc: 0.9444\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4207 - auc: 0.9556\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4218 - auc: 0.9567\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3951 - auc: 0.9588\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3860 - auc: 0.9599\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3857 - auc: 0.9608\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3740 - auc: 0.9598\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3907 - auc: 0.9629\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3598 - auc: 0.9628\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3802 - auc: 0.9598\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3658 - auc: 0.9652\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3717 - auc: 0.9638\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3527 - auc: 0.9665\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3468 - auc: 0.9658\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3419 - auc: 0.9663\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3393 - auc: 0.9678\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3548 - auc: 0.9682\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3476 - auc: 0.9660\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3489 - auc: 0.9687\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3638 - auc: 0.9678\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 61s 39ms/step - loss: 0.3345 - auc: 0.9679\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3459 - auc: 0.9691\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3408 - auc: 0.9699\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3375 - auc: 0.9702\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3414 - auc: 0.9692\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3323 - auc: 0.9706\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3319 - auc: 0.9709\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3234 - auc: 0.9698\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3182 - auc: 0.9718\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3219 - auc: 0.9722\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3167 - auc: 0.9724\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3156 - auc: 0.9711\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3030 - auc: 0.9707\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3236 - auc: 0.9719\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3150 - auc: 0.9731\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3145 - auc: 0.9721\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3172 - auc: 0.9729\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.2992 - auc: 0.9743\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3086 - auc: 0.9741\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3197 - auc: 0.9732\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3059 - auc: 0.9743\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3025 - auc: 0.9716\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3192 - auc: 0.9736\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3204 - auc: 0.9754\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3002 - auc: 0.9752\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3033 - auc: 0.9751\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3087 - auc: 0.9759\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3030 - auc: 0.9719\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3038 - auc: 0.9757\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3031 - auc: 0.9734\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3093 - auc: 0.9740\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2957 - auc: 0.9738\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3089 - auc: 0.9746\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2943 - auc: 0.9754\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3068 - auc: 0.9742\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3136 - auc: 0.9760\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3139 - auc: 0.9747\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3107 - auc: 0.9746\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.2971 - auc: 0.9742\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3071 - auc: 0.9755\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3055 - auc: 0.9760\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3022 - auc: 0.9771\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3099 - auc: 0.9759\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3063 - auc: 0.9758\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3110 - auc: 0.9756\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3108 - auc: 0.9745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.007677436162319629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.06554863655581905\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0076', 'eer_eval': '0.0655', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0076.hdf5', 'tnow': '2022-06-03 22:25:03.668619'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 69s 40ms/step - loss: 1.2668 - auc: 0.7845\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.6485 - auc: 0.9175\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.5299 - auc: 0.9390\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.4748 - auc: 0.9484\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.4402 - auc: 0.9539\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.4175 - auc: 0.9535\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3957 - auc: 0.9584\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.4040 - auc: 0.9575\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3876 - auc: 0.9607\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.3675 - auc: 0.9617\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.3840 - auc: 0.9616\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.3742 - auc: 0.9643\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3712 - auc: 0.9640\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3514 - auc: 0.9627\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3489 - auc: 0.9655\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3495 - auc: 0.9660\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3562 - auc: 0.9656\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3593 - auc: 0.9652\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3365 - auc: 0.9683\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3480 - auc: 0.9674\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.3473 - auc: 0.9666\n",
      "Epoch 22/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3458 - auc: 0.9679\n",
      "Epoch 23/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3391 - auc: 0.9674\n",
      "Epoch 24/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3393 - auc: 0.9679\n",
      "Epoch 25/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3310 - auc: 0.9697\n",
      "Epoch 26/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3308 - auc: 0.9711\n",
      "Epoch 27/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.3298 - auc: 0.9695\n",
      "Epoch 28/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3301 - auc: 0.9713\n",
      "Epoch 29/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3274 - auc: 0.9710\n",
      "Epoch 30/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3142 - auc: 0.9705\n",
      "Epoch 31/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3253 - auc: 0.9707\n",
      "Epoch 32/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3205 - auc: 0.9712\n",
      "Epoch 33/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3146 - auc: 0.9737\n",
      "Epoch 34/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3110 - auc: 0.9733\n",
      "Epoch 35/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.3164 - auc: 0.9718\n",
      "Epoch 36/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.3177 - auc: 0.9721\n",
      "Epoch 37/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3179 - auc: 0.9720\n",
      "Epoch 38/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.3088 - auc: 0.9724\n",
      "Epoch 39/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3120 - auc: 0.9738\n",
      "Epoch 40/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3117 - auc: 0.9737\n",
      "Epoch 41/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.3180 - auc: 0.9747\n",
      "Epoch 42/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3077 - auc: 0.9745\n",
      "Epoch 43/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.2976 - auc: 0.9753\n",
      "Epoch 44/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.3036 - auc: 0.9752\n",
      "Epoch 45/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2981 - auc: 0.9744\n",
      "Epoch 46/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3008 - auc: 0.9750\n",
      "Epoch 47/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3167 - auc: 0.9746\n",
      "Epoch 48/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3069 - auc: 0.9728\n",
      "Epoch 49/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3072 - auc: 0.9758\n",
      "Epoch 50/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3073 - auc: 0.9754\n",
      "Epoch 51/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3088 - auc: 0.9744\n",
      "Epoch 52/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2886 - auc: 0.9774\n",
      "Epoch 53/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3113 - auc: 0.9756\n",
      "Epoch 54/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.2979 - auc: 0.9738\n",
      "Epoch 55/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2961 - auc: 0.9740\n",
      "Epoch 56/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2994 - auc: 0.9749\n",
      "Epoch 57/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3007 - auc: 0.9766\n",
      "Epoch 58/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2982 - auc: 0.9759\n",
      "Epoch 59/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.3002 - auc: 0.9754\n",
      "Epoch 60/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2943 - auc: 0.9759\n",
      "Epoch 61/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2985 - auc: 0.9753\n",
      "Epoch 62/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.2980 - auc: 0.9758\n",
      "Epoch 63/70\n",
      "1586/1586 [==============================] - 64s 40ms/step - loss: 0.3110 - auc: 0.9764\n",
      "Epoch 64/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.3143 - auc: 0.9743\n",
      "Epoch 65/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3119 - auc: 0.9762\n",
      "Epoch 66/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.2986 - auc: 0.9780\n",
      "Epoch 67/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3023 - auc: 0.9738\n",
      "Epoch 68/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3143 - auc: 0.9750\n",
      "Epoch 69/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.2947 - auc: 0.9759\n",
      "Epoch 70/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.2998 - auc: 0.9775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.006370735196029466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.0582134902400422\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': 0.7, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': [2, [8, 9, 10, 11, 12]], 'model': 'DDWSseq_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0063', 'eer_eval': '0.0582', 'saved_model': 'saved_models/model_name!DDWSseq_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!0.7!lowpass!--!highpass!--!ranfilter2!--!0.0063.hdf5', 'tnow': '2022-06-03 23:39:36.724541'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "1586/1586 [==============================] - 68s 39ms/step - loss: 1.2990 - auc: 0.7856\n",
      "Epoch 2/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.7149 - auc: 0.9145\n",
      "Epoch 3/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.5659 - auc: 0.9321\n",
      "Epoch 4/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.4843 - auc: 0.9478\n",
      "Epoch 5/70\n",
      "1586/1586 [==============================] - 63s 40ms/step - loss: 0.4693 - auc: 0.9517\n",
      "Epoch 6/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4367 - auc: 0.9541\n",
      "Epoch 7/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4083 - auc: 0.9587\n",
      "Epoch 8/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.4122 - auc: 0.9593\n",
      "Epoch 9/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.4006 - auc: 0.9617\n",
      "Epoch 10/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3867 - auc: 0.9616\n",
      "Epoch 11/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3829 - auc: 0.9609\n",
      "Epoch 12/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.3663 - auc: 0.9633\n",
      "Epoch 13/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3728 - auc: 0.9627\n",
      "Epoch 14/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3669 - auc: 0.9616\n",
      "Epoch 15/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.3653 - auc: 0.9617\n",
      "Epoch 16/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.3755 - auc: 0.9651\n",
      "Epoch 17/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3687 - auc: 0.9654\n",
      "Epoch 18/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3584 - auc: 0.9646\n",
      "Epoch 19/70\n",
      "1586/1586 [==============================] - 62s 39ms/step - loss: 0.3643 - auc: 0.9656\n",
      "Epoch 20/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.3478 - auc: 0.9660\n",
      "Epoch 21/70\n",
      "1586/1586 [==============================] - 63s 39ms/step - loss: 0.3540 - auc: 0.9678\n",
      "Epoch 22/70\n",
      "1052/1586 [==================>...........] - ETA: 21s - loss: 0.3494 - auc: 0.9673"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from utils.DataLoader import data_loader\n",
    "from utils.Generator0 import DataGenerator, feature_extract_cqt, evalEER,  evalScore, evalEER_f, evalEER_f2, gen_fname\n",
    "from models.models import get_ResMax, get_LCNN, sigmoidal_decay\n",
    "from models.models2 import get_BCResMax, get_DDWSseq\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import add,concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, maximum, DepthwiseConv2D, AveragePooling2D, UpSampling2D\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, SpatialDropout2D\n",
    "from tensorflow.keras.layers import Convolution2D, GlobalAveragePooling2D, MaxPool2D, ZeroPadding2D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.activations import relu, softmax, swish\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import pickle\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "add2022 = '/home/ubuntu/data/ADD/'\n",
    "asv2019 = '/home/ubuntu/data/asv2019/'\n",
    "\n",
    "pathset = { 'add2022' : add2022 , 'asv2019':asv2019}\n",
    "        \n",
    "dl = data_loader(pathset)\n",
    "\n",
    "#dl.get_data(data_pick = '2', tde_pick = 't', pl_pick = 'l', to = 't')\n",
    "#dl.get_data(data_pick = '2', tde_pick = 'd', pl_pick = 'l', to = 't')\n",
    "#dl.get_data(data_pick = '2', tde_pick = 'e', pl_pick = 'l', to = 'd')\n",
    "\n",
    "\n",
    "datapick = '2' ## 1:ADD, 2:LA\n",
    "\n",
    "dl.get_data(data_pick = datapick, tde_pick = 't', pl_pick = 'l',  to = 't')\n",
    "dl.get_data(data_pick = datapick, tde_pick = 'd', pl_pick = 'l', to = 'd')\n",
    "dl.get_data(data_pick = datapick, tde_pick = 'e', pl_pick = 'l', to = 'e')\n",
    "\n",
    "#track1 = data_loader(pathset)\n",
    "#track1_generator = DataGenerator(track1.eval, track1.labels, **params_no_shuffle)\n",
    "\n",
    "#################################################\n",
    "### get_ResMax\n",
    "mname = 'ResMax_LA_'\n",
    "#################################################\n",
    "\n",
    "### None\n",
    "\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = False\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "### Mixup\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### LP        \n",
    " \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "#    ru = np.random.uniform(.1, .9)\n",
    "    ru = 0.5\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "      \n",
    "### HP        \n",
    " \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "#    ru = np.random.uniform(.1, .9)\n",
    "    ru = 0.5\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### RP\n",
    "\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "### LP + RP\n",
    "\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### HP + RP\n",
    "\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 # np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #[2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################\n",
    "mname = \"LCNN_LA_\"\n",
    "################################\n",
    "\n",
    "## None\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = False\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### Mixup\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "\n",
    "### LP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "### LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #[2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "\n",
    "\n",
    "##################################################\n",
    "mname = \"BCResMax_LA_\"\n",
    "##################################################\n",
    "\n",
    "### None\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = False\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### mixup\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### LP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "        \n",
    "### LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### HP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### HP + LP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #[2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "##################################################\n",
    "mname = \"DDWSseq_LA_\"\n",
    "##################################################\n",
    "\n",
    "### None\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = False\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### Mixup\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### LP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "### LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #[2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9383cb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      " 121/1586 [=>............................] - ETA: 36s - loss: 0.8313 - auc: 0.7086"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b3a97e552dd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhuman_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;31m## human: 0, 1: speaker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n\u001b[0;32m--> 140\u001b[0;31m                               epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0meer_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevalEER\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0meer_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevalEER\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1859\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from utils.DataLoader import data_loader\n",
    "from utils.Generator0 import DataGenerator, feature_extract_cqt, evalEER,  evalScore, evalEER_f, evalEER_f2, gen_fname\n",
    "from models.models import get_ResMax, get_LCNN, sigmoidal_decay\n",
    "from models.models2 import get_BCResMax, get_DDWSseq\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import add,concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, maximum, DepthwiseConv2D, AveragePooling2D, UpSampling2D\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, SpatialDropout2D\n",
    "from tensorflow.keras.layers import Convolution2D, GlobalAveragePooling2D, MaxPool2D, ZeroPadding2D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.activations import relu, softmax, swish\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import pickle\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "add2022 = '/home/ubuntu/data/ADD/'\n",
    "asv2019 = '/home/ubuntu/data/asv2019/'\n",
    "\n",
    "pathset = { 'add2022' : add2022 , 'asv2019':asv2019}\n",
    "        \n",
    "dl = data_loader(pathset)\n",
    "\n",
    "#dl.get_data(data_pick = '2', tde_pick = 't', pl_pick = 'l', to = 't')\n",
    "#dl.get_data(data_pick = '2', tde_pick = 'd', pl_pick = 'l', to = 't')\n",
    "#dl.get_data(data_pick = '2', tde_pick = 'e', pl_pick = 'l', to = 'd')\n",
    "\n",
    "\n",
    "datapick = '2' ## 1:ADD, 2:LA\n",
    "\n",
    "dl.get_data(data_pick = datapick, tde_pick = 't', pl_pick = 'l',  to = 't')\n",
    "dl.get_data(data_pick = datapick, tde_pick = 'd', pl_pick = 'l', to = 'd')\n",
    "dl.get_data(data_pick = datapick, tde_pick = 'e', pl_pick = 'l', to = 'e')\n",
    "\n",
    "#track1 = data_loader(pathset)\n",
    "#track1_generator = DataGenerator(track1.eval, track1.labels, **params_no_shuffle)\n",
    "\n",
    "#################################################\n",
    "### get_ResMax\n",
    "mname = 'ResMax_LA_'\n",
    "#################################################\n",
    "\n",
    "### None\n",
    "\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = False\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "### Mixup\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### LP        \n",
    " \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "#    ru = np.random.uniform(.1, .9)\n",
    "    ru = 0.5\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "      \n",
    "### HP        \n",
    " \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "#    ru = np.random.uniform(.1, .9)\n",
    "    ru = 0.5\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### RP\n",
    "\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "### LP + RP\n",
    "\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### HP + RP\n",
    "\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 # np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #[2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_ResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################\n",
    "mname = \"LCNN_LA_\"\n",
    "################################\n",
    "\n",
    "## None\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = False\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### Mixup\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "\n",
    "### LP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "### LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #[2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_LCNN(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "\n",
    "\n",
    "##################################################\n",
    "mname = \"BCResMax_LA_\"\n",
    "##################################################\n",
    "\n",
    "### None\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = False\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### mixup\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### LP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "        \n",
    "### LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### HP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### HP + LP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #[2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "##################################################\n",
    "mname = \"DDWSseq_LA_\"\n",
    "##################################################\n",
    "\n",
    "### None\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = False\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### Mixup\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### LP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "### LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #[2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_mask_LA/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b378c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2.4_p37)",
   "language": "python",
   "name": "conda_tensorflow2.4_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
