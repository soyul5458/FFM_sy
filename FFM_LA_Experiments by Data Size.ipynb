{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b215ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline, hf, lf, hf  성능 좋은 모델로만 실험 진행해서 3가지 그래프로 그리기\n",
    "validation, dev 는 전체 데이터 사용"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "24ded9df",
   "metadata": {},
   "source": [
    "# 데이터 크기에 따른 실험   \n",
    "1. ASV 2019 데이터로 환자정보별 데이터 개수 나눠서 성능 확인\n",
    "\t- 각 모델별로 성능확인 (그래프로 출력)\n",
    "    - [데이터 설명](https://datashare.ed.ac.uk/bitstream/handle/10283/3336/asvspoof2019_evaluation_plan.pdf?sequence=1&isAllowed=y)\n",
    "2. ASV 2019 데이터 구성\n",
    "    - LA (논리), PA (물리) 데이터 셋으로 분리. 각각 전체 107명의 화자 데이터\n",
    "    - Train: 20명(남성 8명, 여성 12명), development: 20명(남성 8명, 여성 12명), evaluation: 67명\n",
    "    - 성별 정보는 ASV protocols 폴더에서 dev, eval에 대해서만 정보가 분리되어 있음\n",
    "        - dev: 10명 (남성 4명, 여성 6명)\n",
    "        - evaluation: 48명(남성 21명, 여성 27명)\n",
    "        > readme.txt 및 ASV protocols 파일과 실제 데이터 상이함. 따라서 성별에 따른 데이터 분할은 어렵고 랜덤하게 화자 선택  \n",
    "        \n",
    "3. T/D/E로 분할된 데이터 셋에서 0.1 ~ 0.9 비율로 데이터 크기 조절해 실험 진행중  \n",
    "4. 아래 그램과 같이 출력할 예정  \n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d0dff74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 20 12:52:16 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:05.0 Off |                  Off |\r\n",
      "| N/A   38C    P0    39W / 300W |      0MiB / 32510MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:00:06.0 Off |                  Off |\r\n",
      "| N/A   41C    P0    63W / 300W |      0MiB / 32510MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ffeb53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from utils.DataLoader import data_loader\n",
    "from utils.Generator0 import DataGenerator, feature_extract_cqt, evalEER,  evalScore, evalEER_f, evalEER_f2, gen_fname\n",
    "from models.models import get_ResMax, get_LCNN, sigmoidal_decay\n",
    "from models.models2 import get_BCResMax, get_DDWSseq\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import add,concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, maximum, DepthwiseConv2D, AveragePooling2D, UpSampling2D\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, SpatialDropout2D\n",
    "from tensorflow.keras.layers import Convolution2D, GlobalAveragePooling2D, MaxPool2D, ZeroPadding2D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.activations import relu, softmax, swish\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a092d794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46ad8e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "asv2019 = '/home/ubuntu/data/asv2019/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94e5f41",
   "metadata": {},
   "source": [
    "## Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ade21901",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 16000\n",
    "sec = 9.0\n",
    "batch_size = 16\n",
    "feature = \"cqt\"\n",
    "filter_scale = 1\n",
    "n_bins = 100\n",
    "fmin = 5\n",
    "epoch = 70\n",
    "dropout_rate = 0.5\n",
    "human_weight = 5.0\n",
    "\n",
    "tmp_string = 'tmp1'\n",
    "\n",
    "\n",
    "params = {'sr': sr,\n",
    "          'feature': feature,\n",
    "          'batch_size': batch_size,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'n_bins' : n_bins,\n",
    "          'fmin': fmin,\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'data_dir': asv2019\n",
    "}\n",
    "\n",
    "\n",
    "params_no_shuffle = {'sr': sr,\n",
    "          'feature': feature,\n",
    "          'batch_size': batch_size,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'n_bins' : n_bins,\n",
    "          'fmin': fmin,\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': False,\n",
    "          'data_dir': asv2019\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93a59b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asvspoof2019_evaluation_plan.pdf',\n",
       " 'asvspoof2019_Interspeech2019_submission.pdf',\n",
       " 'README.txt',\n",
       " 'LICENSE_text.txt',\n",
       " 'LA',\n",
       " 'PA',\n",
       " 'tmp']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = os.listdir(params['data_dir'])\n",
    "fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78a1d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = os.listdir(params['data_dir'])\n",
    "\n",
    "## Train set start with T, Dev set start with D and Eval set start with E\n",
    "\n",
    "LA_train_ids = []\n",
    "PA_train_ids = []\n",
    "LA_dev_ids = []\n",
    "PA_dev_ids = []\n",
    "LA_eval_ids = []\n",
    "PA_eval_ids = []\n",
    "labels_tmp = {}\n",
    "eval_ids = []\n",
    "\n",
    "for (path, dir, files) in os.walk(params['data_dir']) :\n",
    "#     print(\"-----------\")\n",
    "#     print(\"path: \", path)\n",
    "#     print(\"files: \",files)\n",
    "    for filename in files:\n",
    "#         print(\"filname: \", filename)\n",
    "        ext = os.path.splitext(filename)[-1]\n",
    "        if ext == '.flac':\n",
    "            fnm = path + '/' + filename\n",
    "            labels_tmp[filename] = fnm\n",
    "            if filename[:2] == 'LA' :\n",
    "                if filename[3] == 'T' :\n",
    "                    LA_train_ids.append(fnm)\n",
    "\n",
    "                elif filename[3] == 'D' :\n",
    "                    LA_dev_ids.append(fnm)\n",
    "\n",
    "                else :\n",
    "                    LA_eval_ids.append(fnm)\n",
    "            elif filename[:2] == 'PA' :\n",
    "                if filename[3] == 'T' :\n",
    "                    PA_train_ids.append(fnm)\n",
    "\n",
    "                elif filename[3] == 'D' :\n",
    "                    PA_dev_ids.append(fnm)\n",
    "\n",
    "                else :\n",
    "                    PA_eval_ids.append(fnm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cb385e",
   "metadata": {},
   "source": [
    "## labeling  \n",
    "txt 파일에서 파일명과 label 정보만 가져와서 진짜 목소리는 0으로 spoofing은 1로 (T, D, E)로 각각 ids2 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd1acc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "\n",
    "## label for train set\n",
    "PA_train_ids2 = []\n",
    "fname = params['data_dir']+'PA/ASVspoof2019_PA_cm_protocols/ASVspoof2019.PA.cm.train.trn.txt'\n",
    "with open(fname, encoding='utf-8') as f:\n",
    "    wav_fnm = []\n",
    "    label = []\n",
    "    for i, doc in enumerate(f):                \n",
    "        _, wav, _, _, lb = doc.strip().split(' ')\n",
    "        if(lb == 'bonafide'):\n",
    "            labels[labels_tmp[wav+'.flac']] = 0\n",
    "        else: \n",
    "            labels[labels_tmp[wav+'.flac']] = 1\n",
    "        PA_train_ids2.append(labels_tmp[wav+'.flac'])\n",
    "            \n",
    "LA_train_ids2 = []\n",
    "fname = params['data_dir']+'LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt'\n",
    "with open(fname, encoding='utf-8') as f:\n",
    "    wav_fnm = []\n",
    "    label = []\n",
    "    for i, doc in enumerate(f):                \n",
    "        _, wav, _, _, lb = doc.strip().split(' ')\n",
    "        if(lb == 'bonafide'):\n",
    "            labels[labels_tmp[wav+'.flac']] = 0\n",
    "        else: \n",
    "            labels[labels_tmp[wav+'.flac']] = 1\n",
    "        LA_train_ids2.append(labels_tmp[wav+'.flac'])\n",
    "            \n",
    "## label for dev set\n",
    "PA_dev_ids2 = []\n",
    "fname = params['data_dir']+'PA/ASVspoof2019_PA_cm_protocols/ASVspoof2019.PA.cm.dev.trl.txt'\n",
    "with open(fname, encoding='utf-8') as f:\n",
    "    wav_fnm = []\n",
    "    label = []\n",
    "    for i, doc in enumerate(f):                \n",
    "        _, wav, _, _, lb = doc.strip().split(' ')\n",
    "        if(lb == 'bonafide'):\n",
    "            labels[labels_tmp[wav+'.flac']] = 0\n",
    "        else: \n",
    "            labels[labels_tmp[wav+'.flac']] = 1\n",
    "        PA_dev_ids2.append(labels_tmp[wav+'.flac'])\n",
    "\n",
    "LA_dev_ids2 = []\n",
    "fname = params['data_dir']+'LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt'\n",
    "with open(fname, encoding='utf-8') as f:\n",
    "    wav_fnm = []\n",
    "    label = []\n",
    "    for i, doc in enumerate(f):                \n",
    "        _, wav, _, _, lb = doc.strip().split(' ')\n",
    "        if(lb == 'bonafide'):\n",
    "            labels[labels_tmp[wav+'.flac']] = 0\n",
    "        else: \n",
    "            labels[labels_tmp[wav+'.flac']] = 1\n",
    "        LA_dev_ids2.append(labels_tmp[wav+'.flac'])\n",
    "\n",
    "            \n",
    "## label for eval set\n",
    "PA_eval_ids2 = []\n",
    "fname = params['data_dir']+'PA/ASVspoof2019_PA_cm_protocols/ASVspoof2019.PA.cm.eval.trl.txt'\n",
    "with open(fname, encoding='utf-8') as f:\n",
    "    wav_fnm = []\n",
    "    label = []\n",
    "    for i, doc in enumerate(f):                \n",
    "        _, wav, _, _, lb = doc.strip().split(' ')\n",
    "        if(lb == 'bonafide'):\n",
    "            labels[labels_tmp[wav+'.flac']] = 0\n",
    "        else: \n",
    "            labels[labels_tmp[wav+'.flac']] = 1\n",
    "        PA_eval_ids2.append(labels_tmp[wav+'.flac'])\n",
    "            \n",
    "LA_eval_ids2 = []\n",
    "fname = params['data_dir']+'LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt'\n",
    "with open(fname, encoding='utf-8') as f:\n",
    "    wav_fnm = []\n",
    "    label = []\n",
    "    for i, doc in enumerate(f):                \n",
    "        _, wav, _, _, lb = doc.strip().split(' ')\n",
    "        if(lb == 'bonafide'):\n",
    "            labels[labels_tmp[wav+'.flac']] = 0\n",
    "        else: \n",
    "            labels[labels_tmp[wav+'.flac']] = 1\n",
    "        LA_eval_ids2.append(labels_tmp[wav+'.flac'])\n",
    "\n",
    "\n",
    "partition = { 'train' : LA_train_ids2, \n",
    "              'devel' : LA_dev_ids2,\n",
    "              'eval' : LA_eval_ids2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210e098d",
   "metadata": {},
   "source": [
    "## speaker separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f6452db",
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = {}\n",
    "\n",
    "\n",
    "LA_train_persons = []\n",
    "fname = params['data_dir']+'LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt'\n",
    "with open(fname, encoding='utf-8') as f:\n",
    "    wav_fnm = []\n",
    "    label = []\n",
    "    for i, doc in enumerate(f):                \n",
    "        ids, wav, _, _, lb = doc.strip().split(' ')\n",
    "        _, p_id = ids.strip().split('_')\n",
    "        if p_id not in LA_train_persons:\n",
    "            LA_train_persons.append(p_id)\n",
    "            \n",
    "\n",
    "LA_dev_persons= []\n",
    "fname = params['data_dir']+'LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt'\n",
    "with open(fname, encoding='utf-8') as f:\n",
    "    wav_fnm = []\n",
    "    label = []\n",
    "    for i, doc in enumerate(f):                \n",
    "        ids, wav, _, _, lb = doc.strip().split(' ')\n",
    "        _, p_id = ids.strip().split('_')\n",
    "        if p_id not in LA_dev_persons:\n",
    "            LA_dev_persons.append(p_id)\n",
    "\n",
    "        \n",
    "            \n",
    "LA_eval_persons = []\n",
    "fname = params['data_dir']+'LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt'\n",
    "with open(fname, encoding='utf-8') as f:\n",
    "    wav_fnm = []\n",
    "    label = []\n",
    "    for i, doc in enumerate(f):                \n",
    "        ids, wav, _, _, lb = doc.strip().split(' ')\n",
    "        _, p_id = ids.strip().split('_')\n",
    "        if p_id not in LA_eval_persons:\n",
    "            LA_eval_persons.append(p_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c0d9f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(LA_train_persons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a22f642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(LA_dev_persons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97348de1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(LA_eval_persons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776bdc78",
   "metadata": {},
   "source": [
    "## Number of  the ASVspoof 2019 database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "146af231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25380"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Bona fide & Spoof in train set\n",
    "# bonafide : 2,580\n",
    "# spoof : 22,800\n",
    "len(LA_train_ids2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08e7f48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24844"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Bona fide & Spoof in dev set\n",
    "# bonafide : 2,548\n",
    "# spoof : 22,296\n",
    "len(LA_dev_ids2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae0725fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71237"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Bona fide & Spoof in dev set\n",
    "# bonafide : 2,548\n",
    "# spoof : 22,296\n",
    "len(LA_eval_ids2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1663b183",
   "metadata": {},
   "source": [
    "## 랜덤하게 화자별 데이터 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9d3dda",
   "metadata": {},
   "source": [
    "1. 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2dd62e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.9\n",
    "if ratio != None:\n",
    "\n",
    "    random.seed(123)\n",
    "    t_person_split = random.sample(LA_train_persons, int(round(len(LA_train_persons)*ratio, 0)))\n",
    "    d_person_split = random.sample(LA_dev_persons, int(round(len(LA_dev_persons)*ratio, 0))) \n",
    "    e_person_split = random.sample(LA_eval_persons, int(round(len(LA_eval_persons)*ratio, 0)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "003b785c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0080',\n",
       " '0087',\n",
       " '0081',\n",
       " '0092',\n",
       " '0097',\n",
       " '0098',\n",
       " '0095',\n",
       " '0079',\n",
       " '0085',\n",
       " '0094',\n",
       " '0089',\n",
       " '0084',\n",
       " '0088',\n",
       " '0090',\n",
       " '0091',\n",
       " '0093',\n",
       " '0083',\n",
       " '0082']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_person_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "944d0a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "random.seed(123)\n",
    "\n",
    "a = 0.9\n",
    "t_person_split = random.sample(LA_train_persons, int(round(len(LA_train_persons)*a, 0)))\n",
    "d_person_split = random.sample(LA_dev_persons, int(round(len(LA_dev_persons)*a, 0))) \n",
    "e_person_split = random.sample(LA_eval_persons, int(round(len(LA_eval_persons)*a, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "02665bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_split_labels = {}\n",
    "\n",
    "\n",
    "LA_train_persons_split = []\n",
    "fname = params['data_dir']+'LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.train.trn.txt'\n",
    "with open(fname, encoding='utf-8') as f:\n",
    "    for i, doc in enumerate(f):                \n",
    "        ids, wav, _, _, lb = doc.strip().split(' ')\n",
    "        _, p_id = ids.strip().split('_')\n",
    "        for i in t_person_split:\n",
    "            if (p_id == i):\n",
    "                if(lb == 'bonafide'):\n",
    "                    persons_split_labels[labels_tmp[wav+'.flac']] = 0\n",
    "                else: \n",
    "                    persons_split_labels[labels_tmp[wav+'.flac']] = 1\n",
    "                LA_train_persons_split.append(labels_tmp[wav+'.flac'])\n",
    "                \n",
    "                \n",
    "\n",
    "LA_dev_persons_split= []\n",
    "fname = params['data_dir']+'LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.dev.trl.txt'\n",
    "with open(fname, encoding='utf-8') as f:\n",
    "    for i, doc in enumerate(f):                \n",
    "        ids, wav, _, _, lb = doc.strip().split(' ')\n",
    "        _, p_id = ids.strip().split('_')\n",
    "        for i in d_person_split:\n",
    "            if (p_id == i):\n",
    "                if(lb == 'bonafide'):\n",
    "                    persons_split_labels[labels_tmp[wav+'.flac']] = 0\n",
    "                else: \n",
    "                    persons_split_labels[labels_tmp[wav+'.flac']] = 1\n",
    "                LA_dev_persons_split.append(labels_tmp[wav+'.flac'])\n",
    "        \n",
    "            \n",
    "LA_eval_persons_split = []\n",
    "fname = params['data_dir']+'LA/ASVspoof2019_LA_cm_protocols/ASVspoof2019.LA.cm.eval.trl.txt'\n",
    "with open(fname, encoding='utf-8') as f:\n",
    "    for i, doc in enumerate(f):                \n",
    "        ids, wav, _, _, lb = doc.strip().split(' ')\n",
    "        _, p_id = ids.strip().split('_')\n",
    "        for i in e_person_split:\n",
    "            if (p_id == i):\n",
    "                if(lb == 'bonafide'):\n",
    "                    persons_split_labels[labels_tmp[wav+'.flac']] = 0\n",
    "                else: \n",
    "                    persons_split_labels[labels_tmp[wav+'.flac']] = 1\n",
    "                LA_eval_persons_split.append(labels_tmp[wav+'.flac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14e9ca29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train set]\n",
      "Total:  25380\n",
      "90% set:  22829\n",
      " \n",
      "[Dev set]\n",
      "Total:  24844\n",
      "90% set:  22080\n",
      " \n",
      "[Eval set]\n",
      "Total:  71237\n",
      "90% set:  63669\n"
     ]
    }
   ],
   "source": [
    "print(\"[Train set]\")\n",
    "print(\"Total: \", len(LA_train_ids2))\n",
    "print(\"90% set: \", len(LA_train_persons_split))\n",
    "\n",
    "print(\" \")\n",
    "print(\"[Dev set]\")\n",
    "print(\"Total: \", len(LA_dev_ids2))\n",
    "print(\"90% set: \", len(LA_dev_persons_split))\n",
    "\n",
    "print(\" \")\n",
    "print(\"[Eval set]\")\n",
    "print(\"Total: \", len(LA_eval_ids2))\n",
    "print(\"90% set: \", len(LA_eval_persons_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77e2f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = { 'train' : LA_train_persons_split, \n",
    "              'devel' : LA_dev_persons_split,\n",
    "              'eval' : LA_eval_persons_split}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1344089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    }
   ],
   "source": [
    "training_generator = DataGenerator(partition['train'], persons_split_labels, **params)\n",
    "validation_generator = DataGenerator(partition['devel'], persons_split_labels, **params_no_shuffle)\n",
    "evaluation_generator = DataGenerator(partition['eval'], persons_split_labels, **params_no_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e568e45d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 282, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = training_generator.get_input_shape()\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0412477c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 100, 282, 1) dtype=float32 (created by layer 'input_1')>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = Input(input_shape)\n",
    "input_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c55416",
   "metadata": {},
   "source": [
    "## DataLoader1.py 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bd89a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "789/789 [==============================] - 26s 24ms/step - loss: 1.4190 - auc: 0.7687\n",
      "Epoch 2/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.3983 - auc: 0.9624\n",
      "Epoch 3/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.1673 - auc: 0.9937\n",
      "Epoch 4/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.1150 - auc: 0.9968\n",
      "Epoch 5/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0833 - auc: 0.9980\n",
      "Epoch 6/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0648 - auc: 0.9986\n",
      "Epoch 7/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0443 - auc: 0.9993\n",
      "Epoch 8/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.1115 - auc: 0.9967\n",
      "Epoch 9/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0483 - auc: 0.9992\n",
      "Epoch 10/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0460 - auc: 0.9991\n",
      "Epoch 11/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0446 - auc: 0.9992\n",
      "Epoch 12/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0421 - auc: 0.9994\n",
      "Epoch 13/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0367 - auc: 0.9996\n",
      "Epoch 14/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0598 - auc: 0.9982\n",
      "Epoch 15/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0457 - auc: 0.9989\n",
      "Epoch 16/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0216 - auc: 0.9995\n",
      "Epoch 17/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0289 - auc: 0.9993\n",
      "Epoch 18/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0279 - auc: 0.9996\n",
      "Epoch 19/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0187 - auc: 0.9996\n",
      "Epoch 20/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0448 - auc: 0.9992\n",
      "Epoch 21/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0261 - auc: 0.9997\n",
      "Epoch 22/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0409 - auc: 0.9992\n",
      "Epoch 23/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0136 - auc: 0.9996\n",
      "Epoch 24/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0241 - auc: 0.9995\n",
      "Epoch 25/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0151 - auc: 0.9998\n",
      "Epoch 26/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0155 - auc: 0.9999\n",
      "Epoch 27/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0084 - auc: 1.0000\n",
      "Epoch 28/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0268 - auc: 0.9994\n",
      "Epoch 29/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0153 - auc: 0.9998\n",
      "Epoch 30/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0173 - auc: 0.9993\n",
      "Epoch 31/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0083 - auc: 0.9997\n",
      "Epoch 32/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0163 - auc: 0.9994\n",
      "Epoch 33/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0138 - auc: 0.9996\n",
      "Epoch 34/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0069 - auc: 0.9998\n",
      "Epoch 35/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0182 - auc: 0.9997\n",
      "Epoch 36/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0044 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0072 - auc: 0.9994\n",
      "Epoch 38/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0048 - auc: 1.0000\n",
      "Epoch 39/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0060 - auc: 0.9997\n",
      "Epoch 40/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0045 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0052 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0019 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0017 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0021 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0012 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0031 - auc: 0.9999\n",
      "Epoch 47/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0010 - auc: 1.0000\n",
      "Epoch 48/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0017 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 5.4107e-04 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 9.9678e-04 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0010 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0010 - auc: 0.9999\n",
      "Epoch 53/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 5.6127e-04 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 3.4187e-04 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 5.2812e-04 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0011 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0019 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 3.0419e-04 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "789/789 [==============================] - 19s 25ms/step - loss: 8.7273e-04 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0013 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 5.9066e-04 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0010 - auc: 1.0000\n",
      "Epoch 63/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 4.7451e-04 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 3.0813e-04 - auc: 1.0000\n",
      "Epoch 65/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 6.0219e-04 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 8.3039e-04 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 5.9069e-04 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0012 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 2.5311e-04 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 4.8408e-04 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.012842528428459435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.04953520455029594\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0128', 'eer_eval': '0.0495', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0128.hdf5', 'tnow': '2022-12-20 13:16:52.937699'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "789/789 [==============================] - 24s 24ms/step - loss: 1.4453 - auc: 0.7694\n",
      "Epoch 2/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.5152 - auc: 0.9388\n",
      "Epoch 3/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.3698 - auc: 0.9685\n",
      "Epoch 4/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.2207 - auc: 0.9882\n",
      "Epoch 5/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.1317 - auc: 0.9956\n",
      "Epoch 6/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.1083 - auc: 0.9969\n",
      "Epoch 7/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.1017 - auc: 0.9971\n",
      "Epoch 8/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0931 - auc: 0.9978\n",
      "Epoch 9/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0829 - auc: 0.9980\n",
      "Epoch 10/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0583 - auc: 0.9988\n",
      "Epoch 11/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0716 - auc: 0.9985\n",
      "Epoch 12/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0446 - auc: 0.9991\n",
      "Epoch 13/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0389 - auc: 0.9994\n",
      "Epoch 14/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0579 - auc: 0.9984\n",
      "Epoch 15/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0373 - auc: 0.9994\n",
      "Epoch 16/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0319 - auc: 0.9995\n",
      "Epoch 17/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0414 - auc: 0.9989\n",
      "Epoch 18/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0332 - auc: 0.9996\n",
      "Epoch 19/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0322 - auc: 0.9993\n",
      "Epoch 20/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0347 - auc: 0.9994\n",
      "Epoch 21/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0359 - auc: 0.9994\n",
      "Epoch 22/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0170 - auc: 0.9997\n",
      "Epoch 23/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0331 - auc: 0.9992\n",
      "Epoch 24/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0118 - auc: 0.9999\n",
      "Epoch 25/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0230 - auc: 0.9993\n",
      "Epoch 26/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0227 - auc: 0.9996\n",
      "Epoch 27/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0157 - auc: 0.9995\n",
      "Epoch 28/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0160 - auc: 0.9997\n",
      "Epoch 29/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0106 - auc: 0.9999\n",
      "Epoch 30/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0143 - auc: 0.9996\n",
      "Epoch 31/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0235 - auc: 0.9994\n",
      "Epoch 32/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0036 - auc: 1.0000\n",
      "Epoch 33/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0165 - auc: 0.9997\n",
      "Epoch 34/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0195 - auc: 0.9995\n",
      "Epoch 35/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0135 - auc: 0.9997\n",
      "Epoch 36/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0038 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0017 - auc: 1.0000\n",
      "Epoch 38/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0038 - auc: 1.0000\n",
      "Epoch 39/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0074 - auc: 0.9996\n",
      "Epoch 40/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0054 - auc: 0.9998\n",
      "Epoch 41/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0019 - auc: 1.0000\n",
      "Epoch 42/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0029 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0025 - auc: 0.9999\n",
      "Epoch 44/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0028 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0010 - auc: 1.0000\n",
      "Epoch 46/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0030 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0052 - auc: 0.9999\n",
      "Epoch 48/70\n",
      "789/789 [==============================] - 19s 24ms/step - loss: 0.0013 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0024 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0030 - auc: 1.0000\n",
      "Epoch 51/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0024 - auc: 0.9998\n",
      "Epoch 52/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0018 - auc: 1.0000\n",
      "Epoch 53/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0013 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 3.8151e-04 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0018 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 7.8973e-04 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 2.9659e-04 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0014 - auc: 1.0000\n",
      "Epoch 59/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0013 - auc: 1.0000\n",
      "Epoch 60/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0015 - auc: 1.0000\n",
      "Epoch 61/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 4.2951e-04 - auc: 1.0000\n",
      "Epoch 62/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0126 - auc: 0.9999\n",
      "Epoch 63/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0020 - auc: 1.0000\n",
      "Epoch 64/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0077 - auc: 0.9999\n",
      "Epoch 65/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0015 - auc: 1.0000\n",
      "Epoch 66/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 7.2384e-04 - auc: 1.0000\n",
      "Epoch 67/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0011 - auc: 1.0000\n",
      "Epoch 68/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0013 - auc: 1.0000\n",
      "Epoch 69/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 9.1090e-04 - auc: 1.0000\n",
      "Epoch 70/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 2.5510e-04 - auc: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.005472896954810597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EER: 0.04824473605911819\n",
      "{'sr': 16000, 'batch_size': 16, 'feature': 'cqt', 'n_classes': 2, 'sec': 9.0, 'filter_scale': 1, 'fmin': 5, 'n_bins': 100, 'tofile': 'tmp', 'shuffle': True, 'beta_param': False, 'data_dir': '/home/ubuntu/data/asv2019/', 'lowpass': False, 'highpass': False, 'ranfilter2': False, 'model': 'BCResMax_LA_', 'human_weight': '5.0', 'dropout_rate': '0.5', 'eer_val': '0.0054', 'eer_eval': '0.0482', 'saved_model': 'saved_models/model_name!BCResMax_LA_!dropout_rate!0.5!human_weight!5.0!feature!cqt!sec!9.0!filter_scale!1!fmin!5!n_bins!100!shuffle!True!beta_param!False!lowpass!--!highpass!--!ranfilter2!--!0.0054.hdf5', 'tnow': '2022-12-20 13:40:04.132464'}\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n",
      "cqt\n",
      "Input_shape:(100,282,1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow2.4_p37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "789/789 [==============================] - 24s 25ms/step - loss: 1.6221 - auc: 0.7540\n",
      "Epoch 2/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.6565 - auc: 0.9028\n",
      "Epoch 3/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.4482 - auc: 0.9518\n",
      "Epoch 4/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.2802 - auc: 0.9815\n",
      "Epoch 5/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.1445 - auc: 0.9946\n",
      "Epoch 6/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.1043 - auc: 0.9975\n",
      "Epoch 7/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0682 - auc: 0.9983\n",
      "Epoch 8/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0527 - auc: 0.9993\n",
      "Epoch 9/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0527 - auc: 0.9989\n",
      "Epoch 10/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0389 - auc: 0.9993\n",
      "Epoch 11/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0374 - auc: 0.9991\n",
      "Epoch 12/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0317 - auc: 0.9995\n",
      "Epoch 13/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0280 - auc: 0.9992\n",
      "Epoch 14/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0364 - auc: 0.9992\n",
      "Epoch 15/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0369 - auc: 0.9995\n",
      "Epoch 16/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0155 - auc: 0.9999\n",
      "Epoch 17/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0128 - auc: 0.9999\n",
      "Epoch 18/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0158 - auc: 0.9994\n",
      "Epoch 19/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0300 - auc: 0.9994\n",
      "Epoch 20/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0164 - auc: 0.9996\n",
      "Epoch 21/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0318 - auc: 0.9992\n",
      "Epoch 22/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0232 - auc: 0.9999\n",
      "Epoch 23/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0289 - auc: 0.9995\n",
      "Epoch 24/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0179 - auc: 0.9998\n",
      "Epoch 25/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0063 - auc: 0.9999\n",
      "Epoch 26/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0239 - auc: 0.9993\n",
      "Epoch 27/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0195 - auc: 0.9998\n",
      "Epoch 28/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0147 - auc: 0.9999\n",
      "Epoch 29/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0200 - auc: 0.9998\n",
      "Epoch 30/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0186 - auc: 0.9997\n",
      "Epoch 31/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0076 - auc: 1.0000\n",
      "Epoch 32/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0091 - auc: 0.9998\n",
      "Epoch 33/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0080 - auc: 0.9999\n",
      "Epoch 34/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0085 - auc: 0.9999\n",
      "Epoch 35/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0051 - auc: 1.0000\n",
      "Epoch 36/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0067 - auc: 1.0000\n",
      "Epoch 37/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0055 - auc: 0.9999\n",
      "Epoch 38/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0093 - auc: 0.9998\n",
      "Epoch 39/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0034 - auc: 1.0000\n",
      "Epoch 40/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0079 - auc: 1.0000\n",
      "Epoch 41/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0109 - auc: 0.9997\n",
      "Epoch 42/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0023 - auc: 1.0000\n",
      "Epoch 43/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0048 - auc: 1.0000\n",
      "Epoch 44/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0024 - auc: 1.0000\n",
      "Epoch 45/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0121 - auc: 0.9999\n",
      "Epoch 46/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0049 - auc: 1.0000\n",
      "Epoch 47/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0013 - auc: 0.9999\n",
      "Epoch 48/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0014 - auc: 1.0000\n",
      "Epoch 49/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0027 - auc: 1.0000\n",
      "Epoch 50/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0026 - auc: 0.9999\n",
      "Epoch 51/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 7.6975e-04 - auc: 1.0000\n",
      "Epoch 52/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0034 - auc: 0.9999\n",
      "Epoch 53/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0013 - auc: 1.0000\n",
      "Epoch 54/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0011 - auc: 1.0000\n",
      "Epoch 55/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 0.0019 - auc: 1.0000\n",
      "Epoch 56/70\n",
      "789/789 [==============================] - 20s 25ms/step - loss: 5.1129e-04 - auc: 1.0000\n",
      "Epoch 57/70\n",
      "789/789 [==============================] - 20s 26ms/step - loss: 0.0022 - auc: 1.0000\n",
      "Epoch 58/70\n",
      "240/789 [========>.....................] - ETA: 13s - loss: 0.0023 - auc: 1.0000"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "\n",
    "from utils.DataLoader1 import data_loader\n",
    "from utils.Generator0 import DataGenerator, feature_extract_cqt, evalEER,  evalScore, evalEER_f, evalEER_f2, gen_fname\n",
    "from models.models import get_ResMax, get_LCNN, sigmoidal_decay\n",
    "from models.models2 import get_BCResMax, get_DDWSseq\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import add,concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, maximum, DepthwiseConv2D, AveragePooling2D, UpSampling2D\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, SpatialDropout2D\n",
    "from tensorflow.keras.layers import Convolution2D, GlobalAveragePooling2D, MaxPool2D, ZeroPadding2D\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.activations import relu, softmax, swish\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import pickle\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "add2022 = '/home/ubuntu/data/ADD/'\n",
    "asv2019 = '/home/ubuntu/data/asv2019/'\n",
    "\n",
    "pathset = { 'add2022' : add2022 , 'asv2019':asv2019}\n",
    "        \n",
    "dl = data_loader(pathset)\n",
    "datapick = '2' ## 1:ADD, 2:LA\n",
    "\n",
    "\n",
    "dl.get_data(data_pick = datapick, tde_pick = 't', pl_pick = 'l',  to = 't',ratio=0.5)\n",
    "dl.get_data(data_pick = datapick, tde_pick = 'd', pl_pick = 'l', to = 'd',ratio=0.5)\n",
    "dl.get_data(data_pick = datapick, tde_pick = 'e', pl_pick = 'l', to = 'e',ratio=0.5)\n",
    "\n",
    "\n",
    "# #################################################\n",
    "# ### get_ResMax\n",
    "# mname = 'ResMax_LA_'\n",
    "# #################################################\n",
    "\n",
    "# ### None\n",
    "\n",
    "# for i in range(3) :\n",
    "#     sr = 16000\n",
    "#     sec = 9.0\n",
    "#     batch_size = 16\n",
    "#     feature = \"cqt\"\n",
    "#     #hop_length = 128\n",
    "#     #win_length = 512\n",
    "#     #n_bins = 80\n",
    "#     filter_scale = 1\n",
    "#     n_bins = 100\n",
    "#     fmin = 5\n",
    "#     epoch = 70\n",
    "#     beta_param = False\n",
    "#     dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "#     human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "#     win_size = np.random.choice([10,15,20])\n",
    "#     if win_size == 10 :\n",
    "#         lpsize = [8,9,10,11,12]\n",
    "#         hpsize = [88,89,90,91,92]\n",
    "#         ransize = [8,9,10,11,12]\n",
    "#     elif win_size == 15 :\n",
    "#         lpsize = [13,14,15,16,17]\n",
    "#         hpsize = [83,84,85,86,87]\n",
    "#         ransize = [13,14,15,16,17]\n",
    "#     else :\n",
    "#         lpsize = [18,19,20,21,22]\n",
    "#         hpsize = [78,79,80,81,82]\n",
    "#         ransize = [18,19,20,21,22]\n",
    "#     ru = 0.5#np.random.uniform(.1, .9)\n",
    "#     uv = [ru, 1-ru]\n",
    "#     lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "#     highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "#     nm = np.random.choice([2,3,4])\n",
    "#     ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "#     tmp_string = \"tmp\"\n",
    "#     params = {'sr': sr,\n",
    "#           'batch_size': batch_size,\n",
    "#           'feature': feature,\n",
    "#           'n_classes': 2,\n",
    "#           'sec': sec,\n",
    "#           'filter_scale': filter_scale,\n",
    "#           'fmin' : fmin,\n",
    "#           'n_bins': int(n_bins),\n",
    "#           'tofile': tmp_string,\n",
    "#           'shuffle': True,\n",
    "#           'beta_param': beta_param,\n",
    "#           'data_dir': asv2019,\n",
    "#           'lowpass': lowpass,\n",
    "#           'highpass': highpass,\n",
    "#           #          'ranfilter' : [10,11,12,13,14,15]\n",
    "#           'ranfilter2' : ranfilter2 \n",
    "#           #           'dropblock' : [30, 100]\n",
    "#           #'device' : device\n",
    "#     }\n",
    "#     params_no_shuffle = {'sr': sr,\n",
    "#                      'batch_size': batch_size,\n",
    "#                      'feature': feature,\n",
    "#                      'n_classes': 2,\n",
    "#                      'sec': sec,\n",
    "#                      'filter_scale': filter_scale,\n",
    "#                      'fmin' : fmin,\n",
    "#                      'n_bins': int(n_bins),\n",
    "#                      'tofile': tmp_string,\n",
    "#                      'shuffle': False,\n",
    "#                     'data_dir': asv2019\n",
    "#                      #'device': device\n",
    "#     }\n",
    "#     training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "#     validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "#     eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "#     input_shape = training_generator.get_input_shape()\n",
    "#     model = get_ResMax(input_shape)\n",
    "# #    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "#     EPOCHS = epoch\n",
    "#     lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "#     class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "#     history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "#                               epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "#     eer_val = evalEER(validation_generator, model)\n",
    "#     eer_eval = evalEER(eval_generator, model)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "#     savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "#     savefnm = 'saved_models/' + savefnm\n",
    "#     model.save(savefnm)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "#     fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "#     fnm = 'saved_results/' + fnm\n",
    "#     sc1 = model.predict(eval_generator)\n",
    "#     np.save(fnm, sc1)\n",
    "#     params_save = params\n",
    "#     params_save['model'] = mname\n",
    "#     params_save['human_weight'] = str(human_weight)\n",
    "#     params_save['dropout_rate'] = str(dropout_rate)\n",
    "#     params_save['eer_val'] = str(eer_val)[:6]\n",
    "#     params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "#     params_save['saved_model'] = savefnm\n",
    "#     tnow = datetime.datetime.now()\n",
    "#     params_save['tnow'] = str(tnow)\n",
    "#     print(params_save)\n",
    "#     fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "#     with open(fnm, 'wb') as f:\n",
    "#         pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "# ### Mixup\n",
    "# for i in range(3) :\n",
    "#     sr = 16000\n",
    "#     sec = 9.0\n",
    "#     batch_size = 16\n",
    "#     feature = \"cqt\"\n",
    "#     #hop_length = 128\n",
    "#     #win_length = 512\n",
    "#     #n_bins = 80\n",
    "#     filter_scale = 1\n",
    "#     n_bins = 100\n",
    "#     fmin = 5\n",
    "#     epoch = 70\n",
    "#     beta_param = 0.7\n",
    "#     dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "#     human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "#     win_size = np.random.choice([10,15,20])\n",
    "#     if win_size == 10 :\n",
    "#         lpsize = [8,9,10,11,12]\n",
    "#         hpsize = [88,89,90,91,92]\n",
    "#         ransize = [8,9,10,11,12]\n",
    "#     elif win_size == 15 :\n",
    "#         lpsize = [13,14,15,16,17]\n",
    "#         hpsize = [83,84,85,86,87]\n",
    "#         ransize = [13,14,15,16,17]\n",
    "#     else :\n",
    "#         lpsize = [18,19,20,21,22]\n",
    "#         hpsize = [78,79,80,81,82]\n",
    "#         ransize = [18,19,20,21,22]\n",
    "#     ru = 0.5#np.random.uniform(.1, .9)\n",
    "#     uv = [ru, 1-ru]\n",
    "#     lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "#     highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "#     nm = np.random.choice([2,3,4])\n",
    "#     ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "#     tmp_string = \"tmp\"\n",
    "#     params = {'sr': sr,\n",
    "#           'batch_size': batch_size,\n",
    "#           'feature': feature,\n",
    "#           'n_classes': 2,\n",
    "#           'sec': sec,\n",
    "#           'filter_scale': filter_scale,\n",
    "#           'fmin' : fmin,\n",
    "#           'n_bins': int(n_bins),\n",
    "#           'tofile': tmp_string,\n",
    "#           'shuffle': True,\n",
    "#           'beta_param': beta_param,\n",
    "#           'data_dir': asv2019,\n",
    "#           'lowpass': lowpass,\n",
    "#           'highpass': highpass,\n",
    "#           #          'ranfilter' : [10,11,12,13,14,15]\n",
    "#           'ranfilter2' : ranfilter2 \n",
    "#           #           'dropblock' : [30, 100]\n",
    "#           #'device' : device\n",
    "#     }\n",
    "#     params_no_shuffle = {'sr': sr,\n",
    "#                      'batch_size': batch_size,\n",
    "#                      'feature': feature,\n",
    "#                      'n_classes': 2,\n",
    "#                      'sec': sec,\n",
    "#                      'filter_scale': filter_scale,\n",
    "#                      'fmin' : fmin,\n",
    "#                      'n_bins': int(n_bins),\n",
    "#                      'tofile': tmp_string,\n",
    "#                      'shuffle': False,\n",
    "#                     'data_dir': asv2019\n",
    "#                      #'device': device\n",
    "#     }\n",
    "#     training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "#     validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "#     eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "#     input_shape = training_generator.get_input_shape()\n",
    "#     model = get_ResMax(input_shape)\n",
    "# #    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "#     EPOCHS = epoch\n",
    "#     lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "#     class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "#     history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "#                               epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "#     eer_val = evalEER(validation_generator, model)\n",
    "#     eer_eval = evalEER(eval_generator, model)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "#     savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "#     savefnm = 'saved_models/' + savefnm\n",
    "#     model.save(savefnm)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "#     fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "#     fnm = 'saved_results/' + fnm\n",
    "#     sc1 = model.predict(eval_generator)\n",
    "#     np.save(fnm, sc1)\n",
    "#     params_save = params\n",
    "#     params_save['model'] = mname\n",
    "#     params_save['human_weight'] = str(human_weight)\n",
    "#     params_save['dropout_rate'] = str(dropout_rate)\n",
    "#     params_save['eer_val'] = str(eer_val)[:6]\n",
    "#     params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "#     params_save['saved_model'] = savefnm\n",
    "#     tnow = datetime.datetime.now()\n",
    "#     params_save['tnow'] = str(tnow)\n",
    "#     print(params_save)\n",
    "#     fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "#     with open(fnm, 'wb') as f:\n",
    "#         pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "# ### LP        \n",
    " \n",
    "# for i in range(3) :\n",
    "#     sr = 16000\n",
    "#     sec = 9.0\n",
    "#     batch_size = 16\n",
    "#     feature = \"cqt\"\n",
    "#     #hop_length = 128\n",
    "#     #win_length = 512\n",
    "#     #n_bins = 80\n",
    "#     filter_scale = 1\n",
    "#     n_bins = 100\n",
    "#     fmin = 5\n",
    "#     epoch = 70\n",
    "#     beta_param = 0.7\n",
    "#     dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "#     human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "#     win_size = np.random.choice([10,15,20])\n",
    "#     if win_size == 10 :\n",
    "#         lpsize = [8,9,10,11,12]\n",
    "#         hpsize = [88,89,90,91,92]\n",
    "#         ransize = [8,9,10,11,12]\n",
    "#     elif win_size == 15 :\n",
    "#         lpsize = [13,14,15,16,17]\n",
    "#         hpsize = [83,84,85,86,87]\n",
    "#         ransize = [13,14,15,16,17]\n",
    "#     else :\n",
    "#         lpsize = [18,19,20,21,22]\n",
    "#         hpsize = [78,79,80,81,82]\n",
    "#         ransize = [18,19,20,21,22]\n",
    "# #    ru = np.random.uniform(.1, .9)\n",
    "#     ru = 0.5\n",
    "#     uv = [ru, 1-ru]\n",
    "#     lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "#     highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "#     nm = np.random.choice([2,3,4])\n",
    "#     ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "#     tmp_string = \"tmp\"\n",
    "#     params = {'sr': sr,\n",
    "#           'batch_size': batch_size,\n",
    "#           'feature': feature,\n",
    "#           'n_classes': 2,\n",
    "#           'sec': sec,\n",
    "#           'filter_scale': filter_scale,\n",
    "#           'fmin' : fmin,\n",
    "#           'n_bins': int(n_bins),\n",
    "#           'tofile': tmp_string,\n",
    "#           'shuffle': True,\n",
    "#           'beta_param': beta_param,\n",
    "#           'data_dir': asv2019,\n",
    "#           'lowpass': lowpass,\n",
    "#           'highpass': highpass,\n",
    "#           #          'ranfilter' : [10,11,12,13,14,15]\n",
    "#           'ranfilter2' : ranfilter2 \n",
    "#           #           'dropblock' : [30, 100]\n",
    "#           #'device' : device\n",
    "#     }\n",
    "#     params_no_shuffle = {'sr': sr,\n",
    "#                      'batch_size': batch_size,\n",
    "#                      'feature': feature,\n",
    "#                      'n_classes': 2,\n",
    "#                      'sec': sec,\n",
    "#                      'filter_scale': filter_scale,\n",
    "#                      'fmin' : fmin,\n",
    "#                      'n_bins': int(n_bins),\n",
    "#                      'tofile': tmp_string,\n",
    "#                      'shuffle': False,\n",
    "#                     'data_dir': asv2019\n",
    "#                      #'device': device\n",
    "#     }\n",
    "#     training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "#     validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "#     eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "#     input_shape = training_generator.get_input_shape()\n",
    "#     model = get_ResMax(input_shape)\n",
    "# #    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "#     EPOCHS = epoch\n",
    "#     lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "#     class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "#     history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "#                               epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "#     eer_val = evalEER(validation_generator, model)\n",
    "#     eer_eval = evalEER(eval_generator, model)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "#     savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "#     savefnm = 'saved_models/' + savefnm\n",
    "#     model.save(savefnm)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "#     fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "#     fnm = 'saved_results/' + fnm\n",
    "#     sc1 = model.predict(eval_generator)\n",
    "#     np.save(fnm, sc1)\n",
    "#     params_save = params\n",
    "#     params_save['model'] = mname\n",
    "#     params_save['human_weight'] = str(human_weight)\n",
    "#     params_save['dropout_rate'] = str(dropout_rate)\n",
    "#     params_save['eer_val'] = str(eer_val)[:6]\n",
    "#     params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "#     params_save['saved_model'] = savefnm\n",
    "#     tnow = datetime.datetime.now()\n",
    "#     params_save['tnow'] = str(tnow)\n",
    "#     print(params_save)\n",
    "#     fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "#     with open(fnm, 'wb') as f:\n",
    "#         pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "      \n",
    "# ### HP        \n",
    " \n",
    "# for i in range(3) :\n",
    "#     sr = 16000\n",
    "#     sec = 9.0\n",
    "#     batch_size = 16\n",
    "#     feature = \"cqt\"\n",
    "#     #hop_length = 128\n",
    "#     #win_length = 512\n",
    "#     #n_bins = 80\n",
    "#     filter_scale = 1\n",
    "#     n_bins = 100\n",
    "#     fmin = 5\n",
    "#     epoch = 70\n",
    "#     beta_param = 0.7\n",
    "#     dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "#     human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "#     win_size = np.random.choice([10,15,20])\n",
    "#     if win_size == 10 :\n",
    "#         lpsize = [8,9,10,11,12]\n",
    "#         hpsize = [88,89,90,91,92]\n",
    "#         ransize = [8,9,10,11,12]\n",
    "#     elif win_size == 15 :\n",
    "#         lpsize = [13,14,15,16,17]\n",
    "#         hpsize = [83,84,85,86,87]\n",
    "#         ransize = [13,14,15,16,17]\n",
    "#     else :\n",
    "#         lpsize = [18,19,20,21,22]\n",
    "#         hpsize = [78,79,80,81,82]\n",
    "#         ransize = [18,19,20,21,22]\n",
    "# #    ru = np.random.uniform(.1, .9)\n",
    "#     ru = 0.5\n",
    "#     uv = [ru, 1-ru]\n",
    "#     lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "#     highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "#     nm = np.random.choice([2,3,4])\n",
    "#     ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "#     tmp_string = \"tmp\"\n",
    "#     params = {'sr': sr,\n",
    "#           'batch_size': batch_size,\n",
    "#           'feature': feature,\n",
    "#           'n_classes': 2,\n",
    "#           'sec': sec,\n",
    "#           'filter_scale': filter_scale,\n",
    "#           'fmin' : fmin,\n",
    "#           'n_bins': int(n_bins),\n",
    "#           'tofile': tmp_string,\n",
    "#           'shuffle': True,\n",
    "#           'beta_param': beta_param,\n",
    "#           'data_dir': asv2019,\n",
    "#           'lowpass': lowpass,\n",
    "#           'highpass': highpass,\n",
    "#           #          'ranfilter' : [10,11,12,13,14,15]\n",
    "#           'ranfilter2' : ranfilter2 \n",
    "#           #           'dropblock' : [30, 100]\n",
    "#           #'device' : device\n",
    "#     }\n",
    "#     params_no_shuffle = {'sr': sr,\n",
    "#                      'batch_size': batch_size,\n",
    "#                      'feature': feature,\n",
    "#                      'n_classes': 2,\n",
    "#                      'sec': sec,\n",
    "#                      'filter_scale': filter_scale,\n",
    "#                      'fmin' : fmin,\n",
    "#                      'n_bins': int(n_bins),\n",
    "#                      'tofile': tmp_string,\n",
    "#                      'shuffle': False,\n",
    "#                     'data_dir': asv2019\n",
    "#                      #'device': device\n",
    "#     }\n",
    "#     training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "#     validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "#     eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "#     input_shape = training_generator.get_input_shape()\n",
    "#     model = get_ResMax(input_shape)\n",
    "# #    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "#     EPOCHS = epoch\n",
    "#     lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "#     class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "#     history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "#                               epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "#     eer_val = evalEER(validation_generator, model)\n",
    "#     eer_eval = evalEER(eval_generator, model)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "#     savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "#     savefnm = 'saved_models/' + savefnm\n",
    "#     model.save(savefnm)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "#     fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "#     fnm = 'saved_results/' + fnm\n",
    "#     sc1 = model.predict(eval_generator)\n",
    "#     np.save(fnm, sc1)\n",
    "#     params_save = params\n",
    "#     params_save['model'] = mname\n",
    "#     params_save['human_weight'] = str(human_weight)\n",
    "#     params_save['dropout_rate'] = str(dropout_rate)\n",
    "#     params_save['eer_val'] = str(eer_val)[:6]\n",
    "#     params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "#     params_save['saved_model'] = savefnm\n",
    "#     tnow = datetime.datetime.now()\n",
    "#     params_save['tnow'] = str(tnow)\n",
    "#     print(params_save)\n",
    "#     fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "#     with open(fnm, 'wb') as f:\n",
    "#         pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# ### RP\n",
    "\n",
    "# for i in range(3) :\n",
    "#     sr = 16000\n",
    "#     sec = 9.0\n",
    "#     batch_size = 16\n",
    "#     feature = \"cqt\"\n",
    "#     #hop_length = 128\n",
    "#     #win_length = 512\n",
    "#     #n_bins = 80\n",
    "#     filter_scale = 1\n",
    "#     n_bins = 100\n",
    "#     fmin = 5\n",
    "#     epoch = 70\n",
    "#     beta_param = 0.7\n",
    "#     dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "#     human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "#     win_size = np.random.choice([10,15,20])\n",
    "#     if win_size == 10 :\n",
    "#         lpsize = [8,9,10,11,12]\n",
    "#         hpsize = [88,89,90,91,92]\n",
    "#         ransize = [8,9,10,11,12]\n",
    "#     elif win_size == 15 :\n",
    "#         lpsize = [13,14,15,16,17]\n",
    "#         hpsize = [83,84,85,86,87]\n",
    "#         ransize = [13,14,15,16,17]\n",
    "#     else :\n",
    "#         lpsize = [18,19,20,21,22]\n",
    "#         hpsize = [78,79,80,81,82]\n",
    "#         ransize = [18,19,20,21,22]\n",
    "#     ru = 0.5\n",
    "#     uv = [ru, 1-ru]\n",
    "#     lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "#     highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "#     nm = np.random.choice([2,3,4])\n",
    "#     ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "#     tmp_string = \"tmp\"\n",
    "#     params = {'sr': sr,\n",
    "#           'batch_size': batch_size,\n",
    "#           'feature': feature,\n",
    "#           'n_classes': 2,\n",
    "#           'sec': sec,\n",
    "#           'filter_scale': filter_scale,\n",
    "#           'fmin' : fmin,\n",
    "#           'n_bins': int(n_bins),\n",
    "#           'tofile': tmp_string,\n",
    "#           'shuffle': True,\n",
    "#           'beta_param': beta_param,\n",
    "#           'data_dir': asv2019,\n",
    "#           'lowpass': lowpass,\n",
    "#           'highpass': highpass,\n",
    "#           #          'ranfilter' : [10,11,12,13,14,15]\n",
    "#           'ranfilter2' : ranfilter2 \n",
    "#           #           'dropblock' : [30, 100]\n",
    "#           #'device' : device\n",
    "#     }\n",
    "#     params_no_shuffle = {'sr': sr,\n",
    "#                      'batch_size': batch_size,\n",
    "#                      'feature': feature,\n",
    "#                      'n_classes': 2,\n",
    "#                      'sec': sec,\n",
    "#                      'filter_scale': filter_scale,\n",
    "#                      'fmin' : fmin,\n",
    "#                      'n_bins': int(n_bins),\n",
    "#                      'tofile': tmp_string,\n",
    "#                      'shuffle': False,\n",
    "#                     'data_dir': asv2019\n",
    "#                      #'device': device\n",
    "#     }\n",
    "#     training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "#     validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "#     eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "#     input_shape = training_generator.get_input_shape()\n",
    "#     model = get_ResMax(input_shape)\n",
    "# #    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "#     EPOCHS = epoch\n",
    "#     lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "#     class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "#     history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "#                               epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "#     eer_val = evalEER(validation_generator, model)\n",
    "#     eer_eval = evalEER(eval_generator, model)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "#     savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "#     savefnm = 'saved_models/' + savefnm\n",
    "#     model.save(savefnm)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "#     fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "#     fnm = 'saved_results/' + fnm\n",
    "#     sc1 = model.predict(eval_generator)\n",
    "#     np.save(fnm, sc1)\n",
    "#     params_save = params\n",
    "#     params_save['model'] = mname\n",
    "#     params_save['human_weight'] = str(human_weight)\n",
    "#     params_save['dropout_rate'] = str(dropout_rate)\n",
    "#     params_save['eer_val'] = str(eer_val)[:6]\n",
    "#     params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "#     params_save['saved_model'] = savefnm\n",
    "#     tnow = datetime.datetime.now()\n",
    "#     params_save['tnow'] = str(tnow)\n",
    "#     print(params_save)\n",
    "#     fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "#     with open(fnm, 'wb') as f:\n",
    "#         pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "# ### LP + RP\n",
    "\n",
    "# for i in range(3) :\n",
    "#     sr = 16000\n",
    "#     sec = 9.0\n",
    "#     batch_size = 16\n",
    "#     feature = \"cqt\"\n",
    "#     #hop_length = 128\n",
    "#     #win_length = 512\n",
    "#     #n_bins = 80\n",
    "#     filter_scale = 1\n",
    "#     n_bins = 100\n",
    "#     fmin = 5\n",
    "#     epoch = 70\n",
    "#     beta_param = 0.7\n",
    "#     dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "#     human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "#     win_size = np.random.choice([10,15,20])\n",
    "#     if win_size == 10 :\n",
    "#         lpsize = [8,9,10,11,12]\n",
    "#         hpsize = [88,89,90,91,92]\n",
    "#         ransize = [8,9,10,11,12]\n",
    "#     elif win_size == 15 :\n",
    "#         lpsize = [13,14,15,16,17]\n",
    "#         hpsize = [83,84,85,86,87]\n",
    "#         ransize = [13,14,15,16,17]\n",
    "#     else :\n",
    "#         lpsize = [18,19,20,21,22]\n",
    "#         hpsize = [78,79,80,81,82]\n",
    "#         ransize = [18,19,20,21,22]\n",
    "#     ru = 0.5 #np.random.uniform(.1, .9)\n",
    "#     uv = [ru, 1-ru]\n",
    "#     lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "#     highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "#     nm = np.random.choice([2,3,4])\n",
    "#     ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "#     tmp_string = \"tmp\"\n",
    "#     params = {'sr': sr,\n",
    "#           'batch_size': batch_size,\n",
    "#           'feature': feature,\n",
    "#           'n_classes': 2,\n",
    "#           'sec': sec,\n",
    "#           'filter_scale': filter_scale,\n",
    "#           'fmin' : fmin,\n",
    "#           'n_bins': int(n_bins),\n",
    "#           'tofile': tmp_string,\n",
    "#           'shuffle': True,\n",
    "#           'beta_param': beta_param,\n",
    "#           'data_dir': asv2019,\n",
    "#           'lowpass': lowpass,\n",
    "#           'highpass': highpass,\n",
    "#           #          'ranfilter' : [10,11,12,13,14,15]\n",
    "#           'ranfilter2' : ranfilter2 \n",
    "#           #           'dropblock' : [30, 100]\n",
    "#           #'device' : device\n",
    "#     }\n",
    "#     params_no_shuffle = {'sr': sr,\n",
    "#                      'batch_size': batch_size,\n",
    "#                      'feature': feature,\n",
    "#                      'n_classes': 2,\n",
    "#                      'sec': sec,\n",
    "#                      'filter_scale': filter_scale,\n",
    "#                      'fmin' : fmin,\n",
    "#                      'n_bins': int(n_bins),\n",
    "#                      'tofile': tmp_string,\n",
    "#                      'shuffle': False,\n",
    "#                     'data_dir': asv2019\n",
    "#                      #'device': device\n",
    "#     }\n",
    "#     training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "#     validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "#     eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "#     input_shape = training_generator.get_input_shape()\n",
    "#     model = get_ResMax(input_shape)\n",
    "# #    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "#     EPOCHS = epoch\n",
    "#     lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "#     class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "#     history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "#                               epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "#     eer_val = evalEER(validation_generator, model)\n",
    "#     eer_eval = evalEER(eval_generator, model)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "#     savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "#     savefnm = 'saved_models/' + savefnm\n",
    "#     model.save(savefnm)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "#     fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "#     fnm = 'saved_results/' + fnm\n",
    "#     sc1 = model.predict(eval_generator)\n",
    "#     np.save(fnm, sc1)\n",
    "#     params_save = params\n",
    "#     params_save['model'] = mname\n",
    "#     params_save['human_weight'] = str(human_weight)\n",
    "#     params_save['dropout_rate'] = str(dropout_rate)\n",
    "#     params_save['eer_val'] = str(eer_val)[:6]\n",
    "#     params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "#     params_save['saved_model'] = savefnm\n",
    "#     tnow = datetime.datetime.now()\n",
    "#     params_save['tnow'] = str(tnow)\n",
    "#     print(params_save)\n",
    "#     fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "#     with open(fnm, 'wb') as f:\n",
    "#         pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "# ### HP + RP\n",
    "\n",
    "# for i in range(3) :\n",
    "#     sr = 16000\n",
    "#     sec = 9.0\n",
    "#     batch_size = 16\n",
    "#     feature = \"cqt\"\n",
    "#     #hop_length = 128\n",
    "#     #win_length = 512\n",
    "#     #n_bins = 80\n",
    "#     filter_scale = 1\n",
    "#     n_bins = 100\n",
    "#     fmin = 5\n",
    "#     epoch = 70\n",
    "#     beta_param = 0.7\n",
    "#     dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "#     human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "#     win_size = np.random.choice([10,15,20])\n",
    "#     if win_size == 10 :\n",
    "#         lpsize = [8,9,10,11,12]\n",
    "#         hpsize = [88,89,90,91,92]\n",
    "#         ransize = [8,9,10,11,12]\n",
    "#     elif win_size == 15 :\n",
    "#         lpsize = [13,14,15,16,17]\n",
    "#         hpsize = [83,84,85,86,87]\n",
    "#         ransize = [13,14,15,16,17]\n",
    "#     else :\n",
    "#         lpsize = [18,19,20,21,22]\n",
    "#         hpsize = [78,79,80,81,82]\n",
    "#         ransize = [18,19,20,21,22]\n",
    "#     ru = 0.5 # np.random.uniform(.1, .9)\n",
    "#     uv = [ru, 1-ru]\n",
    "#     lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "#     highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "#     nm = np.random.choice([2,3,4])\n",
    "#     ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "#     tmp_string = \"tmp\"\n",
    "#     params = {'sr': sr,\n",
    "#           'batch_size': batch_size,\n",
    "#           'feature': feature,\n",
    "#           'n_classes': 2,\n",
    "#           'sec': sec,\n",
    "#           'filter_scale': filter_scale,\n",
    "#           'fmin' : fmin,\n",
    "#           'n_bins': int(n_bins),\n",
    "#           'tofile': tmp_string,\n",
    "#           'shuffle': True,\n",
    "#           'beta_param': beta_param,\n",
    "#           'data_dir': asv2019,\n",
    "#           'lowpass': lowpass,\n",
    "#           'highpass': highpass,\n",
    "#           #          'ranfilter' : [10,11,12,13,14,15]\n",
    "#           'ranfilter2' : ranfilter2 \n",
    "#           #           'dropblock' : [30, 100]\n",
    "#           #'device' : device\n",
    "#     }\n",
    "#     params_no_shuffle = {'sr': sr,\n",
    "#                      'batch_size': batch_size,\n",
    "#                      'feature': feature,\n",
    "#                      'n_classes': 2,\n",
    "#                      'sec': sec,\n",
    "#                      'filter_scale': filter_scale,\n",
    "#                      'fmin' : fmin,\n",
    "#                      'n_bins': int(n_bins),\n",
    "#                      'tofile': tmp_string,\n",
    "#                      'shuffle': False,\n",
    "#                     'data_dir': asv2019\n",
    "#                      #'device': device\n",
    "#     }\n",
    "#     training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "#     validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "#     eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "#     input_shape = training_generator.get_input_shape()\n",
    "#     model = get_ResMax(input_shape)\n",
    "# #    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "#     EPOCHS = epoch\n",
    "#     lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "#     class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "#     history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "#                               epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "#     eer_val = evalEER(validation_generator, model)\n",
    "#     eer_eval = evalEER(eval_generator, model)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "#     savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "#     savefnm = 'saved_models/' + savefnm\n",
    "#     model.save(savefnm)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "#     fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "#     fnm = 'saved_results/' + fnm\n",
    "#     sc1 = model.predict(eval_generator)\n",
    "#     np.save(fnm, sc1)\n",
    "#     params_save = params\n",
    "#     params_save['model'] = mname\n",
    "#     params_save['human_weight'] = str(human_weight)\n",
    "#     params_save['dropout_rate'] = str(dropout_rate)\n",
    "#     params_save['eer_val'] = str(eer_val)[:6]\n",
    "#     params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "#     params_save['saved_model'] = savefnm\n",
    "#     tnow = datetime.datetime.now()\n",
    "#     params_save['tnow'] = str(tnow)\n",
    "#     print(params_save)\n",
    "#     fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "#     with open(fnm, 'wb') as f:\n",
    "#         pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# ### HP + LP\n",
    "# for i in range(3) :\n",
    "#     sr = 16000\n",
    "#     sec = 9.0\n",
    "#     batch_size = 16\n",
    "#     feature = \"cqt\"\n",
    "#     #hop_length = 128\n",
    "#     #win_length = 512\n",
    "#     #n_bins = 80\n",
    "#     filter_scale = 1\n",
    "#     n_bins = 100\n",
    "#     fmin = 5\n",
    "#     epoch = 70\n",
    "#     beta_param = 0.7\n",
    "#     dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "#     human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "#     win_size = np.random.choice([10,15,20])\n",
    "#     if win_size == 10 :\n",
    "#         lpsize = [8,9,10,11,12]\n",
    "#         hpsize = [88,89,90,91,92]\n",
    "#         ransize = [8,9,10,11,12]\n",
    "#     elif win_size == 15 :\n",
    "#         lpsize = [13,14,15,16,17]\n",
    "#         hpsize = [83,84,85,86,87]\n",
    "#         ransize = [13,14,15,16,17]\n",
    "#     else :\n",
    "#         lpsize = [18,19,20,21,22]\n",
    "#         hpsize = [78,79,80,81,82]\n",
    "#         ransize = [18,19,20,21,22]\n",
    "#     ru = 0.5#np.random.uniform(.1, .9)\n",
    "#     uv = [ru, 1-ru]\n",
    "#     lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "#     highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "#     nm = np.random.choice([2,3,4])\n",
    "#     ranfilter2 = False #[2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "#     tmp_string = \"tmp\"\n",
    "#     params = {'sr': sr,\n",
    "#           'batch_size': batch_size,\n",
    "#           'feature': feature,\n",
    "#           'n_classes': 2,\n",
    "#           'sec': sec,\n",
    "#           'filter_scale': filter_scale,\n",
    "#           'fmin' : fmin,\n",
    "#           'n_bins': int(n_bins),\n",
    "#           'tofile': tmp_string,\n",
    "#           'shuffle': True,\n",
    "#           'beta_param': beta_param,\n",
    "#           'data_dir': asv2019,\n",
    "#           'lowpass': lowpass,\n",
    "#           'highpass': highpass,\n",
    "#           #          'ranfilter' : [10,11,12,13,14,15]\n",
    "#           'ranfilter2' : ranfilter2 \n",
    "#           #           'dropblock' : [30, 100]\n",
    "#           #'device' : device\n",
    "#     }\n",
    "#     params_no_shuffle = {'sr': sr,\n",
    "#                      'batch_size': batch_size,\n",
    "#                      'feature': feature,\n",
    "#                      'n_classes': 2,\n",
    "#                      'sec': sec,\n",
    "#                      'filter_scale': filter_scale,\n",
    "#                      'fmin' : fmin,\n",
    "#                      'n_bins': int(n_bins),\n",
    "#                      'tofile': tmp_string,\n",
    "#                      'shuffle': False,\n",
    "#                     'data_dir': asv2019\n",
    "#                      #'device': device\n",
    "#     }\n",
    "#     training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "#     validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "#     eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "#     input_shape = training_generator.get_input_shape()\n",
    "#     model = get_ResMax(input_shape)\n",
    "# #    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "#     EPOCHS = epoch\n",
    "#     lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "#     class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "#     history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "#                               epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "#     eer_val = evalEER(validation_generator, model)\n",
    "#     eer_eval = evalEER(eval_generator, model)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "#     savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "#     savefnm = 'saved_models/' + savefnm\n",
    "#     model.save(savefnm)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "#     fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "#     fnm = 'saved_results/' + fnm\n",
    "#     sc1 = model.predict(eval_generator)\n",
    "#     np.save(fnm, sc1)\n",
    "#     params_save = params\n",
    "#     params_save['model'] = mname\n",
    "#     params_save['human_weight'] = str(human_weight)\n",
    "#     params_save['dropout_rate'] = str(dropout_rate)\n",
    "#     params_save['eer_val'] = str(eer_val)[:6]\n",
    "#     params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "#     params_save['saved_model'] = savefnm\n",
    "#     tnow = datetime.datetime.now()\n",
    "#     params_save['tnow'] = str(tnow)\n",
    "#     print(params_save)\n",
    "#     fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "#     with open(fnm, 'wb') as f:\n",
    "#         pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# ### HP + LP + RP\n",
    "# for i in range(3) :\n",
    "#     sr = 16000\n",
    "#     sec = 9.0\n",
    "#     batch_size = 16\n",
    "#     feature = \"cqt\"\n",
    "#     #hop_length = 128\n",
    "#     #win_length = 512\n",
    "#     #n_bins = 80\n",
    "#     filter_scale = 1\n",
    "#     n_bins = 100\n",
    "#     fmin = 5\n",
    "#     epoch = 70\n",
    "#     beta_param = 0.7\n",
    "#     dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "#     human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "#     win_size = np.random.choice([10,15,20])\n",
    "#     if win_size == 10 :\n",
    "#         lpsize = [8,9,10,11,12]\n",
    "#         hpsize = [88,89,90,91,92]\n",
    "#         ransize = [8,9,10,11,12]\n",
    "#     elif win_size == 15 :\n",
    "#         lpsize = [13,14,15,16,17]\n",
    "#         hpsize = [83,84,85,86,87]\n",
    "#         ransize = [13,14,15,16,17]\n",
    "#     else :\n",
    "#         lpsize = [18,19,20,21,22]\n",
    "#         hpsize = [78,79,80,81,82]\n",
    "#         ransize = [18,19,20,21,22]\n",
    "#     ru = 0.5 #np.random.uniform(.1, .9)\n",
    "#     uv = [ru, 1-ru]\n",
    "#     lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "#     highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "#     nm = np.random.choice([2,3,4])\n",
    "#     ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "#     tmp_string = \"tmp\"\n",
    "#     params = {'sr': sr,\n",
    "#           'batch_size': batch_size,\n",
    "#           'feature': feature,\n",
    "#           'n_classes': 2,\n",
    "#           'sec': sec,\n",
    "#           'filter_scale': filter_scale,\n",
    "#           'fmin' : fmin,\n",
    "#           'n_bins': int(n_bins),\n",
    "#           'tofile': tmp_string,\n",
    "#           'shuffle': True,\n",
    "#           'beta_param': beta_param,\n",
    "#           'data_dir': asv2019,\n",
    "#           'lowpass': lowpass,\n",
    "#           'highpass': highpass,\n",
    "#           #          'ranfilter' : [10,11,12,13,14,15]\n",
    "#           'ranfilter2' : ranfilter2 \n",
    "#           #           'dropblock' : [30, 100]\n",
    "#           #'device' : device\n",
    "#     }\n",
    "#     params_no_shuffle = {'sr': sr,\n",
    "#                      'batch_size': batch_size,\n",
    "#                      'feature': feature,\n",
    "#                      'n_classes': 2,\n",
    "#                      'sec': sec,\n",
    "#                      'filter_scale': filter_scale,\n",
    "#                      'fmin' : fmin,\n",
    "#                      'n_bins': int(n_bins),\n",
    "#                      'tofile': tmp_string,\n",
    "#                      'shuffle': False,\n",
    "#                     'data_dir': asv2019\n",
    "#                      #'device': device\n",
    "#     }\n",
    "#     training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "#     validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "#     eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "#     input_shape = training_generator.get_input_shape()\n",
    "#     model = get_ResMax(input_shape)\n",
    "# #    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "#     EPOCHS = epoch\n",
    "#     lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "#     class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "#     history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "#                               epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "#     eer_val = evalEER(validation_generator, model)\n",
    "#     eer_eval = evalEER(eval_generator, model)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "#     savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "#     savefnm = 'saved_models/' + savefnm\n",
    "#     model.save(savefnm)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "#     fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "#     fnm = 'saved_results/' + fnm\n",
    "#     sc1 = model.predict(eval_generator)\n",
    "#     np.save(fnm, sc1)\n",
    "#     params_save = params\n",
    "#     params_save['model'] = mname\n",
    "#     params_save['human_weight'] = str(human_weight)\n",
    "#     params_save['dropout_rate'] = str(dropout_rate)\n",
    "#     params_save['eer_val'] = str(eer_val)[:6]\n",
    "#     params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "#     params_save['saved_model'] = savefnm\n",
    "#     tnow = datetime.datetime.now()\n",
    "#     params_save['tnow'] = str(tnow)\n",
    "#     print(params_save)\n",
    "#     fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "#     with open(fnm, 'wb') as f:\n",
    "#         pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ################################\n",
    "# mname = \"LCNN_LA_\"\n",
    "# ################################\n",
    "\n",
    "# ## None\n",
    "# for i in range(3) :\n",
    "#     sr = 16000\n",
    "#     sec = 9.0\n",
    "#     batch_size = 16\n",
    "#     feature = \"cqt\"\n",
    "#     #hop_length = 128\n",
    "#     #win_length = 512\n",
    "#     #n_bins = 80\n",
    "#     filter_scale = 1\n",
    "#     n_bins = 100\n",
    "#     fmin = 5\n",
    "#     epoch = 70\n",
    "#     beta_param = False\n",
    "#     dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "#     human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "#     win_size = np.random.choice([10,15,20])\n",
    "#     if win_size == 10 :\n",
    "#         lpsize = [8,9,10,11,12]\n",
    "#         hpsize = [88,89,90,91,92]\n",
    "#         ransize = [8,9,10,11,12]\n",
    "#     elif win_size == 15 :\n",
    "#         lpsize = [13,14,15,16,17]\n",
    "#         hpsize = [83,84,85,86,87]\n",
    "#         ransize = [13,14,15,16,17]\n",
    "#     else :\n",
    "#         lpsize = [18,19,20,21,22]\n",
    "#         hpsize = [78,79,80,81,82]\n",
    "#         ransize = [18,19,20,21,22]\n",
    "#     ru = 0.5#np.random.uniform(.1, .9)\n",
    "#     uv = [ru, 1-ru]\n",
    "#     lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "#     highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "#     nm = np.random.choice([2,3,4])\n",
    "#     ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "#     tmp_string = \"tmp\"\n",
    "#     params = {'sr': sr,\n",
    "#           'batch_size': batch_size,\n",
    "#           'feature': feature,\n",
    "#           'n_classes': 2,\n",
    "#           'sec': sec,\n",
    "#           'filter_scale': filter_scale,\n",
    "#           'fmin' : fmin,\n",
    "#           'n_bins': int(n_bins),\n",
    "#           'tofile': tmp_string,\n",
    "#           'shuffle': True,\n",
    "#           'beta_param': beta_param,\n",
    "#           'data_dir': asv2019,\n",
    "#           'lowpass': lowpass,\n",
    "#           'highpass': highpass,\n",
    "#           #          'ranfilter' : [10,11,12,13,14,15]\n",
    "#           'ranfilter2' : ranfilter2 \n",
    "#           #           'dropblock' : [30, 100]\n",
    "#           #'device' : device\n",
    "#     }\n",
    "#     params_no_shuffle = {'sr': sr,\n",
    "#                      'batch_size': batch_size,\n",
    "#                      'feature': feature,\n",
    "#                      'n_classes': 2,\n",
    "#                      'sec': sec,\n",
    "#                      'filter_scale': filter_scale,\n",
    "#                      'fmin' : fmin,\n",
    "#                      'n_bins': int(n_bins),\n",
    "#                      'tofile': tmp_string,\n",
    "#                      'shuffle': False,\n",
    "#                     'data_dir': asv2019\n",
    "#                      #'device': device\n",
    "#     }\n",
    "#     training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "#     validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "#     eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "#     input_shape = training_generator.get_input_shape()\n",
    "#     model = get_LCNN(input_shape)\n",
    "# #    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "#     EPOCHS = epoch\n",
    "#     lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "#     class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "#     history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "#                               epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "#     eer_val = evalEER(validation_generator, model)\n",
    "#     eer_eval = evalEER(eval_generator, model)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "#     savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "#     savefnm = 'saved_models/' + savefnm\n",
    "#     model.save(savefnm)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "#     fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "#     fnm = 'saved_results/' + fnm\n",
    "#     sc1 = model.predict(eval_generator)\n",
    "#     np.save(fnm, sc1)\n",
    "#     params_save = params\n",
    "#     params_save['model'] = mname\n",
    "#     params_save['human_weight'] = str(human_weight)\n",
    "#     params_save['dropout_rate'] = str(dropout_rate)\n",
    "#     params_save['eer_val'] = str(eer_val)[:6]\n",
    "#     params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "#     params_save['saved_model'] = savefnm\n",
    "#     tnow = datetime.datetime.now()\n",
    "#     params_save['tnow'] = str(tnow)\n",
    "#     print(params_save)\n",
    "#     fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "#     with open(fnm, 'wb') as f:\n",
    "#         pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# ### Mixup\n",
    "# for i in range(3) :\n",
    "#     sr = 16000\n",
    "#     sec = 9.0\n",
    "#     batch_size = 16\n",
    "#     feature = \"cqt\"\n",
    "#     #hop_length = 128\n",
    "#     #win_length = 512\n",
    "#     #n_bins = 80\n",
    "#     filter_scale = 1\n",
    "#     n_bins = 100\n",
    "#     fmin = 5\n",
    "#     epoch = 70\n",
    "#     beta_param = 0.7\n",
    "#     dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "#     human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "#     win_size = np.random.choice([10,15,20])\n",
    "#     if win_size == 10 :\n",
    "#         lpsize = [8,9,10,11,12]\n",
    "#         hpsize = [88,89,90,91,92]\n",
    "#         ransize = [8,9,10,11,12]\n",
    "#     elif win_size == 15 :\n",
    "#         lpsize = [13,14,15,16,17]\n",
    "#         hpsize = [83,84,85,86,87]\n",
    "#         ransize = [13,14,15,16,17]\n",
    "#     else :\n",
    "#         lpsize = [18,19,20,21,22]\n",
    "#         hpsize = [78,79,80,81,82]\n",
    "#         ransize = [18,19,20,21,22]\n",
    "#     ru = 0.5#np.random.uniform(.1, .9)\n",
    "#     uv = [ru, 1-ru]\n",
    "#     lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "#     highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "#     nm = np.random.choice([2,3,4])\n",
    "#     ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "#     tmp_string = \"tmp\"\n",
    "#     params = {'sr': sr,\n",
    "#           'batch_size': batch_size,\n",
    "#           'feature': feature,\n",
    "#           'n_classes': 2,\n",
    "#           'sec': sec,\n",
    "#           'filter_scale': filter_scale,\n",
    "#           'fmin' : fmin,\n",
    "#           'n_bins': int(n_bins),\n",
    "#           'tofile': tmp_string,\n",
    "#           'shuffle': True,\n",
    "#           'beta_param': beta_param,\n",
    "#           'data_dir': asv2019,\n",
    "#           'lowpass': lowpass,\n",
    "#           'highpass': highpass,\n",
    "#           #          'ranfilter' : [10,11,12,13,14,15]\n",
    "#           'ranfilter2' : ranfilter2 \n",
    "#           #           'dropblock' : [30, 100]\n",
    "#           #'device' : device\n",
    "#     }\n",
    "#     params_no_shuffle = {'sr': sr,\n",
    "#                      'batch_size': batch_size,\n",
    "#                      'feature': feature,\n",
    "#                      'n_classes': 2,\n",
    "#                      'sec': sec,\n",
    "#                      'filter_scale': filter_scale,\n",
    "#                      'fmin' : fmin,\n",
    "#                      'n_bins': int(n_bins),\n",
    "#                      'tofile': tmp_string,\n",
    "#                      'shuffle': False,\n",
    "#                     'data_dir': asv2019\n",
    "#                      #'device': device\n",
    "#     }\n",
    "#     training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "#     validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "#     eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "#     input_shape = training_generator.get_input_shape()\n",
    "#     model = get_LCNN(input_shape)\n",
    "# #    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "#     EPOCHS = epoch\n",
    "#     lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "#     class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "#     history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "#                               epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "#     eer_val = evalEER(validation_generator, model)\n",
    "#     eer_eval = evalEER(eval_generator, model)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "#     savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "#     savefnm = 'saved_models/' + savefnm\n",
    "#     model.save(savefnm)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "#     fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "#     fnm = 'saved_results/' + fnm\n",
    "#     sc1 = model.predict(eval_generator)\n",
    "#     np.save(fnm, sc1)\n",
    "#     params_save = params\n",
    "#     params_save['model'] = mname\n",
    "#     params_save['human_weight'] = str(human_weight)\n",
    "#     params_save['dropout_rate'] = str(dropout_rate)\n",
    "#     params_save['eer_val'] = str(eer_val)[:6]\n",
    "#     params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "#     params_save['saved_model'] = savefnm\n",
    "#     tnow = datetime.datetime.now()\n",
    "#     params_save['tnow'] = str(tnow)\n",
    "#     print(params_save)\n",
    "#     fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "#     with open(fnm, 'wb') as f:\n",
    "#         pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "\n",
    "# ### LP         \n",
    "# for i in range(3) :\n",
    "#     sr = 16000\n",
    "#     sec = 9.0\n",
    "#     batch_size = 16\n",
    "#     feature = \"cqt\"\n",
    "#     #hop_length = 128\n",
    "#     #win_length = 512\n",
    "#     #n_bins = 80\n",
    "#     filter_scale = 1\n",
    "#     n_bins = 100\n",
    "#     fmin = 5\n",
    "#     epoch = 70\n",
    "#     beta_param = 0.7\n",
    "#     dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "#     human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "#     win_size = np.random.choice([10,15,20])\n",
    "#     if win_size == 10 :\n",
    "#         lpsize = [8,9,10,11,12]\n",
    "#         hpsize = [88,89,90,91,92]\n",
    "#         ransize = [8,9,10,11,12]\n",
    "#     elif win_size == 15 :\n",
    "#         lpsize = [13,14,15,16,17]\n",
    "#         hpsize = [83,84,85,86,87]\n",
    "#         ransize = [13,14,15,16,17]\n",
    "#     else :\n",
    "#         lpsize = [18,19,20,21,22]\n",
    "#         hpsize = [78,79,80,81,82]\n",
    "#         ransize = [18,19,20,21,22]\n",
    "#     ru = 0.5#np.random.uniform(.1, .9)\n",
    "#     uv = [ru, 1-ru]\n",
    "#     lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "#     highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "#     nm = np.random.choice([2,3,4])\n",
    "#     ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "#     tmp_string = \"tmp\"\n",
    "#     params = {'sr': sr,\n",
    "#           'batch_size': batch_size,\n",
    "#           'feature': feature,\n",
    "#           'n_classes': 2,\n",
    "#           'sec': sec,\n",
    "#           'filter_scale': filter_scale,\n",
    "#           'fmin' : fmin,\n",
    "#           'n_bins': int(n_bins),\n",
    "#           'tofile': tmp_string,\n",
    "#           'shuffle': True,\n",
    "#           'beta_param': beta_param,\n",
    "#           'data_dir': asv2019,\n",
    "#           'lowpass': lowpass,\n",
    "#           'highpass': highpass,\n",
    "#           #          'ranfilter' : [10,11,12,13,14,15]\n",
    "#           'ranfilter2' : ranfilter2 \n",
    "#           #           'dropblock' : [30, 100]\n",
    "#           #'device' : device\n",
    "#     }\n",
    "#     params_no_shuffle = {'sr': sr,\n",
    "#                      'batch_size': batch_size,\n",
    "#                      'feature': feature,\n",
    "#                      'n_classes': 2,\n",
    "#                      'sec': sec,\n",
    "#                      'filter_scale': filter_scale,\n",
    "#                      'fmin' : fmin,\n",
    "#                      'n_bins': int(n_bins),\n",
    "#                      'tofile': tmp_string,\n",
    "#                      'shuffle': False,\n",
    "#                     'data_dir': asv2019\n",
    "#                      #'device': device\n",
    "#     }\n",
    "#     training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "#     validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "#     eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "#     input_shape = training_generator.get_input_shape()\n",
    "#     model = get_LCNN(input_shape)\n",
    "# #    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "#     EPOCHS = epoch\n",
    "#     lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "#     class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "#     history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "#                               epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "#     eer_val = evalEER(validation_generator, model)\n",
    "#     eer_eval = evalEER(eval_generator, model)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "#     savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "#     savefnm = 'saved_models/' + savefnm\n",
    "#     model.save(savefnm)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "#     fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "#     fnm = 'saved_results/' + fnm\n",
    "#     sc1 = model.predict(eval_generator)\n",
    "#     np.save(fnm, sc1)\n",
    "#     params_save = params\n",
    "#     params_save['model'] = mname\n",
    "#     params_save['human_weight'] = str(human_weight)\n",
    "#     params_save['dropout_rate'] = str(dropout_rate)\n",
    "#     params_save['eer_val'] = str(eer_val)[:6]\n",
    "#     params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "#     params_save['saved_model'] = savefnm\n",
    "#     tnow = datetime.datetime.now()\n",
    "#     params_save['tnow'] = str(tnow)\n",
    "#     print(params_save)\n",
    "#     fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "#     with open(fnm, 'wb') as f:\n",
    "#         pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# ### HP         \n",
    "# for i in range(3) :\n",
    "#     sr = 16000\n",
    "#     sec = 9.0\n",
    "#     batch_size = 16\n",
    "#     feature = \"cqt\"\n",
    "#     #hop_length = 128\n",
    "#     #win_length = 512\n",
    "#     #n_bins = 80\n",
    "#     filter_scale = 1\n",
    "#     n_bins = 100\n",
    "#     fmin = 5\n",
    "#     epoch = 70\n",
    "#     beta_param = 0.7\n",
    "#     dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "#     human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "#     win_size = np.random.choice([10,15,20])\n",
    "#     if win_size == 10 :\n",
    "#         lpsize = [8,9,10,11,12]\n",
    "#         hpsize = [88,89,90,91,92]\n",
    "#         ransize = [8,9,10,11,12]\n",
    "#     elif win_size == 15 :\n",
    "#         lpsize = [13,14,15,16,17]\n",
    "#         hpsize = [83,84,85,86,87]\n",
    "#         ransize = [13,14,15,16,17]\n",
    "#     else :\n",
    "#         lpsize = [18,19,20,21,22]\n",
    "#         hpsize = [78,79,80,81,82]\n",
    "#         ransize = [18,19,20,21,22]\n",
    "#     ru = 0.5#np.random.uniform(.1, .9)\n",
    "#     uv = [ru, 1-ru]\n",
    "#     lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "#     highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "#     nm = np.random.choice([2,3,4])\n",
    "#     ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "#     tmp_string = \"tmp\"\n",
    "#     params = {'sr': sr,\n",
    "#           'batch_size': batch_size,\n",
    "#           'feature': feature,\n",
    "#           'n_classes': 2,\n",
    "#           'sec': sec,\n",
    "#           'filter_scale': filter_scale,\n",
    "#           'fmin' : fmin,\n",
    "#           'n_bins': int(n_bins),\n",
    "#           'tofile': tmp_string,\n",
    "#           'shuffle': True,\n",
    "#           'beta_param': beta_param,\n",
    "#           'data_dir': asv2019,\n",
    "#           'lowpass': lowpass,\n",
    "#           'highpass': highpass,\n",
    "#           #          'ranfilter' : [10,11,12,13,14,15]\n",
    "#           'ranfilter2' : ranfilter2 \n",
    "#           #           'dropblock' : [30, 100]\n",
    "#           #'device' : device\n",
    "#     }\n",
    "#     params_no_shuffle = {'sr': sr,\n",
    "#                      'batch_size': batch_size,\n",
    "#                      'feature': feature,\n",
    "#                      'n_classes': 2,\n",
    "#                      'sec': sec,\n",
    "#                      'filter_scale': filter_scale,\n",
    "#                      'fmin' : fmin,\n",
    "#                      'n_bins': int(n_bins),\n",
    "#                      'tofile': tmp_string,\n",
    "#                      'shuffle': False,\n",
    "#                     'data_dir': asv2019\n",
    "#                      #'device': device\n",
    "#     }\n",
    "#     training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "#     validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "#     eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "#     input_shape = training_generator.get_input_shape()\n",
    "#     model = get_LCNN(input_shape)\n",
    "# #    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "#     EPOCHS = epoch\n",
    "#     lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "#     class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "#     history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "#                               epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "#     eer_val = evalEER(validation_generator, model)\n",
    "#     eer_eval = evalEER(eval_generator, model)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "#     savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "#     savefnm = 'saved_models/' + savefnm\n",
    "#     model.save(savefnm)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "#     fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "#     fnm = 'saved_results/' + fnm\n",
    "#     sc1 = model.predict(eval_generator)\n",
    "#     np.save(fnm, sc1)\n",
    "#     params_save = params\n",
    "#     params_save['model'] = mname\n",
    "#     params_save['human_weight'] = str(human_weight)\n",
    "#     params_save['dropout_rate'] = str(dropout_rate)\n",
    "#     params_save['eer_val'] = str(eer_val)[:6]\n",
    "#     params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "#     params_save['saved_model'] = savefnm\n",
    "#     tnow = datetime.datetime.now()\n",
    "#     params_save['tnow'] = str(tnow)\n",
    "#     print(params_save)\n",
    "#     fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "#     with open(fnm, 'wb') as f:\n",
    "#         pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# ### RP\n",
    "# for i in range(3) :\n",
    "#     sr = 16000\n",
    "#     sec = 9.0\n",
    "#     batch_size = 16\n",
    "#     feature = \"cqt\"\n",
    "#     #hop_length = 128\n",
    "#     #win_length = 512\n",
    "#     #n_bins = 80\n",
    "#     filter_scale = 1\n",
    "#     n_bins = 100\n",
    "#     fmin = 5\n",
    "#     epoch = 70\n",
    "#     beta_param = 0.7\n",
    "#     dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "#     human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "#     win_size = np.random.choice([10,15,20])\n",
    "#     if win_size == 10 :\n",
    "#         lpsize = [8,9,10,11,12]\n",
    "#         hpsize = [88,89,90,91,92]\n",
    "#         ransize = [8,9,10,11,12]\n",
    "#     elif win_size == 15 :\n",
    "#         lpsize = [13,14,15,16,17]\n",
    "#         hpsize = [83,84,85,86,87]\n",
    "#         ransize = [13,14,15,16,17]\n",
    "#     else :\n",
    "#         lpsize = [18,19,20,21,22]\n",
    "#         hpsize = [78,79,80,81,82]\n",
    "#         ransize = [18,19,20,21,22]\n",
    "#     ru = np.random.uniform(.1, .9)\n",
    "#     uv = [ru, 1-ru]\n",
    "#     lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "#     highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "#     nm = np.random.choice([2,3,4])\n",
    "#     ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "#     tmp_string = \"tmp\"\n",
    "#     params = {'sr': sr,\n",
    "#           'batch_size': batch_size,\n",
    "#           'feature': feature,\n",
    "#           'n_classes': 2,\n",
    "#           'sec': sec,\n",
    "#           'filter_scale': filter_scale,\n",
    "#           'fmin' : fmin,\n",
    "#           'n_bins': int(n_bins),\n",
    "#           'tofile': tmp_string,\n",
    "#           'shuffle': True,\n",
    "#           'beta_param': beta_param,\n",
    "#           'data_dir': asv2019,\n",
    "#           'lowpass': lowpass,\n",
    "#           'highpass': highpass,\n",
    "#           #          'ranfilter' : [10,11,12,13,14,15]\n",
    "#           'ranfilter2' : ranfilter2 \n",
    "#           #           'dropblock' : [30, 100]\n",
    "#           #'device' : device\n",
    "#     }\n",
    "#     params_no_shuffle = {'sr': sr,\n",
    "#                      'batch_size': batch_size,\n",
    "#                      'feature': feature,\n",
    "#                      'n_classes': 2,\n",
    "#                      'sec': sec,\n",
    "#                      'filter_scale': filter_scale,\n",
    "#                      'fmin' : fmin,\n",
    "#                      'n_bins': int(n_bins),\n",
    "#                      'tofile': tmp_string,\n",
    "#                      'shuffle': False,\n",
    "#                     'data_dir': asv2019\n",
    "#                      #'device': device\n",
    "#     }\n",
    "#     training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "#     validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "#     eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "#     input_shape = training_generator.get_input_shape()\n",
    "#     model = get_LCNN(input_shape)\n",
    "# #    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "#     EPOCHS = epoch\n",
    "#     lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "#     class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "#     history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "#                               epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "#     eer_val = evalEER(validation_generator, model)\n",
    "#     eer_eval = evalEER(eval_generator, model)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "#     savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "#     savefnm = 'saved_models/' + savefnm\n",
    "#     model.save(savefnm)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "#     fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "#     fnm = 'saved_results/' + fnm\n",
    "#     sc1 = model.predict(eval_generator)\n",
    "#     np.save(fnm, sc1)\n",
    "#     params_save = params\n",
    "#     params_save['model'] = mname\n",
    "#     params_save['human_weight'] = str(human_weight)\n",
    "#     params_save['dropout_rate'] = str(dropout_rate)\n",
    "#     params_save['eer_val'] = str(eer_val)[:6]\n",
    "#     params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "#     params_save['saved_model'] = savefnm\n",
    "#     tnow = datetime.datetime.now()\n",
    "#     params_save['tnow'] = str(tnow)\n",
    "#     print(params_save)\n",
    "#     fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "#     with open(fnm, 'wb') as f:\n",
    "#         pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "# ### LP + RP\n",
    "# for i in range(3) :\n",
    "#     sr = 16000\n",
    "#     sec = 9.0\n",
    "#     batch_size = 16\n",
    "#     feature = \"cqt\"\n",
    "#     #hop_length = 128\n",
    "#     #win_length = 512\n",
    "#     #n_bins = 80\n",
    "#     filter_scale = 1\n",
    "#     n_bins = 100\n",
    "#     fmin = 5\n",
    "#     epoch = 70\n",
    "#     beta_param = 0.7\n",
    "#     dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "#     human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "#     win_size = np.random.choice([10,15,20])\n",
    "#     if win_size == 10 :\n",
    "#         lpsize = [8,9,10,11,12]\n",
    "#         hpsize = [88,89,90,91,92]\n",
    "#         ransize = [8,9,10,11,12]\n",
    "#     elif win_size == 15 :\n",
    "#         lpsize = [13,14,15,16,17]\n",
    "#         hpsize = [83,84,85,86,87]\n",
    "#         ransize = [13,14,15,16,17]\n",
    "#     else :\n",
    "#         lpsize = [18,19,20,21,22]\n",
    "#         hpsize = [78,79,80,81,82]\n",
    "#         ransize = [18,19,20,21,22]\n",
    "#     ru = 0.5 #np.random.uniform(.1, .9)\n",
    "#     uv = [ru, 1-ru]\n",
    "#     lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "#     highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "#     nm = np.random.choice([2,3,4])\n",
    "#     ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "#     tmp_string = \"tmp\"\n",
    "#     params = {'sr': sr,\n",
    "#           'batch_size': batch_size,\n",
    "#           'feature': feature,\n",
    "#           'n_classes': 2,\n",
    "#           'sec': sec,\n",
    "#           'filter_scale': filter_scale,\n",
    "#           'fmin' : fmin,\n",
    "#           'n_bins': int(n_bins),\n",
    "#           'tofile': tmp_string,\n",
    "#           'shuffle': True,\n",
    "#           'beta_param': beta_param,\n",
    "#           'data_dir': asv2019,\n",
    "#           'lowpass': lowpass,\n",
    "#           'highpass': highpass,\n",
    "#           #          'ranfilter' : [10,11,12,13,14,15]\n",
    "#           'ranfilter2' : ranfilter2 \n",
    "#           #           'dropblock' : [30, 100]\n",
    "#           #'device' : device\n",
    "#     }\n",
    "#     params_no_shuffle = {'sr': sr,\n",
    "#                      'batch_size': batch_size,\n",
    "#                      'feature': feature,\n",
    "#                      'n_classes': 2,\n",
    "#                      'sec': sec,\n",
    "#                      'filter_scale': filter_scale,\n",
    "#                      'fmin' : fmin,\n",
    "#                      'n_bins': int(n_bins),\n",
    "#                      'tofile': tmp_string,\n",
    "#                      'shuffle': False,\n",
    "#                     'data_dir': asv2019\n",
    "#                      #'device': device\n",
    "#     }\n",
    "#     training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "#     validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "#     eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "#     input_shape = training_generator.get_input_shape()\n",
    "#     model = get_LCNN(input_shape)\n",
    "# #    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "#     EPOCHS = epoch\n",
    "#     lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "#     class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "#     history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "#                               epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "#     eer_val = evalEER(validation_generator, model)\n",
    "#     eer_eval = evalEER(eval_generator, model)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "#     savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "#     savefnm = 'saved_models/' + savefnm\n",
    "#     model.save(savefnm)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "#     fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "#     fnm = 'saved_results/' + fnm\n",
    "#     sc1 = model.predict(eval_generator)\n",
    "#     np.save(fnm, sc1)\n",
    "#     params_save = params\n",
    "#     params_save['model'] = mname\n",
    "#     params_save['human_weight'] = str(human_weight)\n",
    "#     params_save['dropout_rate'] = str(dropout_rate)\n",
    "#     params_save['eer_val'] = str(eer_val)[:6]\n",
    "#     params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "#     params_save['saved_model'] = savefnm\n",
    "#     tnow = datetime.datetime.now()\n",
    "#     params_save['tnow'] = str(tnow)\n",
    "#     print(params_save)\n",
    "#     fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "#     with open(fnm, 'wb') as f:\n",
    "#         pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# ### HP + RP\n",
    "# for i in range(3) :\n",
    "#     sr = 16000\n",
    "#     sec = 9.0\n",
    "#     batch_size = 16\n",
    "#     feature = \"cqt\"\n",
    "#     #hop_length = 128\n",
    "#     #win_length = 512\n",
    "#     #n_bins = 80\n",
    "#     filter_scale = 1\n",
    "#     n_bins = 100\n",
    "#     fmin = 5\n",
    "#     epoch = 70\n",
    "#     beta_param = 0.7\n",
    "#     dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "#     human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "#     win_size = np.random.choice([10,15,20])\n",
    "#     if win_size == 10 :\n",
    "#         lpsize = [8,9,10,11,12]\n",
    "#         hpsize = [88,89,90,91,92]\n",
    "#         ransize = [8,9,10,11,12]\n",
    "#     elif win_size == 15 :\n",
    "#         lpsize = [13,14,15,16,17]\n",
    "#         hpsize = [83,84,85,86,87]\n",
    "#         ransize = [13,14,15,16,17]\n",
    "#     else :\n",
    "#         lpsize = [18,19,20,21,22]\n",
    "#         hpsize = [78,79,80,81,82]\n",
    "#         ransize = [18,19,20,21,22]\n",
    "#     ru = 0.5 #np.random.uniform(.1, .9)\n",
    "#     uv = [ru, 1-ru]\n",
    "#     lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "#     highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "#     nm = np.random.choice([2,3,4])\n",
    "#     ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "#     tmp_string = \"tmp\"\n",
    "#     params = {'sr': sr,\n",
    "#           'batch_size': batch_size,\n",
    "#           'feature': feature,\n",
    "#           'n_classes': 2,\n",
    "#           'sec': sec,\n",
    "#           'filter_scale': filter_scale,\n",
    "#           'fmin' : fmin,\n",
    "#           'n_bins': int(n_bins),\n",
    "#           'tofile': tmp_string,\n",
    "#           'shuffle': True,\n",
    "#           'beta_param': beta_param,\n",
    "#           'data_dir': asv2019,\n",
    "#           'lowpass': lowpass,\n",
    "#           'highpass': highpass,\n",
    "#           #          'ranfilter' : [10,11,12,13,14,15]\n",
    "#           'ranfilter2' : ranfilter2 \n",
    "#           #           'dropblock' : [30, 100]\n",
    "#           #'device' : device\n",
    "#     }\n",
    "#     params_no_shuffle = {'sr': sr,\n",
    "#                      'batch_size': batch_size,\n",
    "#                      'feature': feature,\n",
    "#                      'n_classes': 2,\n",
    "#                      'sec': sec,\n",
    "#                      'filter_scale': filter_scale,\n",
    "#                      'fmin' : fmin,\n",
    "#                      'n_bins': int(n_bins),\n",
    "#                      'tofile': tmp_string,\n",
    "#                      'shuffle': False,\n",
    "#                     'data_dir': asv2019\n",
    "#                      #'device': device\n",
    "#     }\n",
    "#     training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "#     validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "#     eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "#     input_shape = training_generator.get_input_shape()\n",
    "#     model = get_LCNN(input_shape)\n",
    "# #    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "#     EPOCHS = epoch\n",
    "#     lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "#     class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "#     history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "#                               epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "#     eer_val = evalEER(validation_generator, model)\n",
    "#     eer_eval = evalEER(eval_generator, model)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "#     savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "#     savefnm = 'saved_models/' + savefnm\n",
    "#     model.save(savefnm)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "#     fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "#     fnm = 'saved_results/' + fnm\n",
    "#     sc1 = model.predict(eval_generator)\n",
    "#     np.save(fnm, sc1)\n",
    "#     params_save = params\n",
    "#     params_save['model'] = mname\n",
    "#     params_save['human_weight'] = str(human_weight)\n",
    "#     params_save['dropout_rate'] = str(dropout_rate)\n",
    "#     params_save['eer_val'] = str(eer_val)[:6]\n",
    "#     params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "#     params_save['saved_model'] = savefnm\n",
    "#     tnow = datetime.datetime.now()\n",
    "#     params_save['tnow'] = str(tnow)\n",
    "#     print(params_save)\n",
    "#     fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "#     with open(fnm, 'wb') as f:\n",
    "#         pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# ### HP + LP\n",
    "# for i in range(3) :\n",
    "#     sr = 16000\n",
    "#     sec = 9.0\n",
    "#     batch_size = 16\n",
    "#     feature = \"cqt\"\n",
    "#     #hop_length = 128\n",
    "#     #win_length = 512\n",
    "#     #n_bins = 80\n",
    "#     filter_scale = 1\n",
    "#     n_bins = 100\n",
    "#     fmin = 5\n",
    "#     epoch = 70\n",
    "#     beta_param = 0.7\n",
    "#     dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "#     human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "#     win_size = np.random.choice([10,15,20])\n",
    "#     if win_size == 10 :\n",
    "#         lpsize = [8,9,10,11,12]\n",
    "#         hpsize = [88,89,90,91,92]\n",
    "#         ransize = [8,9,10,11,12]\n",
    "#     elif win_size == 15 :\n",
    "#         lpsize = [13,14,15,16,17]\n",
    "#         hpsize = [83,84,85,86,87]\n",
    "#         ransize = [13,14,15,16,17]\n",
    "#     else :\n",
    "#         lpsize = [18,19,20,21,22]\n",
    "#         hpsize = [78,79,80,81,82]\n",
    "#         ransize = [18,19,20,21,22]\n",
    "#     ru = 0.5#np.random.uniform(.1, .9)\n",
    "#     uv = [ru, 1-ru]\n",
    "#     lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "#     highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "#     nm = np.random.choice([2,3,4])\n",
    "#     ranfilter2 = False #[2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "#     tmp_string = \"tmp\"\n",
    "#     params = {'sr': sr,\n",
    "#           'batch_size': batch_size,\n",
    "#           'feature': feature,\n",
    "#           'n_classes': 2,\n",
    "#           'sec': sec,\n",
    "#           'filter_scale': filter_scale,\n",
    "#           'fmin' : fmin,\n",
    "#           'n_bins': int(n_bins),\n",
    "#           'tofile': tmp_string,\n",
    "#           'shuffle': True,\n",
    "#           'beta_param': beta_param,\n",
    "#           'data_dir': asv2019,\n",
    "#           'lowpass': lowpass,\n",
    "#           'highpass': highpass,\n",
    "#           #          'ranfilter' : [10,11,12,13,14,15]\n",
    "#           'ranfilter2' : ranfilter2 \n",
    "#           #           'dropblock' : [30, 100]\n",
    "#           #'device' : device\n",
    "#     }\n",
    "#     params_no_shuffle = {'sr': sr,\n",
    "#                      'batch_size': batch_size,\n",
    "#                      'feature': feature,\n",
    "#                      'n_classes': 2,\n",
    "#                      'sec': sec,\n",
    "#                      'filter_scale': filter_scale,\n",
    "#                      'fmin' : fmin,\n",
    "#                      'n_bins': int(n_bins),\n",
    "#                      'tofile': tmp_string,\n",
    "#                      'shuffle': False,\n",
    "#                     'data_dir': asv2019\n",
    "#                      #'device': device\n",
    "#     }\n",
    "#     training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "#     validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "#     eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "#     input_shape = training_generator.get_input_shape()\n",
    "#     model = get_LCNN(input_shape)\n",
    "# #    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "#     EPOCHS = epoch\n",
    "#     lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "#     class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "#     history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "#                               epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "#     eer_val = evalEER(validation_generator, model)\n",
    "#     eer_eval = evalEER(eval_generator, model)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "#     savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "#     savefnm = 'saved_models/' + savefnm\n",
    "#     model.save(savefnm)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "#     fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "#     fnm = 'saved_results/' + fnm\n",
    "#     sc1 = model.predict(eval_generator)\n",
    "#     np.save(fnm, sc1)\n",
    "#     params_save = params\n",
    "#     params_save['model'] = mname\n",
    "#     params_save['human_weight'] = str(human_weight)\n",
    "#     params_save['dropout_rate'] = str(dropout_rate)\n",
    "#     params_save['eer_val'] = str(eer_val)[:6]\n",
    "#     params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "#     params_save['saved_model'] = savefnm\n",
    "#     tnow = datetime.datetime.now()\n",
    "#     params_save['tnow'] = str(tnow)\n",
    "#     print(params_save)\n",
    "#     fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "#     with open(fnm, 'wb') as f:\n",
    "#         pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# ### HP + LP + RP\n",
    "# for i in range(3) :\n",
    "#     sr = 16000\n",
    "#     sec = 9.0\n",
    "#     batch_size = 16\n",
    "#     feature = \"cqt\"\n",
    "#     #hop_length = 128\n",
    "#     #win_length = 512\n",
    "#     #n_bins = 80\n",
    "#     filter_scale = 1\n",
    "#     n_bins = 100\n",
    "#     fmin = 5\n",
    "#     epoch = 70\n",
    "#     beta_param = 0.7\n",
    "#     dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "#     human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "#     win_size = np.random.choice([10,15,20])\n",
    "#     if win_size == 10 :\n",
    "#         lpsize = [8,9,10,11,12]\n",
    "#         hpsize = [88,89,90,91,92]\n",
    "#         ransize = [8,9,10,11,12]\n",
    "#     elif win_size == 15 :\n",
    "#         lpsize = [13,14,15,16,17]\n",
    "#         hpsize = [83,84,85,86,87]\n",
    "#         ransize = [13,14,15,16,17]\n",
    "#     else :\n",
    "#         lpsize = [18,19,20,21,22]\n",
    "#         hpsize = [78,79,80,81,82]\n",
    "#         ransize = [18,19,20,21,22]\n",
    "#     ru = 0.5 #np.random.uniform(.1, .9)\n",
    "#     uv = [ru, 1-ru]\n",
    "#     lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "#     highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "#     nm = np.random.choice([2,3,4])\n",
    "#     ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "#     tmp_string = \"tmp\"\n",
    "#     params = {'sr': sr,\n",
    "#           'batch_size': batch_size,\n",
    "#           'feature': feature,\n",
    "#           'n_classes': 2,\n",
    "#           'sec': sec,\n",
    "#           'filter_scale': filter_scale,\n",
    "#           'fmin' : fmin,\n",
    "#           'n_bins': int(n_bins),\n",
    "#           'tofile': tmp_string,\n",
    "#           'shuffle': True,\n",
    "#           'beta_param': beta_param,\n",
    "#           'data_dir': asv2019,\n",
    "#           'lowpass': lowpass,\n",
    "#           'highpass': highpass,\n",
    "#           #          'ranfilter' : [10,11,12,13,14,15]\n",
    "#           'ranfilter2' : ranfilter2 \n",
    "#           #           'dropblock' : [30, 100]\n",
    "#           #'device' : device\n",
    "#     }\n",
    "#     params_no_shuffle = {'sr': sr,\n",
    "#                      'batch_size': batch_size,\n",
    "#                      'feature': feature,\n",
    "#                      'n_classes': 2,\n",
    "#                      'sec': sec,\n",
    "#                      'filter_scale': filter_scale,\n",
    "#                      'fmin' : fmin,\n",
    "#                      'n_bins': int(n_bins),\n",
    "#                      'tofile': tmp_string,\n",
    "#                      'shuffle': False,\n",
    "#                     'data_dir': asv2019\n",
    "#                      #'device': device\n",
    "#     }\n",
    "#     training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "#     validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "#     eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "#     input_shape = training_generator.get_input_shape()\n",
    "#     model = get_LCNN(input_shape)\n",
    "# #    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "#     EPOCHS = epoch\n",
    "#     lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "#     class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "#     history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "#                               epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "#     eer_val = evalEER(validation_generator, model)\n",
    "#     eer_eval = evalEER(eval_generator, model)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "#     savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "#     savefnm = 'saved_models/' + savefnm\n",
    "#     model.save(savefnm)\n",
    "#     endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "#     fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "#     fnm = 'saved_results/' + fnm\n",
    "#     sc1 = model.predict(eval_generator)\n",
    "#     np.save(fnm, sc1)\n",
    "#     params_save = params\n",
    "#     params_save['model'] = mname\n",
    "#     params_save['human_weight'] = str(human_weight)\n",
    "#     params_save['dropout_rate'] = str(dropout_rate)\n",
    "#     params_save['eer_val'] = str(eer_val)[:6]\n",
    "#     params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "#     params_save['saved_model'] = savefnm\n",
    "#     tnow = datetime.datetime.now()\n",
    "#     params_save['tnow'] = str(tnow)\n",
    "#     print(params_save)\n",
    "#     fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "#     with open(fnm, 'wb') as f:\n",
    "#         pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "\n",
    "\n",
    "##################################################\n",
    "mname = \"BCResMax_LA_\"\n",
    "##################################################\n",
    "\n",
    "### None\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = False\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### mixup\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### LP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "        \n",
    "### LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### HP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### HP + LP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #[2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_BCResMax(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "##################################################\n",
    "mname = \"DDWSseq_LA_\"\n",
    "##################################################\n",
    "\n",
    "### None\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = False\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### Mixup\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "### LP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP         \n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "### LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = False #[0.5, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = False #[0.5, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5#np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = False #[2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### HP + LP + RP\n",
    "for i in range(3) :\n",
    "    sr = 16000\n",
    "    sec = 9.0\n",
    "    batch_size = 16\n",
    "    feature = \"cqt\"\n",
    "    #hop_length = 128\n",
    "    #win_length = 512\n",
    "    #n_bins = 80\n",
    "    filter_scale = 1\n",
    "    n_bins = 100\n",
    "    fmin = 5\n",
    "    epoch = 70\n",
    "    beta_param = 0.7\n",
    "    dropout_rate = 0.5 #np.random.choice([0.4, 0.5, 0.6])\n",
    "    human_weight = 5.0 #np.random.choice([4.0, 5.0, 6.0])\n",
    "    win_size = np.random.choice([10,15,20])\n",
    "    if win_size == 10 :\n",
    "        lpsize = [8,9,10,11,12]\n",
    "        hpsize = [88,89,90,91,92]\n",
    "        ransize = [8,9,10,11,12]\n",
    "    elif win_size == 15 :\n",
    "        lpsize = [13,14,15,16,17]\n",
    "        hpsize = [83,84,85,86,87]\n",
    "        ransize = [13,14,15,16,17]\n",
    "    else :\n",
    "        lpsize = [18,19,20,21,22]\n",
    "        hpsize = [78,79,80,81,82]\n",
    "        ransize = [18,19,20,21,22]\n",
    "    ru = 0.5 #np.random.uniform(.1, .9)\n",
    "    uv = [ru, 1-ru]\n",
    "    lowpass = [uv, [7,8,9,10,11,12]] #np.random.choice([[uv ,lpsize], False])\n",
    "    highpass = [uv, [80,81,82,83,84,85,86,87] ] #np.random.choice([[uv, hpsize], False])\n",
    "    nm = np.random.choice([2,3,4])\n",
    "    ranfilter2 = [2, [8,9,10,11,12]] #np.random.choice([[nm, ransize], False])\n",
    "    tmp_string = \"tmp\"\n",
    "    params = {'sr': sr,\n",
    "          'batch_size': batch_size,\n",
    "          'feature': feature,\n",
    "          'n_classes': 2,\n",
    "          'sec': sec,\n",
    "          'filter_scale': filter_scale,\n",
    "          'fmin' : fmin,\n",
    "          'n_bins': int(n_bins),\n",
    "          'tofile': tmp_string,\n",
    "          'shuffle': True,\n",
    "          'beta_param': beta_param,\n",
    "          'data_dir': asv2019,\n",
    "          'lowpass': lowpass,\n",
    "          'highpass': highpass,\n",
    "          #          'ranfilter' : [10,11,12,13,14,15]\n",
    "          'ranfilter2' : ranfilter2 \n",
    "          #           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'sr': sr,\n",
    "                     'batch_size': batch_size,\n",
    "                     'feature': feature,\n",
    "                     'n_classes': 2,\n",
    "                     'sec': sec,\n",
    "                     'filter_scale': filter_scale,\n",
    "                     'fmin' : fmin,\n",
    "                     'n_bins': int(n_bins),\n",
    "                     'tofile': tmp_string,\n",
    "                     'shuffle': False,\n",
    "                    'data_dir': asv2019\n",
    "                     #'device': device\n",
    "    }\n",
    "    training_generator = DataGenerator(dl.train, dl.labels, **params)\n",
    "    validation_generator = DataGenerator(dl.dev, dl.labels, **params_no_shuffle)\n",
    "    eval_generator = DataGenerator(dl.eval, dl.labels, **params_no_shuffle)\n",
    "    input_shape = training_generator.get_input_shape()\n",
    "    model = get_DDWSseq(input_shape)\n",
    "#    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC'])\n",
    "\n",
    "    EPOCHS = epoch\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=EPOCHS))\n",
    "    class_weight = {0: human_weight, 1: 1.} ## human: 0, 1: speaker\n",
    "    history = model.fit_generator(generator=training_generator, #validation_data=track1_generator,\n",
    "                              epochs=EPOCHS, class_weight=class_weight, callbacks=[lr], verbose=1)\n",
    "    eer_val = evalEER(validation_generator, model)\n",
    "    eer_eval = evalEER(eval_generator, model)\n",
    "    endtxt1 = str(eer_val)[:6] + '.hdf5'\n",
    "    savefnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1 )\n",
    "    savefnm = 'saved_models/' + savefnm\n",
    "    model.save(savefnm)\n",
    "    endtxt1 = str(eer_val)[:6] + '.npy'\n",
    "    fnm = gen_fname(model_name = mname, params = params , dropout_rate = str(dropout_rate), human_weight = str(human_weight), endtxt = endtxt1)\n",
    "    fnm = 'saved_results/' + fnm\n",
    "    sc1 = model.predict(eval_generator)\n",
    "    np.save(fnm, sc1)\n",
    "    params_save = params\n",
    "    params_save['model'] = mname\n",
    "    params_save['human_weight'] = str(human_weight)\n",
    "    params_save['dropout_rate'] = str(dropout_rate)\n",
    "    params_save['eer_val'] = str(eer_val)[:6]\n",
    "    params_save['eer_eval'] = str(eer_eval)[:6]\n",
    "    params_save['saved_model'] = savefnm\n",
    "    tnow = datetime.datetime.now()\n",
    "    params_save['tnow'] = str(tnow)\n",
    "    print(params_save)\n",
    "    fnm = 'res_LA_DataSize_50/rec'+str(tnow) + '.pickle'\n",
    "    with open(fnm, 'wb') as f:\n",
    "        pickle.dump(params_save, fget_BCResMax, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfdb7eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7232c9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2.4_p37)",
   "language": "python",
   "name": "conda_tensorflow2.4_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
